{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"YAML structure","text":""},{"location":"#geniusrise-documentation","title":"Geniusrise Documentation","text":""},{"location":"#about","title":"About","text":"<p>Geniusrise is a modular, loosely-coupled MLOps framework designed for the era of Large Language Models, offering flexibility, inclusivity, and standardization. It seamlessly integrates tasks, state management, data handling, and model versioning, all while supporting diverse infrastructures and user expertise levels. With its plug-and-play architecture, Geniusrise empowers teams to build, share, and deploy ML workflows across various platforms efficiently.</p>"},{"location":"#guides","title":"Guides","text":""},{"location":"#getting-started","title":"Getting started","text":"<ol> <li>Home: Front page</li> <li>Concepts: Concepts of the framework, start here</li> <li>Architecture: Design and architecture of the framework</li> <li>Installation: Installation and setup</li> </ol>"},{"location":"#development","title":"Development","text":"<ol> <li>Local experimentation: Local setup and project creation.</li> <li>Packaging: Packaging your application</li> <li>Staged deployment: Deploying parts or whole of your application</li> <li>Workflow ops: Operations and management of workflows</li> <li>Data ops: Operations and management of data</li> <li>Model ops: Operations and management of models</li> </ol>"},{"location":"#deployment","title":"Deployment","text":"<ol> <li>Kubernetes: Running geniusrise on kubernetes</li> <li>Apache Airflow: Orchestrating batch jobs on Apache Airflow</li> <li>Apache Spark: Using geniusrise as a spark library</li> <li>Apache Flink: Using geniusrise as a flink library</li> <li>Apache Beam: Using geniusrise as a beam library</li> <li>Apache Storm: Using geniusrise as a storm library</li> <li>AWS ECS: Running geniusrise on AWS ECS</li> <li>AWS Batch: Running geniusrise batch jobs on AWS Batch</li> </ol>"},{"location":"#reference","title":"Reference","text":"<ol> <li>YAML structure: Geniusfile structure and configuration</li> <li>Community Plugins: Building and shipping community plugins (spouts and bolts)</li> <li>Project templates: Project templates for community plugins</li> </ol>"},{"location":"#examples","title":"Examples","text":"<ol> <li>Write a confluence PRD and have jira and github issues created and linked automatically</li> <li>Monitor, alert and summarize machinery metrics in a process industry</li> <li>Read news and stock market tickers to generate buy and sell alerts</li> <li>Read infosec logs generated by various services and decide whether to generate an alert</li> <li>Batch or streaming fine-tuning and managing a huggingface-hosted model</li> <li>Batch or streaming fine-tuning and managing an openAI model</li> </ol>"},{"location":"#library-reference","title":"Library Reference","text":"<ul> <li>geniusrise.cli:<ul> <li>geniusctl: The main command line application</li> <li>yamlctl: Control spouts and bolts defined in a YAML file</li> <li>boltctl: The main bolt controller</li> <li>spoutctl: The main spout controller</li> <li>schema: YAML schema definition as pydantic</li> <li>discover: Module discovery</li> </ul> </li> <li>geniusrise.core:<ul> <li>bolt: Core Bolt class</li> <li>spout: Core Spout class</li> <li>geniusrise.core.data:<ul> <li>batch_input: Batch input manager</li> <li>batch_output: Batch output manager</li> <li>input: Input manager base class</li> <li>output: Output manager base class</li> <li>streaming_input: Streaming input manager</li> <li>streaming_output: Streaming output manager</li> </ul> </li> <li>geniusrise.core.state:<ul> <li>base: Base class for task state mnager</li> <li>dynamo: State manager using dynamoDB</li> <li>memory: State manager using local memory</li> <li>postgres: State manager using postgres database</li> <li>redis: State manager using redis</li> </ul> </li> <li>geniusrise.core.task:<ul> <li>base: Base class for Task</li> </ul> </li> <li>geniusrise.runners:<ul> <li>ecs: Runner class using AWS ECS</li> <li>k8s: Runner class using kubernetes</li> </ul> </li> </ul> </li> </ul>"},{"location":"core/cli_boltctl/","title":"Boltctl","text":"<p>The main bolt controller</p>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl","title":"<code>BoltCtl</code>","text":"<p>Class for managing bolts end-to-end from the command line.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>class BoltCtl:\n\"\"\"\n    Class for managing bolts end-to-end from the command line.\n    \"\"\"\ndef __init__(self, discovered_bolt: DiscoveredBolt):\n\"\"\"\n        Initialize BoltCtl with a DiscoveredBolt object.\n        Args:\n            discovered_bolt (DiscoveredBolt): DiscoveredBolt object used to create and manage bolts.\n        \"\"\"\nself.discovered_bolt = discovered_bolt\nself.bolt = None\nself.log = logging.getLogger(self.__class__.__name__)\ndef create_parser(self, parser):\n\"\"\"\n        Add arguments to the command-line parser for managing the bolt.\n        Args:\n            parser (argparse.ArgumentParser): Command-line parser.\n        \"\"\"\nsubparsers = parser.add_subparsers(dest=\"command\")\n# Create subparser for 'run' command\nrun_parser = subparsers.add_parser(\"rise\", help=\"Run a bolt locally.\")\nrun_parser.add_argument(\n\"input_type\",\nchoices=[\"batch\", \"streaming\"],\nhelp=\"Choose the type of input configuration: batch or streaming.\",\ndefault=\"batch\",\n)\nrun_parser.add_argument(\n\"output_type\",\nchoices=[\"batch\", \"streaming\"],\nhelp=\"Choose the type of output configuration: batch or streaming.\",\ndefault=\"batch\",\n)\nrun_parser.add_argument(\n\"state_type\",\nchoices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"],\nhelp=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\",\ndefault=\"in_memory\",\n)\nrun_parser.add_argument(\n\"--input_folder\",\nhelp=\"Specify the directory where output files should be stored temporarily.\",\ndefault=\"/tmp\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--input_kafka_topic\",\nhelp=\"Kafka output topic for streaming spouts.\",\ndefault=\"test\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--input_kafka_cluster_connection_string\",\nhelp=\"Kafka connection string for streaming spouts.\",\ndefault=\"localhost:9092\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--input_s3_bucket\",\nhelp=\"Provide the name of the S3 bucket for output storage.\",\ndefault=\"my-bucket\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--input_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n)\nrun_parser.add_argument(\n\"--output_folder\",\nhelp=\"Specify the directory where output files should be stored temporarily.\",\ndefault=\"/tmp\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--output_kafka_topic\",\nhelp=\"Kafka output topic for streaming spouts.\",\ndefault=\"test\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--output_kafka_cluster_connection_string\",\nhelp=\"Kafka connection string for streaming spouts.\",\ndefault=\"localhost:9092\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--output_s3_bucket\",\nhelp=\"Provide the name of the S3 bucket for output storage.\",\ndefault=\"my-bucket\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n)\nrun_parser.add_argument(\n\"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str\n)\nrun_parser.add_argument(\n\"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int\n)\nrun_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int)\nrun_parser.add_argument(\n\"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str\n)\nrun_parser.add_argument(\n\"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int\n)\nrun_parser.add_argument(\n\"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str\n)\nrun_parser.add_argument(\n\"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str\n)\nrun_parser.add_argument(\n\"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str\n)\nrun_parser.add_argument(\n\"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str\n)\nrun_parser.add_argument(\n\"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str\n)\nrun_parser.add_argument(\n\"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str\n)\nrun_parser.add_argument(\n\"method_name\",\nhelp=\"The name of the method to execute on the bolt.\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--args\",\nnargs=argparse.REMAINDER,\nhelp=\"Additional keyword arguments to pass to the bolt.\",\n)\n# Create subparser for 'help' command\nhelp_parser = subparsers.add_parser(\"help\", help=\"Print help for the bolt.\")\nhelp_parser.add_argument(\"method\", help=\"The method to execute.\")\nreturn parser\ndef run(self, args):\n\"\"\"\n        Run the command-line interface.\n        Args:\n            args (argparse.Namespace): Parsed command-line arguments.\n        \"\"\"\nself.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\"))\ntry:\nif args.command == \"rise\":\nkwargs = {\nk: v\nfor k, v in vars(args).items()\nif v is not None and k not in [\"input_type\", \"output_type\", \"state_type\", \"args\", \"method_name\"]\n}\nother = args.args or []\nother_args, other_kwargs = self.parse_args_kwargs(other)\nself.bolt = self.create_bolt(args.input_type, args.output_type, args.state_type, **kwargs)\n# Pass the method_name from args to execute_bolt\nresult = self.execute_bolt(self.bolt, args.method_name, *other_args, **other_kwargs)\nself.log.info(emoji.emojize(f\"Successfully executed the bolt method: {args.method_name} :thumbs_up:\"))\nreturn result\nelif args.command == \"help\":\nself.discovered_bolt.klass.print_help(self.discovered_bolt.klass)\nexcept ValueError as ve:\nself.log.exception(f\"Value error: {ve}\")\nraise\nexcept AttributeError as ae:\nself.log.exception(f\"Attribute error: {ae}\")\nraise\nexcept KeyError as ke:\nself.log.exception(f\"Missing key: {ke}\")\nraise\nexcept Exception as e:\nself.log.exception(f\"An unexpected error occurred: {e}\")\nraise\n@staticmethod\ndef parse_args_kwargs(args_list):\nargs = []\nkwargs = {}\ndef convert(value):\ntry:\nreturn int(value)\nexcept ValueError:\ntry:\nreturn float(value)\nexcept ValueError:\nreturn value\nfor item in args_list:\nif \"=\" in item:\nkey, value = item.split(\"=\", 1)\nkwargs[key] = convert(value)\nelse:\nargs.append(convert(item))\nreturn args, kwargs\ndef create_bolt(self, input_type: str, output_type: str, state_type: str, **kwargs) -&gt; Bolt:\n\"\"\"\n        Create a bolt of a specific type.\n        Args:\n            input_type (str): The type of input config (\"batch\" or \"streaming\").\n            output_type (str): The type of output config (\"batch\" or \"streaming\").\n            state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n            **kwargs: Additional keyword arguments for initializing the bolt.\n                Keyword Arguments:\n                    Batch input config:\n                    - input_folder (str): The input folder argument.\n                    - input_s3_bucket (str): The input bucket argument.\n                    - input_s3_folder (str): The input S3 folder argument.\n                    Batch outupt config:\n                    - output_folder (str): The output folder argument.\n                    - output_s3_bucket (str): The output bucket argument.\n                    - output_s3_folder (str): The output S3 folder argument.\n                    Streaming input config:\n                    - input_kafka_cluster_connection_string (str): The input Kafka servers argument.\n                    - input_kafka_topic (str): The input kafka topic argument.\n                    - input_kafka_consumer_group_id (str): The Kafka consumer group id.\n                    Streaming output config:\n                    - output_kafka_cluster_connection_string (str): The output Kafka servers argument.\n                    - output_kafka_topic (str): The output kafka topic argument.\n                    Redis state manager config:\n                    - redis_host (str): The Redis host argument.\n                    - redis_port (str): The Redis port argument.\n                    - redis_db (str): The Redis database argument.\n                    Postgres state manager config:\n                    - postgres_host (str): The PostgreSQL host argument.\n                    - postgres_port (str): The PostgreSQL port argument.\n                    - postgres_user (str): The PostgreSQL user argument.\n                    - postgres_password (str): The PostgreSQL password argument.\n                    - postgres_database (str): The PostgreSQL database argument.\n                    - postgres_table (str): The PostgreSQL table argument.\n                    DynamoDB state manager config:\n                    - dynamodb_table_name (str): The DynamoDB table name argument.\n                    - dynamodb_region_name (str): The DynamoDB region name argument.\n        Returns:\n            Bolt: The created bolt.\n        \"\"\"\nreturn Bolt.create(\nklass=self.discovered_bolt.klass,\ninput_type=input_type,\noutput_type=output_type,\nstate_type=state_type,\n**kwargs,\n)\ndef execute_bolt(self, bolt: Bolt, method_name: str, *args, **kwargs):\n\"\"\"\n        Execute a method of a bolt.\n        Args:\n            bolt (Bolt): The bolt to execute.\n            method_name (str): The name of the method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n        Returns:\n            Any: The result of the method.\n        \"\"\"\nreturn bolt.__call__(method_name, *args, **kwargs)\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.__init__","title":"<code>__init__(discovered_bolt)</code>","text":"<p>Initialize BoltCtl with a DiscoveredBolt object.</p> <p>Parameters:</p> Name Type Description Default <code>discovered_bolt</code> <code>DiscoveredBolt</code> <p>DiscoveredBolt object used to create and manage bolts.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def __init__(self, discovered_bolt: DiscoveredBolt):\n\"\"\"\n    Initialize BoltCtl with a DiscoveredBolt object.\n    Args:\n        discovered_bolt (DiscoveredBolt): DiscoveredBolt object used to create and manage bolts.\n    \"\"\"\nself.discovered_bolt = discovered_bolt\nself.bolt = None\nself.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.create_bolt","title":"<code>create_bolt(input_type, output_type, state_type, **kwargs)</code>","text":"<p>Create a bolt of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>input_type</code> <code>str</code> <p>The type of input config (\"batch\" or \"streaming\").</p> required <code>output_type</code> <code>str</code> <p>The type of output config (\"batch\" or \"streaming\").</p> required <code>state_type</code> <code>str</code> <p>The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").</p> required <code>**kwargs</code> <p>Additional keyword arguments for initializing the bolt. Keyword Arguments:     Batch input config:     - input_folder (str): The input folder argument.     - input_s3_bucket (str): The input bucket argument.     - input_s3_folder (str): The input S3 folder argument.     Batch outupt config:     - output_folder (str): The output folder argument.     - output_s3_bucket (str): The output bucket argument.     - output_s3_folder (str): The output S3 folder argument.     Streaming input config:     - input_kafka_cluster_connection_string (str): The input Kafka servers argument.     - input_kafka_topic (str): The input kafka topic argument.     - input_kafka_consumer_group_id (str): The Kafka consumer group id.     Streaming output config:     - output_kafka_cluster_connection_string (str): The output Kafka servers argument.     - output_kafka_topic (str): The output kafka topic argument.     Redis state manager config:     - redis_host (str): The Redis host argument.     - redis_port (str): The Redis port argument.     - redis_db (str): The Redis database argument.     Postgres state manager config:     - postgres_host (str): The PostgreSQL host argument.     - postgres_port (str): The PostgreSQL port argument.     - postgres_user (str): The PostgreSQL user argument.     - postgres_password (str): The PostgreSQL password argument.     - postgres_database (str): The PostgreSQL database argument.     - postgres_table (str): The PostgreSQL table argument.     DynamoDB state manager config:     - dynamodb_table_name (str): The DynamoDB table name argument.     - dynamodb_region_name (str): The DynamoDB region name argument.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Bolt</code> <code>Bolt</code> <p>The created bolt.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def create_bolt(self, input_type: str, output_type: str, state_type: str, **kwargs) -&gt; Bolt:\n\"\"\"\n    Create a bolt of a specific type.\n    Args:\n        input_type (str): The type of input config (\"batch\" or \"streaming\").\n        output_type (str): The type of output config (\"batch\" or \"streaming\").\n        state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n        **kwargs: Additional keyword arguments for initializing the bolt.\n            Keyword Arguments:\n                Batch input config:\n                - input_folder (str): The input folder argument.\n                - input_s3_bucket (str): The input bucket argument.\n                - input_s3_folder (str): The input S3 folder argument.\n                Batch outupt config:\n                - output_folder (str): The output folder argument.\n                - output_s3_bucket (str): The output bucket argument.\n                - output_s3_folder (str): The output S3 folder argument.\n                Streaming input config:\n                - input_kafka_cluster_connection_string (str): The input Kafka servers argument.\n                - input_kafka_topic (str): The input kafka topic argument.\n                - input_kafka_consumer_group_id (str): The Kafka consumer group id.\n                Streaming output config:\n                - output_kafka_cluster_connection_string (str): The output Kafka servers argument.\n                - output_kafka_topic (str): The output kafka topic argument.\n                Redis state manager config:\n                - redis_host (str): The Redis host argument.\n                - redis_port (str): The Redis port argument.\n                - redis_db (str): The Redis database argument.\n                Postgres state manager config:\n                - postgres_host (str): The PostgreSQL host argument.\n                - postgres_port (str): The PostgreSQL port argument.\n                - postgres_user (str): The PostgreSQL user argument.\n                - postgres_password (str): The PostgreSQL password argument.\n                - postgres_database (str): The PostgreSQL database argument.\n                - postgres_table (str): The PostgreSQL table argument.\n                DynamoDB state manager config:\n                - dynamodb_table_name (str): The DynamoDB table name argument.\n                - dynamodb_region_name (str): The DynamoDB region name argument.\n    Returns:\n        Bolt: The created bolt.\n    \"\"\"\nreturn Bolt.create(\nklass=self.discovered_bolt.klass,\ninput_type=input_type,\noutput_type=output_type,\nstate_type=state_type,\n**kwargs,\n)\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.create_parser","title":"<code>create_parser(parser)</code>","text":"<p>Add arguments to the command-line parser for managing the bolt.</p> <p>Parameters:</p> Name Type Description Default <code>parser</code> <code>argparse.ArgumentParser</code> <p>Command-line parser.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def create_parser(self, parser):\n\"\"\"\n    Add arguments to the command-line parser for managing the bolt.\n    Args:\n        parser (argparse.ArgumentParser): Command-line parser.\n    \"\"\"\nsubparsers = parser.add_subparsers(dest=\"command\")\n# Create subparser for 'run' command\nrun_parser = subparsers.add_parser(\"rise\", help=\"Run a bolt locally.\")\nrun_parser.add_argument(\n\"input_type\",\nchoices=[\"batch\", \"streaming\"],\nhelp=\"Choose the type of input configuration: batch or streaming.\",\ndefault=\"batch\",\n)\nrun_parser.add_argument(\n\"output_type\",\nchoices=[\"batch\", \"streaming\"],\nhelp=\"Choose the type of output configuration: batch or streaming.\",\ndefault=\"batch\",\n)\nrun_parser.add_argument(\n\"state_type\",\nchoices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"],\nhelp=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\",\ndefault=\"in_memory\",\n)\nrun_parser.add_argument(\n\"--input_folder\",\nhelp=\"Specify the directory where output files should be stored temporarily.\",\ndefault=\"/tmp\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--input_kafka_topic\",\nhelp=\"Kafka output topic for streaming spouts.\",\ndefault=\"test\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--input_kafka_cluster_connection_string\",\nhelp=\"Kafka connection string for streaming spouts.\",\ndefault=\"localhost:9092\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--input_s3_bucket\",\nhelp=\"Provide the name of the S3 bucket for output storage.\",\ndefault=\"my-bucket\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--input_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n)\nrun_parser.add_argument(\n\"--output_folder\",\nhelp=\"Specify the directory where output files should be stored temporarily.\",\ndefault=\"/tmp\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--output_kafka_topic\",\nhelp=\"Kafka output topic for streaming spouts.\",\ndefault=\"test\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--output_kafka_cluster_connection_string\",\nhelp=\"Kafka connection string for streaming spouts.\",\ndefault=\"localhost:9092\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--output_s3_bucket\",\nhelp=\"Provide the name of the S3 bucket for output storage.\",\ndefault=\"my-bucket\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n)\nrun_parser.add_argument(\n\"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str\n)\nrun_parser.add_argument(\n\"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int\n)\nrun_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int)\nrun_parser.add_argument(\n\"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str\n)\nrun_parser.add_argument(\n\"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int\n)\nrun_parser.add_argument(\n\"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str\n)\nrun_parser.add_argument(\n\"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str\n)\nrun_parser.add_argument(\n\"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str\n)\nrun_parser.add_argument(\n\"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str\n)\nrun_parser.add_argument(\n\"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str\n)\nrun_parser.add_argument(\n\"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str\n)\nrun_parser.add_argument(\n\"method_name\",\nhelp=\"The name of the method to execute on the bolt.\",\ntype=str,\n)\nrun_parser.add_argument(\n\"--args\",\nnargs=argparse.REMAINDER,\nhelp=\"Additional keyword arguments to pass to the bolt.\",\n)\n# Create subparser for 'help' command\nhelp_parser = subparsers.add_parser(\"help\", help=\"Print help for the bolt.\")\nhelp_parser.add_argument(\"method\", help=\"The method to execute.\")\nreturn parser\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.execute_bolt","title":"<code>execute_bolt(bolt, method_name, *args, **kwargs)</code>","text":"<p>Execute a method of a bolt.</p> <p>Parameters:</p> Name Type Description Default <code>bolt</code> <code>Bolt</code> <p>The bolt to execute.</p> required <code>method_name</code> <code>str</code> <p>The name of the method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>The result of the method.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def execute_bolt(self, bolt: Bolt, method_name: str, *args, **kwargs):\n\"\"\"\n    Execute a method of a bolt.\n    Args:\n        bolt (Bolt): The bolt to execute.\n        method_name (str): The name of the method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n    Returns:\n        Any: The result of the method.\n    \"\"\"\nreturn bolt.__call__(method_name, *args, **kwargs)\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.run","title":"<code>run(args)</code>","text":"<p>Run the command-line interface.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>argparse.Namespace</code> <p>Parsed command-line arguments.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def run(self, args):\n\"\"\"\n    Run the command-line interface.\n    Args:\n        args (argparse.Namespace): Parsed command-line arguments.\n    \"\"\"\nself.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\"))\ntry:\nif args.command == \"rise\":\nkwargs = {\nk: v\nfor k, v in vars(args).items()\nif v is not None and k not in [\"input_type\", \"output_type\", \"state_type\", \"args\", \"method_name\"]\n}\nother = args.args or []\nother_args, other_kwargs = self.parse_args_kwargs(other)\nself.bolt = self.create_bolt(args.input_type, args.output_type, args.state_type, **kwargs)\n# Pass the method_name from args to execute_bolt\nresult = self.execute_bolt(self.bolt, args.method_name, *other_args, **other_kwargs)\nself.log.info(emoji.emojize(f\"Successfully executed the bolt method: {args.method_name} :thumbs_up:\"))\nreturn result\nelif args.command == \"help\":\nself.discovered_bolt.klass.print_help(self.discovered_bolt.klass)\nexcept ValueError as ve:\nself.log.exception(f\"Value error: {ve}\")\nraise\nexcept AttributeError as ae:\nself.log.exception(f\"Attribute error: {ae}\")\nraise\nexcept KeyError as ke:\nself.log.exception(f\"Missing key: {ke}\")\nraise\nexcept Exception as e:\nself.log.exception(f\"An unexpected error occurred: {e}\")\nraise\n</code></pre>"},{"location":"core/cli_discover/","title":"Discover","text":"<p>Module discovery</p>"},{"location":"core/cli_discover/#cli.discover.Discover","title":"<code>Discover</code>","text":"Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>class Discover:\ndef __init__(self, directory: Optional[str] = None):\n\"\"\"Initialize the Discover class.\"\"\"\nself.classes: Dict[str, Any] = {}\nself.log = logging.getLogger(self.__class__.__name__)\nself.directory = directory\ndef scan_directory(self, directory: Optional[str] = None) -&gt; Dict[str, Any]:\n\"\"\"\n        Scan for spouts/bolts in installed extensions and user's codebase.\n        Args:\n            directory (Optional[str]): Directory to scan for user-defined spouts/bolts.\n        Returns:\n            Dict[str, Any]: Discovered spouts/bolts.\n        \"\"\"\ndirectory = directory if directory else self.directory\nself.log.info(emoji.emojize(\"\ud83d\udd0d Starting discovery...\"))\n# Discover installed extensions\nself.discover_installed_extensions()\n# Discover user-defined spouts/bolts\nif directory:\nself.directory = directory\nfor root, _, files in os.walk(self.directory):\nif \"__init__.py\" in files:\nmodule = self.import_module(root)\nself.find_classes(module)\nreturn self.classes\ndef discover_installed_extensions(self):\n\"\"\"Discover installed geniusrise extensions.\"\"\"\nself.log.info(emoji.emojize(\"\ud83d\udd0e Discovering installed extensions...\"))\nfor entry_point in pkg_resources.iter_entry_points(group=\"geniusrise.extensions\"):\ntry:\nmodule = entry_point.load()\nself.find_classes(module)\nexcept Exception as e:\nself.log.error(emoji.emojize(f\"\u274c Error discovering classes in {entry_point.name}: {e}\"))\ndef import_module(self, path: str):\n\"\"\"\n        Import a module given its path.\n        Args:\n            path (str): Path to the module.\n        Returns:\n            Any: Imported module.\n        \"\"\"\nproject_root = os.path.abspath(os.path.join(self.directory, \"../../../../\"))  # type: ignore\nrelative_path = os.path.relpath(path, project_root)\nmodule_path = relative_path.replace(os.sep, \".\")\nif module_path.endswith(\"__init__\"):\nmodule_path = module_path[:-9]  # remove trailing '__init__'\nself.log.info(emoji.emojize(f\"\ud83d\udce6 Importing module {module_path}...\"))\nmodule = importlib.import_module(module_path)\nreturn module\ndef find_classes(self, module: Any):\n\"\"\"\n        Discover spout/bolt classes in a module.\n        Args:\n            module (Any): Module to scan for spout/bolt classes.\n        \"\"\"\nfor name, obj in inspect.getmembers(module):\ndiscovered: DiscoveredSpout | DiscoveredBolt\nif inspect.isclass(obj) and issubclass(obj, Spout) and obj != Spout:\ndiscovered = DiscoveredSpout(name=name, klass=obj, init_args=self.get_init_args(obj))\nself.log.info(emoji.emojize(f\"\ud83d\ude80 Discovered Spout {discovered.name}\"))\nself.classes[name] = discovered\nelif inspect.isclass(obj) and issubclass(obj, Bolt) and obj != Bolt:\ndiscovered = DiscoveredBolt(name=name, klass=obj, init_args=self.get_init_args(obj))\nself.log.info(emoji.emojize(f\"\u26a1 Discovered Bolt {discovered.name}\"))\nself.classes[name] = discovered\ndef get_init_args(self, cls: type) -&gt; Dict[str, Any]:\n\"\"\"\n        Extract initialization arguments of a class.\n        Args:\n            cls (type): Class to extract initialization arguments from.\n        Returns:\n            Dict[str, Any]: Initialization arguments.\n        \"\"\"\ninit_signature = inspect.signature(cls.__init__)  # type: ignore\ninit_params = init_signature.parameters\ninit_args = {}\nfor name, kind in init_params.items():\nif name == \"self\":\ncontinue\nif name == \"kwargs\" or name == \"args\":\ninit_args[\"kwargs\"] = Any\ncontinue\nif isinstance(kind.annotation, ABCMeta):\ninit_args[name] = self.get_init_args(kind.annotation)\nelif kind.annotation == inspect.Parameter.empty:\ninit_args[name] = \"No type hint provided \ud83d\ude22\"\nelse:\ninit_args[name] = kind.annotation\nreturn init_args\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.__init__","title":"<code>__init__(directory=None)</code>","text":"<p>Initialize the Discover class.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def __init__(self, directory: Optional[str] = None):\n\"\"\"Initialize the Discover class.\"\"\"\nself.classes: Dict[str, Any] = {}\nself.log = logging.getLogger(self.__class__.__name__)\nself.directory = directory\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.discover_installed_extensions","title":"<code>discover_installed_extensions()</code>","text":"<p>Discover installed geniusrise extensions.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def discover_installed_extensions(self):\n\"\"\"Discover installed geniusrise extensions.\"\"\"\nself.log.info(emoji.emojize(\"\ud83d\udd0e Discovering installed extensions...\"))\nfor entry_point in pkg_resources.iter_entry_points(group=\"geniusrise.extensions\"):\ntry:\nmodule = entry_point.load()\nself.find_classes(module)\nexcept Exception as e:\nself.log.error(emoji.emojize(f\"\u274c Error discovering classes in {entry_point.name}: {e}\"))\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.find_classes","title":"<code>find_classes(module)</code>","text":"<p>Discover spout/bolt classes in a module.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Any</code> <p>Module to scan for spout/bolt classes.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def find_classes(self, module: Any):\n\"\"\"\n    Discover spout/bolt classes in a module.\n    Args:\n        module (Any): Module to scan for spout/bolt classes.\n    \"\"\"\nfor name, obj in inspect.getmembers(module):\ndiscovered: DiscoveredSpout | DiscoveredBolt\nif inspect.isclass(obj) and issubclass(obj, Spout) and obj != Spout:\ndiscovered = DiscoveredSpout(name=name, klass=obj, init_args=self.get_init_args(obj))\nself.log.info(emoji.emojize(f\"\ud83d\ude80 Discovered Spout {discovered.name}\"))\nself.classes[name] = discovered\nelif inspect.isclass(obj) and issubclass(obj, Bolt) and obj != Bolt:\ndiscovered = DiscoveredBolt(name=name, klass=obj, init_args=self.get_init_args(obj))\nself.log.info(emoji.emojize(f\"\u26a1 Discovered Bolt {discovered.name}\"))\nself.classes[name] = discovered\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.get_init_args","title":"<code>get_init_args(cls)</code>","text":"<p>Extract initialization arguments of a class.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>type</code> <p>Class to extract initialization arguments from.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Initialization arguments.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def get_init_args(self, cls: type) -&gt; Dict[str, Any]:\n\"\"\"\n    Extract initialization arguments of a class.\n    Args:\n        cls (type): Class to extract initialization arguments from.\n    Returns:\n        Dict[str, Any]: Initialization arguments.\n    \"\"\"\ninit_signature = inspect.signature(cls.__init__)  # type: ignore\ninit_params = init_signature.parameters\ninit_args = {}\nfor name, kind in init_params.items():\nif name == \"self\":\ncontinue\nif name == \"kwargs\" or name == \"args\":\ninit_args[\"kwargs\"] = Any\ncontinue\nif isinstance(kind.annotation, ABCMeta):\ninit_args[name] = self.get_init_args(kind.annotation)\nelif kind.annotation == inspect.Parameter.empty:\ninit_args[name] = \"No type hint provided \ud83d\ude22\"\nelse:\ninit_args[name] = kind.annotation\nreturn init_args\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.import_module","title":"<code>import_module(path)</code>","text":"<p>Import a module given its path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the module.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Imported module.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def import_module(self, path: str):\n\"\"\"\n    Import a module given its path.\n    Args:\n        path (str): Path to the module.\n    Returns:\n        Any: Imported module.\n    \"\"\"\nproject_root = os.path.abspath(os.path.join(self.directory, \"../../../../\"))  # type: ignore\nrelative_path = os.path.relpath(path, project_root)\nmodule_path = relative_path.replace(os.sep, \".\")\nif module_path.endswith(\"__init__\"):\nmodule_path = module_path[:-9]  # remove trailing '__init__'\nself.log.info(emoji.emojize(f\"\ud83d\udce6 Importing module {module_path}...\"))\nmodule = importlib.import_module(module_path)\nreturn module\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.scan_directory","title":"<code>scan_directory(directory=None)</code>","text":"<p>Scan for spouts/bolts in installed extensions and user's codebase.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Optional[str]</code> <p>Directory to scan for user-defined spouts/bolts.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Discovered spouts/bolts.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def scan_directory(self, directory: Optional[str] = None) -&gt; Dict[str, Any]:\n\"\"\"\n    Scan for spouts/bolts in installed extensions and user's codebase.\n    Args:\n        directory (Optional[str]): Directory to scan for user-defined spouts/bolts.\n    Returns:\n        Dict[str, Any]: Discovered spouts/bolts.\n    \"\"\"\ndirectory = directory if directory else self.directory\nself.log.info(emoji.emojize(\"\ud83d\udd0d Starting discovery...\"))\n# Discover installed extensions\nself.discover_installed_extensions()\n# Discover user-defined spouts/bolts\nif directory:\nself.directory = directory\nfor root, _, files in os.walk(self.directory):\nif \"__init__.py\" in files:\nmodule = self.import_module(root)\nself.find_classes(module)\nreturn self.classes\n</code></pre>"},{"location":"core/cli_geniusctl/","title":"Geniusctl","text":"<p>The main command line application</p>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl","title":"<code>GeniusCtl</code>","text":"<p>Main class for managing the geniusrise CLI application.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>class GeniusCtl:\n\"\"\"\n    Main class for managing the geniusrise CLI application.\n    \"\"\"\ndef __init__(self):\n\"\"\"\n        Initialize GeniusCtl.\n        Args:\n            directory (str): The directory to scan for spouts and bolts.\n        \"\"\"\nself.log = logging.getLogger(self.__class__.__name__)\nself.spout_ctls: Dict[str, SpoutCtl] = {}\nself.bolt_ctls: Dict[str, BoltCtl] = {}\ndef create_parser(self):\n\"\"\"\n        Create a command-line parser with arguments for managing the application.\n        Returns:\n            argparse.ArgumentParser: Command-line parser.\n        \"\"\"\nparser = argparse.ArgumentParser(description=\"Manage the geniusrise application.\")\nsubparsers = parser.add_subparsers(dest=\"command\")\n# Create subparser for each discovered spout\nfor spout_name, discovered_spout in self.spouts.items():\nspout_parser = subparsers.add_parser(spout_name, help=f\"Manage {spout_name}.\")\nspout_ctl = SpoutCtl(discovered_spout)\nself.spout_ctls[spout_name] = spout_ctl\nspout_ctl.create_parser(spout_parser)\n# Create subparser for each discovered bolt\nfor bolt_name, discovered_bolt in self.bolts.items():\nbolt_parser = subparsers.add_parser(bolt_name, help=f\"Manage {bolt_name}.\")\nbolt_ctl = BoltCtl(discovered_bolt)\nself.bolt_ctls[bolt_name] = bolt_ctl\nbolt_ctl.create_parser(bolt_parser)\n# Create subparser for YAML operations\nyaml_parser = subparsers.add_parser(\"yaml\", help=\"Control spouts and bolts with a YAML file.\")\n# Initialize YamlCtl with both spout_ctls and bolt_ctls\nself.yaml_ctl = YamlCtl(self.spout_ctls, self.bolt_ctls)\nself.yaml_ctl.create_parser(yaml_parser)\n# Add a 'help' command to print help for all spouts and bolts\nhelp_parser = subparsers.add_parser(\"plugins\", help=\"Print help for all spouts and bolts.\")\nhelp_parser.add_argument(\"spout_or_bolt\", nargs=\"?\", help=\"The spout or bolt to print help for.\")\n# Add a 'list' command to list all discovered spouts and bolts\nlist_parser = subparsers.add_parser(\"list\", help=\"List all discovered spouts and bolts.\")\nreturn parser\ndef run(self, args):\n\"\"\"\n        Run the command-line interface.\n        Args:\n            args (argparse.Namespace): Parsed command-line arguments.\n        \"\"\"\nself.log.info(f\"Running command: {args.command}\")\nself.discover = Discover()\ndiscovered_components = self.discover.scan_directory(os.getenv(\"GENIUS_COMPONENTS_DIR\", \".\"))\n# Segregate the discovered components based on their type\nself.spouts = {\nname: component\nfor name, component in discovered_components.items()\nif isinstance(component, DiscoveredSpout)\n}\nself.bolts = {\nname: component\nfor name, component in discovered_components.items()\nif isinstance(component, DiscoveredBolt)\n}\nif args.command in self.spouts:\nself.spout_ctls[args.command].run(args)\nelif args.command in self.bolts:\nself.bolt_ctls[args.command].run(args)\nelif args.command == \"yaml\":\nself.yaml_ctl.run(args)\nelif args.command == \"plugins\":\nif args.spout_or_bolt in self.spouts:\nself.spout_ctls[args.spout_or_bolt].run(args)\nelif args.spout_or_bolt in self.bolts:\nself.bolt_ctls[args.spout_or_bolt].run(args)\nelse:\nfor spout_ctl in self.spout_ctls.values():\nspout_ctl.run(args)\nfor bolt_ctl in self.bolt_ctls.values():\nbolt_ctl.run(args)\nelif args.command == \"list\":\nif len(self.spout.keys()) == 0:\nprint(\"No spouts or bolts discovered.\")\nself.list_spouts_and_bolts()\ndef list_spouts_and_bolts(self):\n\"\"\"\n        List all discovered spouts and bolts in a table.\n        \"\"\"\ntable = PrettyTable(\n[colored(\"Name\", \"green\"), colored(\"Type\", \"green\"), colored(\"Methods\", \"green\")], align=\"l\"\n)\nfor spout_name in self.spouts.keys():\ns = self.spouts[spout_name].klass\ntable.add_row(\n[\ncolored(spout_name, \"yellow\"),\ncolored(\"Spout\", \"cyan\"),\n\"\\n\".join([x for x in dir(s) if \"fetch_\" in x]),\n],\ndivider=True,\n)\nfor bolt_name in self.bolts.keys():\nb = self.bolts[bolt_name].klass\ntable.add_row(\n[\ncolored(bolt_name, \"yellow\"),\ncolored(\"Bolt\", \"magenta\"),\n\"\\n\".join([x for x in dir(b) if not x.startswith(\"_\")]),\n],\ndivider=True,\n)\nprint(table)\ndef cli(self):\n\"\"\"\n        Main function to be called when geniusrise is run from the command line.\n        \"\"\"\nparser = self.create_parser()\nargs = parser.parse_args()\nreturn self.run(args)\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.__init__","title":"<code>__init__()</code>","text":"<p>Initialize GeniusCtl.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>The directory to scan for spouts and bolts.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def __init__(self):\n\"\"\"\n    Initialize GeniusCtl.\n    Args:\n        directory (str): The directory to scan for spouts and bolts.\n    \"\"\"\nself.log = logging.getLogger(self.__class__.__name__)\nself.spout_ctls: Dict[str, SpoutCtl] = {}\nself.bolt_ctls: Dict[str, BoltCtl] = {}\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.cli","title":"<code>cli()</code>","text":"<p>Main function to be called when geniusrise is run from the command line.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def cli(self):\n\"\"\"\n    Main function to be called when geniusrise is run from the command line.\n    \"\"\"\nparser = self.create_parser()\nargs = parser.parse_args()\nreturn self.run(args)\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.create_parser","title":"<code>create_parser()</code>","text":"<p>Create a command-line parser with arguments for managing the application.</p> <p>Returns:</p> Type Description <p>argparse.ArgumentParser: Command-line parser.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def create_parser(self):\n\"\"\"\n    Create a command-line parser with arguments for managing the application.\n    Returns:\n        argparse.ArgumentParser: Command-line parser.\n    \"\"\"\nparser = argparse.ArgumentParser(description=\"Manage the geniusrise application.\")\nsubparsers = parser.add_subparsers(dest=\"command\")\n# Create subparser for each discovered spout\nfor spout_name, discovered_spout in self.spouts.items():\nspout_parser = subparsers.add_parser(spout_name, help=f\"Manage {spout_name}.\")\nspout_ctl = SpoutCtl(discovered_spout)\nself.spout_ctls[spout_name] = spout_ctl\nspout_ctl.create_parser(spout_parser)\n# Create subparser for each discovered bolt\nfor bolt_name, discovered_bolt in self.bolts.items():\nbolt_parser = subparsers.add_parser(bolt_name, help=f\"Manage {bolt_name}.\")\nbolt_ctl = BoltCtl(discovered_bolt)\nself.bolt_ctls[bolt_name] = bolt_ctl\nbolt_ctl.create_parser(bolt_parser)\n# Create subparser for YAML operations\nyaml_parser = subparsers.add_parser(\"yaml\", help=\"Control spouts and bolts with a YAML file.\")\n# Initialize YamlCtl with both spout_ctls and bolt_ctls\nself.yaml_ctl = YamlCtl(self.spout_ctls, self.bolt_ctls)\nself.yaml_ctl.create_parser(yaml_parser)\n# Add a 'help' command to print help for all spouts and bolts\nhelp_parser = subparsers.add_parser(\"plugins\", help=\"Print help for all spouts and bolts.\")\nhelp_parser.add_argument(\"spout_or_bolt\", nargs=\"?\", help=\"The spout or bolt to print help for.\")\n# Add a 'list' command to list all discovered spouts and bolts\nlist_parser = subparsers.add_parser(\"list\", help=\"List all discovered spouts and bolts.\")\nreturn parser\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.list_spouts_and_bolts","title":"<code>list_spouts_and_bolts()</code>","text":"<p>List all discovered spouts and bolts in a table.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def list_spouts_and_bolts(self):\n\"\"\"\n    List all discovered spouts and bolts in a table.\n    \"\"\"\ntable = PrettyTable(\n[colored(\"Name\", \"green\"), colored(\"Type\", \"green\"), colored(\"Methods\", \"green\")], align=\"l\"\n)\nfor spout_name in self.spouts.keys():\ns = self.spouts[spout_name].klass\ntable.add_row(\n[\ncolored(spout_name, \"yellow\"),\ncolored(\"Spout\", \"cyan\"),\n\"\\n\".join([x for x in dir(s) if \"fetch_\" in x]),\n],\ndivider=True,\n)\nfor bolt_name in self.bolts.keys():\nb = self.bolts[bolt_name].klass\ntable.add_row(\n[\ncolored(bolt_name, \"yellow\"),\ncolored(\"Bolt\", \"magenta\"),\n\"\\n\".join([x for x in dir(b) if not x.startswith(\"_\")]),\n],\ndivider=True,\n)\nprint(table)\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.run","title":"<code>run(args)</code>","text":"<p>Run the command-line interface.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>argparse.Namespace</code> <p>Parsed command-line arguments.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def run(self, args):\n\"\"\"\n    Run the command-line interface.\n    Args:\n        args (argparse.Namespace): Parsed command-line arguments.\n    \"\"\"\nself.log.info(f\"Running command: {args.command}\")\nself.discover = Discover()\ndiscovered_components = self.discover.scan_directory(os.getenv(\"GENIUS_COMPONENTS_DIR\", \".\"))\n# Segregate the discovered components based on their type\nself.spouts = {\nname: component\nfor name, component in discovered_components.items()\nif isinstance(component, DiscoveredSpout)\n}\nself.bolts = {\nname: component\nfor name, component in discovered_components.items()\nif isinstance(component, DiscoveredBolt)\n}\nif args.command in self.spouts:\nself.spout_ctls[args.command].run(args)\nelif args.command in self.bolts:\nself.bolt_ctls[args.command].run(args)\nelif args.command == \"yaml\":\nself.yaml_ctl.run(args)\nelif args.command == \"plugins\":\nif args.spout_or_bolt in self.spouts:\nself.spout_ctls[args.spout_or_bolt].run(args)\nelif args.spout_or_bolt in self.bolts:\nself.bolt_ctls[args.spout_or_bolt].run(args)\nelse:\nfor spout_ctl in self.spout_ctls.values():\nspout_ctl.run(args)\nfor bolt_ctl in self.bolt_ctls.values():\nbolt_ctl.run(args)\nelif args.command == \"list\":\nif len(self.spout.keys()) == 0:\nprint(\"No spouts or bolts discovered.\")\nself.list_spouts_and_bolts()\n</code></pre>"},{"location":"core/cli_schema/","title":"YAML schema","text":"<p>YAML schema definition as pydantic</p>"},{"location":"core/cli_schema/#cli.schema.Bolt","title":"<code>Bolt</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines a bolt. A bolt has a name, method, optional arguments, input, output, state, and deployment.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Bolt(BaseModel):\n\"\"\"\n    This class defines a bolt. A bolt has a name, method, optional arguments, input, output, state, and deployment.\n    \"\"\"\nname: str\nmethod: str\nargs: Optional[ExtraKwargs]\ninput: Input\noutput: Output\nstate: State\ndeploy: Deploy\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Deploy","title":"<code>Deploy</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the deployment of the spout or bolt. The deployment can be of type k8s or ecs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Deploy(BaseModel):\n\"\"\"\n    This class defines the deployment of the spout or bolt. The deployment can be of type k8s or ecs.\n    \"\"\"\ntype: str\nargs: Optional[DeployArgs]\n@validator(\"type\")\ndef validate_type(cls, v, values, **kwargs):\nif v not in [\"k8s\", \"ecs\"]:\nraise ValueError(\"Invalid deploy type\")\nreturn v\n@validator(\"args\", pre=True, always=True)\ndef validate_args(cls, v, values, **kwargs):\nif \"type\" in values:\nif values[\"type\"] == \"ecs\":\nrequired_fields = [\n\"name\",\n\"namespace\",\n\"image\",\n\"replicas\",\n\"account_id\",\n\"cluster\",\n\"subnet_ids\",\n\"security_group_ids\",\n\"log_group\",\n\"cpu\",\n\"memory\",\n]\nfor field in required_fields:\nif not v or field not in v or not v[field]:\nraise ValueError(f\"Missing required field '{field}' for ecs deploy type\")\nelif values[\"type\"] == \"k8s\":\nrequired_fields = [\"name\", \"namespace\", \"image\", \"replicas\"]\nfor field in required_fields:\nif not v or field not in v or not v[field]:\nraise ValueError(f\"Missing required field '{field}' for k8s deploy type\")\nreturn v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.DeployArgs","title":"<code>DeployArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the arguments for the deployment. Depending on the type of deployment (k8s, ecs), different arguments are required.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class DeployArgs(BaseModel):\n\"\"\"\n    This class defines the arguments for the deployment. Depending on the type of deployment (k8s, ecs),\n    different arguments are required.\n    \"\"\"\nname: Optional[str]\nnamespace: Optional[str]\nimage: Optional[str]\nreplicas: Optional[int]\naccount_id: Optional[str]\ncluster: Optional[str]\nsubnet_ids: Optional[List[str]]\nsecurity_group_ids: Optional[List[str]]\nlog_group: Optional[str]\ncpu: Optional[int]\nmemory: Optional[int]\nclass Config:\nextra = Extra.allow\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.ExtraKwargs","title":"<code>ExtraKwargs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class is used to handle any extra arguments that are not explicitly defined in the schema.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class ExtraKwargs(BaseModel):\n\"\"\"\n    This class is used to handle any extra arguments that are not explicitly defined in the schema.\n    \"\"\"\nclass Config:\nextra = Extra.allow\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Geniusfile","title":"<code>Geniusfile</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the overall structure of the YAML file. It includes a version, spouts, and bolts.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Geniusfile(BaseModel):\n\"\"\"\n    This class defines the overall structure of the YAML file. It includes a version, spouts, and bolts.\n    \"\"\"\nversion: str\nspouts: Dict[str, Spout]\nbolts: Dict[str, Bolt]\n@validator(\"version\")\ndef validate_version(cls, v, values, **kwargs):\nif v != \"1\":\nraise ValueError(\"Invalid version\")\nreturn v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Input","title":"<code>Input</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the input of the bolt. The input can be of type batch, streaming, spout, or bolt.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Input(BaseModel):\n\"\"\"\n    This class defines the input of the bolt. The input can be of type batch, streaming, spout, or bolt.\n    \"\"\"\ntype: str\nargs: Optional[InputArgs]\n@validator(\"type\")\ndef validate_type(cls, v, values, **kwargs):\nif v not in [\"batch\", \"streaming\", \"spout\", \"bolt\"]:\nraise ValueError(\"Invalid input type\")\nreturn v\n@validator(\"args\", pre=True, always=True)\ndef validate_args(cls, v, values, **kwargs):\nif \"type\" in values:\nif values[\"type\"] == \"batch\":\nif not v or \"bucket\" not in v or \"folder\" not in v:\nraise ValueError(\"Missing required fields for batch input type\")\nelif values[\"type\"] == \"streaming\":\nif not v or \"input_topic\" not in v or \"kafka_servers\" not in v:\nraise ValueError(\"Missing required fields for streaming input type\")\nelif values[\"type\"] in [\"spout\", \"bolt\"]:\nif not v or \"name\" not in v:\nraise ValueError(f\"Missing required fields for {values['type']} input type\")\nreturn v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.InputArgs","title":"<code>InputArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the arguments for the input. Depending on the type of input (batch, streaming, spout, bolt), different arguments are required.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class InputArgs(BaseModel):\n\"\"\"\n    This class defines the arguments for the input. Depending on the type of input (batch, streaming, spout, bolt),\n    different arguments are required.\n    \"\"\"\ninput_topic: Optional[str]\nkafka_servers: Optional[str]\noutput_folder: Optional[str]\nbucket: Optional[str]\nfolder: Optional[str]\nname: Optional[str]\nclass Config:\nextra = Extra.allow\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Output","title":"<code>Output</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the output of the spout or bolt. The output can be of type batch or streaming.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Output(BaseModel):\n\"\"\"\n    This class defines the output of the spout or bolt. The output can be of type batch or streaming.\n    \"\"\"\ntype: str\nargs: Optional[OutputArgs]\n@validator(\"type\")\ndef validate_type(cls, v, values, **kwargs):\nif v not in [\"batch\", \"streaming\"]:\nraise ValueError(\"Invalid output type\")\nreturn v\n@validator(\"args\", pre=True, always=True)\ndef validate_args(cls, v, values, **kwargs):\nif \"type\" in values:\nif values[\"type\"] == \"batch\":\nif not v or \"bucket\" not in v or \"folder\" not in v:\nraise ValueError(\"Missing required fields for batch output type\")\nelif values[\"type\"] == \"streaming\":\nif not v or \"output_topic\" not in v or \"kafka_servers\" not in v:\nraise ValueError(\"Missing required fields for streaming output type\")\nreturn v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.OutputArgs","title":"<code>OutputArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the arguments for the output. Depending on the type of output (batch, streaming), different arguments are required.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class OutputArgs(BaseModel):\n\"\"\"\n    This class defines the arguments for the output. Depending on the type of output (batch, streaming),\n    different arguments are required.\n    \"\"\"\nbucket: Optional[str]\nfolder: Optional[str]\noutput_topic: Optional[str]\nkafka_servers: Optional[str]\nclass Config:\nextra = Extra.allow\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Spout","title":"<code>Spout</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines a spout. A spout has a name, method, optional arguments, output, state, and deployment.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Spout(BaseModel):\n\"\"\"\n    This class defines a spout. A spout has a name, method, optional arguments, output, state, and deployment.\n    \"\"\"\nname: str\nmethod: str\nargs: Optional[ExtraKwargs]\noutput: Output\nstate: State\ndeploy: Deploy\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.State","title":"<code>State</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the state of the spout or bolt. The state can be of type in_memory, redis, postgres, or dynamodb.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class State(BaseModel):\n\"\"\"\n    This class defines the state of the spout or bolt. The state can be of type in_memory, redis, postgres, or dynamodb.\n    \"\"\"\ntype: str\nargs: Optional[StateArgs]\n@validator(\"type\")\ndef validate_type(cls, v, values, **kwargs):\nif v not in [\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"]:\nraise ValueError(\"Invalid state type\")\nreturn v\n@validator(\"args\", pre=True, always=True)\ndef validate_args(cls, v, values, **kwargs):\nif \"type\" in values:\nif values[\"type\"] == \"redis\":\nif not v or \"redis_host\" not in v or \"redis_port\" not in v or \"redis_db\" not in v:\nraise ValueError(\"Missing required fields for redis state type\")\nelif values[\"type\"] == \"postgres\":\nif (\nnot v\nor \"postgres_host\" not in v\nor \"postgres_port\" not in v\nor \"postgres_user\" not in v\nor \"postgres_password\" not in v\nor \"postgres_database\" not in v\nor \"postgres_table\" not in v\n):\nraise ValueError(\"Missing required fields for postgres state type\")\nelif values[\"type\"] == \"dynamodb\":\nif not v or \"dynamodb_table_name\" not in v or \"dynamodb_region_name\" not in v:\nraise ValueError(\"Missing required fields for dynamodb state type\")\nreturn v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.StateArgs","title":"<code>StateArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the arguments for the state. Depending on the type of state (in_memory, redis, postgres, dynamodb), different arguments are required.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class StateArgs(BaseModel):\n\"\"\"\n    This class defines the arguments for the state. Depending on the type of state (in_memory, redis, postgres, dynamodb),\n    different arguments are required.\n    \"\"\"\nredis_host: Optional[str]\nredis_port: Optional[int]\nredis_db: Optional[int]\npostgres_host: Optional[str]\npostgres_port: Optional[int]\npostgres_user: Optional[str]\npostgres_password: Optional[str]\npostgres_database: Optional[str]\npostgres_table: Optional[str]\ndynamodb_table_name: Optional[str]\ndynamodb_region_name: Optional[str]\nclass Config:\nextra = Extra.allow\n</code></pre>"},{"location":"core/cli_spoutctl/","title":"Spoutctl","text":"<p>The main spout controller</p>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl","title":"<code>SpoutCtl</code>","text":"<p>Class for managing spouts end-to-end from the command line.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>class SpoutCtl:\n\"\"\"\n    Class for managing spouts end-to-end from the command line.\n    \"\"\"\ndef __init__(self, discovered_spout: DiscoveredSpout):\n\"\"\"\n        Initialize SpoutCtl with a DiscoveredSpout object.\n        Args:\n            discovered_spout (DiscoveredSpout): DiscoveredSpout object used to create and manage spouts.\n        \"\"\"\nself.discovered_spout = discovered_spout\nself.spout = None\nself.log = logging.getLogger(self.__class__.__name__)\ndef create_parser(self, parser):\n\"\"\"\n        Add arguments to the command-line parser for managing the spout.\n        Args:\n            parser (argparse.ArgumentParser): Command-line parser.\n        \"\"\"\nsubparsers = parser.add_subparsers(dest=\"command\")\n# Create subparser for 'create' command\ncreate_parser = subparsers.add_parser(\"rise\", help=\"Run a spout locally.\")\ncreate_parser.add_argument(\n\"output_type\",\nchoices=[\"batch\", \"streaming\"],\nhelp=\"Choose the type of output configuration: batch or streaming.\",\ndefault=\"batch\",\n)\ncreate_parser.add_argument(\n\"state_type\",\nchoices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"],\nhelp=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\",\ndefault=\"in_memory\",\n)\ncreate_parser.add_argument(\n\"--output_folder\",\nhelp=\"Specify the directory where output files should be stored temporarily.\",\ndefault=\"/tmp\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--output_kafka_topic\",\nhelp=\"Kafka output topic for streaming spouts.\",\ndefault=\"test\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--output_kafka_cluster_connection_string\",\nhelp=\"Kafka connection string for streaming spouts.\",\ndefault=\"localhost:9092\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--output_s3_bucket\",\nhelp=\"Provide the name of the S3 bucket for output storage.\",\ndefault=\"my-bucket\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n)\ncreate_parser.add_argument(\n\"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str\n)\ncreate_parser.add_argument(\n\"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int\n)\ncreate_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int)\ncreate_parser.add_argument(\n\"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str\n)\ncreate_parser.add_argument(\n\"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int\n)\ncreate_parser.add_argument(\n\"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str\n)\ncreate_parser.add_argument(\n\"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str\n)\ncreate_parser.add_argument(\n\"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str\n)\ncreate_parser.add_argument(\n\"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str\n)\ncreate_parser.add_argument(\n\"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str\n)\ncreate_parser.add_argument(\n\"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str\n)\ncreate_parser.add_argument(\n\"method_name\",\nhelp=\"The name of the method to execute on the spout.\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--args\",\nnargs=argparse.REMAINDER,\nhelp=\"Additional keyword arguments to pass to the spout.\",\n)\n# Create subparser for 'help' command\nexecute_parser = subparsers.add_parser(\"help\", help=\"Print help for the spout.\")\nexecute_parser.add_argument(\"method\", help=\"The method to execute.\")\nreturn parser\ndef run(self, args):\n\"\"\"\n        Run the command-line interface.\n        Args:\n            args (argparse.Namespace): Parsed command-line arguments.\n        \"\"\"\nself.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\"))\ntry:\nif args.command == \"rise\":\nkwargs = {\nk: v\nfor k, v in vars(args).items()\nif v is not None and k not in [\"output_type\", \"state_type\", \"args\", \"method_name\"]\n}\nother = args.args or []\nother_args, other_kwargs = self.parse_args_kwargs(other)\nself.spout = self.create_spout(args.output_type, args.state_type, **kwargs)\n# Pass the method_name from args to execute_spout\nresult = self.execute_spout(self.spout, args.method_name, *other_args, **other_kwargs)\nreturn result\nelif args.command == \"help\":\nself.discovered_spout.klass.print_help(self.discovered_spout.klass)\nexcept ValueError as ve:\nself.log.exception(f\"Value error: {ve}\")\nraise\nexcept AttributeError as ae:\nself.log.exception(f\"Attribute error: {ae}\")\nraise\nexcept Exception as e:\nself.log.exception(f\"An unexpected error occurred: {e}\")\nraise\n@staticmethod\ndef parse_args_kwargs(args_list):\nargs = []\nkwargs = {}\ndef convert(value):\ntry:\nreturn int(value)\nexcept ValueError:\ntry:\nreturn float(value)\nexcept ValueError:\nreturn value\nfor item in args_list:\nif \"=\" in item:\nkey, value = item.split(\"=\", 1)\nkwargs[key] = convert(value)\nelse:\nargs.append(convert(item))\nreturn args, kwargs\ndef create_spout(self, output_type: str, state_type: str, **kwargs) -&gt; Spout:\n\"\"\"\n        Create a spout of a specific type.\n        Args:\n            output_type (str): The type of output config (\"batch\" or \"streaming\").\n            state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n            **kwargs: Additional keyword arguments for initializing the spout.\n                Keyword Arguments:\n                    Batch output config:\n                    - output_folder (str): The directory where output files should be stored temporarily.\n                    - output_s3_bucket (str): The name of the S3 bucket for output storage.\n                    - output_s3_folder (str): The S3 folder for output storage.\n                    Streaming output config:\n                    - output_kafka_topic (str): Kafka output topic for streaming spouts.\n                    - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.\n                    Redis state manager config:\n                    - redis_host (str): The Redis host argument.\n                    - redis_port (str): The Redis port argument.\n                    - redis_db (str): The Redis database argument.\n                    Postgres state manager config:\n                    - postgres_host (str): The PostgreSQL host argument.\n                    - postgres_port (str): The PostgreSQL port argument.\n                    - postgres_user (str): The PostgreSQL user argument.\n                    - postgres_password (str): The PostgreSQL password argument.\n                    - postgres_database (str): The PostgreSQL database argument.\n                    - postgres_table (str): The PostgreSQL table argument.\n                    DynamoDB state manager config:\n                    - dynamodb_table_name (str): The DynamoDB table name argument.\n                    - dynamodb_region_name (str): The DynamoDB region name argument.\n        Returns:\n            Spout: The created spout.\n        \"\"\"\nreturn Spout.create(klass=self.discovered_spout.klass, output_type=output_type, state_type=state_type, **kwargs)\ndef execute_spout(self, spout: Spout, method_name: str, *args, **kwargs):\n\"\"\"\n        Execute a method of a spout.\n        Args:\n            spout (Spout): The spout to execute.\n            method_name (str): The name of the method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n        Returns:\n            Any: The result of the method.\n        \"\"\"\nreturn spout.__call__(method_name, *args, **kwargs)\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.__init__","title":"<code>__init__(discovered_spout)</code>","text":"<p>Initialize SpoutCtl with a DiscoveredSpout object.</p> <p>Parameters:</p> Name Type Description Default <code>discovered_spout</code> <code>DiscoveredSpout</code> <p>DiscoveredSpout object used to create and manage spouts.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def __init__(self, discovered_spout: DiscoveredSpout):\n\"\"\"\n    Initialize SpoutCtl with a DiscoveredSpout object.\n    Args:\n        discovered_spout (DiscoveredSpout): DiscoveredSpout object used to create and manage spouts.\n    \"\"\"\nself.discovered_spout = discovered_spout\nself.spout = None\nself.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.create_parser","title":"<code>create_parser(parser)</code>","text":"<p>Add arguments to the command-line parser for managing the spout.</p> <p>Parameters:</p> Name Type Description Default <code>parser</code> <code>argparse.ArgumentParser</code> <p>Command-line parser.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def create_parser(self, parser):\n\"\"\"\n    Add arguments to the command-line parser for managing the spout.\n    Args:\n        parser (argparse.ArgumentParser): Command-line parser.\n    \"\"\"\nsubparsers = parser.add_subparsers(dest=\"command\")\n# Create subparser for 'create' command\ncreate_parser = subparsers.add_parser(\"rise\", help=\"Run a spout locally.\")\ncreate_parser.add_argument(\n\"output_type\",\nchoices=[\"batch\", \"streaming\"],\nhelp=\"Choose the type of output configuration: batch or streaming.\",\ndefault=\"batch\",\n)\ncreate_parser.add_argument(\n\"state_type\",\nchoices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"],\nhelp=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\",\ndefault=\"in_memory\",\n)\ncreate_parser.add_argument(\n\"--output_folder\",\nhelp=\"Specify the directory where output files should be stored temporarily.\",\ndefault=\"/tmp\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--output_kafka_topic\",\nhelp=\"Kafka output topic for streaming spouts.\",\ndefault=\"test\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--output_kafka_cluster_connection_string\",\nhelp=\"Kafka connection string for streaming spouts.\",\ndefault=\"localhost:9092\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--output_s3_bucket\",\nhelp=\"Provide the name of the S3 bucket for output storage.\",\ndefault=\"my-bucket\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n)\ncreate_parser.add_argument(\n\"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str\n)\ncreate_parser.add_argument(\n\"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int\n)\ncreate_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int)\ncreate_parser.add_argument(\n\"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str\n)\ncreate_parser.add_argument(\n\"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int\n)\ncreate_parser.add_argument(\n\"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str\n)\ncreate_parser.add_argument(\n\"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str\n)\ncreate_parser.add_argument(\n\"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str\n)\ncreate_parser.add_argument(\n\"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str\n)\ncreate_parser.add_argument(\n\"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str\n)\ncreate_parser.add_argument(\n\"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str\n)\ncreate_parser.add_argument(\n\"method_name\",\nhelp=\"The name of the method to execute on the spout.\",\ntype=str,\n)\ncreate_parser.add_argument(\n\"--args\",\nnargs=argparse.REMAINDER,\nhelp=\"Additional keyword arguments to pass to the spout.\",\n)\n# Create subparser for 'help' command\nexecute_parser = subparsers.add_parser(\"help\", help=\"Print help for the spout.\")\nexecute_parser.add_argument(\"method\", help=\"The method to execute.\")\nreturn parser\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.create_spout","title":"<code>create_spout(output_type, state_type, **kwargs)</code>","text":"<p>Create a spout of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>output_type</code> <code>str</code> <p>The type of output config (\"batch\" or \"streaming\").</p> required <code>state_type</code> <code>str</code> <p>The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").</p> required <code>**kwargs</code> <p>Additional keyword arguments for initializing the spout. Keyword Arguments:     Batch output config:     - output_folder (str): The directory where output files should be stored temporarily.     - output_s3_bucket (str): The name of the S3 bucket for output storage.     - output_s3_folder (str): The S3 folder for output storage.     Streaming output config:     - output_kafka_topic (str): Kafka output topic for streaming spouts.     - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.     Redis state manager config:     - redis_host (str): The Redis host argument.     - redis_port (str): The Redis port argument.     - redis_db (str): The Redis database argument.     Postgres state manager config:     - postgres_host (str): The PostgreSQL host argument.     - postgres_port (str): The PostgreSQL port argument.     - postgres_user (str): The PostgreSQL user argument.     - postgres_password (str): The PostgreSQL password argument.     - postgres_database (str): The PostgreSQL database argument.     - postgres_table (str): The PostgreSQL table argument.     DynamoDB state manager config:     - dynamodb_table_name (str): The DynamoDB table name argument.     - dynamodb_region_name (str): The DynamoDB region name argument.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Spout</code> <code>Spout</code> <p>The created spout.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def create_spout(self, output_type: str, state_type: str, **kwargs) -&gt; Spout:\n\"\"\"\n    Create a spout of a specific type.\n    Args:\n        output_type (str): The type of output config (\"batch\" or \"streaming\").\n        state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n        **kwargs: Additional keyword arguments for initializing the spout.\n            Keyword Arguments:\n                Batch output config:\n                - output_folder (str): The directory where output files should be stored temporarily.\n                - output_s3_bucket (str): The name of the S3 bucket for output storage.\n                - output_s3_folder (str): The S3 folder for output storage.\n                Streaming output config:\n                - output_kafka_topic (str): Kafka output topic for streaming spouts.\n                - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.\n                Redis state manager config:\n                - redis_host (str): The Redis host argument.\n                - redis_port (str): The Redis port argument.\n                - redis_db (str): The Redis database argument.\n                Postgres state manager config:\n                - postgres_host (str): The PostgreSQL host argument.\n                - postgres_port (str): The PostgreSQL port argument.\n                - postgres_user (str): The PostgreSQL user argument.\n                - postgres_password (str): The PostgreSQL password argument.\n                - postgres_database (str): The PostgreSQL database argument.\n                - postgres_table (str): The PostgreSQL table argument.\n                DynamoDB state manager config:\n                - dynamodb_table_name (str): The DynamoDB table name argument.\n                - dynamodb_region_name (str): The DynamoDB region name argument.\n    Returns:\n        Spout: The created spout.\n    \"\"\"\nreturn Spout.create(klass=self.discovered_spout.klass, output_type=output_type, state_type=state_type, **kwargs)\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.execute_spout","title":"<code>execute_spout(spout, method_name, *args, **kwargs)</code>","text":"<p>Execute a method of a spout.</p> <p>Parameters:</p> Name Type Description Default <code>spout</code> <code>Spout</code> <p>The spout to execute.</p> required <code>method_name</code> <code>str</code> <p>The name of the method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>The result of the method.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def execute_spout(self, spout: Spout, method_name: str, *args, **kwargs):\n\"\"\"\n    Execute a method of a spout.\n    Args:\n        spout (Spout): The spout to execute.\n        method_name (str): The name of the method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n    Returns:\n        Any: The result of the method.\n    \"\"\"\nreturn spout.__call__(method_name, *args, **kwargs)\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.run","title":"<code>run(args)</code>","text":"<p>Run the command-line interface.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>argparse.Namespace</code> <p>Parsed command-line arguments.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def run(self, args):\n\"\"\"\n    Run the command-line interface.\n    Args:\n        args (argparse.Namespace): Parsed command-line arguments.\n    \"\"\"\nself.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\"))\ntry:\nif args.command == \"rise\":\nkwargs = {\nk: v\nfor k, v in vars(args).items()\nif v is not None and k not in [\"output_type\", \"state_type\", \"args\", \"method_name\"]\n}\nother = args.args or []\nother_args, other_kwargs = self.parse_args_kwargs(other)\nself.spout = self.create_spout(args.output_type, args.state_type, **kwargs)\n# Pass the method_name from args to execute_spout\nresult = self.execute_spout(self.spout, args.method_name, *other_args, **other_kwargs)\nreturn result\nelif args.command == \"help\":\nself.discovered_spout.klass.print_help(self.discovered_spout.klass)\nexcept ValueError as ve:\nself.log.exception(f\"Value error: {ve}\")\nraise\nexcept AttributeError as ae:\nself.log.exception(f\"Attribute error: {ae}\")\nraise\nexcept Exception as e:\nself.log.exception(f\"An unexpected error occurred: {e}\")\nraise\n</code></pre>"},{"location":"core/cli_yamlctl/","title":"YamlCtl","text":"<p>Control spouts and bolts defined in a YAML file</p>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl","title":"<code>YamlCtl</code>","text":"<p>Command-line interface for managing spouts and bolts based on a YAML configuration.</p> <p>The YamlCtl class provides methods to run specific or all spouts and bolts defined in a YAML file. The YAML file's structure is defined by the Geniusfile schema.</p> <p>Example YAML structure: <pre><code>version: \"1\"\nspouts:\n  spout_name1:\n    name: \"spout1\"\n    method: \"method_name\"\n    ...\nbolts:\n  bolt_name1:\n    name: \"bolt1\"\n    method: \"method_name\"\n    ...\n</code></pre></p> <p>Attributes:</p> Name Type Description <code>geniusfile</code> <code>Geniusfile</code> <p>Parsed YAML configuration.</p> <code>spout_ctls</code> <code>Dict[str, SpoutCtl]</code> <p>Dictionary of SpoutCtl instances.</p> <code>bolt_ctls</code> <code>Dict[str, BoltCtl]</code> <p>Dictionary of BoltCtl instances.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>class YamlCtl:\n\"\"\"\n    Command-line interface for managing spouts and bolts based on a YAML configuration.\n    The YamlCtl class provides methods to run specific or all spouts and bolts defined in a YAML file.\n    The YAML file's structure is defined by the Geniusfile schema.\n    Example YAML structure:\n    ```\n    version: \"1\"\n    spouts:\n      spout_name1:\n        name: \"spout1\"\n        method: \"method_name\"\n        ...\n    bolts:\n      bolt_name1:\n        name: \"bolt1\"\n        method: \"method_name\"\n        ...\n    ```\n    Attributes:\n        geniusfile (Geniusfile): Parsed YAML configuration.\n        spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances.\n        bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances.\n    \"\"\"\ndef __init__(self, spout_ctls: Dict[str, SpoutCtl], bolt_ctls: Dict[str, BoltCtl]):\n\"\"\"\n        Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts.\n        Args:\n            spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances.\n            bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances.\n        \"\"\"\nself.spout_ctls = spout_ctls\nself.bolt_ctls = bolt_ctls\nself.log = logging.getLogger(self.__class__.__name__)\ndef create_parser(self, parser):\n\"\"\"\n        Create and return the command-line parser for managing spouts and bolts.\n        \"\"\"\nparser.add_argument(\"--spout\", type=str, help=\"Name of the specific spout to run.\")\nparser.add_argument(\"--bolt\", type=str, help=\"Name of the specific bolt to run.\")\nparser.add_argument(\"--file\", default=\".\", type=str, help=\"Path of the genius.yml file, default to .\")\nreturn parser\ndef run(self, args):\n\"\"\"\n        Run the command-line interface for managing spouts and bolts based on provided arguments.\n        Please note that there is no ordering of the spouts and bolts in the YAML configuration.\n        Each spout and bolt is an independent entity even when connected together.\n        Args:\n            args (argparse.Namespace): Parsed command-line arguments.\n        \"\"\"\nwith open(args.file, \"r\") as file:\nself.geniusfile = Geniusfile.parse_obj(yaml.safe_load(file))\nif args.spout == \"all\":\nself.run_spouts()\nelif args.bolt == \"all\":\nself.run_bolts()\nelif args.spout:\nself.run_spout(args.spout)\nelif args.bolt:\nself.run_bolt(args.bolt)\nelse:\nself.run_spouts()\nself.run_bolts()\ndef run_spouts(self):\n\"\"\"Run all spouts defined in the YAML configuration.\"\"\"\nself.log.info(emoji.emojize(\":rocket: Running all spouts...\"))\nfor spout_name, _ in self.geniusfile.spouts.items():\nself.run_spout(spout_name)\ndef run_bolts(self):\n\"\"\"Run all bolts defined in the YAML configuration.\"\"\"\nself.log.info(emoji.emojize(\":rocket: Running all bolts...\"))\nfor bolt_name, _ in self.geniusfile.bolts.items():\nself.run_bolt(bolt_name)\ndef run_spout(self, spout_name: str):\n\"\"\"\n        Run a specific spout based on its name.\n        Args:\n            spout_name (str): Name of the spout to run.\n        \"\"\"\nspout = self.geniusfile.spouts.get(spout_name)\nif not spout:\nself.log.error(emoji.emojize(f\":x: Spout {spout_name} not found.\"))\nreturn\nspout_ctl = self.spout_ctls.get(spout_name)\nif not spout_ctl:\nself.log.error(emoji.emojize(f\":x: SpoutCtl for {spout_name} not found.\"))\nreturn\nself.log.info(emoji.emojize(f\":rocket: Running spout {spout_name}...\"))\nflat_args = [\"rise\", spout.output.type, spout.state.type, spout.method] + self._convert_spout(spout)\nparser = argparse.ArgumentParser()\nself.spout_ctls[spout_name].create_parser(parser)\nnamespace_args = parser.parse_args(flat_args)\nspout_ctl.run(namespace_args)\ndef run_bolt(self, bolt_name: str):\n\"\"\"\n        Run a specific bolt based on its name.\n        Args:\n            bolt_name (str): Name of the bolt to run.\n        \"\"\"\nbolt = self.geniusfile.bolts.get(bolt_name)\nif not bolt:\nself.log.error(emoji.emojize(f\":x: Bolt {bolt_name} not found.\"))\nreturn\n# Resolve reference if input type is \"spout\" or \"bolt\"\nif bolt.input.type in [\"spout\", \"bolt\"]:\nif not bolt.input.args or not bolt.input.args.name:\nraise ValueError(emoji.emojize(f\"Need referenced spouts or bolt to be mentioned here {bolt.input}\"))\nref_name = bolt.input.args.name\nresolved_output = self.resolve_reference(bolt.input.type, ref_name)\nif not resolved_output:\nself.log.error(emoji.emojize(f\":x: Failed to resolve reference for bolt {bolt_name}.\"))\nreturn\nbolt.input.type = resolved_output.type  # Set the resolved output type as the bolt's input type\nbolt.input.args = resolved_output.args  # Set the resolved output args as the bolt's input args\nbolt_ctl = self.bolt_ctls.get(bolt_name)\nif not bolt_ctl:\nself.log.error(emoji.emojize(f\":x: BoltCtl for {bolt_name} not found.\"))\nreturn\nself.log.info(emoji.emojize(f\":rocket: Running bolt {bolt_name}...\"))\nflat_args = [\"rise\", bolt.input.type, bolt.output.type, bolt.state.type, bolt.method] + self._convert_bolt(bolt)\nparser = argparse.ArgumentParser()\nself.bolt_ctls[bolt_name].create_parser(parser)\nnamespace_args = parser.parse_args(flat_args)\nbolt_ctl.run(namespace_args)\ndef resolve_reference(self, input_type: str, ref_name: str):\n\"\"\"\n        Resolve the reference of a bolt's input based on the input type (spout or bolt).\n        Args:\n            input_type (str): Type of the input (\"spout\" or \"bolt\").\n            ref_name (str): Name of the spout or bolt to refer to.\n        Returns:\n            Output: The output configuration of the referred spout or bolt.\n        \"\"\"\nif input_type == \"spout\":\nreferred_spout = self.geniusfile.spouts.get(ref_name)\nif not referred_spout:\nself.log.error(emoji.emojize(f\":x: Referred spout {ref_name} not found.\"))\nreturn None\nreturn referred_spout.output\nelif input_type == \"bolt\":\nreferred_bolt = self.geniusfile.bolts.get(ref_name)\nif not referred_bolt:\nself.log.error(emoji.emojize(f\":x: Referred bolt {ref_name} not found.\"))\nreturn None\nreturn referred_bolt.output\nelse:\nself.log.error(emoji.emojize(f\":x: Invalid reference type {input_type}.\"))\nreturn None\n@typing.no_type_check\ndef _convert_spout(self, spout: Spout) -&gt; List[str]:\nspout_args = []\n# Convert output\nif spout.output.type == \"batch\":\nspout_args.append(f\"--output_folder={spout.output.args.folder}\")\nspout_args.append(f\"--output_s3_bucket={spout.output.args.bucket}\")\nspout_args.append(f\"--output_s3_folder={spout.output.args.folder}\")\nelif spout.output.type == \"streaming\":\nspout_args.append(f\"--output_kafka_topic={spout.output.args.output_topic}\")\nspout_args.append(f\"--output_kafka_cluster_connection_string={spout.output.args.kafka_servers}\")\n# Convert state\nif spout.state.type == \"redis\":\nspout_args.append(f\"--redis_host={spout.state.args.redis_host}\")\nspout_args.append(f\"--redis_port={spout.state.args.redis_port}\")\nspout_args.append(f\"--redis_db={spout.state.args.redis_db}\")\nelif spout.state.type == \"postgres\":\nspout_args.append(f\"--postgres_host={spout.state.args.postgres_host}\")\nspout_args.append(f\"--postgres_port={spout.state.args.postgres_port}\")\nspout_args.append(f\"--postgres_user={spout.state.args.postgres_user}\")\nspout_args.append(f\"--postgres_password={spout.state.args.postgres_password}\")\nspout_args.append(f\"--postgres_database={spout.state.args.postgres_database}\")\nspout_args.append(f\"--postgres_table={spout.state.args.postgres_table}\")\nelif spout.state.type == \"dynamodb\":\nspout_args.append(f\"--dynamodb_table_name={spout.state.args.dynamodb_table_name}\")\nspout_args.append(f\"--dynamodb_region_name={spout.state.args.dynamodb_region_name}\")\nreturn spout_args\n@typing.no_type_check\ndef _convert_bolt(self, bolt: Bolt) -&gt; List[str]:\nbolt_args = []\n# Convert input\nif bolt.input.type == \"batch\":\nbolt_args.append(f\"--input_folder={bolt.input.args.folder}\")\nbolt_args.append(f\"--input_s3_bucket={bolt.input.args.bucket}\")\nbolt_args.append(f\"--input_s3_folder={bolt.input.args.folder}\")\nelif bolt.input.type == \"streaming\":\nbolt_args.append(f\"--input_kafka_topic={bolt.input.args.input_topic}\")\nbolt_args.append(f\"--input_kafka_cluster_connection_string={bolt.input.args.kafka_servers}\")\n# Convert output\nif bolt.output.type == \"batch\":\nbolt_args.append(f\"--output_folder={bolt.output.args.folder}\")\nbolt_args.append(f\"--output_s3_bucket={bolt.output.args.bucket}\")\nbolt_args.append(f\"--output_s3_folder={bolt.output.args.folder}\")\nelif bolt.output.type == \"streaming\":\nbolt_args.append(f\"--output_kafka_topic={bolt.output.args.output_topic}\")\nbolt_args.append(f\"--output_kafka_cluster_connection_string={bolt.output.args.kafka_servers}\")\n# Convert state\nif bolt.state.type == \"redis\":\nbolt_args.append(f\"--redis_host={bolt.state.args.redis_host}\")\nbolt_args.append(f\"--redis_port={bolt.state.args.redis_port}\")\nbolt_args.append(f\"--redis_db={bolt.state.args.redis_db}\")\nelif bolt.state.type == \"postgres\":\nbolt_args.append(f\"--postgres_host={bolt.state.args.postgres_host}\")\nbolt_args.append(f\"--postgres_port={bolt.state.args.postgres_port}\")\nbolt_args.append(f\"--postgres_user={bolt.state.args.postgres_user}\")\nbolt_args.append(f\"--postgres_password={bolt.state.args.postgres_password}\")\nbolt_args.append(f\"--postgres_database={bolt.state.args.postgres_database}\")\nbolt_args.append(f\"--postgres_table={bolt.state.args.postgres_table}\")\nelif bolt.state.type == \"dynamodb\":\nbolt_args.append(f\"--dynamodb_table_name={bolt.state.args.dynamodb_table_name}\")\nbolt_args.append(f\"--dynamodb_region_name={bolt.state.args.dynamodb_region_name}\")\nreturn bolt_args\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.__init__","title":"<code>__init__(spout_ctls, bolt_ctls)</code>","text":"<p>Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts.</p> <p>Parameters:</p> Name Type Description Default <code>spout_ctls</code> <code>Dict[str, SpoutCtl]</code> <p>Dictionary of SpoutCtl instances.</p> required <code>bolt_ctls</code> <code>Dict[str, BoltCtl]</code> <p>Dictionary of BoltCtl instances.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def __init__(self, spout_ctls: Dict[str, SpoutCtl], bolt_ctls: Dict[str, BoltCtl]):\n\"\"\"\n    Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts.\n    Args:\n        spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances.\n        bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances.\n    \"\"\"\nself.spout_ctls = spout_ctls\nself.bolt_ctls = bolt_ctls\nself.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.create_parser","title":"<code>create_parser(parser)</code>","text":"<p>Create and return the command-line parser for managing spouts and bolts.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def create_parser(self, parser):\n\"\"\"\n    Create and return the command-line parser for managing spouts and bolts.\n    \"\"\"\nparser.add_argument(\"--spout\", type=str, help=\"Name of the specific spout to run.\")\nparser.add_argument(\"--bolt\", type=str, help=\"Name of the specific bolt to run.\")\nparser.add_argument(\"--file\", default=\".\", type=str, help=\"Path of the genius.yml file, default to .\")\nreturn parser\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.resolve_reference","title":"<code>resolve_reference(input_type, ref_name)</code>","text":"<p>Resolve the reference of a bolt's input based on the input type (spout or bolt).</p> <p>Parameters:</p> Name Type Description Default <code>input_type</code> <code>str</code> <p>Type of the input (\"spout\" or \"bolt\").</p> required <code>ref_name</code> <code>str</code> <p>Name of the spout or bolt to refer to.</p> required <p>Returns:</p> Name Type Description <code>Output</code> <p>The output configuration of the referred spout or bolt.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def resolve_reference(self, input_type: str, ref_name: str):\n\"\"\"\n    Resolve the reference of a bolt's input based on the input type (spout or bolt).\n    Args:\n        input_type (str): Type of the input (\"spout\" or \"bolt\").\n        ref_name (str): Name of the spout or bolt to refer to.\n    Returns:\n        Output: The output configuration of the referred spout or bolt.\n    \"\"\"\nif input_type == \"spout\":\nreferred_spout = self.geniusfile.spouts.get(ref_name)\nif not referred_spout:\nself.log.error(emoji.emojize(f\":x: Referred spout {ref_name} not found.\"))\nreturn None\nreturn referred_spout.output\nelif input_type == \"bolt\":\nreferred_bolt = self.geniusfile.bolts.get(ref_name)\nif not referred_bolt:\nself.log.error(emoji.emojize(f\":x: Referred bolt {ref_name} not found.\"))\nreturn None\nreturn referred_bolt.output\nelse:\nself.log.error(emoji.emojize(f\":x: Invalid reference type {input_type}.\"))\nreturn None\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run","title":"<code>run(args)</code>","text":"<p>Run the command-line interface for managing spouts and bolts based on provided arguments. Please note that there is no ordering of the spouts and bolts in the YAML configuration. Each spout and bolt is an independent entity even when connected together.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>argparse.Namespace</code> <p>Parsed command-line arguments.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run(self, args):\n\"\"\"\n    Run the command-line interface for managing spouts and bolts based on provided arguments.\n    Please note that there is no ordering of the spouts and bolts in the YAML configuration.\n    Each spout and bolt is an independent entity even when connected together.\n    Args:\n        args (argparse.Namespace): Parsed command-line arguments.\n    \"\"\"\nwith open(args.file, \"r\") as file:\nself.geniusfile = Geniusfile.parse_obj(yaml.safe_load(file))\nif args.spout == \"all\":\nself.run_spouts()\nelif args.bolt == \"all\":\nself.run_bolts()\nelif args.spout:\nself.run_spout(args.spout)\nelif args.bolt:\nself.run_bolt(args.bolt)\nelse:\nself.run_spouts()\nself.run_bolts()\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_bolt","title":"<code>run_bolt(bolt_name)</code>","text":"<p>Run a specific bolt based on its name.</p> <p>Parameters:</p> Name Type Description Default <code>bolt_name</code> <code>str</code> <p>Name of the bolt to run.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run_bolt(self, bolt_name: str):\n\"\"\"\n    Run a specific bolt based on its name.\n    Args:\n        bolt_name (str): Name of the bolt to run.\n    \"\"\"\nbolt = self.geniusfile.bolts.get(bolt_name)\nif not bolt:\nself.log.error(emoji.emojize(f\":x: Bolt {bolt_name} not found.\"))\nreturn\n# Resolve reference if input type is \"spout\" or \"bolt\"\nif bolt.input.type in [\"spout\", \"bolt\"]:\nif not bolt.input.args or not bolt.input.args.name:\nraise ValueError(emoji.emojize(f\"Need referenced spouts or bolt to be mentioned here {bolt.input}\"))\nref_name = bolt.input.args.name\nresolved_output = self.resolve_reference(bolt.input.type, ref_name)\nif not resolved_output:\nself.log.error(emoji.emojize(f\":x: Failed to resolve reference for bolt {bolt_name}.\"))\nreturn\nbolt.input.type = resolved_output.type  # Set the resolved output type as the bolt's input type\nbolt.input.args = resolved_output.args  # Set the resolved output args as the bolt's input args\nbolt_ctl = self.bolt_ctls.get(bolt_name)\nif not bolt_ctl:\nself.log.error(emoji.emojize(f\":x: BoltCtl for {bolt_name} not found.\"))\nreturn\nself.log.info(emoji.emojize(f\":rocket: Running bolt {bolt_name}...\"))\nflat_args = [\"rise\", bolt.input.type, bolt.output.type, bolt.state.type, bolt.method] + self._convert_bolt(bolt)\nparser = argparse.ArgumentParser()\nself.bolt_ctls[bolt_name].create_parser(parser)\nnamespace_args = parser.parse_args(flat_args)\nbolt_ctl.run(namespace_args)\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_bolts","title":"<code>run_bolts()</code>","text":"<p>Run all bolts defined in the YAML configuration.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run_bolts(self):\n\"\"\"Run all bolts defined in the YAML configuration.\"\"\"\nself.log.info(emoji.emojize(\":rocket: Running all bolts...\"))\nfor bolt_name, _ in self.geniusfile.bolts.items():\nself.run_bolt(bolt_name)\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_spout","title":"<code>run_spout(spout_name)</code>","text":"<p>Run a specific spout based on its name.</p> <p>Parameters:</p> Name Type Description Default <code>spout_name</code> <code>str</code> <p>Name of the spout to run.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run_spout(self, spout_name: str):\n\"\"\"\n    Run a specific spout based on its name.\n    Args:\n        spout_name (str): Name of the spout to run.\n    \"\"\"\nspout = self.geniusfile.spouts.get(spout_name)\nif not spout:\nself.log.error(emoji.emojize(f\":x: Spout {spout_name} not found.\"))\nreturn\nspout_ctl = self.spout_ctls.get(spout_name)\nif not spout_ctl:\nself.log.error(emoji.emojize(f\":x: SpoutCtl for {spout_name} not found.\"))\nreturn\nself.log.info(emoji.emojize(f\":rocket: Running spout {spout_name}...\"))\nflat_args = [\"rise\", spout.output.type, spout.state.type, spout.method] + self._convert_spout(spout)\nparser = argparse.ArgumentParser()\nself.spout_ctls[spout_name].create_parser(parser)\nnamespace_args = parser.parse_args(flat_args)\nspout_ctl.run(namespace_args)\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_spouts","title":"<code>run_spouts()</code>","text":"<p>Run all spouts defined in the YAML configuration.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run_spouts(self):\n\"\"\"Run all spouts defined in the YAML configuration.\"\"\"\nself.log.info(emoji.emojize(\":rocket: Running all spouts...\"))\nfor spout_name, _ in self.geniusfile.spouts.items():\nself.run_spout(spout_name)\n</code></pre>"},{"location":"core/config/","title":"Encironment Configuration","text":""},{"location":"core/core_bolt/","title":"Bolt","text":"<p>Core Bolt class</p>"},{"location":"core/core_bolt/#core.bolt.Bolt","title":"<code>Bolt</code>","text":"<p>             Bases: <code>Task</code></p> <p>Base class for all bolts.</p> <p>A bolt is a component that consumes streams of data, processes them, and possibly emits new data streams.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py</code> <pre><code>class Bolt(Task):\n\"\"\"\n    Base class for all bolts.\n    A bolt is a component that consumes streams of data, processes them, and possibly emits new data streams.\n    \"\"\"\ndef __init__(\nself,\ninput_config: InputConfig,\noutput_config: OutputConfig,\nstate_manager: StateManager,\n**kwargs,\n) -&gt; None:\n\"\"\"\n        The `Bolt` class is a base class for all bolts in the given context.\n        It inherits from the `Task` class and provides methods for executing tasks\n        both locally and remotely, as well as managing their state, with state management\n        options including in-memory, Redis, PostgreSQL, and DynamoDB,\n        and input and output configurations for batch or streaming data.\n        The `Bolt` class uses the `InputConfig`, `OutputConfig` and `StateManager` classes, which are abstract base\n        classes for managing input configurations, output configurations and states, respectively. The `InputConfig` and\n        `OutputConfig` classes each have two subclasses: `StreamingInputConfig`, `BatchInputConfig`, `StreamingOutputConfig`\n        and `BatchOutputConfig`, which manage streaming and batch input and output configurations, respectively.\n        The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers.\n        The `Bolt` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method,\n        which are used to manage tasks on Amazon ECS and Kubernetes, respectively.\n        Usage:\n            - Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object.\n            - The InputConfig object specifies the input configuration for the bolt.\n            - The OutputConfig object specifies the output configuration for the bolt.\n            - The StateManager object handles the management of the bolt's state.\n        Example:\n            input_config = InputConfig(...)\n            output_config = OutputConfig(...)\n            state_manager = StateManager(...)\n            bolt = Bolt(input_config, output_config, state_manager)\n        Args:\n            input_config (InputConfig): The input configuration.\n            output_config (OutputConfig): The output configuration.\n            state_manager (StateManager): The state manager.\n        \"\"\"\nsuper().__init__()\nself.input_config = input_config\nself.output_config = output_config\nself.state_manager = state_manager\nself.log = logging.getLogger(self.__class__.__name__)\ndef __call__(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n        Execute a method locally and manage the state.\n        Args:\n            method_name (str): The name of the method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n                Keyword Arguments:\n                    - Additional keyword arguments specific to the method.\n        Returns:\n            Any: The result of the method.\n        \"\"\"\ntry:\n# Get the type of state manager\nstate_type = self.state_manager.get_state(self.id)\n# Save the current set of class variables to the state manager\nself.state_manager.set_state(self.id, {})\n# Copy input data to local or connect to kafka and pass on the details\nif type(self.input_config) is BatchInputConfig:\nself.input_config.copy_from_remote()\ninput_folder = self.input_config.get()\nkwargs[\"input_folder\"] = input_folder\nelif type(self.input_config) is StreamingInputConfig:\nkafka_consumer = self.input_config.get()\nkwargs[\"kafka_consumer\"] = kafka_consumer\n# Execute the task's method\nresult = self.execute(method_name, *args, **kwargs)\n# Flush the output config\nself.output_config.flush()\n# Store the state as successful in the state manager\nstate = {}\nstate[\"status\"] = \"success\"\nself.state_manager.set_state(self.id, state)\nreturn result\nexcept Exception as e:\nstate = {}\nstate[\"status\"] = \"failed\"\nself.state_manager.set_state(self.id, state)\nself.log.exception(f\"Failed to execute method '{method_name}': {e}\")\nraise\n@staticmethod\ndef create(klass: type, input_type: str, output_type: str, state_type: str, **kwargs) -&gt; \"Bolt\":\n\"\"\"\n        Create a bolt of a specific type.\n        This static method is used to create a bolt of a specific type. It takes in an input type,\n        an output type, a state type, and additional keyword arguments for initializing the bolt.\n        The method creates the input config, output config, and state manager based on the provided types,\n        and then creates and returns a bolt using these configurations.\n        Args:\n            klass (type): The Bolt class to create.\n            input_type (str): The type of input config (\"batch\" or \"streaming\").\n            output_type (str): The type of output config (\"batch\" or \"streaming\").\n            state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n            **kwargs: Additional keyword arguments for initializing the bolt.\n                Keyword Arguments:\n                    Batch input config:\n                    - input_folder (str): The input folder argument.\n                    - input_s3_bucket (str): The input bucket argument.\n                    - input_s3_folder (str): The input S3 folder argument.\n                    Batch outupt config:\n                    - output_folder (str): The output folder argument.\n                    - output_s3_bucket (str): The output bucket argument.\n                    - output_s3_folder (str): The output S3 folder argument.\n                    Streaming input config:\n                    - input_kafka_cluster_connection_string (str): The input Kafka servers argument.\n                    - input_kafka_topic (str): The input kafka topic argument.\n                    - input_kafka_consumer_group_id (str): The Kafka consumer group id.\n                    Streaming output config:\n                    - output_kafka_cluster_connection_string (str): The output Kafka servers argument.\n                    - output_kafka_topic (str): The output kafka topic argument.\n                    Redis state manager config:\n                    - redis_host (str): The Redis host argument.\n                    - redis_port (str): The Redis port argument.\n                    - redis_db (str): The Redis database argument.\n                    Postgres state manager config:\n                    - postgres_host (str): The PostgreSQL host argument.\n                    - postgres_port (str): The PostgreSQL port argument.\n                    - postgres_user (str): The PostgreSQL user argument.\n                    - postgres_password (str): The PostgreSQL password argument.\n                    - postgres_database (str): The PostgreSQL database argument.\n                    - postgres_table (str): The PostgreSQL table argument.\n                    DynamoDB state manager config:\n                    - dynamodb_table_name (str): The DynamoDB table name argument.\n                    - dynamodb_region_name (str): The DynamoDB region name argument.\n        Returns:\n            Bolt: The created bolt.\n        Raises:\n            ValueError: If an invalid input type, output type, or state type is provided.\n        \"\"\"\n# Create the input config\ninput_config: BatchInputConfig | StreamingInputConfig\nif input_type == \"batch\":\ninput_config = BatchInputConfig(\ninput_folder=kwargs[\"input_folder\"] if \"input_folder\" in kwargs else tempfile.mkdtemp(),\nbucket=kwargs[\"input_s3_bucket\"] if \"input_s3_bucket\" in kwargs else None,\ns3_folder=kwargs[\"input_s3_folder\"] if \"input_s3_folder\" in kwargs else None,\n)\nelif input_type == \"streaming\":\ninput_config = StreamingInputConfig(\ninput_topic=kwargs[\"input_kafka_topic\"] if \"input_kafka_topic\" in kwargs else None,\nkafka_cluster_connection_string=kwargs[\"input_kafka_cluster_connection_string\"]\nif \"input_kafka_cluster_connection_string\" in kwargs\nelse None,\ngroup_id=kwargs[\"input_kafka_consumer_group_id\"] if \"input_kafka_consumer_group_id\" in kwargs else None,\n)\nelse:\nraise ValueError(f\"Invalid input type: {input_type}\")\n# Create the output config\noutput_config: BatchOutputConfig | StreamingOutputConfig\nif output_type == \"batch\":\noutput_config = BatchOutputConfig(\noutput_folder=kwargs[\"output_folder\"] if \"output_folder\" in kwargs else tempfile.mkdtemp(),\nbucket=kwargs[\"output_s3_bucket\"] if \"output_s3_bucket\" in kwargs else tempfile.mkdtemp(),\ns3_folder=kwargs[\"output_s3_folder\"] if \"output_s3_folder\" in kwargs else tempfile.mkdtemp(),\n)\nelif output_type == \"streaming\":\noutput_config = StreamingOutputConfig(\nkwargs[\"output_kafka_topic\"] if \"output_kafka_topic\" in kwargs else None,\nkwargs[\"output_kafka_cluster_connection_string\"]\nif \"output_kafka_cluster_connection_string\" in kwargs\nelse None,\n)\nelse:\nraise ValueError(f\"Invalid output type: {output_type}\")\n# Create the state manager\nstate_manager: StateManager\nif state_type == \"in_memory\":\nstate_manager = InMemoryStateManager()\nelif state_type == \"redis\":\nstate_manager = RedisStateManager(\nhost=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None,\nport=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None,\ndb=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None,\n)\nelif state_type == \"postgres\":\nstate_manager = PostgresStateManager(\nhost=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None,\nport=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None,\nuser=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None,\npassword=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None,\ndatabase=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None,\ntable=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None,\n)\nelif state_type == \"dynamodb\":\nstate_manager = DynamoDBStateManager(\ntable_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None,\nregion_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None,\n)\nelse:\nraise ValueError(f\"Invalid state type: {state_type}\")\n# Create the bolt\nbolt = klass(\ninput_config=input_config,\noutput_config=output_config,\nstate_manager=state_manager,\n**kwargs,\n)\nreturn bolt\n</code></pre>"},{"location":"core/core_bolt/#core.bolt.Bolt.__call__","title":"<code>__call__(method_name, *args, **kwargs)</code>","text":"<p>Execute a method locally and manage the state.</p> <p>Parameters:</p> Name Type Description Default <code>method_name</code> <code>str</code> <p>The name of the method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method. Keyword Arguments:     - Additional keyword arguments specific to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the method.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py</code> <pre><code>def __call__(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n    Execute a method locally and manage the state.\n    Args:\n        method_name (str): The name of the method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n            Keyword Arguments:\n                - Additional keyword arguments specific to the method.\n    Returns:\n        Any: The result of the method.\n    \"\"\"\ntry:\n# Get the type of state manager\nstate_type = self.state_manager.get_state(self.id)\n# Save the current set of class variables to the state manager\nself.state_manager.set_state(self.id, {})\n# Copy input data to local or connect to kafka and pass on the details\nif type(self.input_config) is BatchInputConfig:\nself.input_config.copy_from_remote()\ninput_folder = self.input_config.get()\nkwargs[\"input_folder\"] = input_folder\nelif type(self.input_config) is StreamingInputConfig:\nkafka_consumer = self.input_config.get()\nkwargs[\"kafka_consumer\"] = kafka_consumer\n# Execute the task's method\nresult = self.execute(method_name, *args, **kwargs)\n# Flush the output config\nself.output_config.flush()\n# Store the state as successful in the state manager\nstate = {}\nstate[\"status\"] = \"success\"\nself.state_manager.set_state(self.id, state)\nreturn result\nexcept Exception as e:\nstate = {}\nstate[\"status\"] = \"failed\"\nself.state_manager.set_state(self.id, state)\nself.log.exception(f\"Failed to execute method '{method_name}': {e}\")\nraise\n</code></pre>"},{"location":"core/core_bolt/#core.bolt.Bolt.__init__","title":"<code>__init__(input_config, output_config, state_manager, **kwargs)</code>","text":"<p>The <code>Bolt</code> class is a base class for all bolts in the given context. It inherits from the <code>Task</code> class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and input and output configurations for batch or streaming data.</p> <p>The <code>Bolt</code> class uses the <code>InputConfig</code>, <code>OutputConfig</code> and <code>StateManager</code> classes, which are abstract base classes for managing input configurations, output configurations and states, respectively. The <code>InputConfig</code> and <code>OutputConfig</code> classes each have two subclasses: <code>StreamingInputConfig</code>, <code>BatchInputConfig</code>, <code>StreamingOutputConfig</code> and <code>BatchOutputConfig</code>, which manage streaming and batch input and output configurations, respectively. The <code>StateManager</code> class is used to get and set state, and it has several subclasses for different types of state managers.</p> <p>The <code>Bolt</code> class also uses the <code>ECSManager</code> and <code>K8sManager</code> classes in the <code>execute_remote</code> method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively.</p> Usage <ul> <li>Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object.</li> <li>The InputConfig object specifies the input configuration for the bolt.</li> <li>The OutputConfig object specifies the output configuration for the bolt.</li> <li>The StateManager object handles the management of the bolt's state.</li> </ul> Example <p>input_config = InputConfig(...) output_config = OutputConfig(...) state_manager = StateManager(...) bolt = Bolt(input_config, output_config, state_manager)</p> <p>Parameters:</p> Name Type Description Default <code>input_config</code> <code>InputConfig</code> <p>The input configuration.</p> required <code>output_config</code> <code>OutputConfig</code> <p>The output configuration.</p> required <code>state_manager</code> <code>StateManager</code> <p>The state manager.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py</code> <pre><code>def __init__(\nself,\ninput_config: InputConfig,\noutput_config: OutputConfig,\nstate_manager: StateManager,\n**kwargs,\n) -&gt; None:\n\"\"\"\n    The `Bolt` class is a base class for all bolts in the given context.\n    It inherits from the `Task` class and provides methods for executing tasks\n    both locally and remotely, as well as managing their state, with state management\n    options including in-memory, Redis, PostgreSQL, and DynamoDB,\n    and input and output configurations for batch or streaming data.\n    The `Bolt` class uses the `InputConfig`, `OutputConfig` and `StateManager` classes, which are abstract base\n    classes for managing input configurations, output configurations and states, respectively. The `InputConfig` and\n    `OutputConfig` classes each have two subclasses: `StreamingInputConfig`, `BatchInputConfig`, `StreamingOutputConfig`\n    and `BatchOutputConfig`, which manage streaming and batch input and output configurations, respectively.\n    The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers.\n    The `Bolt` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method,\n    which are used to manage tasks on Amazon ECS and Kubernetes, respectively.\n    Usage:\n        - Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object.\n        - The InputConfig object specifies the input configuration for the bolt.\n        - The OutputConfig object specifies the output configuration for the bolt.\n        - The StateManager object handles the management of the bolt's state.\n    Example:\n        input_config = InputConfig(...)\n        output_config = OutputConfig(...)\n        state_manager = StateManager(...)\n        bolt = Bolt(input_config, output_config, state_manager)\n    Args:\n        input_config (InputConfig): The input configuration.\n        output_config (OutputConfig): The output configuration.\n        state_manager (StateManager): The state manager.\n    \"\"\"\nsuper().__init__()\nself.input_config = input_config\nself.output_config = output_config\nself.state_manager = state_manager\nself.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/core_bolt/#core.bolt.Bolt.create","title":"<code>create(klass, input_type, output_type, state_type, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a bolt of a specific type.</p> <p>This static method is used to create a bolt of a specific type. It takes in an input type, an output type, a state type, and additional keyword arguments for initializing the bolt.</p> <p>The method creates the input config, output config, and state manager based on the provided types, and then creates and returns a bolt using these configurations.</p> <p>Parameters:</p> Name Type Description Default <code>klass</code> <code>type</code> <p>The Bolt class to create.</p> required <code>input_type</code> <code>str</code> <p>The type of input config (\"batch\" or \"streaming\").</p> required <code>output_type</code> <code>str</code> <p>The type of output config (\"batch\" or \"streaming\").</p> required <code>state_type</code> <code>str</code> <p>The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").</p> required <code>**kwargs</code> <p>Additional keyword arguments for initializing the bolt. Keyword Arguments:     Batch input config:     - input_folder (str): The input folder argument.     - input_s3_bucket (str): The input bucket argument.     - input_s3_folder (str): The input S3 folder argument.     Batch outupt config:     - output_folder (str): The output folder argument.     - output_s3_bucket (str): The output bucket argument.     - output_s3_folder (str): The output S3 folder argument.     Streaming input config:     - input_kafka_cluster_connection_string (str): The input Kafka servers argument.     - input_kafka_topic (str): The input kafka topic argument.     - input_kafka_consumer_group_id (str): The Kafka consumer group id.     Streaming output config:     - output_kafka_cluster_connection_string (str): The output Kafka servers argument.     - output_kafka_topic (str): The output kafka topic argument.     Redis state manager config:     - redis_host (str): The Redis host argument.     - redis_port (str): The Redis port argument.     - redis_db (str): The Redis database argument.     Postgres state manager config:     - postgres_host (str): The PostgreSQL host argument.     - postgres_port (str): The PostgreSQL port argument.     - postgres_user (str): The PostgreSQL user argument.     - postgres_password (str): The PostgreSQL password argument.     - postgres_database (str): The PostgreSQL database argument.     - postgres_table (str): The PostgreSQL table argument.     DynamoDB state manager config:     - dynamodb_table_name (str): The DynamoDB table name argument.     - dynamodb_region_name (str): The DynamoDB region name argument.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Bolt</code> <code>Bolt</code> <p>The created bolt.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid input type, output type, or state type is provided.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py</code> <pre><code>@staticmethod\ndef create(klass: type, input_type: str, output_type: str, state_type: str, **kwargs) -&gt; \"Bolt\":\n\"\"\"\n    Create a bolt of a specific type.\n    This static method is used to create a bolt of a specific type. It takes in an input type,\n    an output type, a state type, and additional keyword arguments for initializing the bolt.\n    The method creates the input config, output config, and state manager based on the provided types,\n    and then creates and returns a bolt using these configurations.\n    Args:\n        klass (type): The Bolt class to create.\n        input_type (str): The type of input config (\"batch\" or \"streaming\").\n        output_type (str): The type of output config (\"batch\" or \"streaming\").\n        state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n        **kwargs: Additional keyword arguments for initializing the bolt.\n            Keyword Arguments:\n                Batch input config:\n                - input_folder (str): The input folder argument.\n                - input_s3_bucket (str): The input bucket argument.\n                - input_s3_folder (str): The input S3 folder argument.\n                Batch outupt config:\n                - output_folder (str): The output folder argument.\n                - output_s3_bucket (str): The output bucket argument.\n                - output_s3_folder (str): The output S3 folder argument.\n                Streaming input config:\n                - input_kafka_cluster_connection_string (str): The input Kafka servers argument.\n                - input_kafka_topic (str): The input kafka topic argument.\n                - input_kafka_consumer_group_id (str): The Kafka consumer group id.\n                Streaming output config:\n                - output_kafka_cluster_connection_string (str): The output Kafka servers argument.\n                - output_kafka_topic (str): The output kafka topic argument.\n                Redis state manager config:\n                - redis_host (str): The Redis host argument.\n                - redis_port (str): The Redis port argument.\n                - redis_db (str): The Redis database argument.\n                Postgres state manager config:\n                - postgres_host (str): The PostgreSQL host argument.\n                - postgres_port (str): The PostgreSQL port argument.\n                - postgres_user (str): The PostgreSQL user argument.\n                - postgres_password (str): The PostgreSQL password argument.\n                - postgres_database (str): The PostgreSQL database argument.\n                - postgres_table (str): The PostgreSQL table argument.\n                DynamoDB state manager config:\n                - dynamodb_table_name (str): The DynamoDB table name argument.\n                - dynamodb_region_name (str): The DynamoDB region name argument.\n    Returns:\n        Bolt: The created bolt.\n    Raises:\n        ValueError: If an invalid input type, output type, or state type is provided.\n    \"\"\"\n# Create the input config\ninput_config: BatchInputConfig | StreamingInputConfig\nif input_type == \"batch\":\ninput_config = BatchInputConfig(\ninput_folder=kwargs[\"input_folder\"] if \"input_folder\" in kwargs else tempfile.mkdtemp(),\nbucket=kwargs[\"input_s3_bucket\"] if \"input_s3_bucket\" in kwargs else None,\ns3_folder=kwargs[\"input_s3_folder\"] if \"input_s3_folder\" in kwargs else None,\n)\nelif input_type == \"streaming\":\ninput_config = StreamingInputConfig(\ninput_topic=kwargs[\"input_kafka_topic\"] if \"input_kafka_topic\" in kwargs else None,\nkafka_cluster_connection_string=kwargs[\"input_kafka_cluster_connection_string\"]\nif \"input_kafka_cluster_connection_string\" in kwargs\nelse None,\ngroup_id=kwargs[\"input_kafka_consumer_group_id\"] if \"input_kafka_consumer_group_id\" in kwargs else None,\n)\nelse:\nraise ValueError(f\"Invalid input type: {input_type}\")\n# Create the output config\noutput_config: BatchOutputConfig | StreamingOutputConfig\nif output_type == \"batch\":\noutput_config = BatchOutputConfig(\noutput_folder=kwargs[\"output_folder\"] if \"output_folder\" in kwargs else tempfile.mkdtemp(),\nbucket=kwargs[\"output_s3_bucket\"] if \"output_s3_bucket\" in kwargs else tempfile.mkdtemp(),\ns3_folder=kwargs[\"output_s3_folder\"] if \"output_s3_folder\" in kwargs else tempfile.mkdtemp(),\n)\nelif output_type == \"streaming\":\noutput_config = StreamingOutputConfig(\nkwargs[\"output_kafka_topic\"] if \"output_kafka_topic\" in kwargs else None,\nkwargs[\"output_kafka_cluster_connection_string\"]\nif \"output_kafka_cluster_connection_string\" in kwargs\nelse None,\n)\nelse:\nraise ValueError(f\"Invalid output type: {output_type}\")\n# Create the state manager\nstate_manager: StateManager\nif state_type == \"in_memory\":\nstate_manager = InMemoryStateManager()\nelif state_type == \"redis\":\nstate_manager = RedisStateManager(\nhost=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None,\nport=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None,\ndb=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None,\n)\nelif state_type == \"postgres\":\nstate_manager = PostgresStateManager(\nhost=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None,\nport=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None,\nuser=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None,\npassword=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None,\ndatabase=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None,\ntable=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None,\n)\nelif state_type == \"dynamodb\":\nstate_manager = DynamoDBStateManager(\ntable_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None,\nregion_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None,\n)\nelse:\nraise ValueError(f\"Invalid state type: {state_type}\")\n# Create the bolt\nbolt = klass(\ninput_config=input_config,\noutput_config=output_config,\nstate_manager=state_manager,\n**kwargs,\n)\nreturn bolt\n</code></pre>"},{"location":"core/core_data_batch_input/","title":"Batch data input","text":"<p>Batch input manager</p>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig","title":"<code>BatchInputConfig</code>","text":"<p>             Bases: <code>InputConfig</code></p> <p>\ud83d\udcc1 BatchInputConfig: Manages batch input configurations.</p> <p>Attributes:</p> Name Type Description <code>input_folder</code> <code>str</code> <p>Folder to read input files.</p> <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> <code>s3_folder</code> <code>str</code> <p>Folder within the S3 bucket.</p> <p>Usage: <pre><code>config = BatchInputConfig(\"/path/to/input\", \"my_bucket\", \"s3/folder\")\nfiles = config.list_files()\ncontent = config.read_file(\"example.txt\")\n</code></pre></p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>class BatchInputConfig(InputConfig):\n\"\"\"\n    \ud83d\udcc1 BatchInputConfig: Manages batch input configurations.\n    Attributes:\n        input_folder (str): Folder to read input files.\n        bucket (str): S3 bucket name.\n        s3_folder (str): Folder within the S3 bucket.\n    Usage:\n    ```python\n    config = BatchInputConfig(\"/path/to/input\", \"my_bucket\", \"s3/folder\")\n    files = config.list_files()\n    content = config.read_file(\"example.txt\")\n    ```\n    \"\"\"\ndef __init__(self, input_folder: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n        Initialize a new batch input configuration.\n        Args:\n            input_folder (str): Folder to read input files.\n            bucket (str): S3 bucket name.\n            s3_folder (str): Folder within the S3 bucket.\n        \"\"\"\nself.input_folder = input_folder\nself.bucket = bucket\nself.s3_folder = s3_folder\nself.log = logging.getLogger(__name__)\ndef get(self) -&gt; str:\n\"\"\"\n        \ud83d\udccd Get the input folder location.\n        Returns:\n            str: The input folder location.\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\nif self.input_folder:\nreturn self.input_folder\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\ndef copy_from_remote(self) -&gt; None:\n\"\"\"\n        \ud83d\udd04 Copy contents from a given S3 bucket and location to the input folder.\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\nif self.input_folder:\ns3 = boto3.resource(\"s3\")\n_bucket = s3.Bucket(self.bucket)\nprefix = self.s3_folder if self.s3_folder.endswith(\"/\") else self.s3_folder + \"/\"\nfor obj in _bucket.objects.filter(Prefix=prefix):\nif not os.path.exists(os.path.dirname(f\"{self.input_folder}/{obj.key}\")):\nos.makedirs(os.path.dirname(f\"{self.input_folder}/{obj.key}\"))\n_bucket.download_file(obj.key, f\"{self.input_folder}/{obj.key}\")\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\ndef list_files(self) -&gt; list:\n\"\"\"\n        \ud83d\udcdc List all files in the input folder.\n        Returns:\n            list: A list of file paths.\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\nif self.input_folder:\nreturn [\nos.path.join(self.input_folder, f)\nfor f in os.listdir(self.input_folder)\nif os.path.isfile(os.path.join(self.input_folder, f))\n]\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\ndef read_file(self, filename: str) -&gt; str:\n\"\"\"\n        \ud83d\udcd6 Read a file from the input folder.\n        Args:\n            filename (str): The name of the file.\n        Returns:\n            str: The contents of the file.\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\nif self.input_folder:\nwith open(os.path.join(self.input_folder, filename), \"r\") as file:\nreturn file.read()\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\ndef delete_file(self, filename: str) -&gt; None:\n\"\"\"\n        \ud83d\uddd1\ufe0f Delete a file from the input folder.\n        Args:\n            filename (str): The name of the file.\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\nif self.input_folder:\nos.remove(os.path.join(self.input_folder, filename))\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\ndef copy_to_remote(self, filename: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n        \u2601\ufe0f Copy a file from the input folder to an S3 bucket.\n        Args:\n            filename (str): The name of the file.\n            bucket (str): The name of the S3 bucket.\n            s3_folder (str): The folder in the S3 bucket.\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\nif self.input_folder:\ns3 = boto3.resource(\"s3\")\ns3.meta.client.upload_file(\nos.path.join(self.input_folder, filename),\nbucket,\nos.path.join(s3_folder, filename),\n)\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.__init__","title":"<code>__init__(input_folder, bucket, s3_folder)</code>","text":"<p>Initialize a new batch input configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_folder</code> <code>str</code> <p>Folder to read input files.</p> required <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>s3_folder</code> <code>str</code> <p>Folder within the S3 bucket.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def __init__(self, input_folder: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n    Initialize a new batch input configuration.\n    Args:\n        input_folder (str): Folder to read input files.\n        bucket (str): S3 bucket name.\n        s3_folder (str): Folder within the S3 bucket.\n    \"\"\"\nself.input_folder = input_folder\nself.bucket = bucket\nself.s3_folder = s3_folder\nself.log = logging.getLogger(__name__)\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.copy_from_remote","title":"<code>copy_from_remote()</code>","text":"<p>\ud83d\udd04 Copy contents from a given S3 bucket and location to the input folder.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def copy_from_remote(self) -&gt; None:\n\"\"\"\n    \ud83d\udd04 Copy contents from a given S3 bucket and location to the input folder.\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\nif self.input_folder:\ns3 = boto3.resource(\"s3\")\n_bucket = s3.Bucket(self.bucket)\nprefix = self.s3_folder if self.s3_folder.endswith(\"/\") else self.s3_folder + \"/\"\nfor obj in _bucket.objects.filter(Prefix=prefix):\nif not os.path.exists(os.path.dirname(f\"{self.input_folder}/{obj.key}\")):\nos.makedirs(os.path.dirname(f\"{self.input_folder}/{obj.key}\"))\n_bucket.download_file(obj.key, f\"{self.input_folder}/{obj.key}\")\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.copy_to_remote","title":"<code>copy_to_remote(filename, bucket, s3_folder)</code>","text":"<p>\u2601\ufe0f Copy a file from the input folder to an S3 bucket.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file.</p> required <code>bucket</code> <code>str</code> <p>The name of the S3 bucket.</p> required <code>s3_folder</code> <code>str</code> <p>The folder in the S3 bucket.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def copy_to_remote(self, filename: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n    \u2601\ufe0f Copy a file from the input folder to an S3 bucket.\n    Args:\n        filename (str): The name of the file.\n        bucket (str): The name of the S3 bucket.\n        s3_folder (str): The folder in the S3 bucket.\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\nif self.input_folder:\ns3 = boto3.resource(\"s3\")\ns3.meta.client.upload_file(\nos.path.join(self.input_folder, filename),\nbucket,\nos.path.join(s3_folder, filename),\n)\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.delete_file","title":"<code>delete_file(filename)</code>","text":"<p>\ud83d\uddd1\ufe0f Delete a file from the input folder.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def delete_file(self, filename: str) -&gt; None:\n\"\"\"\n    \ud83d\uddd1\ufe0f Delete a file from the input folder.\n    Args:\n        filename (str): The name of the file.\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\nif self.input_folder:\nos.remove(os.path.join(self.input_folder, filename))\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.get","title":"<code>get()</code>","text":"<p>\ud83d\udccd Get the input folder location.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The input folder location.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def get(self) -&gt; str:\n\"\"\"\n    \ud83d\udccd Get the input folder location.\n    Returns:\n        str: The input folder location.\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\nif self.input_folder:\nreturn self.input_folder\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.list_files","title":"<code>list_files()</code>","text":"<p>\ud83d\udcdc List all files in the input folder.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of file paths.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def list_files(self) -&gt; list:\n\"\"\"\n    \ud83d\udcdc List all files in the input folder.\n    Returns:\n        list: A list of file paths.\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\nif self.input_folder:\nreturn [\nos.path.join(self.input_folder, f)\nfor f in os.listdir(self.input_folder)\nif os.path.isfile(os.path.join(self.input_folder, f))\n]\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.read_file","title":"<code>read_file(filename)</code>","text":"<p>\ud83d\udcd6 Read a file from the input folder.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The contents of the file.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def read_file(self, filename: str) -&gt; str:\n\"\"\"\n    \ud83d\udcd6 Read a file from the input folder.\n    Args:\n        filename (str): The name of the file.\n    Returns:\n        str: The contents of the file.\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\nif self.input_folder:\nwith open(os.path.join(self.input_folder, filename), \"r\") as file:\nreturn file.read()\nelse:\nself.log.exception(\"\ud83d\udeab No input folder specified.\")\nraise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_output/","title":"Batch data output","text":"<p>Batch output manager</p>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig","title":"<code>BatchOutputConfig</code>","text":"<p>             Bases: <code>OutputConfig</code></p> <p>\ud83d\udcc1 BatchOutputConfig: Manages batch output configurations.</p> <p>Attributes:</p> Name Type Description <code>output_folder</code> <code>str</code> <p>Folder to save output files.</p> <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> <code>s3_folder</code> <code>str</code> <p>Folder within the S3 bucket.</p> <p>Usage: <pre><code>config = BatchOutputConfig(\"/path/to/output\", \"my_bucket\", \"s3/folder\")\nconfig.save({\"key\": \"value\"}, \"example.json\")\nfiles = config.list_files()\ncontent = config.read_file(\"example.json\")\n</code></pre></p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>class BatchOutputConfig(OutputConfig):\n\"\"\"\n    \ud83d\udcc1 BatchOutputConfig: Manages batch output configurations.\n    Attributes:\n        output_folder (str): Folder to save output files.\n        bucket (str): S3 bucket name.\n        s3_folder (str): Folder within the S3 bucket.\n    Usage:\n    ```python\n    config = BatchOutputConfig(\"/path/to/output\", \"my_bucket\", \"s3/folder\")\n    config.save({\"key\": \"value\"}, \"example.json\")\n    files = config.list_files()\n    content = config.read_file(\"example.json\")\n    ```\n    \"\"\"\ndef __init__(self, output_folder: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n        Initialize a new batch output configuration.\n        Args:\n            output_folder (str): Folder to save output files.\n            bucket (str): S3 bucket name.\n            s3_folder (str): Folder within the S3 bucket.\n        \"\"\"\nself.output_folder = output_folder\nself.bucket = bucket\nself.s3_folder = s3_folder\nself.log = logging.getLogger(self.__class__.__name__)\ndef save(self, data: Any, filename: str) -&gt; None:\n\"\"\"\n        \ud83d\udcbe Save data to a file in the output folder.\n        Args:\n            data (Any): The data to save.\n            filename (str): The filename to use when saving the data to a file.\n        \"\"\"\ntry:\nwith open(os.path.join(self.output_folder, filename), \"w\") as f:\nf.write(json.dumps(data))\nself.log.debug(f\"\u2705 Wrote the data into {self.output_folder}/{filename}.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to write data to file: {e}\")\nraise\ndef copy_to_remote(self) -&gt; None:\n\"\"\"\n        \u2601\ufe0f Recursively copy all files and directories from the output folder to a given S3 bucket and folder.\n        \"\"\"\ns3 = boto3.client(\"s3\")\ntry:\nfor root, _, files in os.walk(self.output_folder):\nfor filename in files:\nlocal_path = os.path.join(root, filename)\nrelative_path = os.path.relpath(local_path, self.output_folder)\ns3_key = os.path.join(self.s3_folder, relative_path)\ns3.upload_file(local_path, self.bucket, s3_key)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to copy files to S3: {e}\")\nraise\ndef flush(self) -&gt; None:\n\"\"\"\n        \ud83d\udd04 Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder.\n        \"\"\"\nself.copy_to_remote()\ndef list_files(self) -&gt; List[str]:\n\"\"\"\n        \ud83d\udcdc List all files in the output folder.\n        Returns:\n            list: The list of files in the output folder.\n        \"\"\"\nreturn [\nos.path.join(self.output_folder, f)\nfor f in os.listdir(self.output_folder)\nif os.path.isfile(os.path.join(self.output_folder, f))\n]\ndef read_file(self, filename: str) -&gt; str:\n\"\"\"\n        \ud83d\udcd6 Read a file from the output folder.\n        Args:\n            filename (str): The name of the file to read.\n        Returns:\n            str: The contents of the file.\n        \"\"\"\nwith open(os.path.join(self.output_folder, filename), \"r\") as f:\nreturn f.read()\ndef delete_file(self, filename: str) -&gt; None:\n\"\"\"\n        \ud83d\uddd1\ufe0f Delete a file from the output folder.\n        Args:\n            filename (str): The name of the file to delete.\n        \"\"\"\nos.remove(os.path.join(self.output_folder, filename))\ndef copy_file_to_remote(self, filename: str) -&gt; None:\n\"\"\"\n        \u2601\ufe0f Copy a specific file from the output folder to the S3 bucket.\n        Args:\n            filename (str): The name of the file to copy.\n        \"\"\"\ns3 = boto3.client(\"s3\")\ntry:\ns3.upload_file(\nos.path.join(self.output_folder, filename),\nself.bucket,\nos.path.join(self.s3_folder, filename),\n)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to copy file to S3: {e}\")\nraise\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.__init__","title":"<code>__init__(output_folder, bucket, s3_folder)</code>","text":"<p>Initialize a new batch output configuration.</p> <p>Parameters:</p> Name Type Description Default <code>output_folder</code> <code>str</code> <p>Folder to save output files.</p> required <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>s3_folder</code> <code>str</code> <p>Folder within the S3 bucket.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def __init__(self, output_folder: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n    Initialize a new batch output configuration.\n    Args:\n        output_folder (str): Folder to save output files.\n        bucket (str): S3 bucket name.\n        s3_folder (str): Folder within the S3 bucket.\n    \"\"\"\nself.output_folder = output_folder\nself.bucket = bucket\nself.s3_folder = s3_folder\nself.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.copy_file_to_remote","title":"<code>copy_file_to_remote(filename)</code>","text":"<p>\u2601\ufe0f Copy a specific file from the output folder to the S3 bucket.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to copy.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def copy_file_to_remote(self, filename: str) -&gt; None:\n\"\"\"\n    \u2601\ufe0f Copy a specific file from the output folder to the S3 bucket.\n    Args:\n        filename (str): The name of the file to copy.\n    \"\"\"\ns3 = boto3.client(\"s3\")\ntry:\ns3.upload_file(\nos.path.join(self.output_folder, filename),\nself.bucket,\nos.path.join(self.s3_folder, filename),\n)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to copy file to S3: {e}\")\nraise\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.copy_to_remote","title":"<code>copy_to_remote()</code>","text":"<p>\u2601\ufe0f Recursively copy all files and directories from the output folder to a given S3 bucket and folder.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def copy_to_remote(self) -&gt; None:\n\"\"\"\n    \u2601\ufe0f Recursively copy all files and directories from the output folder to a given S3 bucket and folder.\n    \"\"\"\ns3 = boto3.client(\"s3\")\ntry:\nfor root, _, files in os.walk(self.output_folder):\nfor filename in files:\nlocal_path = os.path.join(root, filename)\nrelative_path = os.path.relpath(local_path, self.output_folder)\ns3_key = os.path.join(self.s3_folder, relative_path)\ns3.upload_file(local_path, self.bucket, s3_key)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to copy files to S3: {e}\")\nraise\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.delete_file","title":"<code>delete_file(filename)</code>","text":"<p>\ud83d\uddd1\ufe0f Delete a file from the output folder.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to delete.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def delete_file(self, filename: str) -&gt; None:\n\"\"\"\n    \ud83d\uddd1\ufe0f Delete a file from the output folder.\n    Args:\n        filename (str): The name of the file to delete.\n    \"\"\"\nos.remove(os.path.join(self.output_folder, filename))\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.flush","title":"<code>flush()</code>","text":"<p>\ud83d\udd04 Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def flush(self) -&gt; None:\n\"\"\"\n    \ud83d\udd04 Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder.\n    \"\"\"\nself.copy_to_remote()\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.list_files","title":"<code>list_files()</code>","text":"<p>\ud83d\udcdc List all files in the output folder.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>List[str]</code> <p>The list of files in the output folder.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def list_files(self) -&gt; List[str]:\n\"\"\"\n    \ud83d\udcdc List all files in the output folder.\n    Returns:\n        list: The list of files in the output folder.\n    \"\"\"\nreturn [\nos.path.join(self.output_folder, f)\nfor f in os.listdir(self.output_folder)\nif os.path.isfile(os.path.join(self.output_folder, f))\n]\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.read_file","title":"<code>read_file(filename)</code>","text":"<p>\ud83d\udcd6 Read a file from the output folder.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to read.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The contents of the file.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def read_file(self, filename: str) -&gt; str:\n\"\"\"\n    \ud83d\udcd6 Read a file from the output folder.\n    Args:\n        filename (str): The name of the file to read.\n    Returns:\n        str: The contents of the file.\n    \"\"\"\nwith open(os.path.join(self.output_folder, filename), \"r\") as f:\nreturn f.read()\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.save","title":"<code>save(data, filename)</code>","text":"<p>\ud83d\udcbe Save data to a file in the output folder.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to save.</p> required <code>filename</code> <code>str</code> <p>The filename to use when saving the data to a file.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def save(self, data: Any, filename: str) -&gt; None:\n\"\"\"\n    \ud83d\udcbe Save data to a file in the output folder.\n    Args:\n        data (Any): The data to save.\n        filename (str): The filename to use when saving the data to a file.\n    \"\"\"\ntry:\nwith open(os.path.join(self.output_folder, filename), \"w\") as f:\nf.write(json.dumps(data))\nself.log.debug(f\"\u2705 Wrote the data into {self.output_folder}/{filename}.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to write data to file: {e}\")\nraise\n</code></pre>"},{"location":"core/core_data_input/","title":"Data input","text":"<p>Input manager base class</p>"},{"location":"core/core_data_input/#core.data.input.InputConfig","title":"<code>InputConfig</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class for managing input configurations.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/input.py</code> <pre><code>class InputConfig(ABC):\n\"\"\"\n    Abstract class for managing input configurations.\n    \"\"\"\n@abstractmethod\ndef get(self):\n\"\"\"\n        Abstract method to get data from the input source.\n        Returns:\n            The data from the input source.\n        \"\"\"\npass\n</code></pre>"},{"location":"core/core_data_input/#core.data.input.InputConfig.get","title":"<code>get()</code>  <code>abstractmethod</code>","text":"<p>Abstract method to get data from the input source.</p> <p>Returns:</p> Type Description <p>The data from the input source.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/input.py</code> <pre><code>@abstractmethod\ndef get(self):\n\"\"\"\n    Abstract method to get data from the input source.\n    Returns:\n        The data from the input source.\n    \"\"\"\npass\n</code></pre>"},{"location":"core/core_data_output/","title":"Data output","text":"<p>Output manager base class</p>"},{"location":"core/core_data_output/#core.data.output.OutputConfig","title":"<code>OutputConfig</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract base class for managing output configurations.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py</code> <pre><code>class OutputConfig(ABC):\n\"\"\"\n    Abstract base class for managing output configurations.\n    \"\"\"\n@abstractmethod\ndef save(self, data: Any, filename: str):\n\"\"\"\n        Save data to a file or ingest it into a Kafka topic.\n        Args:\n            data (Any): The data to save or ingest.\n            filename (str): The filename to use when saving the data to a file.\n        \"\"\"\npass\n@abstractmethod\ndef flush(self):\n\"\"\"\n        Flush the output. This method should be implemented by subclasses.\n        \"\"\"\npass\n</code></pre>"},{"location":"core/core_data_output/#core.data.output.OutputConfig.flush","title":"<code>flush()</code>  <code>abstractmethod</code>","text":"<p>Flush the output. This method should be implemented by subclasses.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py</code> <pre><code>@abstractmethod\ndef flush(self):\n\"\"\"\n    Flush the output. This method should be implemented by subclasses.\n    \"\"\"\npass\n</code></pre>"},{"location":"core/core_data_output/#core.data.output.OutputConfig.save","title":"<code>save(data, filename)</code>  <code>abstractmethod</code>","text":"<p>Save data to a file or ingest it into a Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to save or ingest.</p> required <code>filename</code> <code>str</code> <p>The filename to use when saving the data to a file.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py</code> <pre><code>@abstractmethod\ndef save(self, data: Any, filename: str):\n\"\"\"\n    Save data to a file or ingest it into a Kafka topic.\n    Args:\n        data (Any): The data to save or ingest.\n        filename (str): The filename to use when saving the data to a file.\n    \"\"\"\npass\n</code></pre>"},{"location":"core/core_data_streaming_input/","title":"Streaming data input","text":"<p>Streaming input manager</p>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig","title":"<code>StreamingInputConfig</code>","text":"<p>             Bases: <code>InputConfig</code></p> <p>\ud83d\udce1 StreamingInputConfig: Manages streaming input configurations.</p> <p>Attributes:</p> Name Type Description <code>input_topic</code> <code>str</code> <p>Kafka topic to consume data.</p> <code>consumer</code> <code>KafkaConsumer</code> <p>Kafka consumer for consuming data.</p> <p>Usage: <pre><code>config = StreamingInputConfig(\"my_topic\", \"localhost:9092\")\nfor message in config.iterator():\nprint(message.value)\n</code></pre></p> <p>Note: - Ensure the Kafka cluster is running and accessible. - Adjust the <code>group_id</code> if needed.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>class StreamingInputConfig(InputConfig):\n\"\"\"\n    \ud83d\udce1 **StreamingInputConfig**: Manages streaming input configurations.\n    Attributes:\n        input_topic (str): Kafka topic to consume data.\n        consumer (KafkaConsumer): Kafka consumer for consuming data.\n    Usage:\n    ```python\n    config = StreamingInputConfig(\"my_topic\", \"localhost:9092\")\n    for message in config.iterator():\n        print(message.value)\n    ```\n    Note:\n    - Ensure the Kafka cluster is running and accessible.\n    - Adjust the `group_id` if needed.\n    \"\"\"\ndef __init__(\nself,\ninput_topic: str,\nkafka_cluster_connection_string: str,\ngroup_id: str = \"geniusrise\",\n) -&gt; None:\n\"\"\"\n        Initialize a new streaming input configuration.\n        Args:\n            input_topic (str): Kafka topic to consume data.\n            kafka_cluster_connection_string (str): Kafka cluster connection string.\n            group_id (str, optional): Kafka consumer group id. Defaults to \"geniusrise\".\n        \"\"\"\nself.input_topic = input_topic\nself.log = logging.getLogger(self.__class__.__name__)\ntry:\nself.consumer = KafkaConsumer(\nself.input_topic,\nbootstrap_servers=kafka_cluster_connection_string,\ngroup_id=group_id,\n)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to create Kafka consumer: {e}\")\nraise\nself.consumer = None\ndef get(self) -&gt; KafkaConsumer:\n\"\"\"\n        \ud83d\udce5 Get data from the input topic.\n        Returns:\n            KafkaConsumer: The Kafka consumer.\n        Raises:\n            Exception: If no input source or consumer is specified.\n        \"\"\"\nif self.input_topic and self.consumer:\ntry:\nreturn self.consumer\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to consume from Kafka topic {self.input_topic}: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No input source specified.\")\nraise\ndef iterator(self) -&gt; Iterator:\n\"\"\"\n        \ud83d\udd04 Iterator method for yielding data from the Kafka consumer.\n        Yields:\n            Kafka message: The next message from the Kafka consumer.\n        Raises:\n            Exception: If no Kafka consumer is available.\n        \"\"\"\nif self.consumer:\ntry:\nfor message in self.consumer:\nyield message\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to iterate over Kafka consumer: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\nraise\ndef __iter__(self) -&gt; Iterator:\n\"\"\"\n        Make the class iterable.\n        \"\"\"\nreturn self\ndef __next__(self) -&gt; Any:\n\"\"\"\n        Get the next message from the Kafka consumer.\n        Raises:\n            Exception: If no Kafka consumer is available or an error occurs.\n        \"\"\"\nif self.consumer:\ntry:\nreturn next(self.consumer)\nexcept StopIteration:\nraise\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to get next message from Kafka consumer: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\nraise\ndef close(self) -&gt; None:\n\"\"\"\n        \ud83d\udeaa Close the Kafka consumer.\n        Raises:\n            Exception: If an error occurs while closing the consumer.\n        \"\"\"\nif self.consumer:\ntry:\nself.consumer.close()\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to close Kafka consumer: {e}\")\nraise\ndef seek(self, partition: int, offset: int) -&gt; None:\n\"\"\"\n        \ud83d\udd0d Change the position from which the Kafka consumer reads.\n        Args:\n            partition (int): The partition to seek.\n            offset (int): The offset to seek to.\n        Raises:\n            Exception: If an error occurs while seeking.\n        \"\"\"\nif self.consumer:\ntry:\nself.consumer.seek(partition, offset)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to seek Kafka consumer: {e}\")\nraise\ndef commit(self) -&gt; None:\n\"\"\"\n        \u2705 Manually commit offsets.\n        Raises:\n            Exception: If an error occurs while committing offsets.\n        \"\"\"\nif self.consumer:\ntry:\nself.consumer.commit()\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to commit offsets: {e}\")\nraise\ndef filter_messages(self, filter_func: Callable) -&gt; Iterator:\n\"\"\"\n        \ud83d\udd0d Filter messages from the Kafka consumer based on a filter function.\n        Args:\n            filter_func (callable): A function that takes a Kafka message and returns a boolean.\n        Yields:\n            Kafka message: The next message from the Kafka consumer that passes the filter.\n        Raises:\n            Exception: If no Kafka consumer is available or an error occurs.\n        \"\"\"\nif self.consumer:\ntry:\nfor message in self.consumer:\nif filter_func(message):\nyield message\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to filter messages from Kafka consumer: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.__init__","title":"<code>__init__(input_topic, kafka_cluster_connection_string, group_id='geniusrise')</code>","text":"<p>Initialize a new streaming input configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_topic</code> <code>str</code> <p>Kafka topic to consume data.</p> required <code>kafka_cluster_connection_string</code> <code>str</code> <p>Kafka cluster connection string.</p> required <code>group_id</code> <code>str</code> <p>Kafka consumer group id. Defaults to \"geniusrise\".</p> <code>'geniusrise'</code> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def __init__(\nself,\ninput_topic: str,\nkafka_cluster_connection_string: str,\ngroup_id: str = \"geniusrise\",\n) -&gt; None:\n\"\"\"\n    Initialize a new streaming input configuration.\n    Args:\n        input_topic (str): Kafka topic to consume data.\n        kafka_cluster_connection_string (str): Kafka cluster connection string.\n        group_id (str, optional): Kafka consumer group id. Defaults to \"geniusrise\".\n    \"\"\"\nself.input_topic = input_topic\nself.log = logging.getLogger(self.__class__.__name__)\ntry:\nself.consumer = KafkaConsumer(\nself.input_topic,\nbootstrap_servers=kafka_cluster_connection_string,\ngroup_id=group_id,\n)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to create Kafka consumer: {e}\")\nraise\nself.consumer = None\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.__iter__","title":"<code>__iter__()</code>","text":"<p>Make the class iterable.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def __iter__(self) -&gt; Iterator:\n\"\"\"\n    Make the class iterable.\n    \"\"\"\nreturn self\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.__next__","title":"<code>__next__()</code>","text":"<p>Get the next message from the Kafka consumer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka consumer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def __next__(self) -&gt; Any:\n\"\"\"\n    Get the next message from the Kafka consumer.\n    Raises:\n        Exception: If no Kafka consumer is available or an error occurs.\n    \"\"\"\nif self.consumer:\ntry:\nreturn next(self.consumer)\nexcept StopIteration:\nraise\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to get next message from Kafka consumer: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.close","title":"<code>close()</code>","text":"<p>\ud83d\udeaa Close the Kafka consumer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs while closing the consumer.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def close(self) -&gt; None:\n\"\"\"\n    \ud83d\udeaa Close the Kafka consumer.\n    Raises:\n        Exception: If an error occurs while closing the consumer.\n    \"\"\"\nif self.consumer:\ntry:\nself.consumer.close()\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to close Kafka consumer: {e}\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.commit","title":"<code>commit()</code>","text":"<p>\u2705 Manually commit offsets.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs while committing offsets.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def commit(self) -&gt; None:\n\"\"\"\n    \u2705 Manually commit offsets.\n    Raises:\n        Exception: If an error occurs while committing offsets.\n    \"\"\"\nif self.consumer:\ntry:\nself.consumer.commit()\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to commit offsets: {e}\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.filter_messages","title":"<code>filter_messages(filter_func)</code>","text":"<p>\ud83d\udd0d Filter messages from the Kafka consumer based on a filter function.</p> <p>Parameters:</p> Name Type Description Default <code>filter_func</code> <code>callable</code> <p>A function that takes a Kafka message and returns a boolean.</p> required <p>Yields:</p> Type Description <code>Iterator</code> <p>Kafka message: The next message from the Kafka consumer that passes the filter.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka consumer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def filter_messages(self, filter_func: Callable) -&gt; Iterator:\n\"\"\"\n    \ud83d\udd0d Filter messages from the Kafka consumer based on a filter function.\n    Args:\n        filter_func (callable): A function that takes a Kafka message and returns a boolean.\n    Yields:\n        Kafka message: The next message from the Kafka consumer that passes the filter.\n    Raises:\n        Exception: If no Kafka consumer is available or an error occurs.\n    \"\"\"\nif self.consumer:\ntry:\nfor message in self.consumer:\nif filter_func(message):\nyield message\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to filter messages from Kafka consumer: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.get","title":"<code>get()</code>","text":"<p>\ud83d\udce5 Get data from the input topic.</p> <p>Returns:</p> Name Type Description <code>KafkaConsumer</code> <code>KafkaConsumer</code> <p>The Kafka consumer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input source or consumer is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def get(self) -&gt; KafkaConsumer:\n\"\"\"\n    \ud83d\udce5 Get data from the input topic.\n    Returns:\n        KafkaConsumer: The Kafka consumer.\n    Raises:\n        Exception: If no input source or consumer is specified.\n    \"\"\"\nif self.input_topic and self.consumer:\ntry:\nreturn self.consumer\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to consume from Kafka topic {self.input_topic}: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No input source specified.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.iterator","title":"<code>iterator()</code>","text":"<p>\ud83d\udd04 Iterator method for yielding data from the Kafka consumer.</p> <p>Yields:</p> Type Description <code>Iterator</code> <p>Kafka message: The next message from the Kafka consumer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka consumer is available.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def iterator(self) -&gt; Iterator:\n\"\"\"\n    \ud83d\udd04 Iterator method for yielding data from the Kafka consumer.\n    Yields:\n        Kafka message: The next message from the Kafka consumer.\n    Raises:\n        Exception: If no Kafka consumer is available.\n    \"\"\"\nif self.consumer:\ntry:\nfor message in self.consumer:\nyield message\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to iterate over Kafka consumer: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.seek","title":"<code>seek(partition, offset)</code>","text":"<p>\ud83d\udd0d Change the position from which the Kafka consumer reads.</p> <p>Parameters:</p> Name Type Description Default <code>partition</code> <code>int</code> <p>The partition to seek.</p> required <code>offset</code> <code>int</code> <p>The offset to seek to.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs while seeking.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def seek(self, partition: int, offset: int) -&gt; None:\n\"\"\"\n    \ud83d\udd0d Change the position from which the Kafka consumer reads.\n    Args:\n        partition (int): The partition to seek.\n        offset (int): The offset to seek to.\n    Raises:\n        Exception: If an error occurs while seeking.\n    \"\"\"\nif self.consumer:\ntry:\nself.consumer.seek(partition, offset)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to seek Kafka consumer: {e}\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_output/","title":"Streaming data output","text":"<p>Streaming output manager</p>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig","title":"<code>StreamingOutputConfig</code>","text":"<p>             Bases: <code>OutputConfig</code></p> <p>\ud83d\udce1 StreamingOutputConfig: Manages streaming output configurations.</p> <p>Attributes:</p> Name Type Description <code>output_topic</code> <code>str</code> <p>Kafka topic to ingest data.</p> <code>producer</code> <code>KafkaProducer</code> <p>Kafka producer for ingesting data.</p> <p>Usage: <pre><code>config = StreamingOutputConfig(\"my_topic\", \"localhost:9092\")\nconfig.save({\"key\": \"value\"}, \"ignored_filename\")\nconfig.flush()\n</code></pre></p> <p>Note: - Ensure the Kafka cluster is running and accessible.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>class StreamingOutputConfig(OutputConfig):\n\"\"\"\n    \ud83d\udce1 **StreamingOutputConfig**: Manages streaming output configurations.\n    Attributes:\n        output_topic (str): Kafka topic to ingest data.\n        producer (KafkaProducer): Kafka producer for ingesting data.\n    Usage:\n    ```python\n    config = StreamingOutputConfig(\"my_topic\", \"localhost:9092\")\n    config.save({\"key\": \"value\"}, \"ignored_filename\")\n    config.flush()\n    ```\n    Note:\n    - Ensure the Kafka cluster is running and accessible.\n    \"\"\"\ndef __init__(self, output_topic: str, kafka_servers: str) -&gt; None:\n\"\"\"\n        Initialize a new streaming output configuration.\n        Args:\n            output_topic (str): Kafka topic to ingest data.\n            kafka_servers (str): Kafka bootstrap servers.\n        \"\"\"\nself.output_topic = output_topic\nself.log = logging.getLogger(self.__class__.__name__)\ntry:\nself.producer = KafkaProducer(bootstrap_servers=kafka_servers)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to create Kafka producer: {e}\")\nraise\nself.producer = None\ndef save(self, data: Any, filename: str) -&gt; None:\n\"\"\"\n        \ud83d\udce4 Ingest data into the Kafka topic.\n        Args:\n            data (Any): The data to ingest.\n            filename (str): This argument is ignored for streaming outputs.\n        Raises:\n            Exception: If no Kafka producer is available or an error occurs.\n        \"\"\"\nif self.producer:\ntry:\nself.producer.send(self.output_topic, bytes(json.dumps(data).encode(\"utf-8\")))\nself.log.debug(f\"\u2705 Inserted the data into {self.output_topic} topic.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to send data to Kafka topic: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\ndef flush(self) -&gt; None:\n\"\"\"\n        \ud83d\udd04 Flush the output by flushing the Kafka producer.\n        Raises:\n            Exception: If no Kafka producer is available.\n        \"\"\"\nif self.producer:\nself.producer.flush()\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\ndef send_key_value(self, key: Any, value: Any) -&gt; None:\n\"\"\"\n        \ud83d\udd11 Send a message with a key to the Kafka topic.\n        Args:\n            key (Any): The key of the message.\n            value (Any): The value of the message.\n        Raises:\n            Exception: If no Kafka producer is available or an error occurs.\n        \"\"\"\nif self.producer:\ntry:\nself.producer.send(\nself.output_topic,\nkey=bytes(json.dumps(key).encode(\"utf-8\")),\nvalue=bytes(json.dumps(value).encode(\"utf-8\")),\n)\nself.log.debug(f\"\u2705 Inserted the key-value pair into {self.output_topic} topic.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to send key-value pair to Kafka topic: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\ndef close(self) -&gt; None:\n\"\"\"\n        \ud83d\udeaa Close the Kafka producer.\n        Raises:\n            Exception: If no Kafka producer is available.\n        \"\"\"\nif self.producer:\nself.producer.close()\nself.producer = None\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\ndef partition_available(self, partition: int) -&gt; bool:\n\"\"\"\n        \ud83e\uddd0 Check if a partition is available in the Kafka topic.\n        Args:\n            partition (int): The partition to check.\n        Returns:\n            bool: True if the partition is available, False otherwise.\n        Raises:\n            Exception: If no Kafka producer is available.\n        \"\"\"\nif self.producer:\nreturn partition in self.producer.partitions_for(self.output_topic)\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\nreturn False\ndef save_to_partition(self, value: Any, partition: int) -&gt; None:\n\"\"\"\n        \ud83c\udfaf Send a message to a specific partition in the Kafka topic.\n        Args:\n            value (Any): The value of the message.\n            partition (int): The partition to send the message to.\n        Raises:\n            Exception: If no Kafka producer is available or an error occurs.\n        \"\"\"\nif self.producer:\ntry:\nself.producer.send(\nself.output_topic,\nvalue=bytes(json.dumps(value).encode(\"utf-8\")),\npartition=partition,\n)\nself.log.debug(f\"\u2705 Inserted the message into partition {partition} of {self.output_topic} topic.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to send message to Kafka topic: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\ndef save_bulk(self, messages: List[Any]) -&gt; None:\n\"\"\"\n        \ud83d\udce6 Send multiple messages at once to the Kafka topic.\n        Args:\n            messages (list): The messages to send.\n        Raises:\n            Exception: If no Kafka producer is available or an error occurs.\n        \"\"\"\nif self.producer:\ntry:\nfor message in messages:\nself.producer.send(self.output_topic, bytes(json.dumps(message).encode(\"utf-8\")))\nself.log.debug(f\"\u2705 Inserted {len(messages)} messages into {self.output_topic} topic.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to send messages to Kafka topic: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.__init__","title":"<code>__init__(output_topic, kafka_servers)</code>","text":"<p>Initialize a new streaming output configuration.</p> <p>Parameters:</p> Name Type Description Default <code>output_topic</code> <code>str</code> <p>Kafka topic to ingest data.</p> required <code>kafka_servers</code> <code>str</code> <p>Kafka bootstrap servers.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def __init__(self, output_topic: str, kafka_servers: str) -&gt; None:\n\"\"\"\n    Initialize a new streaming output configuration.\n    Args:\n        output_topic (str): Kafka topic to ingest data.\n        kafka_servers (str): Kafka bootstrap servers.\n    \"\"\"\nself.output_topic = output_topic\nself.log = logging.getLogger(self.__class__.__name__)\ntry:\nself.producer = KafkaProducer(bootstrap_servers=kafka_servers)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to create Kafka producer: {e}\")\nraise\nself.producer = None\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.close","title":"<code>close()</code>","text":"<p>\ud83d\udeaa Close the Kafka producer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def close(self) -&gt; None:\n\"\"\"\n    \ud83d\udeaa Close the Kafka producer.\n    Raises:\n        Exception: If no Kafka producer is available.\n    \"\"\"\nif self.producer:\nself.producer.close()\nself.producer = None\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.flush","title":"<code>flush()</code>","text":"<p>\ud83d\udd04 Flush the output by flushing the Kafka producer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def flush(self) -&gt; None:\n\"\"\"\n    \ud83d\udd04 Flush the output by flushing the Kafka producer.\n    Raises:\n        Exception: If no Kafka producer is available.\n    \"\"\"\nif self.producer:\nself.producer.flush()\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.partition_available","title":"<code>partition_available(partition)</code>","text":"<p>\ud83e\uddd0 Check if a partition is available in the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>partition</code> <code>int</code> <p>The partition to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the partition is available, False otherwise.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def partition_available(self, partition: int) -&gt; bool:\n\"\"\"\n    \ud83e\uddd0 Check if a partition is available in the Kafka topic.\n    Args:\n        partition (int): The partition to check.\n    Returns:\n        bool: True if the partition is available, False otherwise.\n    Raises:\n        Exception: If no Kafka producer is available.\n    \"\"\"\nif self.producer:\nreturn partition in self.producer.partitions_for(self.output_topic)\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\nreturn False\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.save","title":"<code>save(data, filename)</code>","text":"<p>\ud83d\udce4 Ingest data into the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to ingest.</p> required <code>filename</code> <code>str</code> <p>This argument is ignored for streaming outputs.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def save(self, data: Any, filename: str) -&gt; None:\n\"\"\"\n    \ud83d\udce4 Ingest data into the Kafka topic.\n    Args:\n        data (Any): The data to ingest.\n        filename (str): This argument is ignored for streaming outputs.\n    Raises:\n        Exception: If no Kafka producer is available or an error occurs.\n    \"\"\"\nif self.producer:\ntry:\nself.producer.send(self.output_topic, bytes(json.dumps(data).encode(\"utf-8\")))\nself.log.debug(f\"\u2705 Inserted the data into {self.output_topic} topic.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to send data to Kafka topic: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.save_bulk","title":"<code>save_bulk(messages)</code>","text":"<p>\ud83d\udce6 Send multiple messages at once to the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>list</code> <p>The messages to send.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def save_bulk(self, messages: List[Any]) -&gt; None:\n\"\"\"\n    \ud83d\udce6 Send multiple messages at once to the Kafka topic.\n    Args:\n        messages (list): The messages to send.\n    Raises:\n        Exception: If no Kafka producer is available or an error occurs.\n    \"\"\"\nif self.producer:\ntry:\nfor message in messages:\nself.producer.send(self.output_topic, bytes(json.dumps(message).encode(\"utf-8\")))\nself.log.debug(f\"\u2705 Inserted {len(messages)} messages into {self.output_topic} topic.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to send messages to Kafka topic: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.save_to_partition","title":"<code>save_to_partition(value, partition)</code>","text":"<p>\ud83c\udfaf Send a message to a specific partition in the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value of the message.</p> required <code>partition</code> <code>int</code> <p>The partition to send the message to.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def save_to_partition(self, value: Any, partition: int) -&gt; None:\n\"\"\"\n    \ud83c\udfaf Send a message to a specific partition in the Kafka topic.\n    Args:\n        value (Any): The value of the message.\n        partition (int): The partition to send the message to.\n    Raises:\n        Exception: If no Kafka producer is available or an error occurs.\n    \"\"\"\nif self.producer:\ntry:\nself.producer.send(\nself.output_topic,\nvalue=bytes(json.dumps(value).encode(\"utf-8\")),\npartition=partition,\n)\nself.log.debug(f\"\u2705 Inserted the message into partition {partition} of {self.output_topic} topic.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to send message to Kafka topic: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.send_key_value","title":"<code>send_key_value(key, value)</code>","text":"<p>\ud83d\udd11 Send a message with a key to the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Any</code> <p>The key of the message.</p> required <code>value</code> <code>Any</code> <p>The value of the message.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def send_key_value(self, key: Any, value: Any) -&gt; None:\n\"\"\"\n    \ud83d\udd11 Send a message with a key to the Kafka topic.\n    Args:\n        key (Any): The key of the message.\n        value (Any): The value of the message.\n    Raises:\n        Exception: If no Kafka producer is available or an error occurs.\n    \"\"\"\nif self.producer:\ntry:\nself.producer.send(\nself.output_topic,\nkey=bytes(json.dumps(key).encode(\"utf-8\")),\nvalue=bytes(json.dumps(value).encode(\"utf-8\")),\n)\nself.log.debug(f\"\u2705 Inserted the key-value pair into {self.output_topic} topic.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to send key-value pair to Kafka topic: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No Kafka producer available.\")\nraise\n</code></pre>"},{"location":"core/core_spout/","title":"Spout","text":"<p>Core Spout class</p>"},{"location":"core/core_spout/#core.spout.Spout","title":"<code>Spout</code>","text":"<p>             Bases: <code>Task</code></p> <p>Base class for all spouts.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py</code> <pre><code>class Spout(Task):\n\"\"\"\n    Base class for all spouts.\n    \"\"\"\ndef __init__(self, output_config: OutputConfig, state_manager: StateManager, **kwargs) -&gt; None:\n\"\"\"\n        The `Spout` class is a base class for all spouts in the given context.\n        It inherits from the `Task` class and provides methods for executing tasks\n        both locally and remotely, as well as managing their state, with state management\n        options including in-memory, Redis, PostgreSQL, and DynamoDB,\n        and output configurations for batch or streaming data.\n        The `Spout` class uses the `OutputConfig` and `StateManager` classes, which are abstract base\n         classes for managing output configurations and states, respectively. The `OutputConfig` class\n         has two subclasses: `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and\n         batch output configurations, respectively. The `StateManager` class is used to get and set state,\n         and it has several subclasses for different types of state managers.\n        The `Spout` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method,\n        which are used to manage tasks on Amazon ECS and Kubernetes, respectively.\n        Usage:\n            - Create an instance of the Spout class by providing an OutputConfig object and a StateManager object.\n            - The OutputConfig object specifies the output configuration for the spout.\n            - The StateManager object handles the management of the spout's state.\n        Example:\n            output_config = OutputConfig(...)\n            state_manager = StateManager(...)\n            spout = Spout(output_config, state_manager)\n        Args:\n            output_config (OutputConfig): The output configuration.\n            state_manager (StateManager): The state manager.\n        \"\"\"\nsuper().__init__()\nself.output_config = output_config\nself.state_manager = state_manager\nself.log = logging.getLogger(self.__class__.__name__)\ndef __call__(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n        Execute a method locally and manage the state.\n        Args:\n            method_name (str): The name of the method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n                Keyword Arguments:\n                    - Additional keyword arguments specific to the method.\n        Returns:\n            Any: The result of the method.\n        \"\"\"\ntry:\n# Get the type of state manager\nstate_type = self.state_manager.get_state(self.id)\n# Save the current set of class variables to the state manager\nself.state_manager.set_state(self.id, {})\n# Execute the task's method\nresult = self.execute(method_name, *args, **kwargs)\n# Flush the output config\nself.output_config.flush()\n# Store the state as successful in the state manager\nstate = {}\nstate[\"status\"] = \"success\"\nself.state_manager.set_state(self.id, state)\nreturn result\nexcept Exception as e:\nstate = {}\nstate[\"status\"] = \"failed\"\nself.state_manager.set_state(self.id, state)\nself.log.exception(f\"Failed to execute method '{method_name}': {e}\")\nraise\n@staticmethod\ndef create(klass: type, output_type: str, state_type: str, **kwargs) -&gt; \"Spout\":\n\"\"\"\n        Create a spout of a specific type.\n        Args:\n            klass (type): The Spout class to create.\n            output_type (str): The type of output config (\"batch\" or \"streaming\").\n            state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n            **kwargs: Additional keyword arguments for initializing the spout.\n                Keyword Arguments:\n                    Batch output config:\n                    - output_folder (str): The directory where output files should be stored temporarily.\n                    - output_s3_bucket (str): The name of the S3 bucket for output storage.\n                    - output_s3_folder (str): The S3 folder for output storage.\n                    Streaming output config:\n                    - output_kafka_topic (str): Kafka output topic for streaming spouts.\n                    - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.\n                    Redis state manager config:\n                    - redis_host (str): The host address for the Redis server.\n                    - redis_port (int): The port number for the Redis server.\n                    - redis_db (int): The Redis database to be used.\n                    Postgres state manager config:\n                    - postgres_host (str): The host address for the PostgreSQL server.\n                    - postgres_port (int): The port number for the PostgreSQL server.\n                    - postgres_user (str): The username for the PostgreSQL server.\n                    - postgres_password (str): The password for the PostgreSQL server.\n                    - postgres_database (str): The PostgreSQL database to be used.\n                    - postgres_table (str): The PostgreSQL table to be used.\n                    DynamoDB state manager config:\n                    - dynamodb_table_name (str): The name of the DynamoDB table.\n                    - dynamodb_region_name (str): The AWS region for DynamoDB.\n        Returns:\n            Spout: The created spout.\n        Raises:\n            ValueError: If an invalid output type or state type is provided.\n        \"\"\"\n# Create the output config\noutput_config: BatchOutputConfig | StreamingOutputConfig\nif output_type == \"batch\":\noutput_config = BatchOutputConfig(\noutput_folder=kwargs.get(\"output_folder\", tempfile.mkdtemp()),\nbucket=kwargs.get(\"output_s3_bucket\", \"geniusrise\"),\ns3_folder=kwargs.get(\"output_s3_folder\", klass.__class__.__name__),\n)\nelif output_type == \"streaming\":\noutput_config = StreamingOutputConfig(\noutput_topic=kwargs.get(\"output_kafka_topic\", None),\nkafka_servers=kwargs.get(\"output_kafka_cluster_connection_string\", None),\n)\nelse:\nraise ValueError(f\"Invalid output type: {output_type}\")\n# Create the state manager\nstate_manager: StateManager\nif state_type == \"in_memory\":\nstate_manager = InMemoryStateManager()\nelif state_type == \"redis\":\nstate_manager = RedisStateManager(\nhost=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None,\nport=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None,\ndb=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None,\n)\nelif state_type == \"postgres\":\nstate_manager = PostgresStateManager(\nhost=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None,\nport=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None,\nuser=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None,\npassword=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None,\ndatabase=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None,\ntable=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None,\n)\nelif state_type == \"dynamodb\":\nstate_manager = DynamoDBStateManager(\ntable_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None,\nregion_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None,\n)\nelse:\nraise ValueError(f\"Invalid state type: {state_type}\")\n# Create the spout\nspout = klass(output_config=output_config, state_manager=state_manager, **kwargs)\nreturn spout\n</code></pre>"},{"location":"core/core_spout/#core.spout.Spout.__call__","title":"<code>__call__(method_name, *args, **kwargs)</code>","text":"<p>Execute a method locally and manage the state.</p> <p>Parameters:</p> Name Type Description Default <code>method_name</code> <code>str</code> <p>The name of the method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method. Keyword Arguments:     - Additional keyword arguments specific to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the method.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py</code> <pre><code>def __call__(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n    Execute a method locally and manage the state.\n    Args:\n        method_name (str): The name of the method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n            Keyword Arguments:\n                - Additional keyword arguments specific to the method.\n    Returns:\n        Any: The result of the method.\n    \"\"\"\ntry:\n# Get the type of state manager\nstate_type = self.state_manager.get_state(self.id)\n# Save the current set of class variables to the state manager\nself.state_manager.set_state(self.id, {})\n# Execute the task's method\nresult = self.execute(method_name, *args, **kwargs)\n# Flush the output config\nself.output_config.flush()\n# Store the state as successful in the state manager\nstate = {}\nstate[\"status\"] = \"success\"\nself.state_manager.set_state(self.id, state)\nreturn result\nexcept Exception as e:\nstate = {}\nstate[\"status\"] = \"failed\"\nself.state_manager.set_state(self.id, state)\nself.log.exception(f\"Failed to execute method '{method_name}': {e}\")\nraise\n</code></pre>"},{"location":"core/core_spout/#core.spout.Spout.__init__","title":"<code>__init__(output_config, state_manager, **kwargs)</code>","text":"<p>The <code>Spout</code> class is a base class for all spouts in the given context. It inherits from the <code>Task</code> class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and output configurations for batch or streaming data.</p> <p>The <code>Spout</code> class uses the <code>OutputConfig</code> and <code>StateManager</code> classes, which are abstract base  classes for managing output configurations and states, respectively. The <code>OutputConfig</code> class  has two subclasses: <code>StreamingOutputConfig</code> and <code>BatchOutputConfig</code>, which manage streaming and  batch output configurations, respectively. The <code>StateManager</code> class is used to get and set state,  and it has several subclasses for different types of state managers.</p> <p>The <code>Spout</code> class also uses the <code>ECSManager</code> and <code>K8sManager</code> classes in the <code>execute_remote</code> method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively.</p> Usage <ul> <li>Create an instance of the Spout class by providing an OutputConfig object and a StateManager object.</li> <li>The OutputConfig object specifies the output configuration for the spout.</li> <li>The StateManager object handles the management of the spout's state.</li> </ul> Example <p>output_config = OutputConfig(...) state_manager = StateManager(...) spout = Spout(output_config, state_manager)</p> <p>Parameters:</p> Name Type Description Default <code>output_config</code> <code>OutputConfig</code> <p>The output configuration.</p> required <code>state_manager</code> <code>StateManager</code> <p>The state manager.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py</code> <pre><code>def __init__(self, output_config: OutputConfig, state_manager: StateManager, **kwargs) -&gt; None:\n\"\"\"\n    The `Spout` class is a base class for all spouts in the given context.\n    It inherits from the `Task` class and provides methods for executing tasks\n    both locally and remotely, as well as managing their state, with state management\n    options including in-memory, Redis, PostgreSQL, and DynamoDB,\n    and output configurations for batch or streaming data.\n    The `Spout` class uses the `OutputConfig` and `StateManager` classes, which are abstract base\n     classes for managing output configurations and states, respectively. The `OutputConfig` class\n     has two subclasses: `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and\n     batch output configurations, respectively. The `StateManager` class is used to get and set state,\n     and it has several subclasses for different types of state managers.\n    The `Spout` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method,\n    which are used to manage tasks on Amazon ECS and Kubernetes, respectively.\n    Usage:\n        - Create an instance of the Spout class by providing an OutputConfig object and a StateManager object.\n        - The OutputConfig object specifies the output configuration for the spout.\n        - The StateManager object handles the management of the spout's state.\n    Example:\n        output_config = OutputConfig(...)\n        state_manager = StateManager(...)\n        spout = Spout(output_config, state_manager)\n    Args:\n        output_config (OutputConfig): The output configuration.\n        state_manager (StateManager): The state manager.\n    \"\"\"\nsuper().__init__()\nself.output_config = output_config\nself.state_manager = state_manager\nself.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/core_spout/#core.spout.Spout.create","title":"<code>create(klass, output_type, state_type, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a spout of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>klass</code> <code>type</code> <p>The Spout class to create.</p> required <code>output_type</code> <code>str</code> <p>The type of output config (\"batch\" or \"streaming\").</p> required <code>state_type</code> <code>str</code> <p>The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").</p> required <code>**kwargs</code> <p>Additional keyword arguments for initializing the spout. Keyword Arguments:     Batch output config:     - output_folder (str): The directory where output files should be stored temporarily.     - output_s3_bucket (str): The name of the S3 bucket for output storage.     - output_s3_folder (str): The S3 folder for output storage.     Streaming output config:     - output_kafka_topic (str): Kafka output topic for streaming spouts.     - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.     Redis state manager config:     - redis_host (str): The host address for the Redis server.     - redis_port (int): The port number for the Redis server.     - redis_db (int): The Redis database to be used.     Postgres state manager config:     - postgres_host (str): The host address for the PostgreSQL server.     - postgres_port (int): The port number for the PostgreSQL server.     - postgres_user (str): The username for the PostgreSQL server.     - postgres_password (str): The password for the PostgreSQL server.     - postgres_database (str): The PostgreSQL database to be used.     - postgres_table (str): The PostgreSQL table to be used.     DynamoDB state manager config:     - dynamodb_table_name (str): The name of the DynamoDB table.     - dynamodb_region_name (str): The AWS region for DynamoDB.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Spout</code> <code>Spout</code> <p>The created spout.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid output type or state type is provided.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py</code> <pre><code>@staticmethod\ndef create(klass: type, output_type: str, state_type: str, **kwargs) -&gt; \"Spout\":\n\"\"\"\n    Create a spout of a specific type.\n    Args:\n        klass (type): The Spout class to create.\n        output_type (str): The type of output config (\"batch\" or \"streaming\").\n        state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n        **kwargs: Additional keyword arguments for initializing the spout.\n            Keyword Arguments:\n                Batch output config:\n                - output_folder (str): The directory where output files should be stored temporarily.\n                - output_s3_bucket (str): The name of the S3 bucket for output storage.\n                - output_s3_folder (str): The S3 folder for output storage.\n                Streaming output config:\n                - output_kafka_topic (str): Kafka output topic for streaming spouts.\n                - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.\n                Redis state manager config:\n                - redis_host (str): The host address for the Redis server.\n                - redis_port (int): The port number for the Redis server.\n                - redis_db (int): The Redis database to be used.\n                Postgres state manager config:\n                - postgres_host (str): The host address for the PostgreSQL server.\n                - postgres_port (int): The port number for the PostgreSQL server.\n                - postgres_user (str): The username for the PostgreSQL server.\n                - postgres_password (str): The password for the PostgreSQL server.\n                - postgres_database (str): The PostgreSQL database to be used.\n                - postgres_table (str): The PostgreSQL table to be used.\n                DynamoDB state manager config:\n                - dynamodb_table_name (str): The name of the DynamoDB table.\n                - dynamodb_region_name (str): The AWS region for DynamoDB.\n    Returns:\n        Spout: The created spout.\n    Raises:\n        ValueError: If an invalid output type or state type is provided.\n    \"\"\"\n# Create the output config\noutput_config: BatchOutputConfig | StreamingOutputConfig\nif output_type == \"batch\":\noutput_config = BatchOutputConfig(\noutput_folder=kwargs.get(\"output_folder\", tempfile.mkdtemp()),\nbucket=kwargs.get(\"output_s3_bucket\", \"geniusrise\"),\ns3_folder=kwargs.get(\"output_s3_folder\", klass.__class__.__name__),\n)\nelif output_type == \"streaming\":\noutput_config = StreamingOutputConfig(\noutput_topic=kwargs.get(\"output_kafka_topic\", None),\nkafka_servers=kwargs.get(\"output_kafka_cluster_connection_string\", None),\n)\nelse:\nraise ValueError(f\"Invalid output type: {output_type}\")\n# Create the state manager\nstate_manager: StateManager\nif state_type == \"in_memory\":\nstate_manager = InMemoryStateManager()\nelif state_type == \"redis\":\nstate_manager = RedisStateManager(\nhost=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None,\nport=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None,\ndb=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None,\n)\nelif state_type == \"postgres\":\nstate_manager = PostgresStateManager(\nhost=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None,\nport=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None,\nuser=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None,\npassword=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None,\ndatabase=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None,\ntable=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None,\n)\nelif state_type == \"dynamodb\":\nstate_manager = DynamoDBStateManager(\ntable_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None,\nregion_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None,\n)\nelse:\nraise ValueError(f\"Invalid state type: {state_type}\")\n# Create the spout\nspout = klass(output_config=output_config, state_manager=state_manager, **kwargs)\nreturn spout\n</code></pre>"},{"location":"core/core_state_base/","title":"State","text":"<p>Base class for task state mnager</p>"},{"location":"core/core_state_base/#core.state.base.StateManager","title":"<code>StateManager</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract base class for a state manager.</p> <p>A state manager is responsible for getting and setting state.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py</code> <pre><code>class StateManager(ABC):\n\"\"\"\n    Abstract base class for a state manager.\n    A state manager is responsible for getting and setting state.\n    \"\"\"\n@abstractmethod\ndef get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        Get the state associated with a key.\n        Args:\n            key (str): The key to get the state for.\n        Returns:\n            Dict: The state associated with the key.\n        \"\"\"\npass\n@abstractmethod\ndef set_state(self, key: str, value: Dict):\n\"\"\"\n        Set the state associated with a key.\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n        \"\"\"\npass\n</code></pre>"},{"location":"core/core_state_base/#core.state.base.StateManager.get_state","title":"<code>get_state(key)</code>  <code>abstractmethod</code>","text":"<p>Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py</code> <pre><code>@abstractmethod\ndef get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    Get the state associated with a key.\n    Args:\n        key (str): The key to get the state for.\n    Returns:\n        Dict: The state associated with the key.\n    \"\"\"\npass\n</code></pre>"},{"location":"core/core_state_base/#core.state.base.StateManager.set_state","title":"<code>set_state(key, value)</code>  <code>abstractmethod</code>","text":"<p>Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py</code> <pre><code>@abstractmethod\ndef set_state(self, key: str, value: Dict):\n\"\"\"\n    Set the state associated with a key.\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n    \"\"\"\npass\n</code></pre>"},{"location":"core/core_state_dynamo/","title":"DynamoDB State","text":"<p>State manager using dynamoDB</p>"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager","title":"<code>DynamoDBStateManager</code>","text":"<p>             Bases: <code>StateManager</code></p> <p>\ud83d\uddc4\ufe0f DynamoDBStateManager: A state manager that stores state in DynamoDB.</p> <p>Attributes:</p> Name Type Description <code>dynamodb</code> <code>boto3.resources.factory.dynamodb.ServiceResource</code> <p>The DynamoDB service resource.</p> <code>table</code> <code>boto3.resources.factory.dynamodb.Table</code> <p>The DynamoDB table.</p> <p>Usage: <pre><code>manager = DynamoDBStateManager(\"my_table\", \"us-west-1\")\nmanager.set_state(\"key123\", {\"status\": \"active\"})\nstate = manager.get_state(\"key123\")\nprint(state)  # Outputs: {\"status\": \"active\"}\n</code></pre></p> <p>Note: - Ensure DynamoDB is accessible and the table exists.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py</code> <pre><code>class DynamoDBStateManager(StateManager):\n\"\"\"\n    \ud83d\uddc4\ufe0f **DynamoDBStateManager**: A state manager that stores state in DynamoDB.\n    Attributes:\n        dynamodb (boto3.resources.factory.dynamodb.ServiceResource): The DynamoDB service resource.\n        table (boto3.resources.factory.dynamodb.Table): The DynamoDB table.\n    Usage:\n    ```python\n    manager = DynamoDBStateManager(\"my_table\", \"us-west-1\")\n    manager.set_state(\"key123\", {\"status\": \"active\"})\n    state = manager.get_state(\"key123\")\n    print(state)  # Outputs: {\"status\": \"active\"}\n    ```\n    Note:\n    - Ensure DynamoDB is accessible and the table exists.\n    \"\"\"\ndef __init__(self, table_name: str, region_name: str) -&gt; None:\n\"\"\"\n        Initialize a new DynamoDB state manager.\n        Args:\n            table_name (str): The name of the DynamoDB table.\n            region_name (str): The name of the AWS region.\n        \"\"\"\nsuper().__init__()\nself.log = logging.getLogger(self.__class__.__name__)\ntry:\nself.dynamodb = boto3.resource(\"dynamodb\", region_name=region_name)\nself.table = self.dynamodb.Table(table_name)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to connect to DynamoDB: {e}\")\nraise\nself.dynamodb = None\nself.table = None\ndef get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        \ud83d\udcd6 Get the state associated with a key.\n        Args:\n            key (str): The key to get the state for.\n        Returns:\n            Dict: The state associated with the key, or None if not found.\n        Raises:\n            Exception: If there's an error accessing DynamoDB.\n        \"\"\"\nif self.table:\ntry:\nresponse = self.table.get_item(Key={\"id\": key})\nreturn jsonpickle.decode(response[\"Item\"][\"value\"]) if \"Item\" in response else None\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to get state from DynamoDB: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No DynamoDB table.\")\nraise\ndef set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n        \ud83d\udcdd Set the state associated with a key.\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n        Raises:\n            Exception: If there's an error accessing DynamoDB.\n        \"\"\"\nif self.table:\ntry:\nself.table.put_item(Item={\"id\": key, \"value\": jsonpickle.encode(value)})\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to set state in DynamoDB: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No DynamoDB table.\")\nraise\n</code></pre>"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager.__init__","title":"<code>__init__(table_name, region_name)</code>","text":"<p>Initialize a new DynamoDB state manager.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the DynamoDB table.</p> required <code>region_name</code> <code>str</code> <p>The name of the AWS region.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py</code> <pre><code>def __init__(self, table_name: str, region_name: str) -&gt; None:\n\"\"\"\n    Initialize a new DynamoDB state manager.\n    Args:\n        table_name (str): The name of the DynamoDB table.\n        region_name (str): The name of the AWS region.\n    \"\"\"\nsuper().__init__()\nself.log = logging.getLogger(self.__class__.__name__)\ntry:\nself.dynamodb = boto3.resource(\"dynamodb\", region_name=region_name)\nself.table = self.dynamodb.Table(table_name)\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to connect to DynamoDB: {e}\")\nraise\nself.dynamodb = None\nself.table = None\n</code></pre>"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager.get_state","title":"<code>get_state(key)</code>","text":"<p>\ud83d\udcd6 Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key, or None if not found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing DynamoDB.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py</code> <pre><code>def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    \ud83d\udcd6 Get the state associated with a key.\n    Args:\n        key (str): The key to get the state for.\n    Returns:\n        Dict: The state associated with the key, or None if not found.\n    Raises:\n        Exception: If there's an error accessing DynamoDB.\n    \"\"\"\nif self.table:\ntry:\nresponse = self.table.get_item(Key={\"id\": key})\nreturn jsonpickle.decode(response[\"Item\"][\"value\"]) if \"Item\" in response else None\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to get state from DynamoDB: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No DynamoDB table.\")\nraise\n</code></pre>"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager.set_state","title":"<code>set_state(key, value)</code>","text":"<p>\ud83d\udcdd Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing DynamoDB.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py</code> <pre><code>def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n    \ud83d\udcdd Set the state associated with a key.\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n    Raises:\n        Exception: If there's an error accessing DynamoDB.\n    \"\"\"\nif self.table:\ntry:\nself.table.put_item(Item={\"id\": key, \"value\": jsonpickle.encode(value)})\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to set state in DynamoDB: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No DynamoDB table.\")\nraise\n</code></pre>"},{"location":"core/core_state_memory/","title":"In-memory State","text":"<p>State manager using local memory</p>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager","title":"<code>InMemoryStateManager</code>","text":"<p>             Bases: <code>StateManager</code></p> <p>\ud83e\udde0 InMemoryStateManager: A state manager that stores state in memory.</p> <p>This manager is useful for temporary storage or testing purposes. Since it's in-memory, the data will be lost once the application stops.</p>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager--attributes","title":"Attributes:","text":"<ul> <li><code>store</code> (Dict[str, Dict]): The in-memory store for states.</li> </ul>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager--usage","title":"Usage:","text":"<pre><code>manager = InMemoryStateManager()\nmanager.set_state(\"user123\", {\"status\": \"active\"})\nstate = manager.get_state(\"user123\")\nprint(state)  # Outputs: {\"status\": \"active\"}\n</code></pre> <p>!!! warning     Remember, this is an in-memory store. Do not use it for persistent storage!</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py</code> <pre><code>class InMemoryStateManager(StateManager):\n\"\"\"\n    \ud83e\udde0 **InMemoryStateManager**: A state manager that stores state in memory.\n    This manager is useful for temporary storage or testing purposes. Since it's in-memory, the data will be lost once the application stops.\n    ## Attributes:\n    - `store` (Dict[str, Dict]): The in-memory store for states.\n    ## Usage:\n    ```python\n    manager = InMemoryStateManager()\n    manager.set_state(\"user123\", {\"status\": \"active\"})\n    state = manager.get_state(\"user123\")\n    print(state)  # Outputs: {\"status\": \"active\"}\n    ```\n    !!! warning\n        Remember, this is an in-memory store. Do not use it for persistent storage!\n    \"\"\"\nstore: Dict[str, Dict]\ndef __init__(self) -&gt; None:\n\"\"\"\n        Initialize a new in-memory state manager.\n        \"\"\"\nself.store = {}\nself.log = logging.getLogger(self.__class__.__name__)\ndef get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        \ud83d\udcd6 Get the state associated with a key.\n        Args:\n            key (str): The key to get the state for.\n        Returns:\n            Dict: The state associated with the key, or None if not found.\n        \"\"\"\nstate = self.store.get(key)\nif state:\nself.log.debug(f\"\u2705 Retrieved state for key: {key}\")\nelse:\nself.log.warning(f\"\ud83d\udeab No state found for key: {key}\")\nreturn state\ndef set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n        \ud83d\udcdd Set the state associated with a key.\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n        Example:\n        ```python\n        manager.set_state(\"user123\", {\"status\": \"active\"})\n        ```\n        \"\"\"\nself.store[key] = value\nself.log.debug(f\"\u2705 Set state for key: {key}\")\n</code></pre>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.__init__","title":"<code>__init__()</code>","text":"<p>Initialize a new in-memory state manager.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py</code> <pre><code>def __init__(self) -&gt; None:\n\"\"\"\n    Initialize a new in-memory state manager.\n    \"\"\"\nself.store = {}\nself.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.get_state","title":"<code>get_state(key)</code>","text":"<p>\ud83d\udcd6 Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key, or None if not found.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py</code> <pre><code>def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    \ud83d\udcd6 Get the state associated with a key.\n    Args:\n        key (str): The key to get the state for.\n    Returns:\n        Dict: The state associated with the key, or None if not found.\n    \"\"\"\nstate = self.store.get(key)\nif state:\nself.log.debug(f\"\u2705 Retrieved state for key: {key}\")\nelse:\nself.log.warning(f\"\ud83d\udeab No state found for key: {key}\")\nreturn state\n</code></pre>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.set_state","title":"<code>set_state(key, value)</code>","text":"<p>\ud83d\udcdd Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required <p>Example: <pre><code>manager.set_state(\"user123\", {\"status\": \"active\"})\n</code></pre></p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py</code> <pre><code>def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n    \ud83d\udcdd Set the state associated with a key.\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n    Example:\n    ```python\n    manager.set_state(\"user123\", {\"status\": \"active\"})\n    ```\n    \"\"\"\nself.store[key] = value\nself.log.debug(f\"\u2705 Set state for key: {key}\")\n</code></pre>"},{"location":"core/core_state_postgres/","title":"Postgres State","text":"<p>State manager using postgres database</p>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager","title":"<code>PostgresStateManager</code>","text":"<p>             Bases: <code>StateManager</code></p> <p>\ud83d\uddc4\ufe0f PostgresStateManager: A state manager that stores state in a PostgreSQL database.</p> <p>This manager provides a persistent storage solution using a PostgreSQL database.</p>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager--attributes","title":"Attributes:","text":"<ul> <li><code>conn</code> (psycopg2.extensions.connection): The PostgreSQL connection.</li> </ul>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager--usage","title":"Usage:","text":"<pre><code>manager = PostgresStateManager(host=\"localhost\", port=5432, user=\"admin\", password=\"password\", database=\"mydb\")\nmanager.set_state(\"user123\", {\"status\": \"active\"})\nstate = manager.get_state(\"user123\")\nprint(state)  # Outputs: {\"status\": \"active\"}\n</code></pre> <p>!!! warning     Ensure PostgreSQL is accessible and the table exists.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py</code> <pre><code>class PostgresStateManager(StateManager):\n\"\"\"\n    \ud83d\uddc4\ufe0f **PostgresStateManager**: A state manager that stores state in a PostgreSQL database.\n    This manager provides a persistent storage solution using a PostgreSQL database.\n    ## Attributes:\n    - `conn` (psycopg2.extensions.connection): The PostgreSQL connection.\n    ## Usage:\n    ```python\n    manager = PostgresStateManager(host=\"localhost\", port=5432, user=\"admin\", password=\"password\", database=\"mydb\")\n    manager.set_state(\"user123\", {\"status\": \"active\"})\n    state = manager.get_state(\"user123\")\n    print(state)  # Outputs: {\"status\": \"active\"}\n    ```\n    !!! warning\n        Ensure PostgreSQL is accessible and the table exists.\n    \"\"\"\ndef __init__(\nself,\nhost: str,\nport: int,\nuser: str,\npassword: str,\ndatabase: str,\ntable: str = \"geniusrise_state\",\n) -&gt; None:\n\"\"\"\n        Initialize a new PostgreSQL state manager.\n        Args:\n            host (str): The host of the PostgreSQL server.\n            port (int): The port of the PostgreSQL server.\n            user (str): The user to connect as.\n            password (str): The user's password.\n            database (str): The database to connect to.\n            table (str, optional): The table to use. Defaults to \"geniusrise_state\".\n        \"\"\"\nsuper().__init__()\nself.table = table\nself.log = logging.getLogger(self.__class__.__name__)\ntry:\nself.conn = psycopg2.connect(host=host, port=port, user=user, password=password, database=database)\nexcept psycopg2.Error as e:\nself.log.exception(f\"\ud83d\udeab Failed to connect to PostgreSQL: {e}\")\nraise\nself.conn = None\ndef get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        \ud83d\udcd6 Get the state associated with a key.\n        Args:\n            key (str): The key to get the state for.\n        Returns:\n            Dict: The state associated with the key, or None if not found.\n        Raises:\n            Exception: If there's an error accessing PostgreSQL.\n        \"\"\"\nif self.conn:\ntry:\nwith self.conn.cursor() as cur:\ncur.execute(f\"SELECT value FROM {self.table} WHERE key = %s\", (key,))\nresult = cur.fetchone()\nreturn jsonpickle.decode(result[0][\"data\"]) if result else None\nexcept psycopg2.Error as e:\nself.log.exception(f\"\ud83d\udeab Failed to get state from PostgreSQL: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No PostgreSQL connection.\")\nraise\ndef set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n        \ud83d\udcdd Set the state associated with a key.\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n        Raises:\n            Exception: If there's an error accessing PostgreSQL.\n        \"\"\"\nif self.conn:\ntry:\nwith self.conn.cursor() as cur:\ndata = {\"data\": jsonpickle.encode(value)}\ncur.execute(\nf\"\"\"\n                        INSERT INTO {self.table} (key, value)\n                        VALUES (%s, %s)\n                        ON CONFLICT (key)\n                        DO UPDATE SET value = EXCLUDED.value;\n                        \"\"\",\n(key, json.dumps(data)),\n)\nself.conn.commit()\nexcept psycopg2.Error as e:\nself.log.exception(f\"\ud83d\udeab Failed to set state in PostgreSQL: {e}\")\nraise\nelse:\nself.log.error(\"\ud83d\udeab No PostgreSQL connection.\")\n</code></pre>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager.__init__","title":"<code>__init__(host, port, user, password, database, table='geniusrise_state')</code>","text":"<p>Initialize a new PostgreSQL state manager.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>The host of the PostgreSQL server.</p> required <code>port</code> <code>int</code> <p>The port of the PostgreSQL server.</p> required <code>user</code> <code>str</code> <p>The user to connect as.</p> required <code>password</code> <code>str</code> <p>The user's password.</p> required <code>database</code> <code>str</code> <p>The database to connect to.</p> required <code>table</code> <code>str</code> <p>The table to use. Defaults to \"geniusrise_state\".</p> <code>'geniusrise_state'</code> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py</code> <pre><code>def __init__(\nself,\nhost: str,\nport: int,\nuser: str,\npassword: str,\ndatabase: str,\ntable: str = \"geniusrise_state\",\n) -&gt; None:\n\"\"\"\n    Initialize a new PostgreSQL state manager.\n    Args:\n        host (str): The host of the PostgreSQL server.\n        port (int): The port of the PostgreSQL server.\n        user (str): The user to connect as.\n        password (str): The user's password.\n        database (str): The database to connect to.\n        table (str, optional): The table to use. Defaults to \"geniusrise_state\".\n    \"\"\"\nsuper().__init__()\nself.table = table\nself.log = logging.getLogger(self.__class__.__name__)\ntry:\nself.conn = psycopg2.connect(host=host, port=port, user=user, password=password, database=database)\nexcept psycopg2.Error as e:\nself.log.exception(f\"\ud83d\udeab Failed to connect to PostgreSQL: {e}\")\nraise\nself.conn = None\n</code></pre>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager.get_state","title":"<code>get_state(key)</code>","text":"<p>\ud83d\udcd6 Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key, or None if not found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing PostgreSQL.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py</code> <pre><code>def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    \ud83d\udcd6 Get the state associated with a key.\n    Args:\n        key (str): The key to get the state for.\n    Returns:\n        Dict: The state associated with the key, or None if not found.\n    Raises:\n        Exception: If there's an error accessing PostgreSQL.\n    \"\"\"\nif self.conn:\ntry:\nwith self.conn.cursor() as cur:\ncur.execute(f\"SELECT value FROM {self.table} WHERE key = %s\", (key,))\nresult = cur.fetchone()\nreturn jsonpickle.decode(result[0][\"data\"]) if result else None\nexcept psycopg2.Error as e:\nself.log.exception(f\"\ud83d\udeab Failed to get state from PostgreSQL: {e}\")\nraise\nelse:\nself.log.exception(\"\ud83d\udeab No PostgreSQL connection.\")\nraise\n</code></pre>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager.set_state","title":"<code>set_state(key, value)</code>","text":"<p>\ud83d\udcdd Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing PostgreSQL.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py</code> <pre><code>def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n    \ud83d\udcdd Set the state associated with a key.\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n    Raises:\n        Exception: If there's an error accessing PostgreSQL.\n    \"\"\"\nif self.conn:\ntry:\nwith self.conn.cursor() as cur:\ndata = {\"data\": jsonpickle.encode(value)}\ncur.execute(\nf\"\"\"\n                    INSERT INTO {self.table} (key, value)\n                    VALUES (%s, %s)\n                    ON CONFLICT (key)\n                    DO UPDATE SET value = EXCLUDED.value;\n                    \"\"\",\n(key, json.dumps(data)),\n)\nself.conn.commit()\nexcept psycopg2.Error as e:\nself.log.exception(f\"\ud83d\udeab Failed to set state in PostgreSQL: {e}\")\nraise\nelse:\nself.log.error(\"\ud83d\udeab No PostgreSQL connection.\")\n</code></pre>"},{"location":"core/core_state_redis/","title":"Redis State","text":"<p>State manager using redis</p>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager","title":"<code>RedisStateManager</code>","text":"<p>             Bases: <code>StateManager</code></p> <p>\ud83d\uddc4\ufe0f RedisStateManager: A state manager that stores state in Redis.</p> <p>This manager provides a fast, in-memory storage solution using Redis.</p>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager--attributes","title":"Attributes:","text":"<ul> <li><code>redis</code> (redis.Redis): The Redis connection.</li> </ul>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager--usage","title":"Usage:","text":"<pre><code>manager = RedisStateManager(host=\"localhost\", port=6379, db=0)\nmanager.set_state(\"user123\", {\"status\": \"active\"})\nstate = manager.get_state(\"user123\")\nprint(state)  # Outputs: {\"status\": \"active\"}\n</code></pre> <p>!!! warning     Ensure Redis is accessible and running.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py</code> <pre><code>class RedisStateManager(StateManager):\n\"\"\"\n    \ud83d\uddc4\ufe0f **RedisStateManager**: A state manager that stores state in Redis.\n    This manager provides a fast, in-memory storage solution using Redis.\n    ## Attributes:\n    - `redis` (redis.Redis): The Redis connection.\n    ## Usage:\n    ```python\n    manager = RedisStateManager(host=\"localhost\", port=6379, db=0)\n    manager.set_state(\"user123\", {\"status\": \"active\"})\n    state = manager.get_state(\"user123\")\n    print(state)  # Outputs: {\"status\": \"active\"}\n    ```\n    !!! warning\n        Ensure Redis is accessible and running.\n    \"\"\"\ndef __init__(self, host: str, port: int, db: int) -&gt; None:\n\"\"\"\n        Initialize a new Redis state manager.\n        Args:\n            host (str): The host of the Redis server.\n            port (int): The port of the Redis server.\n            db (int): The database number to connect to.\n        \"\"\"\nsuper().__init__()\nself.redis = redis.Redis(host=host, port=port, db=db)\nself.log = logging.getLogger(self.__class__.__name__)\nself.log.info(f\"\ud83d\udd0c Connected to Redis at {host}:{port}, DB: {db}\")\ndef get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        \ud83d\udcd6 Get the state associated with a key.\n        Args:\n            key (str): The key to get the state for.\n        Returns:\n            Dict: The state associated with the key, or None if not found.\n        Raises:\n            Exception: If there's an error accessing Redis.\n        \"\"\"\nvalue = self.redis.get(key)\nif not value:\nself.log.warning(f\"\ud83d\udd0d Key '{key}' not found in Redis.\")\nreturn None\nelse:\nreturn jsonpickle.decode(value.decode(\"utf-8\"))\ndef set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n        \ud83d\udcdd Set the state associated with a key.\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n        Raises:\n            Exception: If there's an error accessing Redis.\n        \"\"\"\ntry:\nself.redis.set(key, jsonpickle.encode(value))\nself.log.info(f\"\u2705 State for key '{key}' set in Redis.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to set state in Redis: {e}\")\nraise\n</code></pre>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager.__init__","title":"<code>__init__(host, port, db)</code>","text":"<p>Initialize a new Redis state manager.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>The host of the Redis server.</p> required <code>port</code> <code>int</code> <p>The port of the Redis server.</p> required <code>db</code> <code>int</code> <p>The database number to connect to.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py</code> <pre><code>def __init__(self, host: str, port: int, db: int) -&gt; None:\n\"\"\"\n    Initialize a new Redis state manager.\n    Args:\n        host (str): The host of the Redis server.\n        port (int): The port of the Redis server.\n        db (int): The database number to connect to.\n    \"\"\"\nsuper().__init__()\nself.redis = redis.Redis(host=host, port=port, db=db)\nself.log = logging.getLogger(self.__class__.__name__)\nself.log.info(f\"\ud83d\udd0c Connected to Redis at {host}:{port}, DB: {db}\")\n</code></pre>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager.get_state","title":"<code>get_state(key)</code>","text":"<p>\ud83d\udcd6 Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key, or None if not found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing Redis.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py</code> <pre><code>def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    \ud83d\udcd6 Get the state associated with a key.\n    Args:\n        key (str): The key to get the state for.\n    Returns:\n        Dict: The state associated with the key, or None if not found.\n    Raises:\n        Exception: If there's an error accessing Redis.\n    \"\"\"\nvalue = self.redis.get(key)\nif not value:\nself.log.warning(f\"\ud83d\udd0d Key '{key}' not found in Redis.\")\nreturn None\nelse:\nreturn jsonpickle.decode(value.decode(\"utf-8\"))\n</code></pre>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager.set_state","title":"<code>set_state(key, value)</code>","text":"<p>\ud83d\udcdd Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing Redis.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py</code> <pre><code>def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n    \ud83d\udcdd Set the state associated with a key.\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n    Raises:\n        Exception: If there's an error accessing Redis.\n    \"\"\"\ntry:\nself.redis.set(key, jsonpickle.encode(value))\nself.log.info(f\"\u2705 State for key '{key}' set in Redis.\")\nexcept Exception as e:\nself.log.exception(f\"\ud83d\udeab Failed to set state in Redis: {e}\")\nraise\n</code></pre>"},{"location":"core/core_task_base/","title":"Task","text":"<p>Base class for Task</p>"},{"location":"core/core_task_base/#core.task.base.Task","title":"<code>Task</code>","text":"<p>             Bases: <code>ABC</code></p> <p>\ud83d\udee0\ufe0f Task: Class for managing tasks.</p> <p>This class provides a foundation for creating and managing tasks. Each task has a unique identifier and can be associated with specific input and output configurations.</p>"},{"location":"core/core_task_base/#core.task.base.Task--attributes","title":"Attributes:","text":"<ul> <li><code>id</code> (uuid.UUID): Unique identifier for the task.</li> <li><code>input_config</code> (InputConfig): Configuration for input data.</li> <li><code>output_config</code> (OutputConfig): Configuration for output data.</li> </ul>"},{"location":"core/core_task_base/#core.task.base.Task--usage","title":"Usage:","text":"<pre><code>task = Task()\ntask.execute(\"fetch_data\")\n</code></pre> <p>!!! note     Extend this class to implement specific task functionalities.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>class Task(ABC):\n\"\"\"\n    \ud83d\udee0\ufe0f **Task**: Class for managing tasks.\n    This class provides a foundation for creating and managing tasks. Each task has a unique identifier and can be associated with specific input and output configurations.\n    ## Attributes:\n    - `id` (uuid.UUID): Unique identifier for the task.\n    - `input_config` (InputConfig): Configuration for input data.\n    - `output_config` (OutputConfig): Configuration for output data.\n    ## Usage:\n    ```python\n    task = Task()\n    task.execute(\"fetch_data\")\n    ```\n    !!! note\n        Extend this class to implement specific task functionalities.\n    \"\"\"\ninput_config: InputConfig\noutput_config: OutputConfig\ndef __init__(self) -&gt; None:\n\"\"\"\n        Initialize a new task.\n        Args:\n            input_config (InputConfig): Configuration for input data.\n            output_config (OutputConfig): Configuration for output data.\n        \"\"\"\nself.id = str(uuid.uuid4())\nself.log = logging.getLogger(self.__class__.__name__)\nself.log.info(f\"\ud83d\ude80 Initialized Task with ID: {self.id}\")\ndef __repr__(self) -&gt; str:\n\"\"\"\n        Return a string representation of the task.\n        Returns:\n            str: A string representation of the task.\n        \"\"\"\nreturn f\"Task(id={self.id}, input_config={self.input_config}, output_config={self.output_config})\"\ndef execute(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n        \ud83d\ude80 Execute a given fetch_* method if it exists.\n        Args:\n            method_name (str): The name of the fetch_* method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n        Returns:\n            Any: The result of the fetch_* method, or None if the method does not exist.\n        Raises:\n            AttributeError: If the specified method doesn't exist.\n        \"\"\"\nmethod = getattr(self, method_name, None)\nif callable(method):\nreturn method(*args, **kwargs)\nelse:\nself.log.error(f\"\ud83d\udeab Method '{method_name}' not found!\")\nraise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{method_name}'\")\n@staticmethod\ndef get_methods(cls) -&gt; List[Tuple[str, List[str], Optional[str]]]:\n\"\"\"\n        \ud83d\udcdc Get all the fetch_* methods and their parameters along with their default values and docstrings.\n        Returns:\n            List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method,\n            a list of its parameters along with their default values, and its docstring.\n        \"\"\"\nfetch_methods = []\nfor name, method in inspect.getmembers(cls, predicate=inspect.isfunction):\nif name.startswith(\"fetch_\"):\nparams = inspect.signature(method).parameters\nparams_str = [\nf\"{name}={param.default if param.default is not param.empty else ''}\"\nfor name, param in params.items()\n]\ndocstring = inspect.getdoc(method)\nfetch_methods.append((name, params_str, docstring))\nreturn fetch_methods\n@staticmethod\ndef print_help(cls) -&gt; None:\n\"\"\"\n        \ud83d\udda8\ufe0f Pretty print the fetch_* methods and their parameters along with their default values and docstrings.\n        Also prints the class's docstring and __init__ parameters.\n        \"\"\"\n# Print class docstring\nprint(cls.__name__, colored(inspect.getdoc(cls) if inspect.getdoc(cls) else \"\", \"green\"))  # type: ignore\n# Print fetch_* methods\nfetch_methods = cls.get_methods(cls)\nif fetch_methods:\ntable = PrettyTable(align=\"l\")\ntable.field_names = [\ncolored(\"Method\", \"cyan\"),\ncolored(\"Parameters\", \"cyan\"),\ncolored(\"Description\", \"cyan\"),\n]\nfor name, params, docstring in fetch_methods:\nparameters = [_p.replace(\"=\", \"\") for _p in params if \"self\" not in _p]\ntable.add_row(\n[colored(name, \"yellow\"), \"\\n\".join(parameters), docstring],\ndivider=True,\n)\nprint(table)\nelse:\nprint(colored(\"No fetch_* methods found.\", \"red\"))\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.__init__","title":"<code>__init__()</code>","text":"<p>Initialize a new task.</p> <p>Parameters:</p> Name Type Description Default <code>input_config</code> <code>InputConfig</code> <p>Configuration for input data.</p> required <code>output_config</code> <code>OutputConfig</code> <p>Configuration for output data.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>def __init__(self) -&gt; None:\n\"\"\"\n    Initialize a new task.\n    Args:\n        input_config (InputConfig): Configuration for input data.\n        output_config (OutputConfig): Configuration for output data.\n    \"\"\"\nself.id = str(uuid.uuid4())\nself.log = logging.getLogger(self.__class__.__name__)\nself.log.info(f\"\ud83d\ude80 Initialized Task with ID: {self.id}\")\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the task.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string representation of the task.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>def __repr__(self) -&gt; str:\n\"\"\"\n    Return a string representation of the task.\n    Returns:\n        str: A string representation of the task.\n    \"\"\"\nreturn f\"Task(id={self.id}, input_config={self.input_config}, output_config={self.output_config})\"\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.execute","title":"<code>execute(method_name, *args, **kwargs)</code>","text":"<p>\ud83d\ude80 Execute a given fetch_* method if it exists.</p> <p>Parameters:</p> Name Type Description Default <code>method_name</code> <code>str</code> <p>The name of the fetch_* method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the fetch_* method, or None if the method does not exist.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the specified method doesn't exist.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>def execute(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n    \ud83d\ude80 Execute a given fetch_* method if it exists.\n    Args:\n        method_name (str): The name of the fetch_* method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n    Returns:\n        Any: The result of the fetch_* method, or None if the method does not exist.\n    Raises:\n        AttributeError: If the specified method doesn't exist.\n    \"\"\"\nmethod = getattr(self, method_name, None)\nif callable(method):\nreturn method(*args, **kwargs)\nelse:\nself.log.error(f\"\ud83d\udeab Method '{method_name}' not found!\")\nraise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{method_name}'\")\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.get_methods","title":"<code>get_methods()</code>  <code>staticmethod</code>","text":"<p>\ud83d\udcdc Get all the fetch_* methods and their parameters along with their default values and docstrings.</p> <p>Returns:</p> Type Description <code>List[Tuple[str, List[str], Optional[str]]]</code> <p>List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method,</p> <code>List[Tuple[str, List[str], Optional[str]]]</code> <p>a list of its parameters along with their default values, and its docstring.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>@staticmethod\ndef get_methods(cls) -&gt; List[Tuple[str, List[str], Optional[str]]]:\n\"\"\"\n    \ud83d\udcdc Get all the fetch_* methods and their parameters along with their default values and docstrings.\n    Returns:\n        List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method,\n        a list of its parameters along with their default values, and its docstring.\n    \"\"\"\nfetch_methods = []\nfor name, method in inspect.getmembers(cls, predicate=inspect.isfunction):\nif name.startswith(\"fetch_\"):\nparams = inspect.signature(method).parameters\nparams_str = [\nf\"{name}={param.default if param.default is not param.empty else ''}\"\nfor name, param in params.items()\n]\ndocstring = inspect.getdoc(method)\nfetch_methods.append((name, params_str, docstring))\nreturn fetch_methods\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.print_help","title":"<code>print_help()</code>  <code>staticmethod</code>","text":"<p>\ud83d\udda8\ufe0f Pretty print the fetch_* methods and their parameters along with their default values and docstrings. Also prints the class's docstring and init parameters.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>@staticmethod\ndef print_help(cls) -&gt; None:\n\"\"\"\n    \ud83d\udda8\ufe0f Pretty print the fetch_* methods and their parameters along with their default values and docstrings.\n    Also prints the class's docstring and __init__ parameters.\n    \"\"\"\n# Print class docstring\nprint(cls.__name__, colored(inspect.getdoc(cls) if inspect.getdoc(cls) else \"\", \"green\"))  # type: ignore\n# Print fetch_* methods\nfetch_methods = cls.get_methods(cls)\nif fetch_methods:\ntable = PrettyTable(align=\"l\")\ntable.field_names = [\ncolored(\"Method\", \"cyan\"),\ncolored(\"Parameters\", \"cyan\"),\ncolored(\"Description\", \"cyan\"),\n]\nfor name, params, docstring in fetch_methods:\nparameters = [_p.replace(\"=\", \"\") for _p in params if \"self\" not in _p]\ntable.add_row(\n[colored(name, \"yellow\"), \"\\n\".join(parameters), docstring],\ndivider=True,\n)\nprint(table)\nelse:\nprint(colored(\"No fetch_* methods found.\", \"red\"))\n</code></pre>"},{"location":"core/core_task_ecs/","title":"ECS Runner","text":""},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager","title":"<code>ECSManager</code>","text":"<p>A class used to manage the lifecycle of an ECS container.</p> <p>...</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager--attributes","title":"Attributes","text":"str <p>the name of the ECS task or service</p> List[str] <p>the command that the container runs</p> str <p>the name of the ECS cluster</p> List[str] <p>the subnet IDs for the task or service</p> List[str] <p>the security group IDs for the task or service</p> str <p>the Docker image for the task</p> int <p>the number of task replicas</p> int <p>the port that the container listens on</p> str <p>the CloudWatch log group for the task logs</p> int <p>the CPU value for the task</p> int <p>the memory value for the task</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager--methods","title":"Methods","text":"<p>create_task_definition()     Registers a new task definition from the attributes of this class run_task(task_definition_arn: str)     Runs a new task using the specified task definition ARN describe_task(task_definition_arn: str)     Describes a task using the specified task definition ARN stop_task(task_definition_arn: str)     Stops a running task using the specified task definition ARN update_task(new_image: str, new_command: list)     Updates a task with a new Docker image and command create_service(task_definition_arn: str)     Creates a new service using the specified task definition ARN update_service(task_definition_arn: str)     Updates a service with a new task definition ARN delete_service()     Deletes the service</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>class ECSManager:\n\"\"\"\n    A class used to manage the lifecycle of an ECS container.\n    ...\n    Attributes\n    ----------\n    name : str\n        the name of the ECS task or service\n    command : List[str]\n        the command that the container runs\n    cluster : str\n        the name of the ECS cluster\n    subnet_ids : List[str]\n        the subnet IDs for the task or service\n    security_group_ids : List[str]\n        the security group IDs for the task or service\n    image : str\n        the Docker image for the task\n    replicas : int\n        the number of task replicas\n    port : int\n        the port that the container listens on\n    log_group : str\n        the CloudWatch log group for the task logs\n    cpu : int\n        the CPU value for the task\n    memory : int\n        the memory value for the task\n    Methods\n    -------\n    create_task_definition()\n        Registers a new task definition from the attributes of this class\n    run_task(task_definition_arn: str)\n        Runs a new task using the specified task definition ARN\n    describe_task(task_definition_arn: str)\n        Describes a task using the specified task definition ARN\n    stop_task(task_definition_arn: str)\n        Stops a running task using the specified task definition ARN\n    update_task(new_image: str, new_command: list)\n        Updates a task with a new Docker image and command\n    create_service(task_definition_arn: str)\n        Creates a new service using the specified task definition ARN\n    update_service(task_definition_arn: str)\n        Updates a service with a new task definition ARN\n    delete_service()\n        Deletes the service\n    \"\"\"\ndef __init__(\nself,\nname: str,\naccount_id: str,\ncluster: str,\ncommand: List[str] = [],\nsubnet_ids: List[str] = [],\nsecurity_group_ids: List[str] = [],\nimage: str = \"geniusrise/geniusrise\",\nreplicas: int = 1,\nport: int = 80,\nlog_group: str = \"/ecs/geniusrise\",\ncpu: int = 256,\nmemory: int = 512,\n):\n\"\"\"\n        Constructs all the necessary attributes for the ECSManager object.\n        Parameters\n        ----------\n            name : str\n                the name of the ECS task or service\n            account_id : str\n                the id of the AWS account\n            command : List[str]\n                the command that the container runs\n            cluster : str\n                the name of the ECS cluster\n            subnet_ids : List[str]\n                the subnet IDs for the task or service\n            security_group_ids : List[str]\n                the security group IDs for the task or service\n            image : str, optional\n                the Docker image for the task (default is \"geniusrise/geniusrise\")\n            replicas : int, optional\n                the number of task replicas (default is 1)\n            port : int, optional\n                the port that the container listens on (default is 80)\n            log_group : str, optional\n                the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\")\n            cpu : int, optional\n                the CPU value for the task (default is 256)\n            memory : int, optional\n                the memory value for the task (default is 512)\n        \"\"\"\nself.name = name\nself.image = image\nself.cluster = cluster\nself.command = command\nself.replicas = replicas\nself.port = port\nself.client = boto3.client(\"ecs\")\nself.log_group = log_group\nself.logs_client = boto3.client(\"logs\")\nself.subnet_ids = subnet_ids\nself.security_group_ids = security_group_ids\nself.cpu = cpu\nself.account_id = account_id\nself.memory = memory\ndef create_task_definition(self) -&gt; Optional[str]:\n\"\"\"\n        Registers a new task definition from the attributes of this class.\n        Returns\n        -------\n        str\n            The ARN of the task definition, or None if an error occurred.\n        \"\"\"\ncontainer_definitions = [\n{\n\"name\": self.name,\n\"image\": self.image,\n\"command\": self.command,\n\"portMappings\": [{\"containerPort\": self.port, \"protocol\": \"tcp\"}],\n}\n]\ntry:\nresponse = self.client.register_task_definition(\nfamily=self.name,\nnetworkMode=\"awsvpc\",\ncontainerDefinitions=container_definitions,\nrequiresCompatibilities=[\n\"FARGATE\",\n],\ncpu=str(self.cpu),\nmemory=str(self.memory),\nexecutionRoleArn=f\"arn:aws:iam::{self.account_id}:role/ecsTaskExecutionRole\",\n)\nlog.info(f\"Task definition {self.name} created.\")\nreturn response[\"taskDefinition\"][\"taskDefinitionArn\"]\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error creating task definition {self.name}: {error}\")\nreturn None\ndef run_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Runs a new task using the specified task definition ARN.\n        Parameters\n        ----------\n        task_definition_arn : str\n            The ARN of the task definition to run.\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\ntry:\nresponse = self.client.run_task(\ncluster=self.cluster,\ntaskDefinition=task_definition_arn,\ncount=self.replicas,\nlaunchType=\"FARGATE\",\nnetworkConfiguration={\n\"awsvpcConfiguration\": {\n\"subnets\": self.subnet_ids,\n\"assignPublicIp\": \"ENABLED\",\n\"securityGroups\": self.security_group_ids,\n}\n},\nplatformVersion=\"LATEST\",\n)\nlog.info(f\"Task {self.name} started.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error starting task {self.name}: {error}\")\nreturn None\ndef describe_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Describes a task using the specified task definition ARN.\n        Parameters\n        ----------\n        task_definition_arn : str\n            The ARN of the task definition to describe.\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\ntry:\nresponse = self.client.describe_tasks(cluster=self.cluster, tasks=[task_definition_arn])\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error getting status of task {self.name}: {error}\")\nreturn None\ndef stop_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Stops a running task using the specified task definition ARN.\n        Parameters\n        ----------\n        task_definition_arn : str\n            The ARN of the task definition to stop.\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\ntry:\nresponse = self.client.stop_task(cluster=self.cluster, task=task_definition_arn)\nlog.info(f\"Task {self.name} stopped.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error stopping task {self.name}: {error}\")\nreturn None\ndef update_task(self, new_image: str, new_command: list) -&gt; None:\n\"\"\"\n        Updates a task with a new Docker image and command.\n        Parameters\n        ----------\n        new_image : str\n            The new Docker image for the task.\n        new_command : list\n            The new command for the task.\n        \"\"\"\nself.image = new_image\nself.command = new_command\ntask_definition_arn = self.create_task_definition()\nif task_definition_arn:\nself.stop_task(task_definition_arn)\nself.run_task(task_definition_arn)\nelse:\nlog.error(f\"Error updating task {self.name} - could not create ECS task definition.\")\ndef create_service(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Creates a new service using the specified task definition ARN.\n        Parameters\n        ----------\n        task_definition_arn : str\n            The ARN of the task definition to use for the service.\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\ntry:\nresponse = self.client.create_service(\ncluster=self.cluster,\nserviceName=self.name,\ntaskDefinition=task_definition_arn,\ndesiredCount=self.replicas,\nlaunchType=\"FARGATE\",\nnetworkConfiguration={\n\"awsvpcConfiguration\": {\n\"subnets\": self.subnet_ids,\n\"assignPublicIp\": \"ENABLED\",\n\"securityGroups\": self.security_group_ids,\n}\n},\n)\nlog.info(f\"Service {self.name} created.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error creating service {self.name}: {error}\")\nreturn None\ndef update_service(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Updates a service with a new task definition ARN.\n        Parameters\n        ----------\n        task_definition_arn : str\n            The new ARN of the task definition to use for the service.\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\ntry:\nresponse = self.client.update_service(\ncluster=self.cluster,\nservice=self.name,\ntaskDefinition=task_definition_arn,\ndesiredCount=self.replicas,\n)\nlog.info(f\"Service {self.name} updated.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error updating service {self.name}: {error}\")\nreturn None\ndef delete_service(self) -&gt; Optional[dict]:\n\"\"\"\n        Deletes the service.\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\ntry:\nresponse = self.client.delete_service(\ncluster=self.cluster,\nservice=self.name,\n)\nlog.info(f\"Service {self.name} deleted.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error deleting service {self.name}: {error}\")\nreturn None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.__init__","title":"<code>__init__(name, account_id, cluster, command=[], subnet_ids=[], security_group_ids=[], image='geniusrise/geniusrise', replicas=1, port=80, log_group='/ecs/geniusrise', cpu=256, memory=512)</code>","text":"<p>Constructs all the necessary attributes for the ECSManager object.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.__init__--parameters","title":"Parameters","text":"<pre><code>name : str\n    the name of the ECS task or service\naccount_id : str\n    the id of the AWS account\ncommand : List[str]\n    the command that the container runs\ncluster : str\n    the name of the ECS cluster\nsubnet_ids : List[str]\n    the subnet IDs for the task or service\nsecurity_group_ids : List[str]\n    the security group IDs for the task or service\nimage : str, optional\n    the Docker image for the task (default is \"geniusrise/geniusrise\")\nreplicas : int, optional\n    the number of task replicas (default is 1)\nport : int, optional\n    the port that the container listens on (default is 80)\nlog_group : str, optional\n    the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\")\ncpu : int, optional\n    the CPU value for the task (default is 256)\nmemory : int, optional\n    the memory value for the task (default is 512)\n</code></pre> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def __init__(\nself,\nname: str,\naccount_id: str,\ncluster: str,\ncommand: List[str] = [],\nsubnet_ids: List[str] = [],\nsecurity_group_ids: List[str] = [],\nimage: str = \"geniusrise/geniusrise\",\nreplicas: int = 1,\nport: int = 80,\nlog_group: str = \"/ecs/geniusrise\",\ncpu: int = 256,\nmemory: int = 512,\n):\n\"\"\"\n    Constructs all the necessary attributes for the ECSManager object.\n    Parameters\n    ----------\n        name : str\n            the name of the ECS task or service\n        account_id : str\n            the id of the AWS account\n        command : List[str]\n            the command that the container runs\n        cluster : str\n            the name of the ECS cluster\n        subnet_ids : List[str]\n            the subnet IDs for the task or service\n        security_group_ids : List[str]\n            the security group IDs for the task or service\n        image : str, optional\n            the Docker image for the task (default is \"geniusrise/geniusrise\")\n        replicas : int, optional\n            the number of task replicas (default is 1)\n        port : int, optional\n            the port that the container listens on (default is 80)\n        log_group : str, optional\n            the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\")\n        cpu : int, optional\n            the CPU value for the task (default is 256)\n        memory : int, optional\n            the memory value for the task (default is 512)\n    \"\"\"\nself.name = name\nself.image = image\nself.cluster = cluster\nself.command = command\nself.replicas = replicas\nself.port = port\nself.client = boto3.client(\"ecs\")\nself.log_group = log_group\nself.logs_client = boto3.client(\"logs\")\nself.subnet_ids = subnet_ids\nself.security_group_ids = security_group_ids\nself.cpu = cpu\nself.account_id = account_id\nself.memory = memory\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_service","title":"<code>create_service(task_definition_arn)</code>","text":"<p>Creates a new service using the specified task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_service--parameters","title":"Parameters","text":"str <p>The ARN of the task definition to use for the service.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_service--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def create_service(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Creates a new service using the specified task definition ARN.\n    Parameters\n    ----------\n    task_definition_arn : str\n        The ARN of the task definition to use for the service.\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\ntry:\nresponse = self.client.create_service(\ncluster=self.cluster,\nserviceName=self.name,\ntaskDefinition=task_definition_arn,\ndesiredCount=self.replicas,\nlaunchType=\"FARGATE\",\nnetworkConfiguration={\n\"awsvpcConfiguration\": {\n\"subnets\": self.subnet_ids,\n\"assignPublicIp\": \"ENABLED\",\n\"securityGroups\": self.security_group_ids,\n}\n},\n)\nlog.info(f\"Service {self.name} created.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error creating service {self.name}: {error}\")\nreturn None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_task_definition","title":"<code>create_task_definition()</code>","text":"<p>Registers a new task definition from the attributes of this class.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_task_definition--returns","title":"Returns","text":"<p>str     The ARN of the task definition, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def create_task_definition(self) -&gt; Optional[str]:\n\"\"\"\n    Registers a new task definition from the attributes of this class.\n    Returns\n    -------\n    str\n        The ARN of the task definition, or None if an error occurred.\n    \"\"\"\ncontainer_definitions = [\n{\n\"name\": self.name,\n\"image\": self.image,\n\"command\": self.command,\n\"portMappings\": [{\"containerPort\": self.port, \"protocol\": \"tcp\"}],\n}\n]\ntry:\nresponse = self.client.register_task_definition(\nfamily=self.name,\nnetworkMode=\"awsvpc\",\ncontainerDefinitions=container_definitions,\nrequiresCompatibilities=[\n\"FARGATE\",\n],\ncpu=str(self.cpu),\nmemory=str(self.memory),\nexecutionRoleArn=f\"arn:aws:iam::{self.account_id}:role/ecsTaskExecutionRole\",\n)\nlog.info(f\"Task definition {self.name} created.\")\nreturn response[\"taskDefinition\"][\"taskDefinitionArn\"]\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error creating task definition {self.name}: {error}\")\nreturn None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.delete_service","title":"<code>delete_service()</code>","text":"<p>Deletes the service.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.delete_service--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def delete_service(self) -&gt; Optional[dict]:\n\"\"\"\n    Deletes the service.\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\ntry:\nresponse = self.client.delete_service(\ncluster=self.cluster,\nservice=self.name,\n)\nlog.info(f\"Service {self.name} deleted.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error deleting service {self.name}: {error}\")\nreturn None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.describe_task","title":"<code>describe_task(task_definition_arn)</code>","text":"<p>Describes a task using the specified task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.describe_task--parameters","title":"Parameters","text":"str <p>The ARN of the task definition to describe.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.describe_task--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def describe_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Describes a task using the specified task definition ARN.\n    Parameters\n    ----------\n    task_definition_arn : str\n        The ARN of the task definition to describe.\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\ntry:\nresponse = self.client.describe_tasks(cluster=self.cluster, tasks=[task_definition_arn])\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error getting status of task {self.name}: {error}\")\nreturn None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.run_task","title":"<code>run_task(task_definition_arn)</code>","text":"<p>Runs a new task using the specified task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.run_task--parameters","title":"Parameters","text":"str <p>The ARN of the task definition to run.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.run_task--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def run_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Runs a new task using the specified task definition ARN.\n    Parameters\n    ----------\n    task_definition_arn : str\n        The ARN of the task definition to run.\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\ntry:\nresponse = self.client.run_task(\ncluster=self.cluster,\ntaskDefinition=task_definition_arn,\ncount=self.replicas,\nlaunchType=\"FARGATE\",\nnetworkConfiguration={\n\"awsvpcConfiguration\": {\n\"subnets\": self.subnet_ids,\n\"assignPublicIp\": \"ENABLED\",\n\"securityGroups\": self.security_group_ids,\n}\n},\nplatformVersion=\"LATEST\",\n)\nlog.info(f\"Task {self.name} started.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error starting task {self.name}: {error}\")\nreturn None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.stop_task","title":"<code>stop_task(task_definition_arn)</code>","text":"<p>Stops a running task using the specified task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.stop_task--parameters","title":"Parameters","text":"str <p>The ARN of the task definition to stop.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.stop_task--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def stop_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Stops a running task using the specified task definition ARN.\n    Parameters\n    ----------\n    task_definition_arn : str\n        The ARN of the task definition to stop.\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\ntry:\nresponse = self.client.stop_task(cluster=self.cluster, task=task_definition_arn)\nlog.info(f\"Task {self.name} stopped.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error stopping task {self.name}: {error}\")\nreturn None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_service","title":"<code>update_service(task_definition_arn)</code>","text":"<p>Updates a service with a new task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_service--parameters","title":"Parameters","text":"str <p>The new ARN of the task definition to use for the service.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_service--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def update_service(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Updates a service with a new task definition ARN.\n    Parameters\n    ----------\n    task_definition_arn : str\n        The new ARN of the task definition to use for the service.\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\ntry:\nresponse = self.client.update_service(\ncluster=self.cluster,\nservice=self.name,\ntaskDefinition=task_definition_arn,\ndesiredCount=self.replicas,\n)\nlog.info(f\"Service {self.name} updated.\")\nreturn response\nexcept (BotoCoreError, ClientError) as error:\nlog.error(f\"Error updating service {self.name}: {error}\")\nreturn None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_task","title":"<code>update_task(new_image, new_command)</code>","text":"<p>Updates a task with a new Docker image and command.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_task--parameters","title":"Parameters","text":"str <p>The new Docker image for the task.</p> list <p>The new command for the task.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def update_task(self, new_image: str, new_command: list) -&gt; None:\n\"\"\"\n    Updates a task with a new Docker image and command.\n    Parameters\n    ----------\n    new_image : str\n        The new Docker image for the task.\n    new_command : list\n        The new command for the task.\n    \"\"\"\nself.image = new_image\nself.command = new_command\ntask_definition_arn = self.create_task_definition()\nif task_definition_arn:\nself.stop_task(task_definition_arn)\nself.run_task(task_definition_arn)\nelse:\nlog.error(f\"Error updating task {self.name} - could not create ECS task definition.\")\n</code></pre>"},{"location":"core/core_task_k8s/","title":"Kubernetes Runner","text":""},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager","title":"<code>K8sManager</code>","text":"<p>A class used to manage Kubernetes deployments and services.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager--attributes","title":"Attributes","text":"str <p>The name of the deployment and service.</p> str <p>The namespace to create the deployment and service in.</p> str <p>The Docker image to use for the deployment.</p> list <p>The command to run in the Docker container.</p> int <p>The number of replicas to create for the deployment.</p> int <p>The port to expose on the service.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager--methods","title":"Methods","text":"<p>create_deployment()     Creates a new deployment. update_deployment(replicas)     Updates the number of replicas in the deployment. scale_deployment(replicas)     Scales the deployment to a new number of replicas. delete_deployment()     Deletes the deployment. create_service()     Creates a new service. delete_service()     Deletes the service. run()     Creates the deployment and service. destroy()     Deletes the deployment and service. get_status()     Returns the status of the deployment. get_statistics()     Returns the details of the deployment and the pods in the deployment. get_logs()     Returns the logs of the pods in the deployment.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>class K8sManager:\n\"\"\"\n    A class used to manage Kubernetes deployments and services.\n    Attributes\n    ----------\n    name : str\n        The name of the deployment and service.\n    namespace : str\n        The namespace to create the deployment and service in.\n    image : str\n        The Docker image to use for the deployment.\n    command : list\n        The command to run in the Docker container.\n    replicas : int\n        The number of replicas to create for the deployment.\n    port : int\n        The port to expose on the service.\n    Methods\n    -------\n    create_deployment()\n        Creates a new deployment.\n    update_deployment(replicas)\n        Updates the number of replicas in the deployment.\n    scale_deployment(replicas)\n        Scales the deployment to a new number of replicas.\n    delete_deployment()\n        Deletes the deployment.\n    create_service()\n        Creates a new service.\n    delete_service()\n        Deletes the service.\n    run()\n        Creates the deployment and service.\n    destroy()\n        Deletes the deployment and service.\n    get_status()\n        Returns the status of the deployment.\n    get_statistics()\n        Returns the details of the deployment and the pods in the deployment.\n    get_logs()\n        Returns the logs of the pods in the deployment.\n    \"\"\"\ndef __init__(\nself,\nname: str,\ncommand: list = [],\nnamespace: str = \"default\",\nimage: str = \"geniusrise/geniusrise\",\nreplicas: int = 1,\nport: int = 80,\n):\n\"\"\"\n        Constructs all the necessary attributes for the K8sManager object.\n        Parameters\n        ----------\n        name : str\n            The name of the deployment and service.\n        command : list\n            The command to run in the Docker container.\n        namespace : str, optional\n            The namespace to create the deployment and service in (default is \"default\").\n        image : str, optional\n            The Docker image to use for the deployment (default is \"geniusrise/geniusrise\").\n        replicas : int, optional\n            The number of replicas to create for the deployment (default is 1).\n        port : int, optional\n            The port to expose on the service (default is 80).\n        \"\"\"\nself.name = name\nself.namespace = namespace\nself.image = image\nself.command = command\nself.replicas = replicas\nself.port = port\n# Load kube config from default location\nconfig.load_kube_config()\n# Create a client instance for Core V1 and Apps V1 of Kubernetes API\nself.core_api = client.CoreV1Api()\nself.apps_api = client.AppsV1Api()\ndef create_deployment(self):\n\"\"\"\n        Creates a new deployment.\n        The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image\n        and command specified in the constructor, and creates the number of replicas specified in the constructor.\n        If an error occurs while creating the deployment, an error message is logged and the method returns None.\n        \"\"\"\n# Define the container\ncontainer = client.V1Container(name=self.name, image=self.image, command=self.command)\n# Define the template\ntemplate = client.V1PodTemplateSpec(\nmetadata=client.V1ObjectMeta(labels={\"app\": self.name, \"service\": \"geniusrise\"}),\nspec=client.V1PodSpec(containers=[container]),\n)\n# Define the spec\nspec = client.V1DeploymentSpec(\nreplicas=self.replicas,\nselector=client.V1LabelSelector(match_labels={\"app\": self.name, \"service\": \"geniusrise\"}),\ntemplate=template,\n)\n# Define the deployment\ndeployment = client.V1Deployment(metadata=client.V1ObjectMeta(name=self.name), spec=spec)\n# Create the deployment\ntry:\nself.apps_api.create_namespaced_deployment(namespace=self.namespace, body=deployment)\nlog.info(f\"Deployment {self.name} created.\")\nexcept ApiException as e:\nlog.error(f\"Exception when creating deployment {self.name}: {e}\")\ndef update_deployment(self, replicas):\n\"\"\"\n        Updates the number of replicas in the deployment.\n        Parameters\n        ----------\n        replicas : int\n            The new number of replicas for the deployment.\n        If an error occurs while updating the deployment, an error message is logged and the method returns None.\n        \"\"\"\n# Get the existing deployment\ntry:\ndeployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n# Update the number of replicas\ndeployment.spec.replicas = replicas\n# Update the deployment\nself.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment)\nlog.info(f\"Deployment {self.name} updated.\")\nexcept ApiException as e:\nlog.error(f\"Exception when updating deployment {self.name}: {e}\")\ndef scale_deployment(self, replicas):\n\"\"\"\n        Scales the deployment to a new number of replicas.\n        Parameters\n        ----------\n        replicas : int\n            The new number of replicas for the deployment.\n        If an error occurs while scaling the deployment, an error message is logged and the method returns None.\n        \"\"\"\n# Get the existing deployment\ntry:\ndeployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n# Update the number of replicas\ndeployment.spec.replicas = replicas\n# Update the deployment\nself.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment)\nlog.info(f\"Deployment {self.name} scaled to {replicas} replicas.\")\nexcept ApiException as e:\nlog.error(f\"Exception when scaling deployment {self.name}: {e}\")\ndef delete_deployment(self):\n# Delete the deployment\ntry:\nself.apps_api.delete_namespaced_deployment(name=self.name, namespace=self.namespace)\nlog.info(f\"Deployment {self.name} deleted.\")\nexcept ApiException as e:\nlog.error(f\"Exception when deleting deployment {self.name}: {e}\")\ndef create_service(self):\n\"\"\"\n        Deletes the deployment.\n        If an error occurs while deleting the deployment, an error message is logged and the method returns None.\n        \"\"\"\n# Define the service spec\nspec = client.V1ServiceSpec(\nselector={\"app\": self.name},\nports=[client.V1ServicePort(port=self.port, target_port=self.port)],\n)\n# Define the service\nservice = client.V1Service(metadata=client.V1ObjectMeta(name=self.name), spec=spec)\n# Create the service\ntry:\nself.core_api.create_namespaced_service(namespace=self.namespace, body=service)\nlog.info(f\"Service {self.name} created.\")\nexcept ApiException as e:\nlog.error(f\"Exception when creating service {self.name}: {e}\")\ndef delete_service(self):\n\"\"\"\n        Creates a new service.\n        The service is created in the namespace specified in the constructor. The service exposes the port specified\n        in the constructor.\n        If an error occurs while creating the service, an error message is logged and the method returns None.\n        \"\"\"\n# Delete the service\ntry:\nself.core_api.delete_namespaced_service(name=self.name, namespace=self.namespace)\nlog.info(f\"Service {self.name} deleted.\")\nexcept ApiException as e:\nlog.error(f\"Exception when deleting service {self.name}: {e}\")\ndef run(self):\n\"\"\"\n        Creates the deployment and service.\n        If an error occurs while creating the deployment or service,\n        an error message is logged and the method returns None.\n        \"\"\"\nself.create_deployment()\nself.create_service()\ndef destroy(self):\n\"\"\"\n        Deletes the deployment and service.\n        If an error occurs while deleting the deployment or service,\n        an error message is logged and the method returns None.\n        \"\"\"\nself.delete_deployment()\nself.delete_service()\ndef get_status(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Get the status of the deployment\n        Returns:\n            Dict[str, Any]: The status of the deployment\n        \"\"\"\ntry:\n# Get the status of the deployment\ndeployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\nreturn deployment.status.__dict__\nexcept ApiException as e:\nlog.error(f\"Exception when getting status of deployment {self.name}: {e}\")\nreturn {}\ndef get_statistics(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Get the details of the deployment and the pods in the deployment\n        Returns:\n            Dict[str, Any]: The details of the deployment and the pods\n        \"\"\"\ntry:\n# Get the details of the deployment\ndeployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\ndeployment_stats = deployment.status\n# Get the details of the pods in the deployment\npod_list = self.core_api.list_namespaced_pod(self.namespace, label_selector=f\"app={self.name}\")\npod_stats = [pod.status for pod in pod_list.items]\nreturn {\"deployment\": deployment_stats, \"pods\": pod_stats}\nexcept ApiException as e:\nlog.error(f\"Exception when getting statistics of deployment {self.name}: {e}\")\nreturn {}\ndef get_logs(self) -&gt; Dict[str, str]:\n\"\"\"\n        Get the logs of the pods in the deployment\n        Returns:\n            Dict[str, str]: The logs of the pods\n        \"\"\"\ntry:\n# Get the logs of the pods in the deployment\nlogs = {}\n_continue = None\nwhile True:\npod_list = self.core_api.list_namespaced_pod(\nself.namespace,\nlabel_selector=f\"app={self.name}\",\n_continue=_continue,\n)\nfor pod in pod_list.items:\nlogs[pod.metadata.name] = self.core_api.read_namespaced_pod_log(pod.metadata.name, self.namespace)\n_continue = pod_list.metadata._continue\nif not _continue:\nbreak\nreturn logs\nexcept ApiException as e:\nlog.error(f\"Exception when getting logs of deployment {self.name}: {e}\")\nreturn {}\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.__init__","title":"<code>__init__(name, command=[], namespace='default', image='geniusrise/geniusrise', replicas=1, port=80)</code>","text":"<p>Constructs all the necessary attributes for the K8sManager object.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.__init__--parameters","title":"Parameters","text":"str <p>The name of the deployment and service.</p> list <p>The command to run in the Docker container.</p> str, optional <p>The namespace to create the deployment and service in (default is \"default\").</p> str, optional <p>The Docker image to use for the deployment (default is \"geniusrise/geniusrise\").</p> int, optional <p>The number of replicas to create for the deployment (default is 1).</p> int, optional <p>The port to expose on the service (default is 80).</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def __init__(\nself,\nname: str,\ncommand: list = [],\nnamespace: str = \"default\",\nimage: str = \"geniusrise/geniusrise\",\nreplicas: int = 1,\nport: int = 80,\n):\n\"\"\"\n    Constructs all the necessary attributes for the K8sManager object.\n    Parameters\n    ----------\n    name : str\n        The name of the deployment and service.\n    command : list\n        The command to run in the Docker container.\n    namespace : str, optional\n        The namespace to create the deployment and service in (default is \"default\").\n    image : str, optional\n        The Docker image to use for the deployment (default is \"geniusrise/geniusrise\").\n    replicas : int, optional\n        The number of replicas to create for the deployment (default is 1).\n    port : int, optional\n        The port to expose on the service (default is 80).\n    \"\"\"\nself.name = name\nself.namespace = namespace\nself.image = image\nself.command = command\nself.replicas = replicas\nself.port = port\n# Load kube config from default location\nconfig.load_kube_config()\n# Create a client instance for Core V1 and Apps V1 of Kubernetes API\nself.core_api = client.CoreV1Api()\nself.apps_api = client.AppsV1Api()\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.create_deployment","title":"<code>create_deployment()</code>","text":"<p>Creates a new deployment.</p> <p>The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image and command specified in the constructor, and creates the number of replicas specified in the constructor.</p> <p>If an error occurs while creating the deployment, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def create_deployment(self):\n\"\"\"\n    Creates a new deployment.\n    The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image\n    and command specified in the constructor, and creates the number of replicas specified in the constructor.\n    If an error occurs while creating the deployment, an error message is logged and the method returns None.\n    \"\"\"\n# Define the container\ncontainer = client.V1Container(name=self.name, image=self.image, command=self.command)\n# Define the template\ntemplate = client.V1PodTemplateSpec(\nmetadata=client.V1ObjectMeta(labels={\"app\": self.name, \"service\": \"geniusrise\"}),\nspec=client.V1PodSpec(containers=[container]),\n)\n# Define the spec\nspec = client.V1DeploymentSpec(\nreplicas=self.replicas,\nselector=client.V1LabelSelector(match_labels={\"app\": self.name, \"service\": \"geniusrise\"}),\ntemplate=template,\n)\n# Define the deployment\ndeployment = client.V1Deployment(metadata=client.V1ObjectMeta(name=self.name), spec=spec)\n# Create the deployment\ntry:\nself.apps_api.create_namespaced_deployment(namespace=self.namespace, body=deployment)\nlog.info(f\"Deployment {self.name} created.\")\nexcept ApiException as e:\nlog.error(f\"Exception when creating deployment {self.name}: {e}\")\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.create_service","title":"<code>create_service()</code>","text":"<p>Deletes the deployment.</p> <p>If an error occurs while deleting the deployment, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def create_service(self):\n\"\"\"\n    Deletes the deployment.\n    If an error occurs while deleting the deployment, an error message is logged and the method returns None.\n    \"\"\"\n# Define the service spec\nspec = client.V1ServiceSpec(\nselector={\"app\": self.name},\nports=[client.V1ServicePort(port=self.port, target_port=self.port)],\n)\n# Define the service\nservice = client.V1Service(metadata=client.V1ObjectMeta(name=self.name), spec=spec)\n# Create the service\ntry:\nself.core_api.create_namespaced_service(namespace=self.namespace, body=service)\nlog.info(f\"Service {self.name} created.\")\nexcept ApiException as e:\nlog.error(f\"Exception when creating service {self.name}: {e}\")\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.delete_service","title":"<code>delete_service()</code>","text":"<p>Creates a new service.</p> <p>The service is created in the namespace specified in the constructor. The service exposes the port specified in the constructor.</p> <p>If an error occurs while creating the service, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def delete_service(self):\n\"\"\"\n    Creates a new service.\n    The service is created in the namespace specified in the constructor. The service exposes the port specified\n    in the constructor.\n    If an error occurs while creating the service, an error message is logged and the method returns None.\n    \"\"\"\n# Delete the service\ntry:\nself.core_api.delete_namespaced_service(name=self.name, namespace=self.namespace)\nlog.info(f\"Service {self.name} deleted.\")\nexcept ApiException as e:\nlog.error(f\"Exception when deleting service {self.name}: {e}\")\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.destroy","title":"<code>destroy()</code>","text":"<p>Deletes the deployment and service.</p> <p>If an error occurs while deleting the deployment or service, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def destroy(self):\n\"\"\"\n    Deletes the deployment and service.\n    If an error occurs while deleting the deployment or service,\n    an error message is logged and the method returns None.\n    \"\"\"\nself.delete_deployment()\nself.delete_service()\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.get_logs","title":"<code>get_logs()</code>","text":"<p>Get the logs of the pods in the deployment</p> <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dict[str, str]: The logs of the pods</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def get_logs(self) -&gt; Dict[str, str]:\n\"\"\"\n    Get the logs of the pods in the deployment\n    Returns:\n        Dict[str, str]: The logs of the pods\n    \"\"\"\ntry:\n# Get the logs of the pods in the deployment\nlogs = {}\n_continue = None\nwhile True:\npod_list = self.core_api.list_namespaced_pod(\nself.namespace,\nlabel_selector=f\"app={self.name}\",\n_continue=_continue,\n)\nfor pod in pod_list.items:\nlogs[pod.metadata.name] = self.core_api.read_namespaced_pod_log(pod.metadata.name, self.namespace)\n_continue = pod_list.metadata._continue\nif not _continue:\nbreak\nreturn logs\nexcept ApiException as e:\nlog.error(f\"Exception when getting logs of deployment {self.name}: {e}\")\nreturn {}\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.get_statistics","title":"<code>get_statistics()</code>","text":"<p>Get the details of the deployment and the pods in the deployment</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: The details of the deployment and the pods</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def get_statistics(self) -&gt; Dict[str, Any]:\n\"\"\"\n    Get the details of the deployment and the pods in the deployment\n    Returns:\n        Dict[str, Any]: The details of the deployment and the pods\n    \"\"\"\ntry:\n# Get the details of the deployment\ndeployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\ndeployment_stats = deployment.status\n# Get the details of the pods in the deployment\npod_list = self.core_api.list_namespaced_pod(self.namespace, label_selector=f\"app={self.name}\")\npod_stats = [pod.status for pod in pod_list.items]\nreturn {\"deployment\": deployment_stats, \"pods\": pod_stats}\nexcept ApiException as e:\nlog.error(f\"Exception when getting statistics of deployment {self.name}: {e}\")\nreturn {}\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.get_status","title":"<code>get_status()</code>","text":"<p>Get the status of the deployment</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: The status of the deployment</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def get_status(self) -&gt; Dict[str, Any]:\n\"\"\"\n    Get the status of the deployment\n    Returns:\n        Dict[str, Any]: The status of the deployment\n    \"\"\"\ntry:\n# Get the status of the deployment\ndeployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\nreturn deployment.status.__dict__\nexcept ApiException as e:\nlog.error(f\"Exception when getting status of deployment {self.name}: {e}\")\nreturn {}\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.run","title":"<code>run()</code>","text":"<p>Creates the deployment and service.</p> <p>If an error occurs while creating the deployment or service, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def run(self):\n\"\"\"\n    Creates the deployment and service.\n    If an error occurs while creating the deployment or service,\n    an error message is logged and the method returns None.\n    \"\"\"\nself.create_deployment()\nself.create_service()\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.scale_deployment","title":"<code>scale_deployment(replicas)</code>","text":"<p>Scales the deployment to a new number of replicas.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.scale_deployment--parameters","title":"Parameters","text":"int <p>The new number of replicas for the deployment.</p> <p>If an error occurs while scaling the deployment, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def scale_deployment(self, replicas):\n\"\"\"\n    Scales the deployment to a new number of replicas.\n    Parameters\n    ----------\n    replicas : int\n        The new number of replicas for the deployment.\n    If an error occurs while scaling the deployment, an error message is logged and the method returns None.\n    \"\"\"\n# Get the existing deployment\ntry:\ndeployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n# Update the number of replicas\ndeployment.spec.replicas = replicas\n# Update the deployment\nself.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment)\nlog.info(f\"Deployment {self.name} scaled to {replicas} replicas.\")\nexcept ApiException as e:\nlog.error(f\"Exception when scaling deployment {self.name}: {e}\")\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.update_deployment","title":"<code>update_deployment(replicas)</code>","text":"<p>Updates the number of replicas in the deployment.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.update_deployment--parameters","title":"Parameters","text":"int <p>The new number of replicas for the deployment.</p> <p>If an error occurs while updating the deployment, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def update_deployment(self, replicas):\n\"\"\"\n    Updates the number of replicas in the deployment.\n    Parameters\n    ----------\n    replicas : int\n        The new number of replicas for the deployment.\n    If an error occurs while updating the deployment, an error message is logged and the method returns None.\n    \"\"\"\n# Get the existing deployment\ntry:\ndeployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n# Update the number of replicas\ndeployment.spec.replicas = replicas\n# Update the deployment\nself.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment)\nlog.info(f\"Deployment {self.name} updated.\")\nexcept ApiException as e:\nlog.error(f\"Exception when updating deployment {self.name}: {e}\")\n</code></pre>"},{"location":"core/logging/","title":"Logging Configuration","text":""},{"location":"core/logging/#logging.setup_logger","title":"<code>setup_logger()</code>","text":"<p>\ud83d\udee0\ufe0f Setup Logger: Configure and return a logger with a default ColoredFormatter.</p> <p>This function sets up a logger for the <code>geniusrise-cli</code> with colorful logging outputs. The log level is determined by the <code>LOGLEVEL</code> from the configuration.</p>"},{"location":"core/logging/#logging.setup_logger--usage","title":"Usage:","text":"<pre><code>logger = setup_logger()\nlogger.info(\"This is a fancy info log!\")\n</code></pre> <p>Returns:</p> Type Description <code>logging.Logger</code> <p>logging.Logger: Configured logger with colorful outputs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/logging.py</code> <pre><code>def setup_logger() -&gt; logging.Logger:\n\"\"\"\n    \ud83d\udee0\ufe0f **Setup Logger**: Configure and return a logger with a default ColoredFormatter.\n    This function sets up a logger for the `geniusrise-cli` with colorful logging outputs. The log level is determined by the `LOGLEVEL` from the configuration.\n    ## Usage:\n    ```python\n    logger = setup_logger()\n    logger.info(\"This is a fancy info log!\")\n    ```\n    Returns:\n        logging.Logger: Configured logger with colorful outputs.\n    \"\"\"\n# Define the custom formatter\nformatter = colorlog.ColoredFormatter(\n\"%(log_color)s%(levelname)-8s%(reset)s \"\n\"%(yellow)s[%(asctime)s] \"\n\"%(blue)s[%(name)s:%(lineno)d] \"\n\"%(green)s%(message)s\",\ndatefmt=\"%Y-%m-%d %H:%M:%S\",\nreset=True,\nlog_colors={\n\"DEBUG\": \"cyan\",\n\"INFO\": \"green\",\n\"WARNING\": \"yellow\",\n\"ERROR\": \"red\",\n\"CRITICAL\": \"bold_red\",\n},\n)\n# Setup logger for geniusrise\nlogger = logging.getLogger(\"geniusrise\")\nhandler = logging.StreamHandler()\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\nlogger.setLevel(LOGLEVEL)\n# \ud83c\udf89 Logger is ready to use!\nlogger.info(\"\ud83d\ude80 Logger is set up and ready to use!\")\nreturn logger\n</code></pre>"},{"location":"guides/architecture/","title":"Architecture","text":""},{"location":"guides/architecture/#introduction","title":"Introduction","text":"<p>The Geniusrise framework is designed to provide a modular, scalable, and interoperable system for orchestrating machine learning workflows, particularly in the context of Large Language Models (LLMs). The architecture is built around the core concept of a <code>Task</code>, which represents a discrete unit of work. This document provides an overview of the architecture, detailing the primary components and their interactions.</p>"},{"location":"guides/architecture/#system-overview","title":"System Overview","text":"<p>The Geniusrise framework is composed of several key components:</p> <ol> <li>Tasks: The fundamental units of work.</li> <li>State Managers: Responsible for monitoring and managing the state of tasks.</li> <li>Data Managers: Oversee the input and output data associated with tasks.</li> <li>Model Managers: Handle model operations, ensuring efficient management.</li> <li>Runners: Wrappers for executing tasks on various platforms.</li> <li>Spouts and Bolts: Specialized tasks for data ingestion and processing.</li> </ol>"},{"location":"guides/architecture/#tasks","title":"Tasks","text":"<p>A task is the fundamental unit of work in the Geniusrise framework. It represents a specific operation or computation and can run for an arbitrary amount of time, performing any amount of work.</p> <pre>0d7cbe7a-e3a8-4250-9ade-41467ac3798a</pre>"},{"location":"guides/architecture/#state-managers","title":"State Managers","text":"<p>State Managers play a pivotal role in maintaining the state of tasks. They ensure that the progress and status of tasks are tracked, especially in distributed environments. Geniusrise offers various types of State Managers:</p> <ol> <li>DynamoDBStateManager: Interfaces with Amazon DynamoDB.</li> <li>InMemoryStateManager: Maintains state within the application's memory.</li> <li>PostgresStateManager: Interfaces with PostgreSQL databases.</li> <li>RedisStateManager: Interfaces with Redis in-memory data structure store.</li> </ol> <p>State Managers store data in various locations, allowing organizations to connect dashboards to these storage systems for real-time monitoring and analytics. This centralized storage and reporting mechanism ensures that stakeholders have a unified view of task states.</p> <pre>d1a996c0-49ea-4f82-9dfd-2b592d82dfa0</pre>"},{"location":"guides/architecture/#data-managers","title":"Data Managers","text":"<p>Data Managers are responsible for handling the input and output data for tasks. They implement various data operations methods that tasks can leverage to ingest or save data during their runs. Data Managers can be categorized based on their function and data processing type:</p> <ol> <li>BatchInputConfig: Manages batch input data.</li> <li>BatchOutputConfig: Manages batch output data.</li> <li>StreamingInputConfig: Manages streaming input data.</li> <li>StreamingOutputConfig: Manages streaming output data.</li> </ol> <p>Data Managers manage data partitioning for both batch and streaming data. By adhering to common data patterns, they enable the system's components to operate independently, fostering the creation of intricate networks of tasks. This independence, while allowing for flexibility and scalability, ensures that cascading failures in one component don't necessarily compromise the entire system.</p> <pre>6fad0abb-038a-4c7b-82fb-5e5d12db7934</pre>"},{"location":"guides/architecture/#model-managers","title":"Model Managers","text":"<p>Model Managers oversee model operations, ensuring that models are saved, loaded, and managed. They can be of two primary types:</p> <ol> <li>S3ModelManager: Interfaces with Amazon S3 for model storage.</li> <li>WANDBModelManager: Interfaces with Weights &amp; Biases for model versioning.</li> <li>GitModelManager: Interfaces with Git repositories for versioning of models.</li> </ol> <pre>ab245909-0c07-4cd1-bef4-920798cbaec2</pre>"},{"location":"guides/architecture/#spouts-and-bolts","title":"Spouts and Bolts","text":"<p>At the heart of the Geniusrise framework are two primary component types: spouts and bolts.</p> <ol> <li> <p>Spouts: These are tasks responsible for ingesting data from various sources. Depending on the output type, spouts can either produce streaming output or batch output.</p> <ol> <li>Batch: Runs periodically, Produces data as a batch output.</li> <li>Stream: Runs forever, produces data into a streaming output.</li> </ol> </li> <li> <p>Bolts: Bolts are tasks that take in data, process it, and produce output. They can be categorized based on their input and output types:</p> <ol> <li>Stream-Stream: Reads streaming data and produces streaming output.</li> <li>Stream-Batch: Reads streaming data and produces batch output.</li> <li>Batch-Stream: Reads batch data and produces streaming output.</li> <li>Batch-Batch: Reads batch data and produces batch output.</li> </ol> </li> </ol> <pre>a8161cfd-cdd2-42ce-bd09-ca14961105ed</pre>"},{"location":"guides/architecture/#runners","title":"Runners","text":"<p>Runners are the backbone of the Geniusrise framework, ensuring that tasks are executed seamlessly across various platforms. They encapsulate the environment and resources required for task execution, abstracting away the underlying complexities. Geniusrise offers the following runners:</p> <ol> <li>Local Runner: Executes tasks directly on a local machine, ideal for development and testing.</li> <li>Docker Runner: Runs tasks within Docker containers, ensuring a consistent and isolated environment.</li> <li>Kubernetes Runner: Deploys tasks on Kubernetes clusters, leveraging its scalability and orchestration capabilities.</li> <li>Airflow Runner: Integrates with Apache Airflow, allowing for complex workflow orchestration and scheduling.</li> <li>ECS Runner: Executes tasks on AWS ECS, providing a managed container service.</li> <li>Batch Runner: Optimized for batch computing workloads on platforms like AWS Batch.</li> </ol>"},{"location":"guides/concepts/","title":"Concepts","text":""},{"location":"guides/concepts/#need","title":"Need","text":"<p>The landscape of machine learning and data processing has been rapidly evolving. While there are numerous solutions available for MLOps and DAG orchestration, most of them cater primarily to data engineering and data science teams. However, the rise of Large Language Models (LLMs) is reshaping this landscape, necessitating a more inclusive approach to MLOps.</p> <p>LLMs have democratized the use of machine learning models, enabling a broader spectrum of users within an organization to engage with them. This means that even organizations without a traditional data science data management or model management functions are now venturing into this domain.</p> <p>This shift brings forth several challenges:</p> <ol> <li> <p>Infrastructure Complexity: The world of MLOps is vast, with a plethora of options available for different use cases. Organizations often grapple with questions like:</p> <ul> <li>Which infrastructure is best suited for their needs?</li> <li>How can they efficiently reuse their existing infrastructure?</li> <li>How can they ensure scalability and performance while managing costs?</li> </ul> </li> <li> <p>Diverse Competence Levels: As LLM workflows become more prevalent, their volume is set to surpass that of traditional ML workflows in many organizations. This surge means that individuals without a formal engineering background or core ML expertise will be involved in the MLOps process. Ensuring that these individuals can contribute effectively without compromising the quality or integrity of the workflows is crucial.</p> </li> <li> <p>Standardization and Productionization: While many aspects of building LLM workflows can be managed without deep engineering expertise, there's a critical need for standardization. Engineers play a pivotal role in defining the processes for productionizing these workflows. Without standardized practices:</p> <ul> <li>How can organizations ensure consistency across workflows?</li> <li>How can they maintain the reliability and robustness of deployed models?</li> <li>How can they ensure that best practices are adhered to, regardless of who is building or deploying the workflow?</li> </ul> </li> </ol> <p>The advent of LLMs underscores the need for an MLOps framework that caters to a diverse audience. Such a framework should be flexible enough to accommodate the varied infrastructure needs of organizations, inclusive enough to empower contributors regardless of their technical expertise, and robust enough to ensure standardized, reliable workflows.</p>"},{"location":"guides/concepts/#introduction","title":"Introduction","text":"<p>The Geniusrise framework is built around loosely-coupled modules acting as a cohesive adhesive between distinct, modular components, much like how one would piece together Lego blocks. This design approach not only promotes flexibility but also ensures that each module or \"Lego block\" remains sufficiently independent. Such independence is crucial for diverse teams, each with its own unique infrastructure and requirements, to seamlessly build and manage their respective components.</p> <p>Geniusrise comes with a sizable set of plugins which implement various features and integrations. The independence and modularity of the design enable sharing of these building blocks in the community.</p>"},{"location":"guides/concepts/#concepts_1","title":"Concepts","text":"<ol> <li> <p>Task: At its core, a task represents a discrete unit of work within the Geniusrise framework. Think of it as a singular action or operation that the system needs to execute. A task further manifests itself into a Bolt or a Spout as stated below.</p> </li> <li> <p>Components of a Task: Each task is equipped with four components:</p> <ol> <li>State Manager: This component is responsible for continuously monitoring and managing the task's state, ensuring that it progresses smoothly from initiation to completion and to report errors and ship logs into a central location.</li> <li>Data Manager: As the name suggests, the Data Manager oversees the input and output data associated with a task, ensuring data integrity and efficient data flow. It also ensures data sanity follows partition semantics and isolation.</li> <li>Model Manager: In the realm of machine learning, model versioning and management are paramount. The Model Manager serves as a GitOps tool for ML models, ensuring that they are versioned, tracked, and managed effectively.</li> <li>Runner: These are wrappers for executing a task on various platforms. Depending on the platform, the runner ensures that the task is executed seamlessly.</li> </ol> </li> <li> <p>Task Classification: Tasks within the Geniusrise framework can be broadly classified into two categories:</p> <ul> <li>Spout: If a task's primary function is to ingest or bring in data, it's termed as a 'spout'.</li> <li>Bolt: For tasks that don't primarily ingest data but perform other operations, they are termed 'bolts'.</li> </ul> </li> </ol> <p>The beauty of the Geniusrise framework lies in its adaptability. Developers can script their workflow components once and have the freedom to deploy them across various platforms. To facilitate this, Geniusrise offers:</p> <ol> <li> <p>Runners for Task Execution: Geniusrise is equipped with a diverse set of runners, each tailored for different platforms, ensuring that tasks can be executed almost anywhere:</p> <ol> <li>On your local machine for quick testing and development.</li> <li>Within Docker containers for isolated, reproducible environments.</li> <li>On Kubernetes clusters for scalable, cloud-native deployments.</li> <li>Using Apache Airflow for complex workflow orchestration.</li> <li>On AWS ECS for containerized application management.</li> <li>With AWS Batch for efficient batch computing workloads.</li> </ol> </li> <li> <p>Library Wrappers: To ensure that tasks can interface with a variety of frameworks, Geniusrise provides integrations with:</p> <ol> <li>Jupyter/ipython for interactive computing.</li> <li>Apache PySpark for large-scale data processing.</li> <li>Apache PyFlink for stream and batch processing.</li> <li>Apache Beam for unified stream and batch data processing.</li> <li>Apache Storm for real-time computation.</li> </ol> </li> <li> <p>Genius hub - Where developers can share and sell their components. Coming soon geniusrise.com.</p> </li> </ol> <p>The framework aims to support multiple languages:</p> <ol> <li>Python</li> <li>Scala / JVM (WIP)</li> <li>Golang (WIP)</li> </ol> <p>This document delves into the core components and concepts that make up the Geniusrise framework.</p>"},{"location":"guides/concepts/#tradeoffs","title":"Tradeoffs","text":"<p>Because of the very loose coupling of the components, though the framework can be used to build very complex networks with independently running nodes, it provides limited orchestration capability, like synchronous pipelines. An external orchestrator like airflow can be used in such cases to orchestrate geniusrise components.</p>"},{"location":"guides/installation/","title":"Installation","text":"<p>Geniusrise is composed of the core framework and various plugins that implement specific tasks. The core has to be installed first, and after that selected plugins can be installed as and when required.</p>"},{"location":"guides/installation/#installing-geniusrise","title":"Installing Geniusrise","text":""},{"location":"guides/installation/#using-pip","title":"Using pip","text":"<p>To install the core framework using pip in local env, simply run:</p> <pre><code>pip install geniusrise\n</code></pre> <p>Or if you wish to install at user level:</p> <pre><code>pip install generiusrise --user\n</code></pre> <p>Or on a global level (might conflict with your OS package manager):</p> <pre><code>sudo pip install geniusrise\n</code></pre> <p>To verify the installation, you can check whether the geniusrise binary exists in PATH:</p> <pre><code>which geniusrise\n\ngeniusrise --help\n</code></pre>"},{"location":"guides/installation/#using-package-managers","title":"Using package managers","text":"<p>Geniusrise is also available as native packages for some Linux distributions.</p>"},{"location":"guides/installation/#aur","title":"AUR","text":"<p>Geniusrise is available on the AUR for arch and derived distros.</p> <pre><code>yay -S geniusrise\n</code></pre> <p>or directly from git master:</p> <pre><code>yay -S geniusrise-git\n</code></pre>"},{"location":"guides/installation/#ppa","title":"PPA","text":"<p>Geniusrise is also available on the PPA for debian-based distros.</p> <pre><code>sudo add-apt-repository ppa:ixaxaar/geniusrise\nsudo apt-get update\nsudo apt-get install -y geniusrise\n</code></pre>"},{"location":"guides/installation/#brew-cask","title":"Brew (cask)","text":"<pre><code>brew cask install geniusrise\n</code></pre>"},{"location":"guides/installation/#docker","title":"Docker","text":"<p>Geniusrise containers are available on Docker hub.</p> <pre><code>docker run -it --rm geniusrise/geniusrise:latest\n</code></pre>"},{"location":"guides/installation/#nix","title":"Nix","text":"<p>Coming soon \ud83d\ude22</p>"},{"location":"guides/installation/#installing-plugins","title":"Installing Plugins","text":"<p>Geniusrise offers a variety of plugins that act as composable lego blocks. To install a specific plugin, use the following format:</p> <pre><code>pip install geniusrise[plugin-name]\n</code></pre> <p>Replace <code>plugin-name</code> with the name of the desired plugin.</p>"},{"location":"guides/installation/#alternative-methods","title":"Alternative Methods","text":""},{"location":"guides/installation/#using-conda","title":"Using Conda","text":"<ol> <li>Activate the environment:</li> </ol> <pre><code>conda activate your-env\n</code></pre> <ol> <li>Install Geniusrise:</li> </ol> <pre><code>pip install geniusrise\n</code></pre> <p>For plugins:</p> <pre><code>pip install geniusrise[plugin-name]\n</code></pre>"},{"location":"guides/installation/#using-poetry","title":"Using Poetry","text":"<ol> <li>Add Geniusrise as a dependency:</li> </ol> <pre><code>poetry add geniusrise\n</code></pre> <p>For plugins:</p> <pre><code>poetry add geniusrise[plugin-name]\n</code></pre>"},{"location":"guides/installation/#development","title":"Development","text":"<p>For development, you may want to install from the repo:</p> <pre><code>git clone git@github.com:geniusrise/geniusrise.git\ncd geniusrise\nvirtualenv venv -p `which python3.10`\nsource venv/bin/activate\npip install -r ./requirements.txt\n\nmake install # installs in your local venv directory\n</code></pre> <p>That's it! You've successfully installed Geniusrise and its plugins. \ud83c\udf89</p>"},{"location":"guides/local/","title":"Local setup","text":"<p>This is probably the first thing that anyone would want to do.</p>"},{"location":"guides/local/#boilerplate","title":"Boilerplate","text":"<p>To setup a local geniusrise project, simply use the geniusrise project creator script:</p> <pre><code>curl -L https://cum.gdn/OfeQir | bash\n</code></pre> <p>or</p> <pre><code>curl -L https://raw.githubusercontent.com/geniusrise/geniusrise/master/scripts/install.sh | bash\n</code></pre>"},{"location":"guides/local/#existing-project","title":"Existing project","text":"<p>If you wish to add geniusrise to an existing project:</p> <pre><code>pip install geniusrise\npip freeze &gt; requirements.txt\n</code></pre>"},{"location":"guides/local/#from-scratch","title":"From scratch","text":"<p>Here is how to set up from scratch:</p> <pre><code>#!/bin/bash\n# Prompt for project details\nread -p \"Enter your project name: \" project_name\nread -p \"Enter your name: \" author_name\nread -p \"Enter your email: \" author_email\nread -p \"Enter your GitHub username: \" github_username\nread -p \"Enter a brief description of your project: \" project_description\n# Create project structure\nmkdir $project_name\ncd $project_name\nmkdir $project_name tests\n# Create basic files\ntouch README.md\ntouch requirements.txt\ntouch setup.py\ntouch Makefile\ntouch $project_name/__init__.py\ntouch tests/__init__.py\n# Populate README.md\necho \"# $project_name\" &gt; README.md\necho \"\\n$project_description\" &gt;&gt; README.md\n# Populate setup.py\ncat &lt;&lt;EOL &gt; setup.py\nfrom setuptools import setup, find_packages\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\nlong_description = fh.read()\nsetup(\nname='$project_name',\nversion='0.1.0',\npackages=find_packages(exclude=[\"tests\", \"tests.*\"]),\ninstall_requires=[],\npython_requires='&gt;=3.10',\nauthor='$author_name',\nauthor_email='$author_email',\ndescription='$project_description',\nlong_description=long_description,\nlong_description_content_type='text/markdown',\nurl='https://github.com/$github_username/$project_name',\nclassifiers=[\n'Programming Language :: Python :: 3',\n'License :: OSI Approved :: MIT License',\n'Operating System :: OS Independent',\n],\n)\nEOL\n# Populate Makefile\ncat &lt;&lt;EOL &gt; Makefile\nsetup:\n@pip install -r ./requirements.txt\ntest:\n@coverage run -m pytest -v ./tests\npublish:\n@python setup.py sdist bdist_wheel\n@twine upload dist/$project_name-\\$${VERSION}-* --verbose\nEOL\n# Set up the virtual environment and install necessary packages\nvirtualenv venv -p `which python3.10`\nsource venv/bin/activate\npip install twine setuptools pytest coverage\npip freeze &gt; requirements.txt\n# Fetch .pre-commit-config.yaml and .gitignore from geniusrise/geniusrise\ncurl -O https://raw.githubusercontent.com/geniusrise/geniusrise/master/.pre-commit-config.yaml\ncurl -O https://raw.githubusercontent.com/geniusrise/geniusrise/master/.gitignore\necho \"Project $project_name initialized!\"\n</code></pre> <p>Create a install script out of this and execute it:</p> <pre><code>touch install.sh\nchmod +x ./install.sh\n./install.sh\n</code></pre>"}]}