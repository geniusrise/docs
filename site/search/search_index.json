{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Geniusrise Documentation Core Reference: cli: boltctl: core/cli_boltctl.md discover: core/cli_discover.md geniusctl: core/cli_geniusctl.md schema: core/cli_schema.md spoutctl: core/cli_spoutctl.md yamlctl: core/cli_yamlctl.md core: bolt: core/core_bolt.md spout: core/core_spout.md data: batch_input: core/core_data_batch_input.md batch_output: core/core_data_batch_output.md input: core/core_data_input.md output: core/core_data_output.md streaming_input: core/core_data_streaming_input.md streaming_output: core/core_data_streaming_output.md state: base: core/core_state_base.md dynamo: core/core_state_dynamo.md memory: core/core_state_memory.md postgres: core/core_state_postgres.md redis: core/core_state_redis.md task: base: core/core_task_base.md ecs: core/core_task_ecs.md k8s: core/core_task_k8s.md","title":"Home"},{"location":"#geniusrise-documentation","text":"Core Reference: cli: boltctl: core/cli_boltctl.md discover: core/cli_discover.md geniusctl: core/cli_geniusctl.md schema: core/cli_schema.md spoutctl: core/cli_spoutctl.md yamlctl: core/cli_yamlctl.md core: bolt: core/core_bolt.md spout: core/core_spout.md data: batch_input: core/core_data_batch_input.md batch_output: core/core_data_batch_output.md input: core/core_data_input.md output: core/core_data_output.md streaming_input: core/core_data_streaming_input.md streaming_output: core/core_data_streaming_output.md state: base: core/core_state_base.md dynamo: core/core_state_dynamo.md memory: core/core_state_memory.md postgres: core/core_state_postgres.md redis: core/core_state_redis.md task: base: core/core_task_base.md ecs: core/core_task_ecs.md k8s: core/core_task_k8s.md","title":"Geniusrise Documentation"},{"location":"cli/boltctl/","text":"","title":"Boltctl"},{"location":"cli/geniusctl/","text":"","title":"Geniusctl"},{"location":"cli/spoutctl/","text":"","title":"Spoutctl"},{"location":"cli/test_boltctl/","text":"","title":"Test boltctl"},{"location":"cli/test_spoutctl/","text":"","title":"Test spoutctl"},{"location":"cli/test_yamlctl/","text":"","title":"Test yamlctl"},{"location":"cli/yamlctl/","text":"","title":"Yamlctl"},{"location":"core/cli_boltctl/","text":"BoltCtl Class for managing bolts end-to-end from the command line. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py class BoltCtl: \"\"\" Class for managing bolts end-to-end from the command line. \"\"\" def __init__(self, discovered_bolt: DiscoveredBolt): \"\"\" Initialize BoltCtl with a DiscoveredBolt object. Args: discovered_bolt (DiscoveredBolt): DiscoveredBolt object used to create and manage bolts. \"\"\" self.discovered_bolt = discovered_bolt self.bolt = None self.log = logging.getLogger(self.__class__.__name__) def create_parser(self, parser): \"\"\" Add arguments to the command-line parser for managing the bolt. Args: parser (argparse.ArgumentParser): Command-line parser. \"\"\" subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for 'run' command run_parser = subparsers.add_parser(\"run\", help=\"Run a bolt locally.\") run_parser.add_argument( \"input_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of input configuration: batch or streaming.\", default=\"batch\", ) run_parser.add_argument( \"output_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of output configuration: batch or streaming.\", default=\"batch\", ) run_parser.add_argument( \"state_type\", choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"], help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\", default=\"in_memory\", ) run_parser.add_argument( \"--input_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) run_parser.add_argument( \"--input_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) run_parser.add_argument( \"--input_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) run_parser.add_argument( \"--input_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) run_parser.add_argument( \"--input_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) run_parser.add_argument( \"--output_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) run_parser.add_argument( \"--output_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) run_parser.add_argument( \"--output_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) run_parser.add_argument( \"--output_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) run_parser.add_argument( \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) run_parser.add_argument( \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str ) run_parser.add_argument( \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int ) run_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int) run_parser.add_argument( \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str ) run_parser.add_argument( \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int ) run_parser.add_argument( \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str ) run_parser.add_argument( \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str ) run_parser.add_argument( \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str ) run_parser.add_argument( \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str ) run_parser.add_argument( \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str ) run_parser.add_argument( \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str ) run_parser.add_argument( \"method_name\", help=\"The name of the method to execute on the bolt.\", type=str, ) run_parser.add_argument( \"--args\", nargs=argparse.REMAINDER, help=\"Additional keyword arguments to pass to the bolt.\", ) # Create subparser for 'help' command help_parser = subparsers.add_parser(\"help\", help=\"Print help for the bolt.\") help_parser.add_argument(\"method\", help=\"The method to execute.\") return parser def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\")) try: if args.command == \"run\": kwargs = { k: v for k, v in vars(args).items() if v is not None and k not in [\"input_type\", \"output_type\", \"state_type\", \"args\", \"method_name\"] } other = args.args or [] other_args, other_kwargs = self.parse_args_kwargs(other) self.bolt = self.create_bolt(args.input_type, args.output_type, args.state_type, **kwargs) # Pass the method_name from args to execute_bolt result = self.execute_bolt(self.bolt, args.method_name, *other_args, **other_kwargs) self.log.info(emoji.emojize(f\"Successfully executed the bolt method: {args.method_name} :thumbs_up:\")) return result elif args.command == \"help\": self.discovered_bolt.klass.print_help(self.discovered_bolt.klass) except ValueError as ve: self.log.exception(f\"Value error: {ve}\") raise except AttributeError as ae: self.log.exception(f\"Attribute error: {ae}\") raise except KeyError as ke: self.log.exception(f\"Missing key: {ke}\") raise except Exception as e: self.log.exception(f\"An unexpected error occurred: {e}\") raise @staticmethod def parse_args_kwargs(args_list): args = [] kwargs = {} def convert(value): try: return int(value) except ValueError: try: return float(value) except ValueError: return value for item in args_list: if \"=\" in item: key, value = item.split(\"=\", 1) kwargs[key] = convert(value) else: args.append(convert(item)) return args, kwargs def create_bolt(self, input_type: str, output_type: str, state_type: str, **kwargs) -> Bolt: \"\"\" Create a bolt of a specific type. Args: input_type (str): The type of input config (\"batch\" or \"streaming\"). output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Bolt: The created bolt. \"\"\" return Bolt.create( klass=self.discovered_bolt.klass, input_type=input_type, output_type=output_type, state_type=state_type, **kwargs, ) def execute_bolt(self, bolt: Bolt, method_name: str, *args, **kwargs): \"\"\" Execute a method of a bolt. Args: bolt (Bolt): The bolt to execute. method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the method. \"\"\" return bolt.__call__(method_name, *args, **kwargs) __init__(discovered_bolt) Initialize BoltCtl with a DiscoveredBolt object. Parameters: Name Type Description Default discovered_bolt DiscoveredBolt DiscoveredBolt object used to create and manage bolts. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def __init__(self, discovered_bolt: DiscoveredBolt): \"\"\" Initialize BoltCtl with a DiscoveredBolt object. Args: discovered_bolt (DiscoveredBolt): DiscoveredBolt object used to create and manage bolts. \"\"\" self.discovered_bolt = discovered_bolt self.bolt = None self.log = logging.getLogger(self.__class__.__name__) create_bolt(input_type, output_type, state_type, **kwargs) Create a bolt of a specific type. Parameters: Name Type Description Default input_type str The type of input config (\"batch\" or \"streaming\"). required output_type str The type of output config (\"batch\" or \"streaming\"). required state_type str The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). required **kwargs Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. {} Returns: Name Type Description Bolt Bolt The created bolt. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def create_bolt(self, input_type: str, output_type: str, state_type: str, **kwargs) -> Bolt: \"\"\" Create a bolt of a specific type. Args: input_type (str): The type of input config (\"batch\" or \"streaming\"). output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Bolt: The created bolt. \"\"\" return Bolt.create( klass=self.discovered_bolt.klass, input_type=input_type, output_type=output_type, state_type=state_type, **kwargs, ) create_parser(parser) Add arguments to the command-line parser for managing the bolt. Parameters: Name Type Description Default parser argparse . ArgumentParser Command-line parser. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def create_parser(self, parser): \"\"\" Add arguments to the command-line parser for managing the bolt. Args: parser (argparse.ArgumentParser): Command-line parser. \"\"\" subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for 'run' command run_parser = subparsers.add_parser(\"run\", help=\"Run a bolt locally.\") run_parser.add_argument( \"input_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of input configuration: batch or streaming.\", default=\"batch\", ) run_parser.add_argument( \"output_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of output configuration: batch or streaming.\", default=\"batch\", ) run_parser.add_argument( \"state_type\", choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"], help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\", default=\"in_memory\", ) run_parser.add_argument( \"--input_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) run_parser.add_argument( \"--input_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) run_parser.add_argument( \"--input_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) run_parser.add_argument( \"--input_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) run_parser.add_argument( \"--input_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) run_parser.add_argument( \"--output_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) run_parser.add_argument( \"--output_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) run_parser.add_argument( \"--output_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) run_parser.add_argument( \"--output_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) run_parser.add_argument( \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) run_parser.add_argument( \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str ) run_parser.add_argument( \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int ) run_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int) run_parser.add_argument( \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str ) run_parser.add_argument( \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int ) run_parser.add_argument( \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str ) run_parser.add_argument( \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str ) run_parser.add_argument( \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str ) run_parser.add_argument( \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str ) run_parser.add_argument( \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str ) run_parser.add_argument( \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str ) run_parser.add_argument( \"method_name\", help=\"The name of the method to execute on the bolt.\", type=str, ) run_parser.add_argument( \"--args\", nargs=argparse.REMAINDER, help=\"Additional keyword arguments to pass to the bolt.\", ) # Create subparser for 'help' command help_parser = subparsers.add_parser(\"help\", help=\"Print help for the bolt.\") help_parser.add_argument(\"method\", help=\"The method to execute.\") return parser execute_bolt(bolt, method_name, *args, **kwargs) Execute a method of a bolt. Parameters: Name Type Description Default bolt Bolt The bolt to execute. required method_name str The name of the method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. {} Returns: Name Type Description Any The result of the method. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def execute_bolt(self, bolt: Bolt, method_name: str, *args, **kwargs): \"\"\" Execute a method of a bolt. Args: bolt (Bolt): The bolt to execute. method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the method. \"\"\" return bolt.__call__(method_name, *args, **kwargs) run(args) Run the command-line interface. Parameters: Name Type Description Default args argparse . Namespace Parsed command-line arguments. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\")) try: if args.command == \"run\": kwargs = { k: v for k, v in vars(args).items() if v is not None and k not in [\"input_type\", \"output_type\", \"state_type\", \"args\", \"method_name\"] } other = args.args or [] other_args, other_kwargs = self.parse_args_kwargs(other) self.bolt = self.create_bolt(args.input_type, args.output_type, args.state_type, **kwargs) # Pass the method_name from args to execute_bolt result = self.execute_bolt(self.bolt, args.method_name, *other_args, **other_kwargs) self.log.info(emoji.emojize(f\"Successfully executed the bolt method: {args.method_name} :thumbs_up:\")) return result elif args.command == \"help\": self.discovered_bolt.klass.print_help(self.discovered_bolt.klass) except ValueError as ve: self.log.exception(f\"Value error: {ve}\") raise except AttributeError as ae: self.log.exception(f\"Attribute error: {ae}\") raise except KeyError as ke: self.log.exception(f\"Missing key: {ke}\") raise except Exception as e: self.log.exception(f\"An unexpected error occurred: {e}\") raise","title":"boltctl"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl","text":"Class for managing bolts end-to-end from the command line. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py class BoltCtl: \"\"\" Class for managing bolts end-to-end from the command line. \"\"\" def __init__(self, discovered_bolt: DiscoveredBolt): \"\"\" Initialize BoltCtl with a DiscoveredBolt object. Args: discovered_bolt (DiscoveredBolt): DiscoveredBolt object used to create and manage bolts. \"\"\" self.discovered_bolt = discovered_bolt self.bolt = None self.log = logging.getLogger(self.__class__.__name__) def create_parser(self, parser): \"\"\" Add arguments to the command-line parser for managing the bolt. Args: parser (argparse.ArgumentParser): Command-line parser. \"\"\" subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for 'run' command run_parser = subparsers.add_parser(\"run\", help=\"Run a bolt locally.\") run_parser.add_argument( \"input_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of input configuration: batch or streaming.\", default=\"batch\", ) run_parser.add_argument( \"output_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of output configuration: batch or streaming.\", default=\"batch\", ) run_parser.add_argument( \"state_type\", choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"], help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\", default=\"in_memory\", ) run_parser.add_argument( \"--input_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) run_parser.add_argument( \"--input_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) run_parser.add_argument( \"--input_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) run_parser.add_argument( \"--input_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) run_parser.add_argument( \"--input_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) run_parser.add_argument( \"--output_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) run_parser.add_argument( \"--output_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) run_parser.add_argument( \"--output_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) run_parser.add_argument( \"--output_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) run_parser.add_argument( \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) run_parser.add_argument( \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str ) run_parser.add_argument( \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int ) run_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int) run_parser.add_argument( \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str ) run_parser.add_argument( \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int ) run_parser.add_argument( \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str ) run_parser.add_argument( \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str ) run_parser.add_argument( \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str ) run_parser.add_argument( \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str ) run_parser.add_argument( \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str ) run_parser.add_argument( \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str ) run_parser.add_argument( \"method_name\", help=\"The name of the method to execute on the bolt.\", type=str, ) run_parser.add_argument( \"--args\", nargs=argparse.REMAINDER, help=\"Additional keyword arguments to pass to the bolt.\", ) # Create subparser for 'help' command help_parser = subparsers.add_parser(\"help\", help=\"Print help for the bolt.\") help_parser.add_argument(\"method\", help=\"The method to execute.\") return parser def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\")) try: if args.command == \"run\": kwargs = { k: v for k, v in vars(args).items() if v is not None and k not in [\"input_type\", \"output_type\", \"state_type\", \"args\", \"method_name\"] } other = args.args or [] other_args, other_kwargs = self.parse_args_kwargs(other) self.bolt = self.create_bolt(args.input_type, args.output_type, args.state_type, **kwargs) # Pass the method_name from args to execute_bolt result = self.execute_bolt(self.bolt, args.method_name, *other_args, **other_kwargs) self.log.info(emoji.emojize(f\"Successfully executed the bolt method: {args.method_name} :thumbs_up:\")) return result elif args.command == \"help\": self.discovered_bolt.klass.print_help(self.discovered_bolt.klass) except ValueError as ve: self.log.exception(f\"Value error: {ve}\") raise except AttributeError as ae: self.log.exception(f\"Attribute error: {ae}\") raise except KeyError as ke: self.log.exception(f\"Missing key: {ke}\") raise except Exception as e: self.log.exception(f\"An unexpected error occurred: {e}\") raise @staticmethod def parse_args_kwargs(args_list): args = [] kwargs = {} def convert(value): try: return int(value) except ValueError: try: return float(value) except ValueError: return value for item in args_list: if \"=\" in item: key, value = item.split(\"=\", 1) kwargs[key] = convert(value) else: args.append(convert(item)) return args, kwargs def create_bolt(self, input_type: str, output_type: str, state_type: str, **kwargs) -> Bolt: \"\"\" Create a bolt of a specific type. Args: input_type (str): The type of input config (\"batch\" or \"streaming\"). output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Bolt: The created bolt. \"\"\" return Bolt.create( klass=self.discovered_bolt.klass, input_type=input_type, output_type=output_type, state_type=state_type, **kwargs, ) def execute_bolt(self, bolt: Bolt, method_name: str, *args, **kwargs): \"\"\" Execute a method of a bolt. Args: bolt (Bolt): The bolt to execute. method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the method. \"\"\" return bolt.__call__(method_name, *args, **kwargs)","title":"BoltCtl"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.__init__","text":"Initialize BoltCtl with a DiscoveredBolt object. Parameters: Name Type Description Default discovered_bolt DiscoveredBolt DiscoveredBolt object used to create and manage bolts. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def __init__(self, discovered_bolt: DiscoveredBolt): \"\"\" Initialize BoltCtl with a DiscoveredBolt object. Args: discovered_bolt (DiscoveredBolt): DiscoveredBolt object used to create and manage bolts. \"\"\" self.discovered_bolt = discovered_bolt self.bolt = None self.log = logging.getLogger(self.__class__.__name__)","title":"__init__()"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.create_bolt","text":"Create a bolt of a specific type. Parameters: Name Type Description Default input_type str The type of input config (\"batch\" or \"streaming\"). required output_type str The type of output config (\"batch\" or \"streaming\"). required state_type str The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). required **kwargs Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. {} Returns: Name Type Description Bolt Bolt The created bolt. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def create_bolt(self, input_type: str, output_type: str, state_type: str, **kwargs) -> Bolt: \"\"\" Create a bolt of a specific type. Args: input_type (str): The type of input config (\"batch\" or \"streaming\"). output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Bolt: The created bolt. \"\"\" return Bolt.create( klass=self.discovered_bolt.klass, input_type=input_type, output_type=output_type, state_type=state_type, **kwargs, )","title":"create_bolt()"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.create_parser","text":"Add arguments to the command-line parser for managing the bolt. Parameters: Name Type Description Default parser argparse . ArgumentParser Command-line parser. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def create_parser(self, parser): \"\"\" Add arguments to the command-line parser for managing the bolt. Args: parser (argparse.ArgumentParser): Command-line parser. \"\"\" subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for 'run' command run_parser = subparsers.add_parser(\"run\", help=\"Run a bolt locally.\") run_parser.add_argument( \"input_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of input configuration: batch or streaming.\", default=\"batch\", ) run_parser.add_argument( \"output_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of output configuration: batch or streaming.\", default=\"batch\", ) run_parser.add_argument( \"state_type\", choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"], help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\", default=\"in_memory\", ) run_parser.add_argument( \"--input_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) run_parser.add_argument( \"--input_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) run_parser.add_argument( \"--input_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) run_parser.add_argument( \"--input_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) run_parser.add_argument( \"--input_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) run_parser.add_argument( \"--output_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) run_parser.add_argument( \"--output_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) run_parser.add_argument( \"--output_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) run_parser.add_argument( \"--output_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) run_parser.add_argument( \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) run_parser.add_argument( \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str ) run_parser.add_argument( \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int ) run_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int) run_parser.add_argument( \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str ) run_parser.add_argument( \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int ) run_parser.add_argument( \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str ) run_parser.add_argument( \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str ) run_parser.add_argument( \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str ) run_parser.add_argument( \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str ) run_parser.add_argument( \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str ) run_parser.add_argument( \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str ) run_parser.add_argument( \"method_name\", help=\"The name of the method to execute on the bolt.\", type=str, ) run_parser.add_argument( \"--args\", nargs=argparse.REMAINDER, help=\"Additional keyword arguments to pass to the bolt.\", ) # Create subparser for 'help' command help_parser = subparsers.add_parser(\"help\", help=\"Print help for the bolt.\") help_parser.add_argument(\"method\", help=\"The method to execute.\") return parser","title":"create_parser()"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.execute_bolt","text":"Execute a method of a bolt. Parameters: Name Type Description Default bolt Bolt The bolt to execute. required method_name str The name of the method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. {} Returns: Name Type Description Any The result of the method. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def execute_bolt(self, bolt: Bolt, method_name: str, *args, **kwargs): \"\"\" Execute a method of a bolt. Args: bolt (Bolt): The bolt to execute. method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the method. \"\"\" return bolt.__call__(method_name, *args, **kwargs)","title":"execute_bolt()"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.run","text":"Run the command-line interface. Parameters: Name Type Description Default args argparse . Namespace Parsed command-line arguments. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\")) try: if args.command == \"run\": kwargs = { k: v for k, v in vars(args).items() if v is not None and k not in [\"input_type\", \"output_type\", \"state_type\", \"args\", \"method_name\"] } other = args.args or [] other_args, other_kwargs = self.parse_args_kwargs(other) self.bolt = self.create_bolt(args.input_type, args.output_type, args.state_type, **kwargs) # Pass the method_name from args to execute_bolt result = self.execute_bolt(self.bolt, args.method_name, *other_args, **other_kwargs) self.log.info(emoji.emojize(f\"Successfully executed the bolt method: {args.method_name} :thumbs_up:\")) return result elif args.command == \"help\": self.discovered_bolt.klass.print_help(self.discovered_bolt.klass) except ValueError as ve: self.log.exception(f\"Value error: {ve}\") raise except AttributeError as ae: self.log.exception(f\"Attribute error: {ae}\") raise except KeyError as ke: self.log.exception(f\"Missing key: {ke}\") raise except Exception as e: self.log.exception(f\"An unexpected error occurred: {e}\") raise","title":"run()"},{"location":"core/cli_discover/","text":"Discover Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py class Discover: def __init__(self, directory: Optional[str] = None): \"\"\"Initialize the Discover class.\"\"\" self.classes: Dict[str, Any] = {} self.log = logging.getLogger(self.__class__.__name__) self.directory = directory def scan_directory(self, directory: Optional[str] = None) -> Dict[str, Any]: \"\"\" Scan for spouts/bolts in installed extensions and user's codebase. Args: directory (Optional[str]): Directory to scan for user-defined spouts/bolts. Returns: Dict[str, Any]: Discovered spouts/bolts. \"\"\" directory = directory if directory else self.directory self.log.info(emoji.emojize(\"\ud83d\udd0d Starting discovery...\")) # Discover installed extensions self.discover_installed_extensions() # Discover user-defined spouts/bolts if directory: self.directory = directory for root, _, files in os.walk(self.directory): if \"__init__.py\" in files: module = self.import_module(root) self.find_classes(module) return self.classes def discover_installed_extensions(self): \"\"\"Discover installed geniusrise extensions.\"\"\" self.log.info(emoji.emojize(\"\ud83d\udd0e Discovering installed extensions...\")) for entry_point in pkg_resources.iter_entry_points(group=\"geniusrise.extensions\"): try: module = entry_point.load() self.find_classes(module) except Exception as e: self.log.error(emoji.emojize(f\"\u274c Error discovering classes in {entry_point.name}: {e}\")) def import_module(self, path: str): \"\"\" Import a module given its path. Args: path (str): Path to the module. Returns: Any: Imported module. \"\"\" project_root = os.path.abspath(os.path.join(self.directory, \"../../../../\")) # type: ignore relative_path = os.path.relpath(path, project_root) module_path = relative_path.replace(os.sep, \".\") if module_path.endswith(\"__init__\"): module_path = module_path[:-9] # remove trailing '__init__' self.log.info(emoji.emojize(f\"\ud83d\udce6 Importing module {module_path}...\")) module = importlib.import_module(module_path) return module def find_classes(self, module: Any): \"\"\" Discover spout/bolt classes in a module. Args: module (Any): Module to scan for spout/bolt classes. \"\"\" for name, obj in inspect.getmembers(module): discovered: DiscoveredSpout | DiscoveredBolt if inspect.isclass(obj) and issubclass(obj, Spout) and obj != Spout: discovered = DiscoveredSpout(name=name, klass=obj, init_args=self.get_init_args(obj)) self.log.info(emoji.emojize(f\"\ud83d\ude80 Discovered Spout {discovered.name}\")) self.classes[name] = discovered elif inspect.isclass(obj) and issubclass(obj, Bolt) and obj != Bolt: discovered = DiscoveredBolt(name=name, klass=obj, init_args=self.get_init_args(obj)) self.log.info(emoji.emojize(f\"\u26a1 Discovered Bolt {discovered.name}\")) self.classes[name] = discovered def get_init_args(self, cls: type) -> Dict[str, Any]: \"\"\" Extract initialization arguments of a class. Args: cls (type): Class to extract initialization arguments from. Returns: Dict[str, Any]: Initialization arguments. \"\"\" init_signature = inspect.signature(cls.__init__) # type: ignore init_params = init_signature.parameters init_args = {} for name, kind in init_params.items(): if name == \"self\": continue if name == \"kwargs\" or name == \"args\": init_args[\"kwargs\"] = Any continue if isinstance(kind.annotation, ABCMeta): init_args[name] = self.get_init_args(kind.annotation) elif kind.annotation == inspect.Parameter.empty: init_args[name] = \"No type hint provided \ud83d\ude22\" else: init_args[name] = kind.annotation return init_args __init__(directory=None) Initialize the Discover class. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def __init__(self, directory: Optional[str] = None): \"\"\"Initialize the Discover class.\"\"\" self.classes: Dict[str, Any] = {} self.log = logging.getLogger(self.__class__.__name__) self.directory = directory discover_installed_extensions() Discover installed geniusrise extensions. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def discover_installed_extensions(self): \"\"\"Discover installed geniusrise extensions.\"\"\" self.log.info(emoji.emojize(\"\ud83d\udd0e Discovering installed extensions...\")) for entry_point in pkg_resources.iter_entry_points(group=\"geniusrise.extensions\"): try: module = entry_point.load() self.find_classes(module) except Exception as e: self.log.error(emoji.emojize(f\"\u274c Error discovering classes in {entry_point.name}: {e}\")) find_classes(module) Discover spout/bolt classes in a module. Parameters: Name Type Description Default module Any Module to scan for spout/bolt classes. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def find_classes(self, module: Any): \"\"\" Discover spout/bolt classes in a module. Args: module (Any): Module to scan for spout/bolt classes. \"\"\" for name, obj in inspect.getmembers(module): discovered: DiscoveredSpout | DiscoveredBolt if inspect.isclass(obj) and issubclass(obj, Spout) and obj != Spout: discovered = DiscoveredSpout(name=name, klass=obj, init_args=self.get_init_args(obj)) self.log.info(emoji.emojize(f\"\ud83d\ude80 Discovered Spout {discovered.name}\")) self.classes[name] = discovered elif inspect.isclass(obj) and issubclass(obj, Bolt) and obj != Bolt: discovered = DiscoveredBolt(name=name, klass=obj, init_args=self.get_init_args(obj)) self.log.info(emoji.emojize(f\"\u26a1 Discovered Bolt {discovered.name}\")) self.classes[name] = discovered get_init_args(cls) Extract initialization arguments of a class. Parameters: Name Type Description Default cls type Class to extract initialization arguments from. required Returns: Type Description Dict [ str , Any ] Dict[str, Any]: Initialization arguments. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def get_init_args(self, cls: type) -> Dict[str, Any]: \"\"\" Extract initialization arguments of a class. Args: cls (type): Class to extract initialization arguments from. Returns: Dict[str, Any]: Initialization arguments. \"\"\" init_signature = inspect.signature(cls.__init__) # type: ignore init_params = init_signature.parameters init_args = {} for name, kind in init_params.items(): if name == \"self\": continue if name == \"kwargs\" or name == \"args\": init_args[\"kwargs\"] = Any continue if isinstance(kind.annotation, ABCMeta): init_args[name] = self.get_init_args(kind.annotation) elif kind.annotation == inspect.Parameter.empty: init_args[name] = \"No type hint provided \ud83d\ude22\" else: init_args[name] = kind.annotation return init_args import_module(path) Import a module given its path. Parameters: Name Type Description Default path str Path to the module. required Returns: Name Type Description Any Imported module. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def import_module(self, path: str): \"\"\" Import a module given its path. Args: path (str): Path to the module. Returns: Any: Imported module. \"\"\" project_root = os.path.abspath(os.path.join(self.directory, \"../../../../\")) # type: ignore relative_path = os.path.relpath(path, project_root) module_path = relative_path.replace(os.sep, \".\") if module_path.endswith(\"__init__\"): module_path = module_path[:-9] # remove trailing '__init__' self.log.info(emoji.emojize(f\"\ud83d\udce6 Importing module {module_path}...\")) module = importlib.import_module(module_path) return module scan_directory(directory=None) Scan for spouts/bolts in installed extensions and user's codebase. Parameters: Name Type Description Default directory Optional [ str ] Directory to scan for user-defined spouts/bolts. None Returns: Type Description Dict [ str , Any ] Dict[str, Any]: Discovered spouts/bolts. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def scan_directory(self, directory: Optional[str] = None) -> Dict[str, Any]: \"\"\" Scan for spouts/bolts in installed extensions and user's codebase. Args: directory (Optional[str]): Directory to scan for user-defined spouts/bolts. Returns: Dict[str, Any]: Discovered spouts/bolts. \"\"\" directory = directory if directory else self.directory self.log.info(emoji.emojize(\"\ud83d\udd0d Starting discovery...\")) # Discover installed extensions self.discover_installed_extensions() # Discover user-defined spouts/bolts if directory: self.directory = directory for root, _, files in os.walk(self.directory): if \"__init__.py\" in files: module = self.import_module(root) self.find_classes(module) return self.classes","title":"discover"},{"location":"core/cli_discover/#cli.discover.Discover","text":"Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py class Discover: def __init__(self, directory: Optional[str] = None): \"\"\"Initialize the Discover class.\"\"\" self.classes: Dict[str, Any] = {} self.log = logging.getLogger(self.__class__.__name__) self.directory = directory def scan_directory(self, directory: Optional[str] = None) -> Dict[str, Any]: \"\"\" Scan for spouts/bolts in installed extensions and user's codebase. Args: directory (Optional[str]): Directory to scan for user-defined spouts/bolts. Returns: Dict[str, Any]: Discovered spouts/bolts. \"\"\" directory = directory if directory else self.directory self.log.info(emoji.emojize(\"\ud83d\udd0d Starting discovery...\")) # Discover installed extensions self.discover_installed_extensions() # Discover user-defined spouts/bolts if directory: self.directory = directory for root, _, files in os.walk(self.directory): if \"__init__.py\" in files: module = self.import_module(root) self.find_classes(module) return self.classes def discover_installed_extensions(self): \"\"\"Discover installed geniusrise extensions.\"\"\" self.log.info(emoji.emojize(\"\ud83d\udd0e Discovering installed extensions...\")) for entry_point in pkg_resources.iter_entry_points(group=\"geniusrise.extensions\"): try: module = entry_point.load() self.find_classes(module) except Exception as e: self.log.error(emoji.emojize(f\"\u274c Error discovering classes in {entry_point.name}: {e}\")) def import_module(self, path: str): \"\"\" Import a module given its path. Args: path (str): Path to the module. Returns: Any: Imported module. \"\"\" project_root = os.path.abspath(os.path.join(self.directory, \"../../../../\")) # type: ignore relative_path = os.path.relpath(path, project_root) module_path = relative_path.replace(os.sep, \".\") if module_path.endswith(\"__init__\"): module_path = module_path[:-9] # remove trailing '__init__' self.log.info(emoji.emojize(f\"\ud83d\udce6 Importing module {module_path}...\")) module = importlib.import_module(module_path) return module def find_classes(self, module: Any): \"\"\" Discover spout/bolt classes in a module. Args: module (Any): Module to scan for spout/bolt classes. \"\"\" for name, obj in inspect.getmembers(module): discovered: DiscoveredSpout | DiscoveredBolt if inspect.isclass(obj) and issubclass(obj, Spout) and obj != Spout: discovered = DiscoveredSpout(name=name, klass=obj, init_args=self.get_init_args(obj)) self.log.info(emoji.emojize(f\"\ud83d\ude80 Discovered Spout {discovered.name}\")) self.classes[name] = discovered elif inspect.isclass(obj) and issubclass(obj, Bolt) and obj != Bolt: discovered = DiscoveredBolt(name=name, klass=obj, init_args=self.get_init_args(obj)) self.log.info(emoji.emojize(f\"\u26a1 Discovered Bolt {discovered.name}\")) self.classes[name] = discovered def get_init_args(self, cls: type) -> Dict[str, Any]: \"\"\" Extract initialization arguments of a class. Args: cls (type): Class to extract initialization arguments from. Returns: Dict[str, Any]: Initialization arguments. \"\"\" init_signature = inspect.signature(cls.__init__) # type: ignore init_params = init_signature.parameters init_args = {} for name, kind in init_params.items(): if name == \"self\": continue if name == \"kwargs\" or name == \"args\": init_args[\"kwargs\"] = Any continue if isinstance(kind.annotation, ABCMeta): init_args[name] = self.get_init_args(kind.annotation) elif kind.annotation == inspect.Parameter.empty: init_args[name] = \"No type hint provided \ud83d\ude22\" else: init_args[name] = kind.annotation return init_args","title":"Discover"},{"location":"core/cli_discover/#cli.discover.Discover.__init__","text":"Initialize the Discover class. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def __init__(self, directory: Optional[str] = None): \"\"\"Initialize the Discover class.\"\"\" self.classes: Dict[str, Any] = {} self.log = logging.getLogger(self.__class__.__name__) self.directory = directory","title":"__init__()"},{"location":"core/cli_discover/#cli.discover.Discover.discover_installed_extensions","text":"Discover installed geniusrise extensions. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def discover_installed_extensions(self): \"\"\"Discover installed geniusrise extensions.\"\"\" self.log.info(emoji.emojize(\"\ud83d\udd0e Discovering installed extensions...\")) for entry_point in pkg_resources.iter_entry_points(group=\"geniusrise.extensions\"): try: module = entry_point.load() self.find_classes(module) except Exception as e: self.log.error(emoji.emojize(f\"\u274c Error discovering classes in {entry_point.name}: {e}\"))","title":"discover_installed_extensions()"},{"location":"core/cli_discover/#cli.discover.Discover.find_classes","text":"Discover spout/bolt classes in a module. Parameters: Name Type Description Default module Any Module to scan for spout/bolt classes. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def find_classes(self, module: Any): \"\"\" Discover spout/bolt classes in a module. Args: module (Any): Module to scan for spout/bolt classes. \"\"\" for name, obj in inspect.getmembers(module): discovered: DiscoveredSpout | DiscoveredBolt if inspect.isclass(obj) and issubclass(obj, Spout) and obj != Spout: discovered = DiscoveredSpout(name=name, klass=obj, init_args=self.get_init_args(obj)) self.log.info(emoji.emojize(f\"\ud83d\ude80 Discovered Spout {discovered.name}\")) self.classes[name] = discovered elif inspect.isclass(obj) and issubclass(obj, Bolt) and obj != Bolt: discovered = DiscoveredBolt(name=name, klass=obj, init_args=self.get_init_args(obj)) self.log.info(emoji.emojize(f\"\u26a1 Discovered Bolt {discovered.name}\")) self.classes[name] = discovered","title":"find_classes()"},{"location":"core/cli_discover/#cli.discover.Discover.get_init_args","text":"Extract initialization arguments of a class. Parameters: Name Type Description Default cls type Class to extract initialization arguments from. required Returns: Type Description Dict [ str , Any ] Dict[str, Any]: Initialization arguments. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def get_init_args(self, cls: type) -> Dict[str, Any]: \"\"\" Extract initialization arguments of a class. Args: cls (type): Class to extract initialization arguments from. Returns: Dict[str, Any]: Initialization arguments. \"\"\" init_signature = inspect.signature(cls.__init__) # type: ignore init_params = init_signature.parameters init_args = {} for name, kind in init_params.items(): if name == \"self\": continue if name == \"kwargs\" or name == \"args\": init_args[\"kwargs\"] = Any continue if isinstance(kind.annotation, ABCMeta): init_args[name] = self.get_init_args(kind.annotation) elif kind.annotation == inspect.Parameter.empty: init_args[name] = \"No type hint provided \ud83d\ude22\" else: init_args[name] = kind.annotation return init_args","title":"get_init_args()"},{"location":"core/cli_discover/#cli.discover.Discover.import_module","text":"Import a module given its path. Parameters: Name Type Description Default path str Path to the module. required Returns: Name Type Description Any Imported module. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def import_module(self, path: str): \"\"\" Import a module given its path. Args: path (str): Path to the module. Returns: Any: Imported module. \"\"\" project_root = os.path.abspath(os.path.join(self.directory, \"../../../../\")) # type: ignore relative_path = os.path.relpath(path, project_root) module_path = relative_path.replace(os.sep, \".\") if module_path.endswith(\"__init__\"): module_path = module_path[:-9] # remove trailing '__init__' self.log.info(emoji.emojize(f\"\ud83d\udce6 Importing module {module_path}...\")) module = importlib.import_module(module_path) return module","title":"import_module()"},{"location":"core/cli_discover/#cli.discover.Discover.scan_directory","text":"Scan for spouts/bolts in installed extensions and user's codebase. Parameters: Name Type Description Default directory Optional [ str ] Directory to scan for user-defined spouts/bolts. None Returns: Type Description Dict [ str , Any ] Dict[str, Any]: Discovered spouts/bolts. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py def scan_directory(self, directory: Optional[str] = None) -> Dict[str, Any]: \"\"\" Scan for spouts/bolts in installed extensions and user's codebase. Args: directory (Optional[str]): Directory to scan for user-defined spouts/bolts. Returns: Dict[str, Any]: Discovered spouts/bolts. \"\"\" directory = directory if directory else self.directory self.log.info(emoji.emojize(\"\ud83d\udd0d Starting discovery...\")) # Discover installed extensions self.discover_installed_extensions() # Discover user-defined spouts/bolts if directory: self.directory = directory for root, _, files in os.walk(self.directory): if \"__init__.py\" in files: module = self.import_module(root) self.find_classes(module) return self.classes","title":"scan_directory()"},{"location":"core/cli_geniusctl/","text":"GeniusCtl Main class for managing the geniusrise CLI application. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py class GeniusCtl: \"\"\" Main class for managing the geniusrise CLI application. \"\"\" def __init__(self): \"\"\" Initialize GeniusCtl. Args: directory (str): The directory to scan for spouts and bolts. \"\"\" self.log = logging.getLogger(self.__class__.__name__) self.discover = Discover() discovered_components = self.discover.scan_directory(os.getenv(\"GENIUS_COMPONENTS_DIR\", \".\")) # Segregate the discovered components based on their type self.spouts = { name: component for name, component in discovered_components.items() if isinstance(component, DiscoveredSpout) } self.bolts = { name: component for name, component in discovered_components.items() if isinstance(component, DiscoveredBolt) } self.spout_ctls: Dict[str, SpoutCtl] = {} self.bolt_ctls: Dict[str, BoltCtl] = {} def create_parser(self): \"\"\" Create a command-line parser with arguments for managing the application. Returns: argparse.ArgumentParser: Command-line parser. \"\"\" parser = argparse.ArgumentParser(description=\"Manage the geniusrise application.\") subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for each discovered spout for spout_name, discovered_spout in self.spouts.items(): spout_parser = subparsers.add_parser(spout_name, help=f\"Manage {spout_name}.\") spout_ctl = SpoutCtl(discovered_spout) self.spout_ctls[spout_name] = spout_ctl spout_ctl.create_parser(spout_parser) # Create subparser for each discovered bolt for bolt_name, discovered_bolt in self.bolts.items(): bolt_parser = subparsers.add_parser(bolt_name, help=f\"Manage {bolt_name}.\") bolt_ctl = BoltCtl(discovered_bolt) self.bolt_ctls[bolt_name] = bolt_ctl bolt_ctl.create_parser(bolt_parser) # Create subparser for YAML operations yaml_parser = subparsers.add_parser(\"yaml\", help=\"Control spouts and bolts with a YAML file.\") # Initialize YamlCtl with both spout_ctls and bolt_ctls self.yaml_ctl = YamlCtl(self.spout_ctls, self.bolt_ctls) self.yaml_ctl.create_parser(yaml_parser) # Add a 'help' command to print help for all spouts and bolts help_parser = subparsers.add_parser(\"help\", help=\"Print help for all spouts and bolts.\") help_parser.add_argument(\"spout_or_bolt\", nargs=\"?\", help=\"The spout or bolt to print help for.\") # Add a 'list' command to list all discovered spouts and bolts list_parser = subparsers.add_parser(\"list\", help=\"List all discovered spouts and bolts.\") return parser def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(f\"Running command: {args.command}\") if args.command in self.spouts: self.spout_ctls[args.command].run(args) elif args.command in self.bolts: self.bolt_ctls[args.command].run(args) elif args.command == \"yaml\": self.yaml_ctl.run(args) elif args.command == \"help\": if args.spout_or_bolt in self.spouts: self.spout_ctls[args.spout_or_bolt].run(args) elif args.spout_or_bolt in self.bolts: self.bolt_ctls[args.spout_or_bolt].run(args) else: for spout_ctl in self.spout_ctls.values(): spout_ctl.run(args) for bolt_ctl in self.bolt_ctls.values(): bolt_ctl.run(args) elif args.command == \"list\": if len(self.spout.keys()) == 0: print(\"No spouts or bolts discovered.\") self.list_spouts_and_bolts() def list_spouts_and_bolts(self): \"\"\" List all discovered spouts and bolts in a table. \"\"\" table = PrettyTable( [colored(\"Name\", \"green\"), colored(\"Type\", \"green\"), colored(\"Methods\", \"green\")], align=\"l\" ) for spout_name in self.spouts.keys(): s = self.spouts[spout_name].klass table.add_row( [ colored(spout_name, \"yellow\"), colored(\"Spout\", \"cyan\"), \"\\n\".join([x for x in dir(s) if \"fetch_\" in x]), ], divider=True, ) for bolt_name in self.bolts.keys(): b = self.bolts[bolt_name].klass table.add_row( [ colored(bolt_name, \"yellow\"), colored(\"Bolt\", \"magenta\"), \"\\n\".join([x for x in dir(b) if not x.startswith(\"_\")]), ], divider=True, ) print(table) def cli(self): \"\"\" Main function to be called when geniusrise is run from the command line. \"\"\" parser = self.create_parser() args = parser.parse_args() return self.run(args) __init__() Initialize GeniusCtl. Parameters: Name Type Description Default directory str The directory to scan for spouts and bolts. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def __init__(self): \"\"\" Initialize GeniusCtl. Args: directory (str): The directory to scan for spouts and bolts. \"\"\" self.log = logging.getLogger(self.__class__.__name__) self.discover = Discover() discovered_components = self.discover.scan_directory(os.getenv(\"GENIUS_COMPONENTS_DIR\", \".\")) # Segregate the discovered components based on their type self.spouts = { name: component for name, component in discovered_components.items() if isinstance(component, DiscoveredSpout) } self.bolts = { name: component for name, component in discovered_components.items() if isinstance(component, DiscoveredBolt) } self.spout_ctls: Dict[str, SpoutCtl] = {} self.bolt_ctls: Dict[str, BoltCtl] = {} cli() Main function to be called when geniusrise is run from the command line. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def cli(self): \"\"\" Main function to be called when geniusrise is run from the command line. \"\"\" parser = self.create_parser() args = parser.parse_args() return self.run(args) create_parser() Create a command-line parser with arguments for managing the application. Returns: Type Description argparse.ArgumentParser: Command-line parser. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def create_parser(self): \"\"\" Create a command-line parser with arguments for managing the application. Returns: argparse.ArgumentParser: Command-line parser. \"\"\" parser = argparse.ArgumentParser(description=\"Manage the geniusrise application.\") subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for each discovered spout for spout_name, discovered_spout in self.spouts.items(): spout_parser = subparsers.add_parser(spout_name, help=f\"Manage {spout_name}.\") spout_ctl = SpoutCtl(discovered_spout) self.spout_ctls[spout_name] = spout_ctl spout_ctl.create_parser(spout_parser) # Create subparser for each discovered bolt for bolt_name, discovered_bolt in self.bolts.items(): bolt_parser = subparsers.add_parser(bolt_name, help=f\"Manage {bolt_name}.\") bolt_ctl = BoltCtl(discovered_bolt) self.bolt_ctls[bolt_name] = bolt_ctl bolt_ctl.create_parser(bolt_parser) # Create subparser for YAML operations yaml_parser = subparsers.add_parser(\"yaml\", help=\"Control spouts and bolts with a YAML file.\") # Initialize YamlCtl with both spout_ctls and bolt_ctls self.yaml_ctl = YamlCtl(self.spout_ctls, self.bolt_ctls) self.yaml_ctl.create_parser(yaml_parser) # Add a 'help' command to print help for all spouts and bolts help_parser = subparsers.add_parser(\"help\", help=\"Print help for all spouts and bolts.\") help_parser.add_argument(\"spout_or_bolt\", nargs=\"?\", help=\"The spout or bolt to print help for.\") # Add a 'list' command to list all discovered spouts and bolts list_parser = subparsers.add_parser(\"list\", help=\"List all discovered spouts and bolts.\") return parser list_spouts_and_bolts() List all discovered spouts and bolts in a table. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def list_spouts_and_bolts(self): \"\"\" List all discovered spouts and bolts in a table. \"\"\" table = PrettyTable( [colored(\"Name\", \"green\"), colored(\"Type\", \"green\"), colored(\"Methods\", \"green\")], align=\"l\" ) for spout_name in self.spouts.keys(): s = self.spouts[spout_name].klass table.add_row( [ colored(spout_name, \"yellow\"), colored(\"Spout\", \"cyan\"), \"\\n\".join([x for x in dir(s) if \"fetch_\" in x]), ], divider=True, ) for bolt_name in self.bolts.keys(): b = self.bolts[bolt_name].klass table.add_row( [ colored(bolt_name, \"yellow\"), colored(\"Bolt\", \"magenta\"), \"\\n\".join([x for x in dir(b) if not x.startswith(\"_\")]), ], divider=True, ) print(table) run(args) Run the command-line interface. Parameters: Name Type Description Default args argparse . Namespace Parsed command-line arguments. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(f\"Running command: {args.command}\") if args.command in self.spouts: self.spout_ctls[args.command].run(args) elif args.command in self.bolts: self.bolt_ctls[args.command].run(args) elif args.command == \"yaml\": self.yaml_ctl.run(args) elif args.command == \"help\": if args.spout_or_bolt in self.spouts: self.spout_ctls[args.spout_or_bolt].run(args) elif args.spout_or_bolt in self.bolts: self.bolt_ctls[args.spout_or_bolt].run(args) else: for spout_ctl in self.spout_ctls.values(): spout_ctl.run(args) for bolt_ctl in self.bolt_ctls.values(): bolt_ctl.run(args) elif args.command == \"list\": if len(self.spout.keys()) == 0: print(\"No spouts or bolts discovered.\") self.list_spouts_and_bolts()","title":"geniusctl"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl","text":"Main class for managing the geniusrise CLI application. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py class GeniusCtl: \"\"\" Main class for managing the geniusrise CLI application. \"\"\" def __init__(self): \"\"\" Initialize GeniusCtl. Args: directory (str): The directory to scan for spouts and bolts. \"\"\" self.log = logging.getLogger(self.__class__.__name__) self.discover = Discover() discovered_components = self.discover.scan_directory(os.getenv(\"GENIUS_COMPONENTS_DIR\", \".\")) # Segregate the discovered components based on their type self.spouts = { name: component for name, component in discovered_components.items() if isinstance(component, DiscoveredSpout) } self.bolts = { name: component for name, component in discovered_components.items() if isinstance(component, DiscoveredBolt) } self.spout_ctls: Dict[str, SpoutCtl] = {} self.bolt_ctls: Dict[str, BoltCtl] = {} def create_parser(self): \"\"\" Create a command-line parser with arguments for managing the application. Returns: argparse.ArgumentParser: Command-line parser. \"\"\" parser = argparse.ArgumentParser(description=\"Manage the geniusrise application.\") subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for each discovered spout for spout_name, discovered_spout in self.spouts.items(): spout_parser = subparsers.add_parser(spout_name, help=f\"Manage {spout_name}.\") spout_ctl = SpoutCtl(discovered_spout) self.spout_ctls[spout_name] = spout_ctl spout_ctl.create_parser(spout_parser) # Create subparser for each discovered bolt for bolt_name, discovered_bolt in self.bolts.items(): bolt_parser = subparsers.add_parser(bolt_name, help=f\"Manage {bolt_name}.\") bolt_ctl = BoltCtl(discovered_bolt) self.bolt_ctls[bolt_name] = bolt_ctl bolt_ctl.create_parser(bolt_parser) # Create subparser for YAML operations yaml_parser = subparsers.add_parser(\"yaml\", help=\"Control spouts and bolts with a YAML file.\") # Initialize YamlCtl with both spout_ctls and bolt_ctls self.yaml_ctl = YamlCtl(self.spout_ctls, self.bolt_ctls) self.yaml_ctl.create_parser(yaml_parser) # Add a 'help' command to print help for all spouts and bolts help_parser = subparsers.add_parser(\"help\", help=\"Print help for all spouts and bolts.\") help_parser.add_argument(\"spout_or_bolt\", nargs=\"?\", help=\"The spout or bolt to print help for.\") # Add a 'list' command to list all discovered spouts and bolts list_parser = subparsers.add_parser(\"list\", help=\"List all discovered spouts and bolts.\") return parser def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(f\"Running command: {args.command}\") if args.command in self.spouts: self.spout_ctls[args.command].run(args) elif args.command in self.bolts: self.bolt_ctls[args.command].run(args) elif args.command == \"yaml\": self.yaml_ctl.run(args) elif args.command == \"help\": if args.spout_or_bolt in self.spouts: self.spout_ctls[args.spout_or_bolt].run(args) elif args.spout_or_bolt in self.bolts: self.bolt_ctls[args.spout_or_bolt].run(args) else: for spout_ctl in self.spout_ctls.values(): spout_ctl.run(args) for bolt_ctl in self.bolt_ctls.values(): bolt_ctl.run(args) elif args.command == \"list\": if len(self.spout.keys()) == 0: print(\"No spouts or bolts discovered.\") self.list_spouts_and_bolts() def list_spouts_and_bolts(self): \"\"\" List all discovered spouts and bolts in a table. \"\"\" table = PrettyTable( [colored(\"Name\", \"green\"), colored(\"Type\", \"green\"), colored(\"Methods\", \"green\")], align=\"l\" ) for spout_name in self.spouts.keys(): s = self.spouts[spout_name].klass table.add_row( [ colored(spout_name, \"yellow\"), colored(\"Spout\", \"cyan\"), \"\\n\".join([x for x in dir(s) if \"fetch_\" in x]), ], divider=True, ) for bolt_name in self.bolts.keys(): b = self.bolts[bolt_name].klass table.add_row( [ colored(bolt_name, \"yellow\"), colored(\"Bolt\", \"magenta\"), \"\\n\".join([x for x in dir(b) if not x.startswith(\"_\")]), ], divider=True, ) print(table) def cli(self): \"\"\" Main function to be called when geniusrise is run from the command line. \"\"\" parser = self.create_parser() args = parser.parse_args() return self.run(args)","title":"GeniusCtl"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.__init__","text":"Initialize GeniusCtl. Parameters: Name Type Description Default directory str The directory to scan for spouts and bolts. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def __init__(self): \"\"\" Initialize GeniusCtl. Args: directory (str): The directory to scan for spouts and bolts. \"\"\" self.log = logging.getLogger(self.__class__.__name__) self.discover = Discover() discovered_components = self.discover.scan_directory(os.getenv(\"GENIUS_COMPONENTS_DIR\", \".\")) # Segregate the discovered components based on their type self.spouts = { name: component for name, component in discovered_components.items() if isinstance(component, DiscoveredSpout) } self.bolts = { name: component for name, component in discovered_components.items() if isinstance(component, DiscoveredBolt) } self.spout_ctls: Dict[str, SpoutCtl] = {} self.bolt_ctls: Dict[str, BoltCtl] = {}","title":"__init__()"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.cli","text":"Main function to be called when geniusrise is run from the command line. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def cli(self): \"\"\" Main function to be called when geniusrise is run from the command line. \"\"\" parser = self.create_parser() args = parser.parse_args() return self.run(args)","title":"cli()"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.create_parser","text":"Create a command-line parser with arguments for managing the application. Returns: Type Description argparse.ArgumentParser: Command-line parser. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def create_parser(self): \"\"\" Create a command-line parser with arguments for managing the application. Returns: argparse.ArgumentParser: Command-line parser. \"\"\" parser = argparse.ArgumentParser(description=\"Manage the geniusrise application.\") subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for each discovered spout for spout_name, discovered_spout in self.spouts.items(): spout_parser = subparsers.add_parser(spout_name, help=f\"Manage {spout_name}.\") spout_ctl = SpoutCtl(discovered_spout) self.spout_ctls[spout_name] = spout_ctl spout_ctl.create_parser(spout_parser) # Create subparser for each discovered bolt for bolt_name, discovered_bolt in self.bolts.items(): bolt_parser = subparsers.add_parser(bolt_name, help=f\"Manage {bolt_name}.\") bolt_ctl = BoltCtl(discovered_bolt) self.bolt_ctls[bolt_name] = bolt_ctl bolt_ctl.create_parser(bolt_parser) # Create subparser for YAML operations yaml_parser = subparsers.add_parser(\"yaml\", help=\"Control spouts and bolts with a YAML file.\") # Initialize YamlCtl with both spout_ctls and bolt_ctls self.yaml_ctl = YamlCtl(self.spout_ctls, self.bolt_ctls) self.yaml_ctl.create_parser(yaml_parser) # Add a 'help' command to print help for all spouts and bolts help_parser = subparsers.add_parser(\"help\", help=\"Print help for all spouts and bolts.\") help_parser.add_argument(\"spout_or_bolt\", nargs=\"?\", help=\"The spout or bolt to print help for.\") # Add a 'list' command to list all discovered spouts and bolts list_parser = subparsers.add_parser(\"list\", help=\"List all discovered spouts and bolts.\") return parser","title":"create_parser()"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.list_spouts_and_bolts","text":"List all discovered spouts and bolts in a table. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def list_spouts_and_bolts(self): \"\"\" List all discovered spouts and bolts in a table. \"\"\" table = PrettyTable( [colored(\"Name\", \"green\"), colored(\"Type\", \"green\"), colored(\"Methods\", \"green\")], align=\"l\" ) for spout_name in self.spouts.keys(): s = self.spouts[spout_name].klass table.add_row( [ colored(spout_name, \"yellow\"), colored(\"Spout\", \"cyan\"), \"\\n\".join([x for x in dir(s) if \"fetch_\" in x]), ], divider=True, ) for bolt_name in self.bolts.keys(): b = self.bolts[bolt_name].klass table.add_row( [ colored(bolt_name, \"yellow\"), colored(\"Bolt\", \"magenta\"), \"\\n\".join([x for x in dir(b) if not x.startswith(\"_\")]), ], divider=True, ) print(table)","title":"list_spouts_and_bolts()"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.run","text":"Run the command-line interface. Parameters: Name Type Description Default args argparse . Namespace Parsed command-line arguments. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(f\"Running command: {args.command}\") if args.command in self.spouts: self.spout_ctls[args.command].run(args) elif args.command in self.bolts: self.bolt_ctls[args.command].run(args) elif args.command == \"yaml\": self.yaml_ctl.run(args) elif args.command == \"help\": if args.spout_or_bolt in self.spouts: self.spout_ctls[args.spout_or_bolt].run(args) elif args.spout_or_bolt in self.bolts: self.bolt_ctls[args.spout_or_bolt].run(args) else: for spout_ctl in self.spout_ctls.values(): spout_ctl.run(args) for bolt_ctl in self.bolt_ctls.values(): bolt_ctl.run(args) elif args.command == \"list\": if len(self.spout.keys()) == 0: print(\"No spouts or bolts discovered.\") self.list_spouts_and_bolts()","title":"run()"},{"location":"core/cli_schema/","text":"Bolt Bases: BaseModel This class defines a bolt. A bolt has a name, method, optional arguments, input, output, state, and deployment. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Bolt(BaseModel): \"\"\" This class defines a bolt. A bolt has a name, method, optional arguments, input, output, state, and deployment. \"\"\" name: str method: str args: Optional[ExtraKwargs] input: Input output: Output state: State deploy: Deploy Deploy Bases: BaseModel This class defines the deployment of the spout or bolt. The deployment can be of type k8s or ecs. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Deploy(BaseModel): \"\"\" This class defines the deployment of the spout or bolt. The deployment can be of type k8s or ecs. \"\"\" type: str args: Optional[DeployArgs] @validator(\"type\") def validate_type(cls, v, values, **kwargs): if v not in [\"k8s\", \"ecs\"]: raise ValueError(\"Invalid deploy type\") return v @validator(\"args\", pre=True, always=True) def validate_args(cls, v, values, **kwargs): if \"type\" in values: if values[\"type\"] == \"ecs\": required_fields = [ \"name\", \"namespace\", \"image\", \"replicas\", \"account_id\", \"cluster\", \"subnet_ids\", \"security_group_ids\", \"log_group\", \"cpu\", \"memory\", ] for field in required_fields: if not v or field not in v or not v[field]: raise ValueError(f\"Missing required field '{field}' for ecs deploy type\") elif values[\"type\"] == \"k8s\": required_fields = [\"name\", \"namespace\", \"image\", \"replicas\"] for field in required_fields: if not v or field not in v or not v[field]: raise ValueError(f\"Missing required field '{field}' for k8s deploy type\") return v DeployArgs Bases: BaseModel This class defines the arguments for the deployment. Depending on the type of deployment (k8s, ecs), different arguments are required. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class DeployArgs(BaseModel): \"\"\" This class defines the arguments for the deployment. Depending on the type of deployment (k8s, ecs), different arguments are required. \"\"\" name: Optional[str] namespace: Optional[str] image: Optional[str] replicas: Optional[int] account_id: Optional[str] cluster: Optional[str] subnet_ids: Optional[List[str]] security_group_ids: Optional[List[str]] log_group: Optional[str] cpu: Optional[int] memory: Optional[int] class Config: extra = Extra.allow ExtraKwargs Bases: BaseModel This class is used to handle any extra arguments that are not explicitly defined in the schema. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class ExtraKwargs(BaseModel): \"\"\" This class is used to handle any extra arguments that are not explicitly defined in the schema. \"\"\" class Config: extra = Extra.allow Geniusfile Bases: BaseModel This class defines the overall structure of the YAML file. It includes a version, spouts, and bolts. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Geniusfile(BaseModel): \"\"\" This class defines the overall structure of the YAML file. It includes a version, spouts, and bolts. \"\"\" version: str spouts: Dict[str, Spout] bolts: Dict[str, Bolt] @validator(\"version\") def validate_version(cls, v, values, **kwargs): if v != \"1\": raise ValueError(\"Invalid version\") return v Input Bases: BaseModel This class defines the input of the bolt. The input can be of type batch, streaming, spout, or bolt. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Input(BaseModel): \"\"\" This class defines the input of the bolt. The input can be of type batch, streaming, spout, or bolt. \"\"\" type: str args: Optional[InputArgs] @validator(\"type\") def validate_type(cls, v, values, **kwargs): if v not in [\"batch\", \"streaming\", \"spout\", \"bolt\"]: raise ValueError(\"Invalid input type\") return v @validator(\"args\", pre=True, always=True) def validate_args(cls, v, values, **kwargs): if \"type\" in values: if values[\"type\"] == \"batch\": if not v or \"bucket\" not in v or \"folder\" not in v: raise ValueError(\"Missing required fields for batch input type\") elif values[\"type\"] == \"streaming\": if not v or \"input_topic\" not in v or \"kafka_servers\" not in v: raise ValueError(\"Missing required fields for streaming input type\") elif values[\"type\"] in [\"spout\", \"bolt\"]: if not v or \"name\" not in v: raise ValueError(f\"Missing required fields for {values['type']} input type\") return v InputArgs Bases: BaseModel This class defines the arguments for the input. Depending on the type of input (batch, streaming, spout, bolt), different arguments are required. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class InputArgs(BaseModel): \"\"\" This class defines the arguments for the input. Depending on the type of input (batch, streaming, spout, bolt), different arguments are required. \"\"\" input_topic: Optional[str] kafka_servers: Optional[str] output_folder: Optional[str] bucket: Optional[str] folder: Optional[str] name: Optional[str] class Config: extra = Extra.allow Output Bases: BaseModel This class defines the output of the spout or bolt. The output can be of type batch or streaming. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Output(BaseModel): \"\"\" This class defines the output of the spout or bolt. The output can be of type batch or streaming. \"\"\" type: str args: Optional[OutputArgs] @validator(\"type\") def validate_type(cls, v, values, **kwargs): if v not in [\"batch\", \"streaming\"]: raise ValueError(\"Invalid output type\") return v @validator(\"args\", pre=True, always=True) def validate_args(cls, v, values, **kwargs): if \"type\" in values: if values[\"type\"] == \"batch\": if not v or \"bucket\" not in v or \"folder\" not in v: raise ValueError(\"Missing required fields for batch output type\") elif values[\"type\"] == \"streaming\": if not v or \"output_topic\" not in v or \"kafka_servers\" not in v: raise ValueError(\"Missing required fields for streaming output type\") return v OutputArgs Bases: BaseModel This class defines the arguments for the output. Depending on the type of output (batch, streaming), different arguments are required. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class OutputArgs(BaseModel): \"\"\" This class defines the arguments for the output. Depending on the type of output (batch, streaming), different arguments are required. \"\"\" bucket: Optional[str] folder: Optional[str] output_topic: Optional[str] kafka_servers: Optional[str] class Config: extra = Extra.allow Spout Bases: BaseModel This class defines a spout. A spout has a name, method, optional arguments, output, state, and deployment. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Spout(BaseModel): \"\"\" This class defines a spout. A spout has a name, method, optional arguments, output, state, and deployment. \"\"\" name: str method: str args: Optional[ExtraKwargs] output: Output state: State deploy: Deploy State Bases: BaseModel This class defines the state of the spout or bolt. The state can be of type in_memory, redis, postgres, or dynamodb. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class State(BaseModel): \"\"\" This class defines the state of the spout or bolt. The state can be of type in_memory, redis, postgres, or dynamodb. \"\"\" type: str args: Optional[StateArgs] @validator(\"type\") def validate_type(cls, v, values, **kwargs): if v not in [\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"]: raise ValueError(\"Invalid state type\") return v @validator(\"args\", pre=True, always=True) def validate_args(cls, v, values, **kwargs): if \"type\" in values: if values[\"type\"] == \"redis\": if not v or \"redis_host\" not in v or \"redis_port\" not in v or \"redis_db\" not in v: raise ValueError(\"Missing required fields for redis state type\") elif values[\"type\"] == \"postgres\": if ( not v or \"postgres_host\" not in v or \"postgres_port\" not in v or \"postgres_user\" not in v or \"postgres_password\" not in v or \"postgres_database\" not in v or \"postgres_table\" not in v ): raise ValueError(\"Missing required fields for postgres state type\") elif values[\"type\"] == \"dynamodb\": if not v or \"dynamodb_table_name\" not in v or \"dynamodb_region_name\" not in v: raise ValueError(\"Missing required fields for dynamodb state type\") return v StateArgs Bases: BaseModel This class defines the arguments for the state. Depending on the type of state (in_memory, redis, postgres, dynamodb), different arguments are required. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class StateArgs(BaseModel): \"\"\" This class defines the arguments for the state. Depending on the type of state (in_memory, redis, postgres, dynamodb), different arguments are required. \"\"\" redis_host: Optional[str] redis_port: Optional[int] redis_db: Optional[int] postgres_host: Optional[str] postgres_port: Optional[int] postgres_user: Optional[str] postgres_password: Optional[str] postgres_database: Optional[str] postgres_table: Optional[str] dynamodb_table_name: Optional[str] dynamodb_region_name: Optional[str] class Config: extra = Extra.allow","title":"schema"},{"location":"core/cli_schema/#cli.schema.Bolt","text":"Bases: BaseModel This class defines a bolt. A bolt has a name, method, optional arguments, input, output, state, and deployment. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Bolt(BaseModel): \"\"\" This class defines a bolt. A bolt has a name, method, optional arguments, input, output, state, and deployment. \"\"\" name: str method: str args: Optional[ExtraKwargs] input: Input output: Output state: State deploy: Deploy","title":"Bolt"},{"location":"core/cli_schema/#cli.schema.Deploy","text":"Bases: BaseModel This class defines the deployment of the spout or bolt. The deployment can be of type k8s or ecs. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Deploy(BaseModel): \"\"\" This class defines the deployment of the spout or bolt. The deployment can be of type k8s or ecs. \"\"\" type: str args: Optional[DeployArgs] @validator(\"type\") def validate_type(cls, v, values, **kwargs): if v not in [\"k8s\", \"ecs\"]: raise ValueError(\"Invalid deploy type\") return v @validator(\"args\", pre=True, always=True) def validate_args(cls, v, values, **kwargs): if \"type\" in values: if values[\"type\"] == \"ecs\": required_fields = [ \"name\", \"namespace\", \"image\", \"replicas\", \"account_id\", \"cluster\", \"subnet_ids\", \"security_group_ids\", \"log_group\", \"cpu\", \"memory\", ] for field in required_fields: if not v or field not in v or not v[field]: raise ValueError(f\"Missing required field '{field}' for ecs deploy type\") elif values[\"type\"] == \"k8s\": required_fields = [\"name\", \"namespace\", \"image\", \"replicas\"] for field in required_fields: if not v or field not in v or not v[field]: raise ValueError(f\"Missing required field '{field}' for k8s deploy type\") return v","title":"Deploy"},{"location":"core/cli_schema/#cli.schema.DeployArgs","text":"Bases: BaseModel This class defines the arguments for the deployment. Depending on the type of deployment (k8s, ecs), different arguments are required. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class DeployArgs(BaseModel): \"\"\" This class defines the arguments for the deployment. Depending on the type of deployment (k8s, ecs), different arguments are required. \"\"\" name: Optional[str] namespace: Optional[str] image: Optional[str] replicas: Optional[int] account_id: Optional[str] cluster: Optional[str] subnet_ids: Optional[List[str]] security_group_ids: Optional[List[str]] log_group: Optional[str] cpu: Optional[int] memory: Optional[int] class Config: extra = Extra.allow","title":"DeployArgs"},{"location":"core/cli_schema/#cli.schema.ExtraKwargs","text":"Bases: BaseModel This class is used to handle any extra arguments that are not explicitly defined in the schema. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class ExtraKwargs(BaseModel): \"\"\" This class is used to handle any extra arguments that are not explicitly defined in the schema. \"\"\" class Config: extra = Extra.allow","title":"ExtraKwargs"},{"location":"core/cli_schema/#cli.schema.Geniusfile","text":"Bases: BaseModel This class defines the overall structure of the YAML file. It includes a version, spouts, and bolts. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Geniusfile(BaseModel): \"\"\" This class defines the overall structure of the YAML file. It includes a version, spouts, and bolts. \"\"\" version: str spouts: Dict[str, Spout] bolts: Dict[str, Bolt] @validator(\"version\") def validate_version(cls, v, values, **kwargs): if v != \"1\": raise ValueError(\"Invalid version\") return v","title":"Geniusfile"},{"location":"core/cli_schema/#cli.schema.Input","text":"Bases: BaseModel This class defines the input of the bolt. The input can be of type batch, streaming, spout, or bolt. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Input(BaseModel): \"\"\" This class defines the input of the bolt. The input can be of type batch, streaming, spout, or bolt. \"\"\" type: str args: Optional[InputArgs] @validator(\"type\") def validate_type(cls, v, values, **kwargs): if v not in [\"batch\", \"streaming\", \"spout\", \"bolt\"]: raise ValueError(\"Invalid input type\") return v @validator(\"args\", pre=True, always=True) def validate_args(cls, v, values, **kwargs): if \"type\" in values: if values[\"type\"] == \"batch\": if not v or \"bucket\" not in v or \"folder\" not in v: raise ValueError(\"Missing required fields for batch input type\") elif values[\"type\"] == \"streaming\": if not v or \"input_topic\" not in v or \"kafka_servers\" not in v: raise ValueError(\"Missing required fields for streaming input type\") elif values[\"type\"] in [\"spout\", \"bolt\"]: if not v or \"name\" not in v: raise ValueError(f\"Missing required fields for {values['type']} input type\") return v","title":"Input"},{"location":"core/cli_schema/#cli.schema.InputArgs","text":"Bases: BaseModel This class defines the arguments for the input. Depending on the type of input (batch, streaming, spout, bolt), different arguments are required. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class InputArgs(BaseModel): \"\"\" This class defines the arguments for the input. Depending on the type of input (batch, streaming, spout, bolt), different arguments are required. \"\"\" input_topic: Optional[str] kafka_servers: Optional[str] output_folder: Optional[str] bucket: Optional[str] folder: Optional[str] name: Optional[str] class Config: extra = Extra.allow","title":"InputArgs"},{"location":"core/cli_schema/#cli.schema.Output","text":"Bases: BaseModel This class defines the output of the spout or bolt. The output can be of type batch or streaming. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Output(BaseModel): \"\"\" This class defines the output of the spout or bolt. The output can be of type batch or streaming. \"\"\" type: str args: Optional[OutputArgs] @validator(\"type\") def validate_type(cls, v, values, **kwargs): if v not in [\"batch\", \"streaming\"]: raise ValueError(\"Invalid output type\") return v @validator(\"args\", pre=True, always=True) def validate_args(cls, v, values, **kwargs): if \"type\" in values: if values[\"type\"] == \"batch\": if not v or \"bucket\" not in v or \"folder\" not in v: raise ValueError(\"Missing required fields for batch output type\") elif values[\"type\"] == \"streaming\": if not v or \"output_topic\" not in v or \"kafka_servers\" not in v: raise ValueError(\"Missing required fields for streaming output type\") return v","title":"Output"},{"location":"core/cli_schema/#cli.schema.OutputArgs","text":"Bases: BaseModel This class defines the arguments for the output. Depending on the type of output (batch, streaming), different arguments are required. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class OutputArgs(BaseModel): \"\"\" This class defines the arguments for the output. Depending on the type of output (batch, streaming), different arguments are required. \"\"\" bucket: Optional[str] folder: Optional[str] output_topic: Optional[str] kafka_servers: Optional[str] class Config: extra = Extra.allow","title":"OutputArgs"},{"location":"core/cli_schema/#cli.schema.Spout","text":"Bases: BaseModel This class defines a spout. A spout has a name, method, optional arguments, output, state, and deployment. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class Spout(BaseModel): \"\"\" This class defines a spout. A spout has a name, method, optional arguments, output, state, and deployment. \"\"\" name: str method: str args: Optional[ExtraKwargs] output: Output state: State deploy: Deploy","title":"Spout"},{"location":"core/cli_schema/#cli.schema.State","text":"Bases: BaseModel This class defines the state of the spout or bolt. The state can be of type in_memory, redis, postgres, or dynamodb. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class State(BaseModel): \"\"\" This class defines the state of the spout or bolt. The state can be of type in_memory, redis, postgres, or dynamodb. \"\"\" type: str args: Optional[StateArgs] @validator(\"type\") def validate_type(cls, v, values, **kwargs): if v not in [\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"]: raise ValueError(\"Invalid state type\") return v @validator(\"args\", pre=True, always=True) def validate_args(cls, v, values, **kwargs): if \"type\" in values: if values[\"type\"] == \"redis\": if not v or \"redis_host\" not in v or \"redis_port\" not in v or \"redis_db\" not in v: raise ValueError(\"Missing required fields for redis state type\") elif values[\"type\"] == \"postgres\": if ( not v or \"postgres_host\" not in v or \"postgres_port\" not in v or \"postgres_user\" not in v or \"postgres_password\" not in v or \"postgres_database\" not in v or \"postgres_table\" not in v ): raise ValueError(\"Missing required fields for postgres state type\") elif values[\"type\"] == \"dynamodb\": if not v or \"dynamodb_table_name\" not in v or \"dynamodb_region_name\" not in v: raise ValueError(\"Missing required fields for dynamodb state type\") return v","title":"State"},{"location":"core/cli_schema/#cli.schema.StateArgs","text":"Bases: BaseModel This class defines the arguments for the state. Depending on the type of state (in_memory, redis, postgres, dynamodb), different arguments are required. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py class StateArgs(BaseModel): \"\"\" This class defines the arguments for the state. Depending on the type of state (in_memory, redis, postgres, dynamodb), different arguments are required. \"\"\" redis_host: Optional[str] redis_port: Optional[int] redis_db: Optional[int] postgres_host: Optional[str] postgres_port: Optional[int] postgres_user: Optional[str] postgres_password: Optional[str] postgres_database: Optional[str] postgres_table: Optional[str] dynamodb_table_name: Optional[str] dynamodb_region_name: Optional[str] class Config: extra = Extra.allow","title":"StateArgs"},{"location":"core/cli_spoutctl/","text":"SpoutCtl Class for managing spouts end-to-end from the command line. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py class SpoutCtl: \"\"\" Class for managing spouts end-to-end from the command line. \"\"\" def __init__(self, discovered_spout: DiscoveredSpout): \"\"\" Initialize SpoutCtl with a DiscoveredSpout object. Args: discovered_spout (DiscoveredSpout): DiscoveredSpout object used to create and manage spouts. \"\"\" self.discovered_spout = discovered_spout self.spout = None self.log = logging.getLogger(self.__class__.__name__) def create_parser(self, parser): \"\"\" Add arguments to the command-line parser for managing the spout. Args: parser (argparse.ArgumentParser): Command-line parser. \"\"\" subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for 'create' command create_parser = subparsers.add_parser(\"run\", help=\"Run a spout locally.\") create_parser.add_argument( \"output_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of output configuration: batch or streaming.\", default=\"batch\", ) create_parser.add_argument( \"state_type\", choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"], help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\", default=\"in_memory\", ) create_parser.add_argument( \"--output_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) create_parser.add_argument( \"--output_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) create_parser.add_argument( \"--output_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) create_parser.add_argument( \"--output_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) create_parser.add_argument( \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) create_parser.add_argument( \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str ) create_parser.add_argument( \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int ) create_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int) create_parser.add_argument( \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str ) create_parser.add_argument( \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int ) create_parser.add_argument( \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str ) create_parser.add_argument( \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str ) create_parser.add_argument( \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str ) create_parser.add_argument( \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str ) create_parser.add_argument( \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str ) create_parser.add_argument( \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str ) create_parser.add_argument( \"method_name\", help=\"The name of the method to execute on the spout.\", type=str, ) create_parser.add_argument( \"--args\", nargs=argparse.REMAINDER, help=\"Additional keyword arguments to pass to the spout.\", ) # Create subparser for 'help' command execute_parser = subparsers.add_parser(\"help\", help=\"Print help for the spout.\") execute_parser.add_argument(\"method\", help=\"The method to execute.\") return parser def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\")) try: if args.command == \"run\": kwargs = { k: v for k, v in vars(args).items() if v is not None and k not in [\"output_type\", \"state_type\", \"args\", \"method_name\"] } other = args.args or [] other_args, other_kwargs = self.parse_args_kwargs(other) self.spout = self.create_spout(args.output_type, args.state_type, **kwargs) # Pass the method_name from args to execute_spout result = self.execute_spout(self.spout, args.method_name, *other_args, **other_kwargs) return result elif args.command == \"help\": self.discovered_spout.klass.print_help(self.discovered_spout.klass) except ValueError as ve: self.log.exception(f\"Value error: {ve}\") raise except AttributeError as ae: self.log.exception(f\"Attribute error: {ae}\") raise except Exception as e: self.log.exception(f\"An unexpected error occurred: {e}\") raise @staticmethod def parse_args_kwargs(args_list): args = [] kwargs = {} def convert(value): try: return int(value) except ValueError: try: return float(value) except ValueError: return value for item in args_list: if \"=\" in item: key, value = item.split(\"=\", 1) kwargs[key] = convert(value) else: args.append(convert(item)) return args, kwargs def create_spout(self, output_type: str, state_type: str, **kwargs) -> Spout: \"\"\" Create a spout of a specific type. Args: output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Spout: The created spout. \"\"\" return Spout.create(klass=self.discovered_spout.klass, output_type=output_type, state_type=state_type, **kwargs) def execute_spout(self, spout: Spout, method_name: str, *args, **kwargs): \"\"\" Execute a method of a spout. Args: spout (Spout): The spout to execute. method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the method. \"\"\" return spout.__call__(method_name, *args, **kwargs) __init__(discovered_spout) Initialize SpoutCtl with a DiscoveredSpout object. Parameters: Name Type Description Default discovered_spout DiscoveredSpout DiscoveredSpout object used to create and manage spouts. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def __init__(self, discovered_spout: DiscoveredSpout): \"\"\" Initialize SpoutCtl with a DiscoveredSpout object. Args: discovered_spout (DiscoveredSpout): DiscoveredSpout object used to create and manage spouts. \"\"\" self.discovered_spout = discovered_spout self.spout = None self.log = logging.getLogger(self.__class__.__name__) create_parser(parser) Add arguments to the command-line parser for managing the spout. Parameters: Name Type Description Default parser argparse . ArgumentParser Command-line parser. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def create_parser(self, parser): \"\"\" Add arguments to the command-line parser for managing the spout. Args: parser (argparse.ArgumentParser): Command-line parser. \"\"\" subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for 'create' command create_parser = subparsers.add_parser(\"run\", help=\"Run a spout locally.\") create_parser.add_argument( \"output_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of output configuration: batch or streaming.\", default=\"batch\", ) create_parser.add_argument( \"state_type\", choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"], help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\", default=\"in_memory\", ) create_parser.add_argument( \"--output_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) create_parser.add_argument( \"--output_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) create_parser.add_argument( \"--output_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) create_parser.add_argument( \"--output_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) create_parser.add_argument( \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) create_parser.add_argument( \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str ) create_parser.add_argument( \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int ) create_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int) create_parser.add_argument( \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str ) create_parser.add_argument( \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int ) create_parser.add_argument( \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str ) create_parser.add_argument( \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str ) create_parser.add_argument( \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str ) create_parser.add_argument( \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str ) create_parser.add_argument( \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str ) create_parser.add_argument( \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str ) create_parser.add_argument( \"method_name\", help=\"The name of the method to execute on the spout.\", type=str, ) create_parser.add_argument( \"--args\", nargs=argparse.REMAINDER, help=\"Additional keyword arguments to pass to the spout.\", ) # Create subparser for 'help' command execute_parser = subparsers.add_parser(\"help\", help=\"Print help for the spout.\") execute_parser.add_argument(\"method\", help=\"The method to execute.\") return parser create_spout(output_type, state_type, **kwargs) Create a spout of a specific type. Parameters: Name Type Description Default output_type str The type of output config (\"batch\" or \"streaming\"). required state_type str The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). required **kwargs Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. {} Returns: Name Type Description Spout Spout The created spout. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def create_spout(self, output_type: str, state_type: str, **kwargs) -> Spout: \"\"\" Create a spout of a specific type. Args: output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Spout: The created spout. \"\"\" return Spout.create(klass=self.discovered_spout.klass, output_type=output_type, state_type=state_type, **kwargs) execute_spout(spout, method_name, *args, **kwargs) Execute a method of a spout. Parameters: Name Type Description Default spout Spout The spout to execute. required method_name str The name of the method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. {} Returns: Name Type Description Any The result of the method. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def execute_spout(self, spout: Spout, method_name: str, *args, **kwargs): \"\"\" Execute a method of a spout. Args: spout (Spout): The spout to execute. method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the method. \"\"\" return spout.__call__(method_name, *args, **kwargs) run(args) Run the command-line interface. Parameters: Name Type Description Default args argparse . Namespace Parsed command-line arguments. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\")) try: if args.command == \"run\": kwargs = { k: v for k, v in vars(args).items() if v is not None and k not in [\"output_type\", \"state_type\", \"args\", \"method_name\"] } other = args.args or [] other_args, other_kwargs = self.parse_args_kwargs(other) self.spout = self.create_spout(args.output_type, args.state_type, **kwargs) # Pass the method_name from args to execute_spout result = self.execute_spout(self.spout, args.method_name, *other_args, **other_kwargs) return result elif args.command == \"help\": self.discovered_spout.klass.print_help(self.discovered_spout.klass) except ValueError as ve: self.log.exception(f\"Value error: {ve}\") raise except AttributeError as ae: self.log.exception(f\"Attribute error: {ae}\") raise except Exception as e: self.log.exception(f\"An unexpected error occurred: {e}\") raise","title":"spoutctl"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl","text":"Class for managing spouts end-to-end from the command line. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py class SpoutCtl: \"\"\" Class for managing spouts end-to-end from the command line. \"\"\" def __init__(self, discovered_spout: DiscoveredSpout): \"\"\" Initialize SpoutCtl with a DiscoveredSpout object. Args: discovered_spout (DiscoveredSpout): DiscoveredSpout object used to create and manage spouts. \"\"\" self.discovered_spout = discovered_spout self.spout = None self.log = logging.getLogger(self.__class__.__name__) def create_parser(self, parser): \"\"\" Add arguments to the command-line parser for managing the spout. Args: parser (argparse.ArgumentParser): Command-line parser. \"\"\" subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for 'create' command create_parser = subparsers.add_parser(\"run\", help=\"Run a spout locally.\") create_parser.add_argument( \"output_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of output configuration: batch or streaming.\", default=\"batch\", ) create_parser.add_argument( \"state_type\", choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"], help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\", default=\"in_memory\", ) create_parser.add_argument( \"--output_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) create_parser.add_argument( \"--output_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) create_parser.add_argument( \"--output_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) create_parser.add_argument( \"--output_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) create_parser.add_argument( \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) create_parser.add_argument( \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str ) create_parser.add_argument( \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int ) create_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int) create_parser.add_argument( \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str ) create_parser.add_argument( \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int ) create_parser.add_argument( \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str ) create_parser.add_argument( \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str ) create_parser.add_argument( \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str ) create_parser.add_argument( \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str ) create_parser.add_argument( \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str ) create_parser.add_argument( \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str ) create_parser.add_argument( \"method_name\", help=\"The name of the method to execute on the spout.\", type=str, ) create_parser.add_argument( \"--args\", nargs=argparse.REMAINDER, help=\"Additional keyword arguments to pass to the spout.\", ) # Create subparser for 'help' command execute_parser = subparsers.add_parser(\"help\", help=\"Print help for the spout.\") execute_parser.add_argument(\"method\", help=\"The method to execute.\") return parser def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\")) try: if args.command == \"run\": kwargs = { k: v for k, v in vars(args).items() if v is not None and k not in [\"output_type\", \"state_type\", \"args\", \"method_name\"] } other = args.args or [] other_args, other_kwargs = self.parse_args_kwargs(other) self.spout = self.create_spout(args.output_type, args.state_type, **kwargs) # Pass the method_name from args to execute_spout result = self.execute_spout(self.spout, args.method_name, *other_args, **other_kwargs) return result elif args.command == \"help\": self.discovered_spout.klass.print_help(self.discovered_spout.klass) except ValueError as ve: self.log.exception(f\"Value error: {ve}\") raise except AttributeError as ae: self.log.exception(f\"Attribute error: {ae}\") raise except Exception as e: self.log.exception(f\"An unexpected error occurred: {e}\") raise @staticmethod def parse_args_kwargs(args_list): args = [] kwargs = {} def convert(value): try: return int(value) except ValueError: try: return float(value) except ValueError: return value for item in args_list: if \"=\" in item: key, value = item.split(\"=\", 1) kwargs[key] = convert(value) else: args.append(convert(item)) return args, kwargs def create_spout(self, output_type: str, state_type: str, **kwargs) -> Spout: \"\"\" Create a spout of a specific type. Args: output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Spout: The created spout. \"\"\" return Spout.create(klass=self.discovered_spout.klass, output_type=output_type, state_type=state_type, **kwargs) def execute_spout(self, spout: Spout, method_name: str, *args, **kwargs): \"\"\" Execute a method of a spout. Args: spout (Spout): The spout to execute. method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the method. \"\"\" return spout.__call__(method_name, *args, **kwargs)","title":"SpoutCtl"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.__init__","text":"Initialize SpoutCtl with a DiscoveredSpout object. Parameters: Name Type Description Default discovered_spout DiscoveredSpout DiscoveredSpout object used to create and manage spouts. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def __init__(self, discovered_spout: DiscoveredSpout): \"\"\" Initialize SpoutCtl with a DiscoveredSpout object. Args: discovered_spout (DiscoveredSpout): DiscoveredSpout object used to create and manage spouts. \"\"\" self.discovered_spout = discovered_spout self.spout = None self.log = logging.getLogger(self.__class__.__name__)","title":"__init__()"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.create_parser","text":"Add arguments to the command-line parser for managing the spout. Parameters: Name Type Description Default parser argparse . ArgumentParser Command-line parser. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def create_parser(self, parser): \"\"\" Add arguments to the command-line parser for managing the spout. Args: parser (argparse.ArgumentParser): Command-line parser. \"\"\" subparsers = parser.add_subparsers(dest=\"command\") # Create subparser for 'create' command create_parser = subparsers.add_parser(\"run\", help=\"Run a spout locally.\") create_parser.add_argument( \"output_type\", choices=[\"batch\", \"streaming\"], help=\"Choose the type of output configuration: batch or streaming.\", default=\"batch\", ) create_parser.add_argument( \"state_type\", choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"], help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\", default=\"in_memory\", ) create_parser.add_argument( \"--output_folder\", help=\"Specify the directory where output files should be stored temporarily.\", default=\"/tmp\", type=str, ) create_parser.add_argument( \"--output_kafka_topic\", help=\"Kafka output topic for streaming spouts.\", default=\"test\", type=str, ) create_parser.add_argument( \"--output_kafka_cluster_connection_string\", help=\"Kafka connection string for streaming spouts.\", default=\"localhost:9092\", type=str, ) create_parser.add_argument( \"--output_s3_bucket\", help=\"Provide the name of the S3 bucket for output storage.\", default=\"my-bucket\", type=str, ) create_parser.add_argument( \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str ) create_parser.add_argument( \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str ) create_parser.add_argument( \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int ) create_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int) create_parser.add_argument( \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str ) create_parser.add_argument( \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int ) create_parser.add_argument( \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str ) create_parser.add_argument( \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str ) create_parser.add_argument( \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str ) create_parser.add_argument( \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str ) create_parser.add_argument( \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str ) create_parser.add_argument( \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str ) create_parser.add_argument( \"method_name\", help=\"The name of the method to execute on the spout.\", type=str, ) create_parser.add_argument( \"--args\", nargs=argparse.REMAINDER, help=\"Additional keyword arguments to pass to the spout.\", ) # Create subparser for 'help' command execute_parser = subparsers.add_parser(\"help\", help=\"Print help for the spout.\") execute_parser.add_argument(\"method\", help=\"The method to execute.\") return parser","title":"create_parser()"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.create_spout","text":"Create a spout of a specific type. Parameters: Name Type Description Default output_type str The type of output config (\"batch\" or \"streaming\"). required state_type str The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). required **kwargs Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. {} Returns: Name Type Description Spout Spout The created spout. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def create_spout(self, output_type: str, state_type: str, **kwargs) -> Spout: \"\"\" Create a spout of a specific type. Args: output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Spout: The created spout. \"\"\" return Spout.create(klass=self.discovered_spout.klass, output_type=output_type, state_type=state_type, **kwargs)","title":"create_spout()"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.execute_spout","text":"Execute a method of a spout. Parameters: Name Type Description Default spout Spout The spout to execute. required method_name str The name of the method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. {} Returns: Name Type Description Any The result of the method. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def execute_spout(self, spout: Spout, method_name: str, *args, **kwargs): \"\"\" Execute a method of a spout. Args: spout (Spout): The spout to execute. method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the method. \"\"\" return spout.__call__(method_name, *args, **kwargs)","title":"execute_spout()"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.run","text":"Run the command-line interface. Parameters: Name Type Description Default args argparse . Namespace Parsed command-line arguments. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py def run(self, args): \"\"\" Run the command-line interface. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\")) try: if args.command == \"run\": kwargs = { k: v for k, v in vars(args).items() if v is not None and k not in [\"output_type\", \"state_type\", \"args\", \"method_name\"] } other = args.args or [] other_args, other_kwargs = self.parse_args_kwargs(other) self.spout = self.create_spout(args.output_type, args.state_type, **kwargs) # Pass the method_name from args to execute_spout result = self.execute_spout(self.spout, args.method_name, *other_args, **other_kwargs) return result elif args.command == \"help\": self.discovered_spout.klass.print_help(self.discovered_spout.klass) except ValueError as ve: self.log.exception(f\"Value error: {ve}\") raise except AttributeError as ae: self.log.exception(f\"Attribute error: {ae}\") raise except Exception as e: self.log.exception(f\"An unexpected error occurred: {e}\") raise","title":"run()"},{"location":"core/cli_yamlctl/","text":"YamlCtl Command-line interface for managing spouts and bolts based on a YAML configuration. The YamlCtl class provides methods to run specific or all spouts and bolts defined in a YAML file. The YAML file's structure is defined by the Geniusfile schema. Example YAML structure: version: \"1\" spouts: spout_name1: name: \"spout1\" method: \"method_name\" ... bolts: bolt_name1: name: \"bolt1\" method: \"method_name\" ... Attributes: Name Type Description geniusfile Geniusfile Parsed YAML configuration. spout_ctls Dict [ str , SpoutCtl ] Dictionary of SpoutCtl instances. bolt_ctls Dict [ str , BoltCtl ] Dictionary of BoltCtl instances. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py class YamlCtl: \"\"\" Command-line interface for managing spouts and bolts based on a YAML configuration. The YamlCtl class provides methods to run specific or all spouts and bolts defined in a YAML file. The YAML file's structure is defined by the Geniusfile schema. Example YAML structure: ``` version: \"1\" spouts: spout_name1: name: \"spout1\" method: \"method_name\" ... bolts: bolt_name1: name: \"bolt1\" method: \"method_name\" ... ``` Attributes: geniusfile (Geniusfile): Parsed YAML configuration. spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances. bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances. \"\"\" def __init__(self, spout_ctls: Dict[str, SpoutCtl], bolt_ctls: Dict[str, BoltCtl]): \"\"\" Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts. Args: spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances. bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances. \"\"\" self.spout_ctls = spout_ctls self.bolt_ctls = bolt_ctls self.log = logging.getLogger(self.__class__.__name__) def create_parser(self, parser): \"\"\" Create and return the command-line parser for managing spouts and bolts. \"\"\" parser.add_argument(\"--spout\", type=str, help=\"Name of the specific spout to run.\") parser.add_argument(\"--bolt\", type=str, help=\"Name of the specific bolt to run.\") parser.add_argument(\"--file\", default=\".\", type=str, help=\"Path of the genius.yml file, default to .\") return parser def run(self, args): \"\"\" Run the command-line interface for managing spouts and bolts based on provided arguments. Please note that there is no ordering of the spouts and bolts in the YAML configuration. Each spout and bolt is an independent entity even when connected together. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" with open(args.file, \"r\") as file: self.geniusfile = Geniusfile.parse_obj(yaml.safe_load(file)) if args.spout == \"all\": self.run_spouts() elif args.bolt == \"all\": self.run_bolts() elif args.spout: self.run_spout(args.spout) elif args.bolt: self.run_bolt(args.bolt) else: self.run_spouts() self.run_bolts() def run_spouts(self): \"\"\"Run all spouts defined in the YAML configuration.\"\"\" self.log.info(emoji.emojize(\":rocket: Running all spouts...\")) for spout_name, _ in self.geniusfile.spouts.items(): self.run_spout(spout_name) def run_bolts(self): \"\"\"Run all bolts defined in the YAML configuration.\"\"\" self.log.info(emoji.emojize(\":rocket: Running all bolts...\")) for bolt_name, _ in self.geniusfile.bolts.items(): self.run_bolt(bolt_name) def run_spout(self, spout_name: str): \"\"\" Run a specific spout based on its name. Args: spout_name (str): Name of the spout to run. \"\"\" spout = self.geniusfile.spouts.get(spout_name) if not spout: self.log.error(emoji.emojize(f\":x: Spout {spout_name} not found.\")) return spout_ctl = self.spout_ctls.get(spout_name) if not spout_ctl: self.log.error(emoji.emojize(f\":x: SpoutCtl for {spout_name} not found.\")) return self.log.info(emoji.emojize(f\":rocket: Running spout {spout_name}...\")) flat_args = [\"run\", spout.output.type, spout.state.type, spout.method] + self._convert_spout(spout) parser = argparse.ArgumentParser() self.spout_ctls[spout_name].create_parser(parser) namespace_args = parser.parse_args(flat_args) spout_ctl.run(namespace_args) def run_bolt(self, bolt_name: str): \"\"\" Run a specific bolt based on its name. Args: bolt_name (str): Name of the bolt to run. \"\"\" bolt = self.geniusfile.bolts.get(bolt_name) if not bolt: self.log.error(emoji.emojize(f\":x: Bolt {bolt_name} not found.\")) return # Resolve reference if input type is \"spout\" or \"bolt\" if bolt.input.type in [\"spout\", \"bolt\"]: if not bolt.input.args or not bolt.input.args.name: raise ValueError(emoji.emojize(f\"Need referenced spouts or bolt to be mentioned here {bolt.input}\")) ref_name = bolt.input.args.name resolved_output = self.resolve_reference(bolt.input.type, ref_name) if not resolved_output: self.log.error(emoji.emojize(f\":x: Failed to resolve reference for bolt {bolt_name}.\")) return bolt.input.type = resolved_output.type # Set the resolved output type as the bolt's input type bolt.input.args = resolved_output.args # Set the resolved output args as the bolt's input args bolt_ctl = self.bolt_ctls.get(bolt_name) if not bolt_ctl: self.log.error(emoji.emojize(f\":x: BoltCtl for {bolt_name} not found.\")) return self.log.info(emoji.emojize(f\":rocket: Running bolt {bolt_name}...\")) flat_args = [\"run\", bolt.input.type, bolt.output.type, bolt.state.type, bolt.method] + self._convert_bolt(bolt) parser = argparse.ArgumentParser() self.bolt_ctls[bolt_name].create_parser(parser) namespace_args = parser.parse_args(flat_args) bolt_ctl.run(namespace_args) def resolve_reference(self, input_type: str, ref_name: str): \"\"\" Resolve the reference of a bolt's input based on the input type (spout or bolt). Args: input_type (str): Type of the input (\"spout\" or \"bolt\"). ref_name (str): Name of the spout or bolt to refer to. Returns: Output: The output configuration of the referred spout or bolt. \"\"\" if input_type == \"spout\": referred_spout = self.geniusfile.spouts.get(ref_name) if not referred_spout: self.log.error(emoji.emojize(f\":x: Referred spout {ref_name} not found.\")) return None return referred_spout.output elif input_type == \"bolt\": referred_bolt = self.geniusfile.bolts.get(ref_name) if not referred_bolt: self.log.error(emoji.emojize(f\":x: Referred bolt {ref_name} not found.\")) return None return referred_bolt.output else: self.log.error(emoji.emojize(f\":x: Invalid reference type {input_type}.\")) return None @typing.no_type_check def _convert_spout(self, spout: Spout) -> List[str]: spout_args = [] # Convert output if spout.output.type == \"batch\": spout_args.append(f\"--output_folder={spout.output.args.folder}\") spout_args.append(f\"--output_s3_bucket={spout.output.args.bucket}\") spout_args.append(f\"--output_s3_folder={spout.output.args.folder}\") elif spout.output.type == \"streaming\": spout_args.append(f\"--output_kafka_topic={spout.output.args.output_topic}\") spout_args.append(f\"--output_kafka_cluster_connection_string={spout.output.args.kafka_servers}\") # Convert state if spout.state.type == \"redis\": spout_args.append(f\"--redis_host={spout.state.args.redis_host}\") spout_args.append(f\"--redis_port={spout.state.args.redis_port}\") spout_args.append(f\"--redis_db={spout.state.args.redis_db}\") elif spout.state.type == \"postgres\": spout_args.append(f\"--postgres_host={spout.state.args.postgres_host}\") spout_args.append(f\"--postgres_port={spout.state.args.postgres_port}\") spout_args.append(f\"--postgres_user={spout.state.args.postgres_user}\") spout_args.append(f\"--postgres_password={spout.state.args.postgres_password}\") spout_args.append(f\"--postgres_database={spout.state.args.postgres_database}\") spout_args.append(f\"--postgres_table={spout.state.args.postgres_table}\") elif spout.state.type == \"dynamodb\": spout_args.append(f\"--dynamodb_table_name={spout.state.args.dynamodb_table_name}\") spout_args.append(f\"--dynamodb_region_name={spout.state.args.dynamodb_region_name}\") return spout_args @typing.no_type_check def _convert_bolt(self, bolt: Bolt) -> List[str]: bolt_args = [] # Convert input if bolt.input.type == \"batch\": bolt_args.append(f\"--input_folder={bolt.input.args.folder}\") bolt_args.append(f\"--input_s3_bucket={bolt.input.args.bucket}\") bolt_args.append(f\"--input_s3_folder={bolt.input.args.folder}\") elif bolt.input.type == \"streaming\": bolt_args.append(f\"--input_kafka_topic={bolt.input.args.input_topic}\") bolt_args.append(f\"--input_kafka_cluster_connection_string={bolt.input.args.kafka_servers}\") # Convert output if bolt.output.type == \"batch\": bolt_args.append(f\"--output_folder={bolt.output.args.folder}\") bolt_args.append(f\"--output_s3_bucket={bolt.output.args.bucket}\") bolt_args.append(f\"--output_s3_folder={bolt.output.args.folder}\") elif bolt.output.type == \"streaming\": bolt_args.append(f\"--output_kafka_topic={bolt.output.args.output_topic}\") bolt_args.append(f\"--output_kafka_cluster_connection_string={bolt.output.args.kafka_servers}\") # Convert state if bolt.state.type == \"redis\": bolt_args.append(f\"--redis_host={bolt.state.args.redis_host}\") bolt_args.append(f\"--redis_port={bolt.state.args.redis_port}\") bolt_args.append(f\"--redis_db={bolt.state.args.redis_db}\") elif bolt.state.type == \"postgres\": bolt_args.append(f\"--postgres_host={bolt.state.args.postgres_host}\") bolt_args.append(f\"--postgres_port={bolt.state.args.postgres_port}\") bolt_args.append(f\"--postgres_user={bolt.state.args.postgres_user}\") bolt_args.append(f\"--postgres_password={bolt.state.args.postgres_password}\") bolt_args.append(f\"--postgres_database={bolt.state.args.postgres_database}\") bolt_args.append(f\"--postgres_table={bolt.state.args.postgres_table}\") elif bolt.state.type == \"dynamodb\": bolt_args.append(f\"--dynamodb_table_name={bolt.state.args.dynamodb_table_name}\") bolt_args.append(f\"--dynamodb_region_name={bolt.state.args.dynamodb_region_name}\") return bolt_args __init__(spout_ctls, bolt_ctls) Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts. Parameters: Name Type Description Default spout_ctls Dict [ str , SpoutCtl ] Dictionary of SpoutCtl instances. required bolt_ctls Dict [ str , BoltCtl ] Dictionary of BoltCtl instances. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def __init__(self, spout_ctls: Dict[str, SpoutCtl], bolt_ctls: Dict[str, BoltCtl]): \"\"\" Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts. Args: spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances. bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances. \"\"\" self.spout_ctls = spout_ctls self.bolt_ctls = bolt_ctls self.log = logging.getLogger(self.__class__.__name__) create_parser(parser) Create and return the command-line parser for managing spouts and bolts. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def create_parser(self, parser): \"\"\" Create and return the command-line parser for managing spouts and bolts. \"\"\" parser.add_argument(\"--spout\", type=str, help=\"Name of the specific spout to run.\") parser.add_argument(\"--bolt\", type=str, help=\"Name of the specific bolt to run.\") parser.add_argument(\"--file\", default=\".\", type=str, help=\"Path of the genius.yml file, default to .\") return parser resolve_reference(input_type, ref_name) Resolve the reference of a bolt's input based on the input type (spout or bolt). Parameters: Name Type Description Default input_type str Type of the input (\"spout\" or \"bolt\"). required ref_name str Name of the spout or bolt to refer to. required Returns: Name Type Description Output The output configuration of the referred spout or bolt. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def resolve_reference(self, input_type: str, ref_name: str): \"\"\" Resolve the reference of a bolt's input based on the input type (spout or bolt). Args: input_type (str): Type of the input (\"spout\" or \"bolt\"). ref_name (str): Name of the spout or bolt to refer to. Returns: Output: The output configuration of the referred spout or bolt. \"\"\" if input_type == \"spout\": referred_spout = self.geniusfile.spouts.get(ref_name) if not referred_spout: self.log.error(emoji.emojize(f\":x: Referred spout {ref_name} not found.\")) return None return referred_spout.output elif input_type == \"bolt\": referred_bolt = self.geniusfile.bolts.get(ref_name) if not referred_bolt: self.log.error(emoji.emojize(f\":x: Referred bolt {ref_name} not found.\")) return None return referred_bolt.output else: self.log.error(emoji.emojize(f\":x: Invalid reference type {input_type}.\")) return None run(args) Run the command-line interface for managing spouts and bolts based on provided arguments. Please note that there is no ordering of the spouts and bolts in the YAML configuration. Each spout and bolt is an independent entity even when connected together. Parameters: Name Type Description Default args argparse . Namespace Parsed command-line arguments. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run(self, args): \"\"\" Run the command-line interface for managing spouts and bolts based on provided arguments. Please note that there is no ordering of the spouts and bolts in the YAML configuration. Each spout and bolt is an independent entity even when connected together. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" with open(args.file, \"r\") as file: self.geniusfile = Geniusfile.parse_obj(yaml.safe_load(file)) if args.spout == \"all\": self.run_spouts() elif args.bolt == \"all\": self.run_bolts() elif args.spout: self.run_spout(args.spout) elif args.bolt: self.run_bolt(args.bolt) else: self.run_spouts() self.run_bolts() run_bolt(bolt_name) Run a specific bolt based on its name. Parameters: Name Type Description Default bolt_name str Name of the bolt to run. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run_bolt(self, bolt_name: str): \"\"\" Run a specific bolt based on its name. Args: bolt_name (str): Name of the bolt to run. \"\"\" bolt = self.geniusfile.bolts.get(bolt_name) if not bolt: self.log.error(emoji.emojize(f\":x: Bolt {bolt_name} not found.\")) return # Resolve reference if input type is \"spout\" or \"bolt\" if bolt.input.type in [\"spout\", \"bolt\"]: if not bolt.input.args or not bolt.input.args.name: raise ValueError(emoji.emojize(f\"Need referenced spouts or bolt to be mentioned here {bolt.input}\")) ref_name = bolt.input.args.name resolved_output = self.resolve_reference(bolt.input.type, ref_name) if not resolved_output: self.log.error(emoji.emojize(f\":x: Failed to resolve reference for bolt {bolt_name}.\")) return bolt.input.type = resolved_output.type # Set the resolved output type as the bolt's input type bolt.input.args = resolved_output.args # Set the resolved output args as the bolt's input args bolt_ctl = self.bolt_ctls.get(bolt_name) if not bolt_ctl: self.log.error(emoji.emojize(f\":x: BoltCtl for {bolt_name} not found.\")) return self.log.info(emoji.emojize(f\":rocket: Running bolt {bolt_name}...\")) flat_args = [\"run\", bolt.input.type, bolt.output.type, bolt.state.type, bolt.method] + self._convert_bolt(bolt) parser = argparse.ArgumentParser() self.bolt_ctls[bolt_name].create_parser(parser) namespace_args = parser.parse_args(flat_args) bolt_ctl.run(namespace_args) run_bolts() Run all bolts defined in the YAML configuration. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run_bolts(self): \"\"\"Run all bolts defined in the YAML configuration.\"\"\" self.log.info(emoji.emojize(\":rocket: Running all bolts...\")) for bolt_name, _ in self.geniusfile.bolts.items(): self.run_bolt(bolt_name) run_spout(spout_name) Run a specific spout based on its name. Parameters: Name Type Description Default spout_name str Name of the spout to run. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run_spout(self, spout_name: str): \"\"\" Run a specific spout based on its name. Args: spout_name (str): Name of the spout to run. \"\"\" spout = self.geniusfile.spouts.get(spout_name) if not spout: self.log.error(emoji.emojize(f\":x: Spout {spout_name} not found.\")) return spout_ctl = self.spout_ctls.get(spout_name) if not spout_ctl: self.log.error(emoji.emojize(f\":x: SpoutCtl for {spout_name} not found.\")) return self.log.info(emoji.emojize(f\":rocket: Running spout {spout_name}...\")) flat_args = [\"run\", spout.output.type, spout.state.type, spout.method] + self._convert_spout(spout) parser = argparse.ArgumentParser() self.spout_ctls[spout_name].create_parser(parser) namespace_args = parser.parse_args(flat_args) spout_ctl.run(namespace_args) run_spouts() Run all spouts defined in the YAML configuration. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run_spouts(self): \"\"\"Run all spouts defined in the YAML configuration.\"\"\" self.log.info(emoji.emojize(\":rocket: Running all spouts...\")) for spout_name, _ in self.geniusfile.spouts.items(): self.run_spout(spout_name)","title":"yamlctl"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl","text":"Command-line interface for managing spouts and bolts based on a YAML configuration. The YamlCtl class provides methods to run specific or all spouts and bolts defined in a YAML file. The YAML file's structure is defined by the Geniusfile schema. Example YAML structure: version: \"1\" spouts: spout_name1: name: \"spout1\" method: \"method_name\" ... bolts: bolt_name1: name: \"bolt1\" method: \"method_name\" ... Attributes: Name Type Description geniusfile Geniusfile Parsed YAML configuration. spout_ctls Dict [ str , SpoutCtl ] Dictionary of SpoutCtl instances. bolt_ctls Dict [ str , BoltCtl ] Dictionary of BoltCtl instances. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py class YamlCtl: \"\"\" Command-line interface for managing spouts and bolts based on a YAML configuration. The YamlCtl class provides methods to run specific or all spouts and bolts defined in a YAML file. The YAML file's structure is defined by the Geniusfile schema. Example YAML structure: ``` version: \"1\" spouts: spout_name1: name: \"spout1\" method: \"method_name\" ... bolts: bolt_name1: name: \"bolt1\" method: \"method_name\" ... ``` Attributes: geniusfile (Geniusfile): Parsed YAML configuration. spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances. bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances. \"\"\" def __init__(self, spout_ctls: Dict[str, SpoutCtl], bolt_ctls: Dict[str, BoltCtl]): \"\"\" Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts. Args: spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances. bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances. \"\"\" self.spout_ctls = spout_ctls self.bolt_ctls = bolt_ctls self.log = logging.getLogger(self.__class__.__name__) def create_parser(self, parser): \"\"\" Create and return the command-line parser for managing spouts and bolts. \"\"\" parser.add_argument(\"--spout\", type=str, help=\"Name of the specific spout to run.\") parser.add_argument(\"--bolt\", type=str, help=\"Name of the specific bolt to run.\") parser.add_argument(\"--file\", default=\".\", type=str, help=\"Path of the genius.yml file, default to .\") return parser def run(self, args): \"\"\" Run the command-line interface for managing spouts and bolts based on provided arguments. Please note that there is no ordering of the spouts and bolts in the YAML configuration. Each spout and bolt is an independent entity even when connected together. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" with open(args.file, \"r\") as file: self.geniusfile = Geniusfile.parse_obj(yaml.safe_load(file)) if args.spout == \"all\": self.run_spouts() elif args.bolt == \"all\": self.run_bolts() elif args.spout: self.run_spout(args.spout) elif args.bolt: self.run_bolt(args.bolt) else: self.run_spouts() self.run_bolts() def run_spouts(self): \"\"\"Run all spouts defined in the YAML configuration.\"\"\" self.log.info(emoji.emojize(\":rocket: Running all spouts...\")) for spout_name, _ in self.geniusfile.spouts.items(): self.run_spout(spout_name) def run_bolts(self): \"\"\"Run all bolts defined in the YAML configuration.\"\"\" self.log.info(emoji.emojize(\":rocket: Running all bolts...\")) for bolt_name, _ in self.geniusfile.bolts.items(): self.run_bolt(bolt_name) def run_spout(self, spout_name: str): \"\"\" Run a specific spout based on its name. Args: spout_name (str): Name of the spout to run. \"\"\" spout = self.geniusfile.spouts.get(spout_name) if not spout: self.log.error(emoji.emojize(f\":x: Spout {spout_name} not found.\")) return spout_ctl = self.spout_ctls.get(spout_name) if not spout_ctl: self.log.error(emoji.emojize(f\":x: SpoutCtl for {spout_name} not found.\")) return self.log.info(emoji.emojize(f\":rocket: Running spout {spout_name}...\")) flat_args = [\"run\", spout.output.type, spout.state.type, spout.method] + self._convert_spout(spout) parser = argparse.ArgumentParser() self.spout_ctls[spout_name].create_parser(parser) namespace_args = parser.parse_args(flat_args) spout_ctl.run(namespace_args) def run_bolt(self, bolt_name: str): \"\"\" Run a specific bolt based on its name. Args: bolt_name (str): Name of the bolt to run. \"\"\" bolt = self.geniusfile.bolts.get(bolt_name) if not bolt: self.log.error(emoji.emojize(f\":x: Bolt {bolt_name} not found.\")) return # Resolve reference if input type is \"spout\" or \"bolt\" if bolt.input.type in [\"spout\", \"bolt\"]: if not bolt.input.args or not bolt.input.args.name: raise ValueError(emoji.emojize(f\"Need referenced spouts or bolt to be mentioned here {bolt.input}\")) ref_name = bolt.input.args.name resolved_output = self.resolve_reference(bolt.input.type, ref_name) if not resolved_output: self.log.error(emoji.emojize(f\":x: Failed to resolve reference for bolt {bolt_name}.\")) return bolt.input.type = resolved_output.type # Set the resolved output type as the bolt's input type bolt.input.args = resolved_output.args # Set the resolved output args as the bolt's input args bolt_ctl = self.bolt_ctls.get(bolt_name) if not bolt_ctl: self.log.error(emoji.emojize(f\":x: BoltCtl for {bolt_name} not found.\")) return self.log.info(emoji.emojize(f\":rocket: Running bolt {bolt_name}...\")) flat_args = [\"run\", bolt.input.type, bolt.output.type, bolt.state.type, bolt.method] + self._convert_bolt(bolt) parser = argparse.ArgumentParser() self.bolt_ctls[bolt_name].create_parser(parser) namespace_args = parser.parse_args(flat_args) bolt_ctl.run(namespace_args) def resolve_reference(self, input_type: str, ref_name: str): \"\"\" Resolve the reference of a bolt's input based on the input type (spout or bolt). Args: input_type (str): Type of the input (\"spout\" or \"bolt\"). ref_name (str): Name of the spout or bolt to refer to. Returns: Output: The output configuration of the referred spout or bolt. \"\"\" if input_type == \"spout\": referred_spout = self.geniusfile.spouts.get(ref_name) if not referred_spout: self.log.error(emoji.emojize(f\":x: Referred spout {ref_name} not found.\")) return None return referred_spout.output elif input_type == \"bolt\": referred_bolt = self.geniusfile.bolts.get(ref_name) if not referred_bolt: self.log.error(emoji.emojize(f\":x: Referred bolt {ref_name} not found.\")) return None return referred_bolt.output else: self.log.error(emoji.emojize(f\":x: Invalid reference type {input_type}.\")) return None @typing.no_type_check def _convert_spout(self, spout: Spout) -> List[str]: spout_args = [] # Convert output if spout.output.type == \"batch\": spout_args.append(f\"--output_folder={spout.output.args.folder}\") spout_args.append(f\"--output_s3_bucket={spout.output.args.bucket}\") spout_args.append(f\"--output_s3_folder={spout.output.args.folder}\") elif spout.output.type == \"streaming\": spout_args.append(f\"--output_kafka_topic={spout.output.args.output_topic}\") spout_args.append(f\"--output_kafka_cluster_connection_string={spout.output.args.kafka_servers}\") # Convert state if spout.state.type == \"redis\": spout_args.append(f\"--redis_host={spout.state.args.redis_host}\") spout_args.append(f\"--redis_port={spout.state.args.redis_port}\") spout_args.append(f\"--redis_db={spout.state.args.redis_db}\") elif spout.state.type == \"postgres\": spout_args.append(f\"--postgres_host={spout.state.args.postgres_host}\") spout_args.append(f\"--postgres_port={spout.state.args.postgres_port}\") spout_args.append(f\"--postgres_user={spout.state.args.postgres_user}\") spout_args.append(f\"--postgres_password={spout.state.args.postgres_password}\") spout_args.append(f\"--postgres_database={spout.state.args.postgres_database}\") spout_args.append(f\"--postgres_table={spout.state.args.postgres_table}\") elif spout.state.type == \"dynamodb\": spout_args.append(f\"--dynamodb_table_name={spout.state.args.dynamodb_table_name}\") spout_args.append(f\"--dynamodb_region_name={spout.state.args.dynamodb_region_name}\") return spout_args @typing.no_type_check def _convert_bolt(self, bolt: Bolt) -> List[str]: bolt_args = [] # Convert input if bolt.input.type == \"batch\": bolt_args.append(f\"--input_folder={bolt.input.args.folder}\") bolt_args.append(f\"--input_s3_bucket={bolt.input.args.bucket}\") bolt_args.append(f\"--input_s3_folder={bolt.input.args.folder}\") elif bolt.input.type == \"streaming\": bolt_args.append(f\"--input_kafka_topic={bolt.input.args.input_topic}\") bolt_args.append(f\"--input_kafka_cluster_connection_string={bolt.input.args.kafka_servers}\") # Convert output if bolt.output.type == \"batch\": bolt_args.append(f\"--output_folder={bolt.output.args.folder}\") bolt_args.append(f\"--output_s3_bucket={bolt.output.args.bucket}\") bolt_args.append(f\"--output_s3_folder={bolt.output.args.folder}\") elif bolt.output.type == \"streaming\": bolt_args.append(f\"--output_kafka_topic={bolt.output.args.output_topic}\") bolt_args.append(f\"--output_kafka_cluster_connection_string={bolt.output.args.kafka_servers}\") # Convert state if bolt.state.type == \"redis\": bolt_args.append(f\"--redis_host={bolt.state.args.redis_host}\") bolt_args.append(f\"--redis_port={bolt.state.args.redis_port}\") bolt_args.append(f\"--redis_db={bolt.state.args.redis_db}\") elif bolt.state.type == \"postgres\": bolt_args.append(f\"--postgres_host={bolt.state.args.postgres_host}\") bolt_args.append(f\"--postgres_port={bolt.state.args.postgres_port}\") bolt_args.append(f\"--postgres_user={bolt.state.args.postgres_user}\") bolt_args.append(f\"--postgres_password={bolt.state.args.postgres_password}\") bolt_args.append(f\"--postgres_database={bolt.state.args.postgres_database}\") bolt_args.append(f\"--postgres_table={bolt.state.args.postgres_table}\") elif bolt.state.type == \"dynamodb\": bolt_args.append(f\"--dynamodb_table_name={bolt.state.args.dynamodb_table_name}\") bolt_args.append(f\"--dynamodb_region_name={bolt.state.args.dynamodb_region_name}\") return bolt_args","title":"YamlCtl"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.__init__","text":"Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts. Parameters: Name Type Description Default spout_ctls Dict [ str , SpoutCtl ] Dictionary of SpoutCtl instances. required bolt_ctls Dict [ str , BoltCtl ] Dictionary of BoltCtl instances. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def __init__(self, spout_ctls: Dict[str, SpoutCtl], bolt_ctls: Dict[str, BoltCtl]): \"\"\" Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts. Args: spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances. bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances. \"\"\" self.spout_ctls = spout_ctls self.bolt_ctls = bolt_ctls self.log = logging.getLogger(self.__class__.__name__)","title":"__init__()"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.create_parser","text":"Create and return the command-line parser for managing spouts and bolts. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def create_parser(self, parser): \"\"\" Create and return the command-line parser for managing spouts and bolts. \"\"\" parser.add_argument(\"--spout\", type=str, help=\"Name of the specific spout to run.\") parser.add_argument(\"--bolt\", type=str, help=\"Name of the specific bolt to run.\") parser.add_argument(\"--file\", default=\".\", type=str, help=\"Path of the genius.yml file, default to .\") return parser","title":"create_parser()"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.resolve_reference","text":"Resolve the reference of a bolt's input based on the input type (spout or bolt). Parameters: Name Type Description Default input_type str Type of the input (\"spout\" or \"bolt\"). required ref_name str Name of the spout or bolt to refer to. required Returns: Name Type Description Output The output configuration of the referred spout or bolt. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def resolve_reference(self, input_type: str, ref_name: str): \"\"\" Resolve the reference of a bolt's input based on the input type (spout or bolt). Args: input_type (str): Type of the input (\"spout\" or \"bolt\"). ref_name (str): Name of the spout or bolt to refer to. Returns: Output: The output configuration of the referred spout or bolt. \"\"\" if input_type == \"spout\": referred_spout = self.geniusfile.spouts.get(ref_name) if not referred_spout: self.log.error(emoji.emojize(f\":x: Referred spout {ref_name} not found.\")) return None return referred_spout.output elif input_type == \"bolt\": referred_bolt = self.geniusfile.bolts.get(ref_name) if not referred_bolt: self.log.error(emoji.emojize(f\":x: Referred bolt {ref_name} not found.\")) return None return referred_bolt.output else: self.log.error(emoji.emojize(f\":x: Invalid reference type {input_type}.\")) return None","title":"resolve_reference()"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run","text":"Run the command-line interface for managing spouts and bolts based on provided arguments. Please note that there is no ordering of the spouts and bolts in the YAML configuration. Each spout and bolt is an independent entity even when connected together. Parameters: Name Type Description Default args argparse . Namespace Parsed command-line arguments. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run(self, args): \"\"\" Run the command-line interface for managing spouts and bolts based on provided arguments. Please note that there is no ordering of the spouts and bolts in the YAML configuration. Each spout and bolt is an independent entity even when connected together. Args: args (argparse.Namespace): Parsed command-line arguments. \"\"\" with open(args.file, \"r\") as file: self.geniusfile = Geniusfile.parse_obj(yaml.safe_load(file)) if args.spout == \"all\": self.run_spouts() elif args.bolt == \"all\": self.run_bolts() elif args.spout: self.run_spout(args.spout) elif args.bolt: self.run_bolt(args.bolt) else: self.run_spouts() self.run_bolts()","title":"run()"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_bolt","text":"Run a specific bolt based on its name. Parameters: Name Type Description Default bolt_name str Name of the bolt to run. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run_bolt(self, bolt_name: str): \"\"\" Run a specific bolt based on its name. Args: bolt_name (str): Name of the bolt to run. \"\"\" bolt = self.geniusfile.bolts.get(bolt_name) if not bolt: self.log.error(emoji.emojize(f\":x: Bolt {bolt_name} not found.\")) return # Resolve reference if input type is \"spout\" or \"bolt\" if bolt.input.type in [\"spout\", \"bolt\"]: if not bolt.input.args or not bolt.input.args.name: raise ValueError(emoji.emojize(f\"Need referenced spouts or bolt to be mentioned here {bolt.input}\")) ref_name = bolt.input.args.name resolved_output = self.resolve_reference(bolt.input.type, ref_name) if not resolved_output: self.log.error(emoji.emojize(f\":x: Failed to resolve reference for bolt {bolt_name}.\")) return bolt.input.type = resolved_output.type # Set the resolved output type as the bolt's input type bolt.input.args = resolved_output.args # Set the resolved output args as the bolt's input args bolt_ctl = self.bolt_ctls.get(bolt_name) if not bolt_ctl: self.log.error(emoji.emojize(f\":x: BoltCtl for {bolt_name} not found.\")) return self.log.info(emoji.emojize(f\":rocket: Running bolt {bolt_name}...\")) flat_args = [\"run\", bolt.input.type, bolt.output.type, bolt.state.type, bolt.method] + self._convert_bolt(bolt) parser = argparse.ArgumentParser() self.bolt_ctls[bolt_name].create_parser(parser) namespace_args = parser.parse_args(flat_args) bolt_ctl.run(namespace_args)","title":"run_bolt()"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_bolts","text":"Run all bolts defined in the YAML configuration. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run_bolts(self): \"\"\"Run all bolts defined in the YAML configuration.\"\"\" self.log.info(emoji.emojize(\":rocket: Running all bolts...\")) for bolt_name, _ in self.geniusfile.bolts.items(): self.run_bolt(bolt_name)","title":"run_bolts()"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_spout","text":"Run a specific spout based on its name. Parameters: Name Type Description Default spout_name str Name of the spout to run. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run_spout(self, spout_name: str): \"\"\" Run a specific spout based on its name. Args: spout_name (str): Name of the spout to run. \"\"\" spout = self.geniusfile.spouts.get(spout_name) if not spout: self.log.error(emoji.emojize(f\":x: Spout {spout_name} not found.\")) return spout_ctl = self.spout_ctls.get(spout_name) if not spout_ctl: self.log.error(emoji.emojize(f\":x: SpoutCtl for {spout_name} not found.\")) return self.log.info(emoji.emojize(f\":rocket: Running spout {spout_name}...\")) flat_args = [\"run\", spout.output.type, spout.state.type, spout.method] + self._convert_spout(spout) parser = argparse.ArgumentParser() self.spout_ctls[spout_name].create_parser(parser) namespace_args = parser.parse_args(flat_args) spout_ctl.run(namespace_args)","title":"run_spout()"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_spouts","text":"Run all spouts defined in the YAML configuration. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py def run_spouts(self): \"\"\"Run all spouts defined in the YAML configuration.\"\"\" self.log.info(emoji.emojize(\":rocket: Running all spouts...\")) for spout_name, _ in self.geniusfile.spouts.items(): self.run_spout(spout_name)","title":"run_spouts()"},{"location":"core/config/","text":"","title":"Config"},{"location":"core/core_bolt/","text":"Bolt Bases: Task Base class for all bolts. A bolt is a component that consumes streams of data, processes them, and possibly emits new data streams. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py class Bolt(Task): \"\"\" Base class for all bolts. A bolt is a component that consumes streams of data, processes them, and possibly emits new data streams. \"\"\" def __init__( self, input_config: InputConfig, output_config: OutputConfig, state_manager: StateManager, **kwargs ) -> None: \"\"\" The `Bolt` class is a base class for all bolts in the given context. It inherits from the `Task` class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and input and output configurations for batch or streaming data. The `Bolt` class uses the `InputConfig`, `OutputConfig` and `StateManager` classes, which are abstract base classes for managing input configurations, output configurations and states, respectively. The `InputConfig` and `OutputConfig` classes each have two subclasses: `StreamingInputConfig`, `BatchInputConfig`, `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and batch input and output configurations, respectively. The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers. The `Bolt` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage: - Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object. - The InputConfig object specifies the input configuration for the bolt. - The OutputConfig object specifies the output configuration for the bolt. - The StateManager object handles the management of the bolt's state. Example: input_config = InputConfig(...) output_config = OutputConfig(...) state_manager = StateManager(...) bolt = Bolt(input_config, output_config, state_manager) Args: input_config (InputConfig): The input configuration. output_config (OutputConfig): The output configuration. state_manager (StateManager): The state manager. \"\"\" super().__init__() self.input_config = input_config self.output_config = output_config self.state_manager = state_manager self.log = logging.getLogger(self.__class__.__name__) def __call__(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a method locally and manage the state. Args: method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. Returns: Any: The result of the method. \"\"\" try: # Get the type of state manager state_type = self.state_manager.get_state(self.id) # Save the current set of class variables to the state manager self.state_manager.set_state(self.id, {}) # Copy input data to local or connect to kafka and pass on the details if type(self.input_config) is BatchInputConfig: self.input_config.copy_from_remote() input_folder = self.input_config.get() kwargs[\"input_folder\"] = input_folder elif type(self.input_config) is StreamingInputConfig: kafka_consumer = self.input_config.get() kwargs[\"kafka_consumer\"] = kafka_consumer # Execute the task's method result = self.execute(method_name, *args, **kwargs) # Flush the output config self.output_config.flush() # Store the state as successful in the state manager state = {} state[\"status\"] = \"success\" self.state_manager.set_state(self.id, state) return result except Exception as e: state = {} state[\"status\"] = \"failed\" self.state_manager.set_state(self.id, state) self.log.exception(f\"Failed to execute method '{method_name}': {e}\") raise @staticmethod def create(klass: type, input_type: str, output_type: str, state_type: str, **kwargs) -> \"Bolt\": \"\"\" Create a bolt of a specific type. This static method is used to create a bolt of a specific type. It takes in an input type, an output type, a state type, and additional keyword arguments for initializing the bolt. The method creates the input config, output config, and state manager based on the provided types, and then creates and returns a bolt using these configurations. Args: klass (type): The Bolt class to create. input_type (str): The type of input config (\"batch\" or \"streaming\"). output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Bolt: The created bolt. Raises: ValueError: If an invalid input type, output type, or state type is provided. \"\"\" # Create the input config input_config: BatchInputConfig | StreamingInputConfig if input_type == \"batch\": input_config = BatchInputConfig( input_folder=kwargs[\"input_folder\"] if \"input_folder\" in kwargs else tempfile.mkdtemp(), bucket=kwargs[\"input_s3_bucket\"] if \"input_s3_bucket\" in kwargs else None, s3_folder=kwargs[\"input_s3_folder\"] if \"input_s3_folder\" in kwargs else None, ) elif input_type == \"streaming\": input_config = StreamingInputConfig( input_topic=kwargs[\"input_kafka_topic\"] if \"input_kafka_topic\" in kwargs else None, kafka_cluster_connection_string=kwargs[\"input_kafka_cluster_connection_string\"] if \"input_kafka_cluster_connection_string\" in kwargs else None, group_id=kwargs[\"input_kafka_consumer_group_id\"] if \"input_kafka_consumer_group_id\" in kwargs else None, ) else: raise ValueError(f\"Invalid input type: {input_type}\") # Create the output config output_config: BatchOutputConfig | StreamingOutputConfig if output_type == \"batch\": output_config = BatchOutputConfig( output_folder=kwargs[\"output_folder\"] if \"output_folder\" in kwargs else tempfile.mkdtemp(), bucket=kwargs[\"output_s3_bucket\"] if \"output_s3_bucket\" in kwargs else tempfile.mkdtemp(), s3_folder=kwargs[\"output_s3_folder\"] if \"output_s3_folder\" in kwargs else tempfile.mkdtemp(), ) elif output_type == \"streaming\": output_config = StreamingOutputConfig( kwargs[\"output_kafka_topic\"] if \"output_kafka_topic\" in kwargs else None, kwargs[\"output_kafka_cluster_connection_string\"] if \"output_kafka_cluster_connection_string\" in kwargs else None, ) else: raise ValueError(f\"Invalid output type: {output_type}\") # Create the state manager state_manager: StateManager if state_type == \"in_memory\": state_manager = InMemoryStateManager() elif state_type == \"redis\": state_manager = RedisStateManager( host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None, port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None, db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None, ) elif state_type == \"postgres\": state_manager = PostgresStateManager( host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None, port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None, user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None, password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None, database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None, table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None, ) elif state_type == \"dynamodb\": state_manager = DynamoDBStateManager( table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None, region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None, ) else: raise ValueError(f\"Invalid state type: {state_type}\") # Create the bolt bolt = klass(input_config=input_config, output_config=output_config, state_manager=state_manager, **kwargs) return bolt __call__(method_name, *args, **kwargs) Execute a method locally and manage the state. Parameters: Name Type Description Default method_name str The name of the method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. {} Returns: Name Type Description Any Any The result of the method. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py def __call__(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a method locally and manage the state. Args: method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. Returns: Any: The result of the method. \"\"\" try: # Get the type of state manager state_type = self.state_manager.get_state(self.id) # Save the current set of class variables to the state manager self.state_manager.set_state(self.id, {}) # Copy input data to local or connect to kafka and pass on the details if type(self.input_config) is BatchInputConfig: self.input_config.copy_from_remote() input_folder = self.input_config.get() kwargs[\"input_folder\"] = input_folder elif type(self.input_config) is StreamingInputConfig: kafka_consumer = self.input_config.get() kwargs[\"kafka_consumer\"] = kafka_consumer # Execute the task's method result = self.execute(method_name, *args, **kwargs) # Flush the output config self.output_config.flush() # Store the state as successful in the state manager state = {} state[\"status\"] = \"success\" self.state_manager.set_state(self.id, state) return result except Exception as e: state = {} state[\"status\"] = \"failed\" self.state_manager.set_state(self.id, state) self.log.exception(f\"Failed to execute method '{method_name}': {e}\") raise __init__(input_config, output_config, state_manager, **kwargs) The Bolt class is a base class for all bolts in the given context. It inherits from the Task class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and input and output configurations for batch or streaming data. The Bolt class uses the InputConfig , OutputConfig and StateManager classes, which are abstract base classes for managing input configurations, output configurations and states, respectively. The InputConfig and OutputConfig classes each have two subclasses: StreamingInputConfig , BatchInputConfig , StreamingOutputConfig and BatchOutputConfig , which manage streaming and batch input and output configurations, respectively. The StateManager class is used to get and set state, and it has several subclasses for different types of state managers. The Bolt class also uses the ECSManager and K8sManager classes in the execute_remote method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object. The InputConfig object specifies the input configuration for the bolt. The OutputConfig object specifies the output configuration for the bolt. The StateManager object handles the management of the bolt's state. Example input_config = InputConfig(...) output_config = OutputConfig(...) state_manager = StateManager(...) bolt = Bolt(input_config, output_config, state_manager) Parameters: Name Type Description Default input_config InputConfig The input configuration. required output_config OutputConfig The output configuration. required state_manager StateManager The state manager. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py def __init__( self, input_config: InputConfig, output_config: OutputConfig, state_manager: StateManager, **kwargs ) -> None: \"\"\" The `Bolt` class is a base class for all bolts in the given context. It inherits from the `Task` class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and input and output configurations for batch or streaming data. The `Bolt` class uses the `InputConfig`, `OutputConfig` and `StateManager` classes, which are abstract base classes for managing input configurations, output configurations and states, respectively. The `InputConfig` and `OutputConfig` classes each have two subclasses: `StreamingInputConfig`, `BatchInputConfig`, `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and batch input and output configurations, respectively. The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers. The `Bolt` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage: - Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object. - The InputConfig object specifies the input configuration for the bolt. - The OutputConfig object specifies the output configuration for the bolt. - The StateManager object handles the management of the bolt's state. Example: input_config = InputConfig(...) output_config = OutputConfig(...) state_manager = StateManager(...) bolt = Bolt(input_config, output_config, state_manager) Args: input_config (InputConfig): The input configuration. output_config (OutputConfig): The output configuration. state_manager (StateManager): The state manager. \"\"\" super().__init__() self.input_config = input_config self.output_config = output_config self.state_manager = state_manager self.log = logging.getLogger(self.__class__.__name__) create(klass, input_type, output_type, state_type, **kwargs) staticmethod Create a bolt of a specific type. This static method is used to create a bolt of a specific type. It takes in an input type, an output type, a state type, and additional keyword arguments for initializing the bolt. The method creates the input config, output config, and state manager based on the provided types, and then creates and returns a bolt using these configurations. Parameters: Name Type Description Default klass type The Bolt class to create. required input_type str The type of input config (\"batch\" or \"streaming\"). required output_type str The type of output config (\"batch\" or \"streaming\"). required state_type str The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). required **kwargs Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. {} Returns: Name Type Description Bolt Bolt The created bolt. Raises: Type Description ValueError If an invalid input type, output type, or state type is provided. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py @staticmethod def create(klass: type, input_type: str, output_type: str, state_type: str, **kwargs) -> \"Bolt\": \"\"\" Create a bolt of a specific type. This static method is used to create a bolt of a specific type. It takes in an input type, an output type, a state type, and additional keyword arguments for initializing the bolt. The method creates the input config, output config, and state manager based on the provided types, and then creates and returns a bolt using these configurations. Args: klass (type): The Bolt class to create. input_type (str): The type of input config (\"batch\" or \"streaming\"). output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Bolt: The created bolt. Raises: ValueError: If an invalid input type, output type, or state type is provided. \"\"\" # Create the input config input_config: BatchInputConfig | StreamingInputConfig if input_type == \"batch\": input_config = BatchInputConfig( input_folder=kwargs[\"input_folder\"] if \"input_folder\" in kwargs else tempfile.mkdtemp(), bucket=kwargs[\"input_s3_bucket\"] if \"input_s3_bucket\" in kwargs else None, s3_folder=kwargs[\"input_s3_folder\"] if \"input_s3_folder\" in kwargs else None, ) elif input_type == \"streaming\": input_config = StreamingInputConfig( input_topic=kwargs[\"input_kafka_topic\"] if \"input_kafka_topic\" in kwargs else None, kafka_cluster_connection_string=kwargs[\"input_kafka_cluster_connection_string\"] if \"input_kafka_cluster_connection_string\" in kwargs else None, group_id=kwargs[\"input_kafka_consumer_group_id\"] if \"input_kafka_consumer_group_id\" in kwargs else None, ) else: raise ValueError(f\"Invalid input type: {input_type}\") # Create the output config output_config: BatchOutputConfig | StreamingOutputConfig if output_type == \"batch\": output_config = BatchOutputConfig( output_folder=kwargs[\"output_folder\"] if \"output_folder\" in kwargs else tempfile.mkdtemp(), bucket=kwargs[\"output_s3_bucket\"] if \"output_s3_bucket\" in kwargs else tempfile.mkdtemp(), s3_folder=kwargs[\"output_s3_folder\"] if \"output_s3_folder\" in kwargs else tempfile.mkdtemp(), ) elif output_type == \"streaming\": output_config = StreamingOutputConfig( kwargs[\"output_kafka_topic\"] if \"output_kafka_topic\" in kwargs else None, kwargs[\"output_kafka_cluster_connection_string\"] if \"output_kafka_cluster_connection_string\" in kwargs else None, ) else: raise ValueError(f\"Invalid output type: {output_type}\") # Create the state manager state_manager: StateManager if state_type == \"in_memory\": state_manager = InMemoryStateManager() elif state_type == \"redis\": state_manager = RedisStateManager( host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None, port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None, db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None, ) elif state_type == \"postgres\": state_manager = PostgresStateManager( host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None, port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None, user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None, password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None, database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None, table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None, ) elif state_type == \"dynamodb\": state_manager = DynamoDBStateManager( table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None, region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None, ) else: raise ValueError(f\"Invalid state type: {state_type}\") # Create the bolt bolt = klass(input_config=input_config, output_config=output_config, state_manager=state_manager, **kwargs) return bolt","title":"bolt"},{"location":"core/core_bolt/#core.bolt.Bolt","text":"Bases: Task Base class for all bolts. A bolt is a component that consumes streams of data, processes them, and possibly emits new data streams. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py class Bolt(Task): \"\"\" Base class for all bolts. A bolt is a component that consumes streams of data, processes them, and possibly emits new data streams. \"\"\" def __init__( self, input_config: InputConfig, output_config: OutputConfig, state_manager: StateManager, **kwargs ) -> None: \"\"\" The `Bolt` class is a base class for all bolts in the given context. It inherits from the `Task` class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and input and output configurations for batch or streaming data. The `Bolt` class uses the `InputConfig`, `OutputConfig` and `StateManager` classes, which are abstract base classes for managing input configurations, output configurations and states, respectively. The `InputConfig` and `OutputConfig` classes each have two subclasses: `StreamingInputConfig`, `BatchInputConfig`, `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and batch input and output configurations, respectively. The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers. The `Bolt` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage: - Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object. - The InputConfig object specifies the input configuration for the bolt. - The OutputConfig object specifies the output configuration for the bolt. - The StateManager object handles the management of the bolt's state. Example: input_config = InputConfig(...) output_config = OutputConfig(...) state_manager = StateManager(...) bolt = Bolt(input_config, output_config, state_manager) Args: input_config (InputConfig): The input configuration. output_config (OutputConfig): The output configuration. state_manager (StateManager): The state manager. \"\"\" super().__init__() self.input_config = input_config self.output_config = output_config self.state_manager = state_manager self.log = logging.getLogger(self.__class__.__name__) def __call__(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a method locally and manage the state. Args: method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. Returns: Any: The result of the method. \"\"\" try: # Get the type of state manager state_type = self.state_manager.get_state(self.id) # Save the current set of class variables to the state manager self.state_manager.set_state(self.id, {}) # Copy input data to local or connect to kafka and pass on the details if type(self.input_config) is BatchInputConfig: self.input_config.copy_from_remote() input_folder = self.input_config.get() kwargs[\"input_folder\"] = input_folder elif type(self.input_config) is StreamingInputConfig: kafka_consumer = self.input_config.get() kwargs[\"kafka_consumer\"] = kafka_consumer # Execute the task's method result = self.execute(method_name, *args, **kwargs) # Flush the output config self.output_config.flush() # Store the state as successful in the state manager state = {} state[\"status\"] = \"success\" self.state_manager.set_state(self.id, state) return result except Exception as e: state = {} state[\"status\"] = \"failed\" self.state_manager.set_state(self.id, state) self.log.exception(f\"Failed to execute method '{method_name}': {e}\") raise @staticmethod def create(klass: type, input_type: str, output_type: str, state_type: str, **kwargs) -> \"Bolt\": \"\"\" Create a bolt of a specific type. This static method is used to create a bolt of a specific type. It takes in an input type, an output type, a state type, and additional keyword arguments for initializing the bolt. The method creates the input config, output config, and state manager based on the provided types, and then creates and returns a bolt using these configurations. Args: klass (type): The Bolt class to create. input_type (str): The type of input config (\"batch\" or \"streaming\"). output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Bolt: The created bolt. Raises: ValueError: If an invalid input type, output type, or state type is provided. \"\"\" # Create the input config input_config: BatchInputConfig | StreamingInputConfig if input_type == \"batch\": input_config = BatchInputConfig( input_folder=kwargs[\"input_folder\"] if \"input_folder\" in kwargs else tempfile.mkdtemp(), bucket=kwargs[\"input_s3_bucket\"] if \"input_s3_bucket\" in kwargs else None, s3_folder=kwargs[\"input_s3_folder\"] if \"input_s3_folder\" in kwargs else None, ) elif input_type == \"streaming\": input_config = StreamingInputConfig( input_topic=kwargs[\"input_kafka_topic\"] if \"input_kafka_topic\" in kwargs else None, kafka_cluster_connection_string=kwargs[\"input_kafka_cluster_connection_string\"] if \"input_kafka_cluster_connection_string\" in kwargs else None, group_id=kwargs[\"input_kafka_consumer_group_id\"] if \"input_kafka_consumer_group_id\" in kwargs else None, ) else: raise ValueError(f\"Invalid input type: {input_type}\") # Create the output config output_config: BatchOutputConfig | StreamingOutputConfig if output_type == \"batch\": output_config = BatchOutputConfig( output_folder=kwargs[\"output_folder\"] if \"output_folder\" in kwargs else tempfile.mkdtemp(), bucket=kwargs[\"output_s3_bucket\"] if \"output_s3_bucket\" in kwargs else tempfile.mkdtemp(), s3_folder=kwargs[\"output_s3_folder\"] if \"output_s3_folder\" in kwargs else tempfile.mkdtemp(), ) elif output_type == \"streaming\": output_config = StreamingOutputConfig( kwargs[\"output_kafka_topic\"] if \"output_kafka_topic\" in kwargs else None, kwargs[\"output_kafka_cluster_connection_string\"] if \"output_kafka_cluster_connection_string\" in kwargs else None, ) else: raise ValueError(f\"Invalid output type: {output_type}\") # Create the state manager state_manager: StateManager if state_type == \"in_memory\": state_manager = InMemoryStateManager() elif state_type == \"redis\": state_manager = RedisStateManager( host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None, port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None, db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None, ) elif state_type == \"postgres\": state_manager = PostgresStateManager( host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None, port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None, user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None, password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None, database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None, table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None, ) elif state_type == \"dynamodb\": state_manager = DynamoDBStateManager( table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None, region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None, ) else: raise ValueError(f\"Invalid state type: {state_type}\") # Create the bolt bolt = klass(input_config=input_config, output_config=output_config, state_manager=state_manager, **kwargs) return bolt","title":"Bolt"},{"location":"core/core_bolt/#core.bolt.Bolt.__call__","text":"Execute a method locally and manage the state. Parameters: Name Type Description Default method_name str The name of the method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. {} Returns: Name Type Description Any Any The result of the method. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py def __call__(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a method locally and manage the state. Args: method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. Returns: Any: The result of the method. \"\"\" try: # Get the type of state manager state_type = self.state_manager.get_state(self.id) # Save the current set of class variables to the state manager self.state_manager.set_state(self.id, {}) # Copy input data to local or connect to kafka and pass on the details if type(self.input_config) is BatchInputConfig: self.input_config.copy_from_remote() input_folder = self.input_config.get() kwargs[\"input_folder\"] = input_folder elif type(self.input_config) is StreamingInputConfig: kafka_consumer = self.input_config.get() kwargs[\"kafka_consumer\"] = kafka_consumer # Execute the task's method result = self.execute(method_name, *args, **kwargs) # Flush the output config self.output_config.flush() # Store the state as successful in the state manager state = {} state[\"status\"] = \"success\" self.state_manager.set_state(self.id, state) return result except Exception as e: state = {} state[\"status\"] = \"failed\" self.state_manager.set_state(self.id, state) self.log.exception(f\"Failed to execute method '{method_name}': {e}\") raise","title":"__call__()"},{"location":"core/core_bolt/#core.bolt.Bolt.__init__","text":"The Bolt class is a base class for all bolts in the given context. It inherits from the Task class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and input and output configurations for batch or streaming data. The Bolt class uses the InputConfig , OutputConfig and StateManager classes, which are abstract base classes for managing input configurations, output configurations and states, respectively. The InputConfig and OutputConfig classes each have two subclasses: StreamingInputConfig , BatchInputConfig , StreamingOutputConfig and BatchOutputConfig , which manage streaming and batch input and output configurations, respectively. The StateManager class is used to get and set state, and it has several subclasses for different types of state managers. The Bolt class also uses the ECSManager and K8sManager classes in the execute_remote method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object. The InputConfig object specifies the input configuration for the bolt. The OutputConfig object specifies the output configuration for the bolt. The StateManager object handles the management of the bolt's state. Example input_config = InputConfig(...) output_config = OutputConfig(...) state_manager = StateManager(...) bolt = Bolt(input_config, output_config, state_manager) Parameters: Name Type Description Default input_config InputConfig The input configuration. required output_config OutputConfig The output configuration. required state_manager StateManager The state manager. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py def __init__( self, input_config: InputConfig, output_config: OutputConfig, state_manager: StateManager, **kwargs ) -> None: \"\"\" The `Bolt` class is a base class for all bolts in the given context. It inherits from the `Task` class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and input and output configurations for batch or streaming data. The `Bolt` class uses the `InputConfig`, `OutputConfig` and `StateManager` classes, which are abstract base classes for managing input configurations, output configurations and states, respectively. The `InputConfig` and `OutputConfig` classes each have two subclasses: `StreamingInputConfig`, `BatchInputConfig`, `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and batch input and output configurations, respectively. The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers. The `Bolt` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage: - Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object. - The InputConfig object specifies the input configuration for the bolt. - The OutputConfig object specifies the output configuration for the bolt. - The StateManager object handles the management of the bolt's state. Example: input_config = InputConfig(...) output_config = OutputConfig(...) state_manager = StateManager(...) bolt = Bolt(input_config, output_config, state_manager) Args: input_config (InputConfig): The input configuration. output_config (OutputConfig): The output configuration. state_manager (StateManager): The state manager. \"\"\" super().__init__() self.input_config = input_config self.output_config = output_config self.state_manager = state_manager self.log = logging.getLogger(self.__class__.__name__)","title":"__init__()"},{"location":"core/core_bolt/#core.bolt.Bolt.create","text":"Create a bolt of a specific type. This static method is used to create a bolt of a specific type. It takes in an input type, an output type, a state type, and additional keyword arguments for initializing the bolt. The method creates the input config, output config, and state manager based on the provided types, and then creates and returns a bolt using these configurations. Parameters: Name Type Description Default klass type The Bolt class to create. required input_type str The type of input config (\"batch\" or \"streaming\"). required output_type str The type of output config (\"batch\" or \"streaming\"). required state_type str The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). required **kwargs Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. {} Returns: Name Type Description Bolt Bolt The created bolt. Raises: Type Description ValueError If an invalid input type, output type, or state type is provided. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py @staticmethod def create(klass: type, input_type: str, output_type: str, state_type: str, **kwargs) -> \"Bolt\": \"\"\" Create a bolt of a specific type. This static method is used to create a bolt of a specific type. It takes in an input type, an output type, a state type, and additional keyword arguments for initializing the bolt. The method creates the input config, output config, and state manager based on the provided types, and then creates and returns a bolt using these configurations. Args: klass (type): The Bolt class to create. input_type (str): The type of input config (\"batch\" or \"streaming\"). output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the bolt. Keyword Arguments: Batch input config: - input_folder (str): The input folder argument. - input_s3_bucket (str): The input bucket argument. - input_s3_folder (str): The input S3 folder argument. Batch outupt config: - output_folder (str): The output folder argument. - output_s3_bucket (str): The output bucket argument. - output_s3_folder (str): The output S3 folder argument. Streaming input config: - input_kafka_cluster_connection_string (str): The input Kafka servers argument. - input_kafka_topic (str): The input kafka topic argument. - input_kafka_consumer_group_id (str): The Kafka consumer group id. Streaming output config: - output_kafka_cluster_connection_string (str): The output Kafka servers argument. - output_kafka_topic (str): The output kafka topic argument. Redis state manager config: - redis_host (str): The Redis host argument. - redis_port (str): The Redis port argument. - redis_db (str): The Redis database argument. Postgres state manager config: - postgres_host (str): The PostgreSQL host argument. - postgres_port (str): The PostgreSQL port argument. - postgres_user (str): The PostgreSQL user argument. - postgres_password (str): The PostgreSQL password argument. - postgres_database (str): The PostgreSQL database argument. - postgres_table (str): The PostgreSQL table argument. DynamoDB state manager config: - dynamodb_table_name (str): The DynamoDB table name argument. - dynamodb_region_name (str): The DynamoDB region name argument. Returns: Bolt: The created bolt. Raises: ValueError: If an invalid input type, output type, or state type is provided. \"\"\" # Create the input config input_config: BatchInputConfig | StreamingInputConfig if input_type == \"batch\": input_config = BatchInputConfig( input_folder=kwargs[\"input_folder\"] if \"input_folder\" in kwargs else tempfile.mkdtemp(), bucket=kwargs[\"input_s3_bucket\"] if \"input_s3_bucket\" in kwargs else None, s3_folder=kwargs[\"input_s3_folder\"] if \"input_s3_folder\" in kwargs else None, ) elif input_type == \"streaming\": input_config = StreamingInputConfig( input_topic=kwargs[\"input_kafka_topic\"] if \"input_kafka_topic\" in kwargs else None, kafka_cluster_connection_string=kwargs[\"input_kafka_cluster_connection_string\"] if \"input_kafka_cluster_connection_string\" in kwargs else None, group_id=kwargs[\"input_kafka_consumer_group_id\"] if \"input_kafka_consumer_group_id\" in kwargs else None, ) else: raise ValueError(f\"Invalid input type: {input_type}\") # Create the output config output_config: BatchOutputConfig | StreamingOutputConfig if output_type == \"batch\": output_config = BatchOutputConfig( output_folder=kwargs[\"output_folder\"] if \"output_folder\" in kwargs else tempfile.mkdtemp(), bucket=kwargs[\"output_s3_bucket\"] if \"output_s3_bucket\" in kwargs else tempfile.mkdtemp(), s3_folder=kwargs[\"output_s3_folder\"] if \"output_s3_folder\" in kwargs else tempfile.mkdtemp(), ) elif output_type == \"streaming\": output_config = StreamingOutputConfig( kwargs[\"output_kafka_topic\"] if \"output_kafka_topic\" in kwargs else None, kwargs[\"output_kafka_cluster_connection_string\"] if \"output_kafka_cluster_connection_string\" in kwargs else None, ) else: raise ValueError(f\"Invalid output type: {output_type}\") # Create the state manager state_manager: StateManager if state_type == \"in_memory\": state_manager = InMemoryStateManager() elif state_type == \"redis\": state_manager = RedisStateManager( host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None, port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None, db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None, ) elif state_type == \"postgres\": state_manager = PostgresStateManager( host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None, port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None, user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None, password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None, database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None, table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None, ) elif state_type == \"dynamodb\": state_manager = DynamoDBStateManager( table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None, region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None, ) else: raise ValueError(f\"Invalid state type: {state_type}\") # Create the bolt bolt = klass(input_config=input_config, output_config=output_config, state_manager=state_manager, **kwargs) return bolt","title":"create()"},{"location":"core/core_data_batch_input/","text":"BatchInputConfig Bases: InputConfig Class for managing batch input configurations. Attributes: Name Type Description input_folder str Folder to read input files. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py class BatchInputConfig(InputConfig): \"\"\" Class for managing batch input configurations. Attributes: input_folder (str): Folder to read input files. \"\"\" def __init__(self, input_folder: str, bucket: str, s3_folder: str): \"\"\" Initialize a new batch input configuration. Args: input_folder (str): Folder to read input files. \"\"\" self.input_folder = input_folder self.bucket = bucket self.s3_folder = s3_folder def get(self): \"\"\" Get the input folder location. Returns: str: The input folder location. \"\"\" if self.input_folder: return self.input_folder else: log.exception(\"No input folder specified.\") raise return None def copy_from_remote(self): \"\"\" Copy contents from a given S3 bucket and location to the input folder. Args: bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" if self.input_folder: s3 = boto3.resource(\"s3\") _bucket = s3.Bucket(self.bucket) prefix = self.s3_folder if self.s3_folder.endswith(\"/\") else self.s3_folder + \"/\" for obj in _bucket.objects.filter(Prefix=prefix): if not os.path.exists(os.path.dirname(f\"{self.input_folder}/{obj.key}\")): os.makedirs(os.path.dirname(f\"{self.input_folder}/{obj.key}\")) _bucket.download_file(obj.key, f\"{self.input_folder}/{obj.key}\") else: log.exception(\"No input folder specified.\") raise def list_files(self): \"\"\" List all files in the input folder. Returns: list: A list of file paths. \"\"\" if self.input_folder: return [ os.path.join(self.input_folder, f) for f in os.listdir(self.input_folder) if os.path.isfile(os.path.join(self.input_folder, f)) ] else: log.exception(\"No input folder specified.\") raise return [] def read_file(self, filename): \"\"\" Read a file from the input folder. Args: filename (str): The name of the file. Returns: str: The contents of the file. \"\"\" if self.input_folder: with open(os.path.join(self.input_folder, filename), \"r\") as file: return file.read() else: log.exception(\"No input folder specified.\") raise return None def delete_file(self, filename): \"\"\" Delete a file from the input folder. Args: filename (str): The name of the file. \"\"\" if self.input_folder: os.remove(os.path.join(self.input_folder, filename)) else: log.exception(\"No input folder specified.\") raise def copy_to_remote(self, filename, bucket, s3_folder): \"\"\" Copy a file from the input folder to an S3 bucket. Args: filename (str): The name of the file. bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" if self.input_folder: s3 = boto3.resource(\"s3\") s3.meta.client.upload_file( os.path.join(self.input_folder, filename), bucket, os.path.join(s3_folder, filename) ) else: log.exception(\"No input folder specified.\") raise __init__(input_folder, bucket, s3_folder) Initialize a new batch input configuration. Parameters: Name Type Description Default input_folder str Folder to read input files. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def __init__(self, input_folder: str, bucket: str, s3_folder: str): \"\"\" Initialize a new batch input configuration. Args: input_folder (str): Folder to read input files. \"\"\" self.input_folder = input_folder self.bucket = bucket self.s3_folder = s3_folder copy_from_remote() Copy contents from a given S3 bucket and location to the input folder. Parameters: Name Type Description Default bucket str The name of the S3 bucket. required s3_folder str The folder in the S3 bucket. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def copy_from_remote(self): \"\"\" Copy contents from a given S3 bucket and location to the input folder. Args: bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" if self.input_folder: s3 = boto3.resource(\"s3\") _bucket = s3.Bucket(self.bucket) prefix = self.s3_folder if self.s3_folder.endswith(\"/\") else self.s3_folder + \"/\" for obj in _bucket.objects.filter(Prefix=prefix): if not os.path.exists(os.path.dirname(f\"{self.input_folder}/{obj.key}\")): os.makedirs(os.path.dirname(f\"{self.input_folder}/{obj.key}\")) _bucket.download_file(obj.key, f\"{self.input_folder}/{obj.key}\") else: log.exception(\"No input folder specified.\") raise copy_to_remote(filename, bucket, s3_folder) Copy a file from the input folder to an S3 bucket. Parameters: Name Type Description Default filename str The name of the file. required bucket str The name of the S3 bucket. required s3_folder str The folder in the S3 bucket. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def copy_to_remote(self, filename, bucket, s3_folder): \"\"\" Copy a file from the input folder to an S3 bucket. Args: filename (str): The name of the file. bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" if self.input_folder: s3 = boto3.resource(\"s3\") s3.meta.client.upload_file( os.path.join(self.input_folder, filename), bucket, os.path.join(s3_folder, filename) ) else: log.exception(\"No input folder specified.\") raise delete_file(filename) Delete a file from the input folder. Parameters: Name Type Description Default filename str The name of the file. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def delete_file(self, filename): \"\"\" Delete a file from the input folder. Args: filename (str): The name of the file. \"\"\" if self.input_folder: os.remove(os.path.join(self.input_folder, filename)) else: log.exception(\"No input folder specified.\") raise get() Get the input folder location. Returns: Name Type Description str The input folder location. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def get(self): \"\"\" Get the input folder location. Returns: str: The input folder location. \"\"\" if self.input_folder: return self.input_folder else: log.exception(\"No input folder specified.\") raise return None list_files() List all files in the input folder. Returns: Name Type Description list A list of file paths. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def list_files(self): \"\"\" List all files in the input folder. Returns: list: A list of file paths. \"\"\" if self.input_folder: return [ os.path.join(self.input_folder, f) for f in os.listdir(self.input_folder) if os.path.isfile(os.path.join(self.input_folder, f)) ] else: log.exception(\"No input folder specified.\") raise return [] read_file(filename) Read a file from the input folder. Parameters: Name Type Description Default filename str The name of the file. required Returns: Name Type Description str The contents of the file. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def read_file(self, filename): \"\"\" Read a file from the input folder. Args: filename (str): The name of the file. Returns: str: The contents of the file. \"\"\" if self.input_folder: with open(os.path.join(self.input_folder, filename), \"r\") as file: return file.read() else: log.exception(\"No input folder specified.\") raise return None","title":"batch_input"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig","text":"Bases: InputConfig Class for managing batch input configurations. Attributes: Name Type Description input_folder str Folder to read input files. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py class BatchInputConfig(InputConfig): \"\"\" Class for managing batch input configurations. Attributes: input_folder (str): Folder to read input files. \"\"\" def __init__(self, input_folder: str, bucket: str, s3_folder: str): \"\"\" Initialize a new batch input configuration. Args: input_folder (str): Folder to read input files. \"\"\" self.input_folder = input_folder self.bucket = bucket self.s3_folder = s3_folder def get(self): \"\"\" Get the input folder location. Returns: str: The input folder location. \"\"\" if self.input_folder: return self.input_folder else: log.exception(\"No input folder specified.\") raise return None def copy_from_remote(self): \"\"\" Copy contents from a given S3 bucket and location to the input folder. Args: bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" if self.input_folder: s3 = boto3.resource(\"s3\") _bucket = s3.Bucket(self.bucket) prefix = self.s3_folder if self.s3_folder.endswith(\"/\") else self.s3_folder + \"/\" for obj in _bucket.objects.filter(Prefix=prefix): if not os.path.exists(os.path.dirname(f\"{self.input_folder}/{obj.key}\")): os.makedirs(os.path.dirname(f\"{self.input_folder}/{obj.key}\")) _bucket.download_file(obj.key, f\"{self.input_folder}/{obj.key}\") else: log.exception(\"No input folder specified.\") raise def list_files(self): \"\"\" List all files in the input folder. Returns: list: A list of file paths. \"\"\" if self.input_folder: return [ os.path.join(self.input_folder, f) for f in os.listdir(self.input_folder) if os.path.isfile(os.path.join(self.input_folder, f)) ] else: log.exception(\"No input folder specified.\") raise return [] def read_file(self, filename): \"\"\" Read a file from the input folder. Args: filename (str): The name of the file. Returns: str: The contents of the file. \"\"\" if self.input_folder: with open(os.path.join(self.input_folder, filename), \"r\") as file: return file.read() else: log.exception(\"No input folder specified.\") raise return None def delete_file(self, filename): \"\"\" Delete a file from the input folder. Args: filename (str): The name of the file. \"\"\" if self.input_folder: os.remove(os.path.join(self.input_folder, filename)) else: log.exception(\"No input folder specified.\") raise def copy_to_remote(self, filename, bucket, s3_folder): \"\"\" Copy a file from the input folder to an S3 bucket. Args: filename (str): The name of the file. bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" if self.input_folder: s3 = boto3.resource(\"s3\") s3.meta.client.upload_file( os.path.join(self.input_folder, filename), bucket, os.path.join(s3_folder, filename) ) else: log.exception(\"No input folder specified.\") raise","title":"BatchInputConfig"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.__init__","text":"Initialize a new batch input configuration. Parameters: Name Type Description Default input_folder str Folder to read input files. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def __init__(self, input_folder: str, bucket: str, s3_folder: str): \"\"\" Initialize a new batch input configuration. Args: input_folder (str): Folder to read input files. \"\"\" self.input_folder = input_folder self.bucket = bucket self.s3_folder = s3_folder","title":"__init__()"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.copy_from_remote","text":"Copy contents from a given S3 bucket and location to the input folder. Parameters: Name Type Description Default bucket str The name of the S3 bucket. required s3_folder str The folder in the S3 bucket. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def copy_from_remote(self): \"\"\" Copy contents from a given S3 bucket and location to the input folder. Args: bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" if self.input_folder: s3 = boto3.resource(\"s3\") _bucket = s3.Bucket(self.bucket) prefix = self.s3_folder if self.s3_folder.endswith(\"/\") else self.s3_folder + \"/\" for obj in _bucket.objects.filter(Prefix=prefix): if not os.path.exists(os.path.dirname(f\"{self.input_folder}/{obj.key}\")): os.makedirs(os.path.dirname(f\"{self.input_folder}/{obj.key}\")) _bucket.download_file(obj.key, f\"{self.input_folder}/{obj.key}\") else: log.exception(\"No input folder specified.\") raise","title":"copy_from_remote()"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.copy_to_remote","text":"Copy a file from the input folder to an S3 bucket. Parameters: Name Type Description Default filename str The name of the file. required bucket str The name of the S3 bucket. required s3_folder str The folder in the S3 bucket. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def copy_to_remote(self, filename, bucket, s3_folder): \"\"\" Copy a file from the input folder to an S3 bucket. Args: filename (str): The name of the file. bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" if self.input_folder: s3 = boto3.resource(\"s3\") s3.meta.client.upload_file( os.path.join(self.input_folder, filename), bucket, os.path.join(s3_folder, filename) ) else: log.exception(\"No input folder specified.\") raise","title":"copy_to_remote()"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.delete_file","text":"Delete a file from the input folder. Parameters: Name Type Description Default filename str The name of the file. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def delete_file(self, filename): \"\"\" Delete a file from the input folder. Args: filename (str): The name of the file. \"\"\" if self.input_folder: os.remove(os.path.join(self.input_folder, filename)) else: log.exception(\"No input folder specified.\") raise","title":"delete_file()"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.get","text":"Get the input folder location. Returns: Name Type Description str The input folder location. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def get(self): \"\"\" Get the input folder location. Returns: str: The input folder location. \"\"\" if self.input_folder: return self.input_folder else: log.exception(\"No input folder specified.\") raise return None","title":"get()"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.list_files","text":"List all files in the input folder. Returns: Name Type Description list A list of file paths. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def list_files(self): \"\"\" List all files in the input folder. Returns: list: A list of file paths. \"\"\" if self.input_folder: return [ os.path.join(self.input_folder, f) for f in os.listdir(self.input_folder) if os.path.isfile(os.path.join(self.input_folder, f)) ] else: log.exception(\"No input folder specified.\") raise return []","title":"list_files()"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.read_file","text":"Read a file from the input folder. Parameters: Name Type Description Default filename str The name of the file. required Returns: Name Type Description str The contents of the file. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py def read_file(self, filename): \"\"\" Read a file from the input folder. Args: filename (str): The name of the file. Returns: str: The contents of the file. \"\"\" if self.input_folder: with open(os.path.join(self.input_folder, filename), \"r\") as file: return file.read() else: log.exception(\"No input folder specified.\") raise return None","title":"read_file()"},{"location":"core/core_data_batch_output/","text":"BatchOutputConfig Bases: OutputConfig Class for managing batch output configurations. Attributes: Name Type Description output_folder str Folder to save output files. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py class BatchOutputConfig(OutputConfig): \"\"\" Class for managing batch output configurations. Attributes: output_folder (str): Folder to save output files. \"\"\" def __init__(self, output_folder: str, bucket: str, s3_folder: str): \"\"\" Initialize a new batch output configuration. Args: output_folder (str): Folder to save output files. \"\"\" self.output_folder = output_folder self.bucket = bucket self.s3_folder = s3_folder def save(self, data: Any, filename: str): \"\"\" Save data to a file in the output folder. Args: data (Any): The data to save. filename (str): The filename to use when saving the data to a file. \"\"\" try: with open(os.path.join(self.output_folder, filename), \"w\") as f: f.write(json.dumps(data)) log.debug(f\"Wrote the data into {self.output_folder}/{filename}.\") except Exception as e: log.exception(f\"Failed to write data to file: {e}\") raise def copy_to_remote(self): \"\"\" Recursively copy all files and directories from the output folder to a given S3 bucket and folder. Args: bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" s3 = boto3.client(\"s3\") try: for root, _, files in os.walk(self.output_folder): for filename in files: local_path = os.path.join(root, filename) relative_path = os.path.relpath(local_path, self.output_folder) s3_key = os.path.join(self.s3_folder, relative_path) s3.upload_file(local_path, self.bucket, s3_key) except Exception as e: log.exception(f\"Failed to copy files to S3: {e}\") raise def flush(self): \"\"\" Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder. \"\"\" # Replace 'bucket' and 's3_folder' with your actual bucket and folder self.copy_to_remote() def list_files(self): \"\"\" List all files in the output folder. Returns: list: The list of files in the output folder. \"\"\" return [ os.path.join(self.output_folder, f) for f in os.listdir(self.output_folder) if os.path.isfile(os.path.join(self.output_folder, f)) ] def read_file(self, filename: str): \"\"\" Read a file from the output folder. Args: filename (str): The name of the file to read. Returns: str: The contents of the file. \"\"\" with open(os.path.join(self.output_folder, filename), \"r\") as f: return f.read() def delete_file(self, filename: str): \"\"\" Delete a file from the output folder. Args: filename (str): The name of the file to delete. \"\"\" os.remove(os.path.join(self.output_folder, filename)) def copy_file_to_remote(self, filename: str): \"\"\" Copy a specific file from the output folder to the S3 bucket. Args: filename (str): The name of the file to copy. \"\"\" s3 = boto3.client(\"s3\") try: s3.upload_file( os.path.join(self.output_folder, filename), self.bucket, os.path.join(self.s3_folder, filename) ) except Exception as e: log.exception(f\"Failed to copy file to S3: {e}\") raise __init__(output_folder, bucket, s3_folder) Initialize a new batch output configuration. Parameters: Name Type Description Default output_folder str Folder to save output files. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def __init__(self, output_folder: str, bucket: str, s3_folder: str): \"\"\" Initialize a new batch output configuration. Args: output_folder (str): Folder to save output files. \"\"\" self.output_folder = output_folder self.bucket = bucket self.s3_folder = s3_folder copy_file_to_remote(filename) Copy a specific file from the output folder to the S3 bucket. Parameters: Name Type Description Default filename str The name of the file to copy. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def copy_file_to_remote(self, filename: str): \"\"\" Copy a specific file from the output folder to the S3 bucket. Args: filename (str): The name of the file to copy. \"\"\" s3 = boto3.client(\"s3\") try: s3.upload_file( os.path.join(self.output_folder, filename), self.bucket, os.path.join(self.s3_folder, filename) ) except Exception as e: log.exception(f\"Failed to copy file to S3: {e}\") raise copy_to_remote() Recursively copy all files and directories from the output folder to a given S3 bucket and folder. Parameters: Name Type Description Default bucket str The name of the S3 bucket. required s3_folder str The folder in the S3 bucket. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def copy_to_remote(self): \"\"\" Recursively copy all files and directories from the output folder to a given S3 bucket and folder. Args: bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" s3 = boto3.client(\"s3\") try: for root, _, files in os.walk(self.output_folder): for filename in files: local_path = os.path.join(root, filename) relative_path = os.path.relpath(local_path, self.output_folder) s3_key = os.path.join(self.s3_folder, relative_path) s3.upload_file(local_path, self.bucket, s3_key) except Exception as e: log.exception(f\"Failed to copy files to S3: {e}\") raise delete_file(filename) Delete a file from the output folder. Parameters: Name Type Description Default filename str The name of the file to delete. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def delete_file(self, filename: str): \"\"\" Delete a file from the output folder. Args: filename (str): The name of the file to delete. \"\"\" os.remove(os.path.join(self.output_folder, filename)) flush() Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def flush(self): \"\"\" Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder. \"\"\" # Replace 'bucket' and 's3_folder' with your actual bucket and folder self.copy_to_remote() list_files() List all files in the output folder. Returns: Name Type Description list The list of files in the output folder. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def list_files(self): \"\"\" List all files in the output folder. Returns: list: The list of files in the output folder. \"\"\" return [ os.path.join(self.output_folder, f) for f in os.listdir(self.output_folder) if os.path.isfile(os.path.join(self.output_folder, f)) ] read_file(filename) Read a file from the output folder. Parameters: Name Type Description Default filename str The name of the file to read. required Returns: Name Type Description str The contents of the file. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def read_file(self, filename: str): \"\"\" Read a file from the output folder. Args: filename (str): The name of the file to read. Returns: str: The contents of the file. \"\"\" with open(os.path.join(self.output_folder, filename), \"r\") as f: return f.read() save(data, filename) Save data to a file in the output folder. Parameters: Name Type Description Default data Any The data to save. required filename str The filename to use when saving the data to a file. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def save(self, data: Any, filename: str): \"\"\" Save data to a file in the output folder. Args: data (Any): The data to save. filename (str): The filename to use when saving the data to a file. \"\"\" try: with open(os.path.join(self.output_folder, filename), \"w\") as f: f.write(json.dumps(data)) log.debug(f\"Wrote the data into {self.output_folder}/{filename}.\") except Exception as e: log.exception(f\"Failed to write data to file: {e}\") raise","title":"batch_output"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig","text":"Bases: OutputConfig Class for managing batch output configurations. Attributes: Name Type Description output_folder str Folder to save output files. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py class BatchOutputConfig(OutputConfig): \"\"\" Class for managing batch output configurations. Attributes: output_folder (str): Folder to save output files. \"\"\" def __init__(self, output_folder: str, bucket: str, s3_folder: str): \"\"\" Initialize a new batch output configuration. Args: output_folder (str): Folder to save output files. \"\"\" self.output_folder = output_folder self.bucket = bucket self.s3_folder = s3_folder def save(self, data: Any, filename: str): \"\"\" Save data to a file in the output folder. Args: data (Any): The data to save. filename (str): The filename to use when saving the data to a file. \"\"\" try: with open(os.path.join(self.output_folder, filename), \"w\") as f: f.write(json.dumps(data)) log.debug(f\"Wrote the data into {self.output_folder}/{filename}.\") except Exception as e: log.exception(f\"Failed to write data to file: {e}\") raise def copy_to_remote(self): \"\"\" Recursively copy all files and directories from the output folder to a given S3 bucket and folder. Args: bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" s3 = boto3.client(\"s3\") try: for root, _, files in os.walk(self.output_folder): for filename in files: local_path = os.path.join(root, filename) relative_path = os.path.relpath(local_path, self.output_folder) s3_key = os.path.join(self.s3_folder, relative_path) s3.upload_file(local_path, self.bucket, s3_key) except Exception as e: log.exception(f\"Failed to copy files to S3: {e}\") raise def flush(self): \"\"\" Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder. \"\"\" # Replace 'bucket' and 's3_folder' with your actual bucket and folder self.copy_to_remote() def list_files(self): \"\"\" List all files in the output folder. Returns: list: The list of files in the output folder. \"\"\" return [ os.path.join(self.output_folder, f) for f in os.listdir(self.output_folder) if os.path.isfile(os.path.join(self.output_folder, f)) ] def read_file(self, filename: str): \"\"\" Read a file from the output folder. Args: filename (str): The name of the file to read. Returns: str: The contents of the file. \"\"\" with open(os.path.join(self.output_folder, filename), \"r\") as f: return f.read() def delete_file(self, filename: str): \"\"\" Delete a file from the output folder. Args: filename (str): The name of the file to delete. \"\"\" os.remove(os.path.join(self.output_folder, filename)) def copy_file_to_remote(self, filename: str): \"\"\" Copy a specific file from the output folder to the S3 bucket. Args: filename (str): The name of the file to copy. \"\"\" s3 = boto3.client(\"s3\") try: s3.upload_file( os.path.join(self.output_folder, filename), self.bucket, os.path.join(self.s3_folder, filename) ) except Exception as e: log.exception(f\"Failed to copy file to S3: {e}\") raise","title":"BatchOutputConfig"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.__init__","text":"Initialize a new batch output configuration. Parameters: Name Type Description Default output_folder str Folder to save output files. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def __init__(self, output_folder: str, bucket: str, s3_folder: str): \"\"\" Initialize a new batch output configuration. Args: output_folder (str): Folder to save output files. \"\"\" self.output_folder = output_folder self.bucket = bucket self.s3_folder = s3_folder","title":"__init__()"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.copy_file_to_remote","text":"Copy a specific file from the output folder to the S3 bucket. Parameters: Name Type Description Default filename str The name of the file to copy. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def copy_file_to_remote(self, filename: str): \"\"\" Copy a specific file from the output folder to the S3 bucket. Args: filename (str): The name of the file to copy. \"\"\" s3 = boto3.client(\"s3\") try: s3.upload_file( os.path.join(self.output_folder, filename), self.bucket, os.path.join(self.s3_folder, filename) ) except Exception as e: log.exception(f\"Failed to copy file to S3: {e}\") raise","title":"copy_file_to_remote()"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.copy_to_remote","text":"Recursively copy all files and directories from the output folder to a given S3 bucket and folder. Parameters: Name Type Description Default bucket str The name of the S3 bucket. required s3_folder str The folder in the S3 bucket. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def copy_to_remote(self): \"\"\" Recursively copy all files and directories from the output folder to a given S3 bucket and folder. Args: bucket (str): The name of the S3 bucket. s3_folder (str): The folder in the S3 bucket. \"\"\" s3 = boto3.client(\"s3\") try: for root, _, files in os.walk(self.output_folder): for filename in files: local_path = os.path.join(root, filename) relative_path = os.path.relpath(local_path, self.output_folder) s3_key = os.path.join(self.s3_folder, relative_path) s3.upload_file(local_path, self.bucket, s3_key) except Exception as e: log.exception(f\"Failed to copy files to S3: {e}\") raise","title":"copy_to_remote()"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.delete_file","text":"Delete a file from the output folder. Parameters: Name Type Description Default filename str The name of the file to delete. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def delete_file(self, filename: str): \"\"\" Delete a file from the output folder. Args: filename (str): The name of the file to delete. \"\"\" os.remove(os.path.join(self.output_folder, filename))","title":"delete_file()"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.flush","text":"Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def flush(self): \"\"\" Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder. \"\"\" # Replace 'bucket' and 's3_folder' with your actual bucket and folder self.copy_to_remote()","title":"flush()"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.list_files","text":"List all files in the output folder. Returns: Name Type Description list The list of files in the output folder. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def list_files(self): \"\"\" List all files in the output folder. Returns: list: The list of files in the output folder. \"\"\" return [ os.path.join(self.output_folder, f) for f in os.listdir(self.output_folder) if os.path.isfile(os.path.join(self.output_folder, f)) ]","title":"list_files()"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.read_file","text":"Read a file from the output folder. Parameters: Name Type Description Default filename str The name of the file to read. required Returns: Name Type Description str The contents of the file. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def read_file(self, filename: str): \"\"\" Read a file from the output folder. Args: filename (str): The name of the file to read. Returns: str: The contents of the file. \"\"\" with open(os.path.join(self.output_folder, filename), \"r\") as f: return f.read()","title":"read_file()"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.save","text":"Save data to a file in the output folder. Parameters: Name Type Description Default data Any The data to save. required filename str The filename to use when saving the data to a file. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py def save(self, data: Any, filename: str): \"\"\" Save data to a file in the output folder. Args: data (Any): The data to save. filename (str): The filename to use when saving the data to a file. \"\"\" try: with open(os.path.join(self.output_folder, filename), \"w\") as f: f.write(json.dumps(data)) log.debug(f\"Wrote the data into {self.output_folder}/{filename}.\") except Exception as e: log.exception(f\"Failed to write data to file: {e}\") raise","title":"save()"},{"location":"core/core_data_input/","text":"InputConfig Bases: ABC Abstract class for managing input configurations. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/input.py class InputConfig(ABC): \"\"\" Abstract class for managing input configurations. \"\"\" @abstractmethod def get(self): \"\"\" Abstract method to get data from the input source. Returns: The data from the input source. \"\"\" pass get() abstractmethod Abstract method to get data from the input source. Returns: Type Description The data from the input source. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/input.py @abstractmethod def get(self): \"\"\" Abstract method to get data from the input source. Returns: The data from the input source. \"\"\" pass","title":"input"},{"location":"core/core_data_input/#core.data.input.InputConfig","text":"Bases: ABC Abstract class for managing input configurations. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/input.py class InputConfig(ABC): \"\"\" Abstract class for managing input configurations. \"\"\" @abstractmethod def get(self): \"\"\" Abstract method to get data from the input source. Returns: The data from the input source. \"\"\" pass","title":"InputConfig"},{"location":"core/core_data_input/#core.data.input.InputConfig.get","text":"Abstract method to get data from the input source. Returns: Type Description The data from the input source. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/input.py @abstractmethod def get(self): \"\"\" Abstract method to get data from the input source. Returns: The data from the input source. \"\"\" pass","title":"get()"},{"location":"core/core_data_output/","text":"OutputConfig Bases: ABC Abstract base class for managing output configurations. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py class OutputConfig(ABC): \"\"\" Abstract base class for managing output configurations. \"\"\" @abstractmethod def save(self, data: Any, filename: str): \"\"\" Save data to a file or ingest it into a Kafka topic. Args: data (Any): The data to save or ingest. filename (str): The filename to use when saving the data to a file. \"\"\" pass @abstractmethod def flush(self): \"\"\" Flush the output. This method should be implemented by subclasses. \"\"\" pass flush() abstractmethod Flush the output. This method should be implemented by subclasses. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py @abstractmethod def flush(self): \"\"\" Flush the output. This method should be implemented by subclasses. \"\"\" pass save(data, filename) abstractmethod Save data to a file or ingest it into a Kafka topic. Parameters: Name Type Description Default data Any The data to save or ingest. required filename str The filename to use when saving the data to a file. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py @abstractmethod def save(self, data: Any, filename: str): \"\"\" Save data to a file or ingest it into a Kafka topic. Args: data (Any): The data to save or ingest. filename (str): The filename to use when saving the data to a file. \"\"\" pass","title":"output"},{"location":"core/core_data_output/#core.data.output.OutputConfig","text":"Bases: ABC Abstract base class for managing output configurations. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py class OutputConfig(ABC): \"\"\" Abstract base class for managing output configurations. \"\"\" @abstractmethod def save(self, data: Any, filename: str): \"\"\" Save data to a file or ingest it into a Kafka topic. Args: data (Any): The data to save or ingest. filename (str): The filename to use when saving the data to a file. \"\"\" pass @abstractmethod def flush(self): \"\"\" Flush the output. This method should be implemented by subclasses. \"\"\" pass","title":"OutputConfig"},{"location":"core/core_data_output/#core.data.output.OutputConfig.flush","text":"Flush the output. This method should be implemented by subclasses. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py @abstractmethod def flush(self): \"\"\" Flush the output. This method should be implemented by subclasses. \"\"\" pass","title":"flush()"},{"location":"core/core_data_output/#core.data.output.OutputConfig.save","text":"Save data to a file or ingest it into a Kafka topic. Parameters: Name Type Description Default data Any The data to save or ingest. required filename str The filename to use when saving the data to a file. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py @abstractmethod def save(self, data: Any, filename: str): \"\"\" Save data to a file or ingest it into a Kafka topic. Args: data (Any): The data to save or ingest. filename (str): The filename to use when saving the data to a file. \"\"\" pass","title":"save()"},{"location":"core/core_data_streaming_input/","text":"StreamingInputConfig Bases: InputConfig Class for managing streaming input configurations. Attributes: Name Type Description input_topic str Kafka topic to consume data. consumer KafkaConsumer Kafka consumer for consuming data. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py class StreamingInputConfig(InputConfig): \"\"\" Class for managing streaming input configurations. Attributes: input_topic (str): Kafka topic to consume data. consumer (KafkaConsumer): Kafka consumer for consuming data. \"\"\" def __init__(self, input_topic: str, kafka_cluster_connection_string: str, group_id: str = \"geniusrise\"): \"\"\" Initialize a new streaming input configuration. Args: input_topic (str): Kafka topic to consume data. kafka_cluster_connection_string (str): Kafka cluster connection string. group_id (str, optional): Kafka consumer group id. Defaults to \"geniusrise\". \"\"\" self.input_topic = input_topic try: self.consumer = KafkaConsumer( self.input_topic, bootstrap_servers=kafka_cluster_connection_string, group_id=group_id ) except Exception as e: log.exception(f\"Failed to create Kafka consumer: {e}\") raise self.consumer = None def get(self): \"\"\" Get data from the input topic. Returns: KafkaConsumer: The Kafka consumer. \"\"\" if self.input_topic and self.consumer: try: return self.consumer except Exception as e: log.exception(f\"Failed to consume from Kafka topic {self.input_topic}: {e}\") raise return None else: log.exception(\"No input source specified.\") raise return None def iterator(self): \"\"\" Iterator method for yielding data from the Kafka consumer. Yields: Kafka message: The next message from the Kafka consumer. \"\"\" if self.consumer: try: for message in self.consumer: yield message except Exception as e: log.exception(f\"Failed to iterate over Kafka consumer: {e}\") raise else: log.exception(\"No Kafka consumer available.\") raise def __iter__(self): \"\"\" Make the class iterable. \"\"\" return self def __next__(self): \"\"\" Get the next message from the Kafka consumer. \"\"\" if self.consumer: try: return next(self.consumer) except StopIteration: raise except Exception as e: log.exception(f\"Failed to get next message from Kafka consumer: {e}\") raise return None else: log.exception(\"No Kafka consumer available.\") raise return None def close(self): \"\"\" Close the Kafka consumer. \"\"\" if self.consumer: try: self.consumer.close() except Exception as e: log.exception(f\"Failed to close Kafka consumer: {e}\") raise def seek(self, partition: int, offset: int): \"\"\" Change the position from which the Kafka consumer reads. \"\"\" if self.consumer: try: self.consumer.seek(partition, offset) except Exception as e: log.exception(f\"Failed to seek Kafka consumer: {e}\") raise def commit(self): \"\"\" Manually commit offsets. \"\"\" if self.consumer: try: self.consumer.commit() except Exception as e: log.exception(f\"Failed to commit offsets: {e}\") raise def filter_messages(self, filter_func: Callable): \"\"\" Filter messages from the Kafka consumer based on a filter function. Args: filter_func (callable): A function that takes a Kafka message and returns a boolean. Yields: Kafka message: The next message from the Kafka consumer that passes the filter. \"\"\" if self.consumer: try: for message in self.consumer: if filter_func(message): yield message except Exception as e: log.exception(f\"Failed to filter messages from Kafka consumer: {e}\") raise else: log.exception(\"No Kafka consumer available.\") raise __init__(input_topic, kafka_cluster_connection_string, group_id='geniusrise') Initialize a new streaming input configuration. Parameters: Name Type Description Default input_topic str Kafka topic to consume data. required kafka_cluster_connection_string str Kafka cluster connection string. required group_id str Kafka consumer group id. Defaults to \"geniusrise\". 'geniusrise' Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def __init__(self, input_topic: str, kafka_cluster_connection_string: str, group_id: str = \"geniusrise\"): \"\"\" Initialize a new streaming input configuration. Args: input_topic (str): Kafka topic to consume data. kafka_cluster_connection_string (str): Kafka cluster connection string. group_id (str, optional): Kafka consumer group id. Defaults to \"geniusrise\". \"\"\" self.input_topic = input_topic try: self.consumer = KafkaConsumer( self.input_topic, bootstrap_servers=kafka_cluster_connection_string, group_id=group_id ) except Exception as e: log.exception(f\"Failed to create Kafka consumer: {e}\") raise self.consumer = None __iter__() Make the class iterable. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def __iter__(self): \"\"\" Make the class iterable. \"\"\" return self __next__() Get the next message from the Kafka consumer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def __next__(self): \"\"\" Get the next message from the Kafka consumer. \"\"\" if self.consumer: try: return next(self.consumer) except StopIteration: raise except Exception as e: log.exception(f\"Failed to get next message from Kafka consumer: {e}\") raise return None else: log.exception(\"No Kafka consumer available.\") raise return None close() Close the Kafka consumer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def close(self): \"\"\" Close the Kafka consumer. \"\"\" if self.consumer: try: self.consumer.close() except Exception as e: log.exception(f\"Failed to close Kafka consumer: {e}\") raise commit() Manually commit offsets. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def commit(self): \"\"\" Manually commit offsets. \"\"\" if self.consumer: try: self.consumer.commit() except Exception as e: log.exception(f\"Failed to commit offsets: {e}\") raise filter_messages(filter_func) Filter messages from the Kafka consumer based on a filter function. Parameters: Name Type Description Default filter_func callable A function that takes a Kafka message and returns a boolean. required Yields: Type Description Kafka message: The next message from the Kafka consumer that passes the filter. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def filter_messages(self, filter_func: Callable): \"\"\" Filter messages from the Kafka consumer based on a filter function. Args: filter_func (callable): A function that takes a Kafka message and returns a boolean. Yields: Kafka message: The next message from the Kafka consumer that passes the filter. \"\"\" if self.consumer: try: for message in self.consumer: if filter_func(message): yield message except Exception as e: log.exception(f\"Failed to filter messages from Kafka consumer: {e}\") raise else: log.exception(\"No Kafka consumer available.\") raise get() Get data from the input topic. Returns: Name Type Description KafkaConsumer The Kafka consumer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def get(self): \"\"\" Get data from the input topic. Returns: KafkaConsumer: The Kafka consumer. \"\"\" if self.input_topic and self.consumer: try: return self.consumer except Exception as e: log.exception(f\"Failed to consume from Kafka topic {self.input_topic}: {e}\") raise return None else: log.exception(\"No input source specified.\") raise return None iterator() Iterator method for yielding data from the Kafka consumer. Yields: Type Description Kafka message: The next message from the Kafka consumer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def iterator(self): \"\"\" Iterator method for yielding data from the Kafka consumer. Yields: Kafka message: The next message from the Kafka consumer. \"\"\" if self.consumer: try: for message in self.consumer: yield message except Exception as e: log.exception(f\"Failed to iterate over Kafka consumer: {e}\") raise else: log.exception(\"No Kafka consumer available.\") raise seek(partition, offset) Change the position from which the Kafka consumer reads. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def seek(self, partition: int, offset: int): \"\"\" Change the position from which the Kafka consumer reads. \"\"\" if self.consumer: try: self.consumer.seek(partition, offset) except Exception as e: log.exception(f\"Failed to seek Kafka consumer: {e}\") raise","title":"streaming_input"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig","text":"Bases: InputConfig Class for managing streaming input configurations. Attributes: Name Type Description input_topic str Kafka topic to consume data. consumer KafkaConsumer Kafka consumer for consuming data. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py class StreamingInputConfig(InputConfig): \"\"\" Class for managing streaming input configurations. Attributes: input_topic (str): Kafka topic to consume data. consumer (KafkaConsumer): Kafka consumer for consuming data. \"\"\" def __init__(self, input_topic: str, kafka_cluster_connection_string: str, group_id: str = \"geniusrise\"): \"\"\" Initialize a new streaming input configuration. Args: input_topic (str): Kafka topic to consume data. kafka_cluster_connection_string (str): Kafka cluster connection string. group_id (str, optional): Kafka consumer group id. Defaults to \"geniusrise\". \"\"\" self.input_topic = input_topic try: self.consumer = KafkaConsumer( self.input_topic, bootstrap_servers=kafka_cluster_connection_string, group_id=group_id ) except Exception as e: log.exception(f\"Failed to create Kafka consumer: {e}\") raise self.consumer = None def get(self): \"\"\" Get data from the input topic. Returns: KafkaConsumer: The Kafka consumer. \"\"\" if self.input_topic and self.consumer: try: return self.consumer except Exception as e: log.exception(f\"Failed to consume from Kafka topic {self.input_topic}: {e}\") raise return None else: log.exception(\"No input source specified.\") raise return None def iterator(self): \"\"\" Iterator method for yielding data from the Kafka consumer. Yields: Kafka message: The next message from the Kafka consumer. \"\"\" if self.consumer: try: for message in self.consumer: yield message except Exception as e: log.exception(f\"Failed to iterate over Kafka consumer: {e}\") raise else: log.exception(\"No Kafka consumer available.\") raise def __iter__(self): \"\"\" Make the class iterable. \"\"\" return self def __next__(self): \"\"\" Get the next message from the Kafka consumer. \"\"\" if self.consumer: try: return next(self.consumer) except StopIteration: raise except Exception as e: log.exception(f\"Failed to get next message from Kafka consumer: {e}\") raise return None else: log.exception(\"No Kafka consumer available.\") raise return None def close(self): \"\"\" Close the Kafka consumer. \"\"\" if self.consumer: try: self.consumer.close() except Exception as e: log.exception(f\"Failed to close Kafka consumer: {e}\") raise def seek(self, partition: int, offset: int): \"\"\" Change the position from which the Kafka consumer reads. \"\"\" if self.consumer: try: self.consumer.seek(partition, offset) except Exception as e: log.exception(f\"Failed to seek Kafka consumer: {e}\") raise def commit(self): \"\"\" Manually commit offsets. \"\"\" if self.consumer: try: self.consumer.commit() except Exception as e: log.exception(f\"Failed to commit offsets: {e}\") raise def filter_messages(self, filter_func: Callable): \"\"\" Filter messages from the Kafka consumer based on a filter function. Args: filter_func (callable): A function that takes a Kafka message and returns a boolean. Yields: Kafka message: The next message from the Kafka consumer that passes the filter. \"\"\" if self.consumer: try: for message in self.consumer: if filter_func(message): yield message except Exception as e: log.exception(f\"Failed to filter messages from Kafka consumer: {e}\") raise else: log.exception(\"No Kafka consumer available.\") raise","title":"StreamingInputConfig"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.__init__","text":"Initialize a new streaming input configuration. Parameters: Name Type Description Default input_topic str Kafka topic to consume data. required kafka_cluster_connection_string str Kafka cluster connection string. required group_id str Kafka consumer group id. Defaults to \"geniusrise\". 'geniusrise' Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def __init__(self, input_topic: str, kafka_cluster_connection_string: str, group_id: str = \"geniusrise\"): \"\"\" Initialize a new streaming input configuration. Args: input_topic (str): Kafka topic to consume data. kafka_cluster_connection_string (str): Kafka cluster connection string. group_id (str, optional): Kafka consumer group id. Defaults to \"geniusrise\". \"\"\" self.input_topic = input_topic try: self.consumer = KafkaConsumer( self.input_topic, bootstrap_servers=kafka_cluster_connection_string, group_id=group_id ) except Exception as e: log.exception(f\"Failed to create Kafka consumer: {e}\") raise self.consumer = None","title":"__init__()"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.__iter__","text":"Make the class iterable. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def __iter__(self): \"\"\" Make the class iterable. \"\"\" return self","title":"__iter__()"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.__next__","text":"Get the next message from the Kafka consumer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def __next__(self): \"\"\" Get the next message from the Kafka consumer. \"\"\" if self.consumer: try: return next(self.consumer) except StopIteration: raise except Exception as e: log.exception(f\"Failed to get next message from Kafka consumer: {e}\") raise return None else: log.exception(\"No Kafka consumer available.\") raise return None","title":"__next__()"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.close","text":"Close the Kafka consumer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def close(self): \"\"\" Close the Kafka consumer. \"\"\" if self.consumer: try: self.consumer.close() except Exception as e: log.exception(f\"Failed to close Kafka consumer: {e}\") raise","title":"close()"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.commit","text":"Manually commit offsets. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def commit(self): \"\"\" Manually commit offsets. \"\"\" if self.consumer: try: self.consumer.commit() except Exception as e: log.exception(f\"Failed to commit offsets: {e}\") raise","title":"commit()"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.filter_messages","text":"Filter messages from the Kafka consumer based on a filter function. Parameters: Name Type Description Default filter_func callable A function that takes a Kafka message and returns a boolean. required Yields: Type Description Kafka message: The next message from the Kafka consumer that passes the filter. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def filter_messages(self, filter_func: Callable): \"\"\" Filter messages from the Kafka consumer based on a filter function. Args: filter_func (callable): A function that takes a Kafka message and returns a boolean. Yields: Kafka message: The next message from the Kafka consumer that passes the filter. \"\"\" if self.consumer: try: for message in self.consumer: if filter_func(message): yield message except Exception as e: log.exception(f\"Failed to filter messages from Kafka consumer: {e}\") raise else: log.exception(\"No Kafka consumer available.\") raise","title":"filter_messages()"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.get","text":"Get data from the input topic. Returns: Name Type Description KafkaConsumer The Kafka consumer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def get(self): \"\"\" Get data from the input topic. Returns: KafkaConsumer: The Kafka consumer. \"\"\" if self.input_topic and self.consumer: try: return self.consumer except Exception as e: log.exception(f\"Failed to consume from Kafka topic {self.input_topic}: {e}\") raise return None else: log.exception(\"No input source specified.\") raise return None","title":"get()"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.iterator","text":"Iterator method for yielding data from the Kafka consumer. Yields: Type Description Kafka message: The next message from the Kafka consumer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def iterator(self): \"\"\" Iterator method for yielding data from the Kafka consumer. Yields: Kafka message: The next message from the Kafka consumer. \"\"\" if self.consumer: try: for message in self.consumer: yield message except Exception as e: log.exception(f\"Failed to iterate over Kafka consumer: {e}\") raise else: log.exception(\"No Kafka consumer available.\") raise","title":"iterator()"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.seek","text":"Change the position from which the Kafka consumer reads. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py def seek(self, partition: int, offset: int): \"\"\" Change the position from which the Kafka consumer reads. \"\"\" if self.consumer: try: self.consumer.seek(partition, offset) except Exception as e: log.exception(f\"Failed to seek Kafka consumer: {e}\") raise","title":"seek()"},{"location":"core/core_data_streaming_output/","text":"StreamingOutputConfig Bases: OutputConfig Class for managing streaming output configurations. Attributes: Name Type Description output_topic str Kafka topic to ingest data. producer KafkaProducer Kafka producer for ingesting data. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py class StreamingOutputConfig(OutputConfig): \"\"\" Class for managing streaming output configurations. Attributes: output_topic (str): Kafka topic to ingest data. producer (KafkaProducer): Kafka producer for ingesting data. \"\"\" def __init__(self, output_topic: str, kafka_servers: str): \"\"\" Initialize a new streaming output configuration. Args: output_topic (str): Kafka topic to ingest data. kafka_servers (str): Kafka bootstrap servers. \"\"\" self.output_topic = output_topic try: self.producer = KafkaProducer(bootstrap_servers=kafka_servers) except Exception as e: log.exception(f\"Failed to create Kafka producer: {e}\") raise self.producer = None def save(self, data: Any, filename: str): \"\"\" Ingest data into the Kafka topic. Args: data (Any): The data to ingest. filename (str): This argument is ignored for streaming outputs. \"\"\" if self.producer: try: self.producer.send(self.output_topic, bytes(json.dumps(data).encode(\"utf-8\"))) log.debug(f\"Inserted the data into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send data to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise def flush(self): \"\"\" Flush the output by flushing the Kafka producer. \"\"\" if self.producer: self.producer.flush() else: log.exception(\"No Kafka producer available.\") raise def send_key_value(self, key: Any, value: Any): \"\"\" Send a message with a key to the Kafka topic. Args: key (Any): The key of the message. value (Any): The value of the message. \"\"\" if self.producer: try: self.producer.send( self.output_topic, key=bytes(json.dumps(key).encode(\"utf-8\")), value=bytes(json.dumps(value).encode(\"utf-8\")), ) log.debug(f\"Inserted the key-value pair into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send key-value pair to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise def close(self): \"\"\" Close the Kafka producer. \"\"\" if self.producer: self.producer.close() self.producer = None else: log.exception(\"No Kafka producer available.\") raise def partition_available(self, partition: int): \"\"\" Check if a partition is available in the Kafka topic. Args: partition (int): The partition to check. Returns: bool: True if the partition is available, False otherwise. \"\"\" if self.producer: return partition in self.producer.partitions_for(self.output_topic) else: log.exception(\"No Kafka producer available.\") raise return False def save_to_partition(self, value: Any, partition: int): \"\"\" Send a message to a specific partition in the Kafka topic. Args: value (Any): The value of the message. partition (int): The partition to send the message to. \"\"\" if self.producer: try: self.producer.send( self.output_topic, value=bytes(json.dumps(value).encode(\"utf-8\")), partition=partition ) log.debug(f\"Inserted the message into partition {partition} of {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send message to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise def save_bulk(self, messages: list): \"\"\" Send multiple messages at once to the Kafka topic. Args: messages (list): The messages to send. \"\"\" if self.producer: try: for message in messages: self.producer.send(self.output_topic, bytes(json.dumps(message).encode(\"utf-8\"))) log.debug(f\"Inserted {len(messages)} messages into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send messages to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise __init__(output_topic, kafka_servers) Initialize a new streaming output configuration. Parameters: Name Type Description Default output_topic str Kafka topic to ingest data. required kafka_servers str Kafka bootstrap servers. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def __init__(self, output_topic: str, kafka_servers: str): \"\"\" Initialize a new streaming output configuration. Args: output_topic (str): Kafka topic to ingest data. kafka_servers (str): Kafka bootstrap servers. \"\"\" self.output_topic = output_topic try: self.producer = KafkaProducer(bootstrap_servers=kafka_servers) except Exception as e: log.exception(f\"Failed to create Kafka producer: {e}\") raise self.producer = None close() Close the Kafka producer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def close(self): \"\"\" Close the Kafka producer. \"\"\" if self.producer: self.producer.close() self.producer = None else: log.exception(\"No Kafka producer available.\") raise flush() Flush the output by flushing the Kafka producer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def flush(self): \"\"\" Flush the output by flushing the Kafka producer. \"\"\" if self.producer: self.producer.flush() else: log.exception(\"No Kafka producer available.\") raise partition_available(partition) Check if a partition is available in the Kafka topic. Parameters: Name Type Description Default partition int The partition to check. required Returns: Name Type Description bool True if the partition is available, False otherwise. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def partition_available(self, partition: int): \"\"\" Check if a partition is available in the Kafka topic. Args: partition (int): The partition to check. Returns: bool: True if the partition is available, False otherwise. \"\"\" if self.producer: return partition in self.producer.partitions_for(self.output_topic) else: log.exception(\"No Kafka producer available.\") raise return False save(data, filename) Ingest data into the Kafka topic. Parameters: Name Type Description Default data Any The data to ingest. required filename str This argument is ignored for streaming outputs. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def save(self, data: Any, filename: str): \"\"\" Ingest data into the Kafka topic. Args: data (Any): The data to ingest. filename (str): This argument is ignored for streaming outputs. \"\"\" if self.producer: try: self.producer.send(self.output_topic, bytes(json.dumps(data).encode(\"utf-8\"))) log.debug(f\"Inserted the data into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send data to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise save_bulk(messages) Send multiple messages at once to the Kafka topic. Parameters: Name Type Description Default messages list The messages to send. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def save_bulk(self, messages: list): \"\"\" Send multiple messages at once to the Kafka topic. Args: messages (list): The messages to send. \"\"\" if self.producer: try: for message in messages: self.producer.send(self.output_topic, bytes(json.dumps(message).encode(\"utf-8\"))) log.debug(f\"Inserted {len(messages)} messages into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send messages to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise save_to_partition(value, partition) Send a message to a specific partition in the Kafka topic. Parameters: Name Type Description Default value Any The value of the message. required partition int The partition to send the message to. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def save_to_partition(self, value: Any, partition: int): \"\"\" Send a message to a specific partition in the Kafka topic. Args: value (Any): The value of the message. partition (int): The partition to send the message to. \"\"\" if self.producer: try: self.producer.send( self.output_topic, value=bytes(json.dumps(value).encode(\"utf-8\")), partition=partition ) log.debug(f\"Inserted the message into partition {partition} of {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send message to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise send_key_value(key, value) Send a message with a key to the Kafka topic. Parameters: Name Type Description Default key Any The key of the message. required value Any The value of the message. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def send_key_value(self, key: Any, value: Any): \"\"\" Send a message with a key to the Kafka topic. Args: key (Any): The key of the message. value (Any): The value of the message. \"\"\" if self.producer: try: self.producer.send( self.output_topic, key=bytes(json.dumps(key).encode(\"utf-8\")), value=bytes(json.dumps(value).encode(\"utf-8\")), ) log.debug(f\"Inserted the key-value pair into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send key-value pair to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise","title":"streaming_output"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig","text":"Bases: OutputConfig Class for managing streaming output configurations. Attributes: Name Type Description output_topic str Kafka topic to ingest data. producer KafkaProducer Kafka producer for ingesting data. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py class StreamingOutputConfig(OutputConfig): \"\"\" Class for managing streaming output configurations. Attributes: output_topic (str): Kafka topic to ingest data. producer (KafkaProducer): Kafka producer for ingesting data. \"\"\" def __init__(self, output_topic: str, kafka_servers: str): \"\"\" Initialize a new streaming output configuration. Args: output_topic (str): Kafka topic to ingest data. kafka_servers (str): Kafka bootstrap servers. \"\"\" self.output_topic = output_topic try: self.producer = KafkaProducer(bootstrap_servers=kafka_servers) except Exception as e: log.exception(f\"Failed to create Kafka producer: {e}\") raise self.producer = None def save(self, data: Any, filename: str): \"\"\" Ingest data into the Kafka topic. Args: data (Any): The data to ingest. filename (str): This argument is ignored for streaming outputs. \"\"\" if self.producer: try: self.producer.send(self.output_topic, bytes(json.dumps(data).encode(\"utf-8\"))) log.debug(f\"Inserted the data into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send data to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise def flush(self): \"\"\" Flush the output by flushing the Kafka producer. \"\"\" if self.producer: self.producer.flush() else: log.exception(\"No Kafka producer available.\") raise def send_key_value(self, key: Any, value: Any): \"\"\" Send a message with a key to the Kafka topic. Args: key (Any): The key of the message. value (Any): The value of the message. \"\"\" if self.producer: try: self.producer.send( self.output_topic, key=bytes(json.dumps(key).encode(\"utf-8\")), value=bytes(json.dumps(value).encode(\"utf-8\")), ) log.debug(f\"Inserted the key-value pair into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send key-value pair to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise def close(self): \"\"\" Close the Kafka producer. \"\"\" if self.producer: self.producer.close() self.producer = None else: log.exception(\"No Kafka producer available.\") raise def partition_available(self, partition: int): \"\"\" Check if a partition is available in the Kafka topic. Args: partition (int): The partition to check. Returns: bool: True if the partition is available, False otherwise. \"\"\" if self.producer: return partition in self.producer.partitions_for(self.output_topic) else: log.exception(\"No Kafka producer available.\") raise return False def save_to_partition(self, value: Any, partition: int): \"\"\" Send a message to a specific partition in the Kafka topic. Args: value (Any): The value of the message. partition (int): The partition to send the message to. \"\"\" if self.producer: try: self.producer.send( self.output_topic, value=bytes(json.dumps(value).encode(\"utf-8\")), partition=partition ) log.debug(f\"Inserted the message into partition {partition} of {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send message to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise def save_bulk(self, messages: list): \"\"\" Send multiple messages at once to the Kafka topic. Args: messages (list): The messages to send. \"\"\" if self.producer: try: for message in messages: self.producer.send(self.output_topic, bytes(json.dumps(message).encode(\"utf-8\"))) log.debug(f\"Inserted {len(messages)} messages into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send messages to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise","title":"StreamingOutputConfig"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.__init__","text":"Initialize a new streaming output configuration. Parameters: Name Type Description Default output_topic str Kafka topic to ingest data. required kafka_servers str Kafka bootstrap servers. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def __init__(self, output_topic: str, kafka_servers: str): \"\"\" Initialize a new streaming output configuration. Args: output_topic (str): Kafka topic to ingest data. kafka_servers (str): Kafka bootstrap servers. \"\"\" self.output_topic = output_topic try: self.producer = KafkaProducer(bootstrap_servers=kafka_servers) except Exception as e: log.exception(f\"Failed to create Kafka producer: {e}\") raise self.producer = None","title":"__init__()"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.close","text":"Close the Kafka producer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def close(self): \"\"\" Close the Kafka producer. \"\"\" if self.producer: self.producer.close() self.producer = None else: log.exception(\"No Kafka producer available.\") raise","title":"close()"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.flush","text":"Flush the output by flushing the Kafka producer. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def flush(self): \"\"\" Flush the output by flushing the Kafka producer. \"\"\" if self.producer: self.producer.flush() else: log.exception(\"No Kafka producer available.\") raise","title":"flush()"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.partition_available","text":"Check if a partition is available in the Kafka topic. Parameters: Name Type Description Default partition int The partition to check. required Returns: Name Type Description bool True if the partition is available, False otherwise. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def partition_available(self, partition: int): \"\"\" Check if a partition is available in the Kafka topic. Args: partition (int): The partition to check. Returns: bool: True if the partition is available, False otherwise. \"\"\" if self.producer: return partition in self.producer.partitions_for(self.output_topic) else: log.exception(\"No Kafka producer available.\") raise return False","title":"partition_available()"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.save","text":"Ingest data into the Kafka topic. Parameters: Name Type Description Default data Any The data to ingest. required filename str This argument is ignored for streaming outputs. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def save(self, data: Any, filename: str): \"\"\" Ingest data into the Kafka topic. Args: data (Any): The data to ingest. filename (str): This argument is ignored for streaming outputs. \"\"\" if self.producer: try: self.producer.send(self.output_topic, bytes(json.dumps(data).encode(\"utf-8\"))) log.debug(f\"Inserted the data into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send data to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise","title":"save()"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.save_bulk","text":"Send multiple messages at once to the Kafka topic. Parameters: Name Type Description Default messages list The messages to send. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def save_bulk(self, messages: list): \"\"\" Send multiple messages at once to the Kafka topic. Args: messages (list): The messages to send. \"\"\" if self.producer: try: for message in messages: self.producer.send(self.output_topic, bytes(json.dumps(message).encode(\"utf-8\"))) log.debug(f\"Inserted {len(messages)} messages into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send messages to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise","title":"save_bulk()"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.save_to_partition","text":"Send a message to a specific partition in the Kafka topic. Parameters: Name Type Description Default value Any The value of the message. required partition int The partition to send the message to. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def save_to_partition(self, value: Any, partition: int): \"\"\" Send a message to a specific partition in the Kafka topic. Args: value (Any): The value of the message. partition (int): The partition to send the message to. \"\"\" if self.producer: try: self.producer.send( self.output_topic, value=bytes(json.dumps(value).encode(\"utf-8\")), partition=partition ) log.debug(f\"Inserted the message into partition {partition} of {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send message to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise","title":"save_to_partition()"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.send_key_value","text":"Send a message with a key to the Kafka topic. Parameters: Name Type Description Default key Any The key of the message. required value Any The value of the message. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py def send_key_value(self, key: Any, value: Any): \"\"\" Send a message with a key to the Kafka topic. Args: key (Any): The key of the message. value (Any): The value of the message. \"\"\" if self.producer: try: self.producer.send( self.output_topic, key=bytes(json.dumps(key).encode(\"utf-8\")), value=bytes(json.dumps(value).encode(\"utf-8\")), ) log.debug(f\"Inserted the key-value pair into {self.output_topic} topic.\") except Exception as e: log.exception(f\"Failed to send key-value pair to Kafka topic: {e}\") raise else: log.exception(\"No Kafka producer available.\") raise","title":"send_key_value()"},{"location":"core/core_spout/","text":"Spout Bases: Task Base class for all spouts. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py class Spout(Task): \"\"\" Base class for all spouts. \"\"\" def __init__(self, output_config: OutputConfig, state_manager: StateManager, **kwargs) -> None: \"\"\" The `Spout` class is a base class for all spouts in the given context. It inherits from the `Task` class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and output configurations for batch or streaming data. The `Spout` class uses the `OutputConfig` and `StateManager` classes, which are abstract base classes for managing output configurations and states, respectively. The `OutputConfig` class has two subclasses: `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and batch output configurations, respectively. The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers. The `Spout` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage: - Create an instance of the Spout class by providing an OutputConfig object and a StateManager object. - The OutputConfig object specifies the output configuration for the spout. - The StateManager object handles the management of the spout's state. Example: output_config = OutputConfig(...) state_manager = StateManager(...) spout = Spout(output_config, state_manager) Args: output_config (OutputConfig): The output configuration. state_manager (StateManager): The state manager. \"\"\" super().__init__() self.output_config = output_config self.state_manager = state_manager self.log = logging.getLogger(self.__class__.__name__) def __call__(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a method locally and manage the state. Args: method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. Returns: Any: The result of the method. \"\"\" try: # Get the type of state manager state_type = self.state_manager.get_state(self.id) # Save the current set of class variables to the state manager self.state_manager.set_state(self.id, {}) # Execute the task's method result = self.execute(method_name, *args, **kwargs) # Flush the output config self.output_config.flush() # Store the state as successful in the state manager state = {} state[\"status\"] = \"success\" self.state_manager.set_state(self.id, state) return result except Exception as e: state = {} state[\"status\"] = \"failed\" self.state_manager.set_state(self.id, state) self.log.exception(f\"Failed to execute method '{method_name}': {e}\") raise @staticmethod def create(klass: type, output_type: str, state_type: str, **kwargs) -> \"Spout\": \"\"\" Create a spout of a specific type. Args: klass (type): The Spout class to create. output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The host address for the Redis server. - redis_port (int): The port number for the Redis server. - redis_db (int): The Redis database to be used. Postgres state manager config: - postgres_host (str): The host address for the PostgreSQL server. - postgres_port (int): The port number for the PostgreSQL server. - postgres_user (str): The username for the PostgreSQL server. - postgres_password (str): The password for the PostgreSQL server. - postgres_database (str): The PostgreSQL database to be used. - postgres_table (str): The PostgreSQL table to be used. DynamoDB state manager config: - dynamodb_table_name (str): The name of the DynamoDB table. - dynamodb_region_name (str): The AWS region for DynamoDB. Returns: Spout: The created spout. Raises: ValueError: If an invalid output type or state type is provided. \"\"\" # Create the output config output_config: BatchOutputConfig | StreamingOutputConfig if output_type == \"batch\": output_config = BatchOutputConfig( output_folder=kwargs.get(\"output_folder\", tempfile.mkdtemp()), bucket=kwargs.get(\"output_s3_bucket\", \"geniusrise\"), s3_folder=kwargs.get(\"output_s3_folder\", klass.__class__.__name__), ) elif output_type == \"streaming\": output_config = StreamingOutputConfig( output_topic=kwargs.get(\"output_kafka_topic\", None), kafka_servers=kwargs.get(\"output_kafka_cluster_connection_string\", None), ) else: raise ValueError(f\"Invalid output type: {output_type}\") # Create the state manager state_manager: StateManager if state_type == \"in_memory\": state_manager = InMemoryStateManager() elif state_type == \"redis\": state_manager = RedisStateManager( host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None, port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None, db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None, ) elif state_type == \"postgres\": state_manager = PostgresStateManager( host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None, port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None, user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None, password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None, database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None, table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None, ) elif state_type == \"dynamodb\": state_manager = DynamoDBStateManager( table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None, region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None, ) else: raise ValueError(f\"Invalid state type: {state_type}\") # Create the spout spout = klass(output_config=output_config, state_manager=state_manager, **kwargs) return spout __call__(method_name, *args, **kwargs) Execute a method locally and manage the state. Parameters: Name Type Description Default method_name str The name of the method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. {} Returns: Name Type Description Any Any The result of the method. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py def __call__(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a method locally and manage the state. Args: method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. Returns: Any: The result of the method. \"\"\" try: # Get the type of state manager state_type = self.state_manager.get_state(self.id) # Save the current set of class variables to the state manager self.state_manager.set_state(self.id, {}) # Execute the task's method result = self.execute(method_name, *args, **kwargs) # Flush the output config self.output_config.flush() # Store the state as successful in the state manager state = {} state[\"status\"] = \"success\" self.state_manager.set_state(self.id, state) return result except Exception as e: state = {} state[\"status\"] = \"failed\" self.state_manager.set_state(self.id, state) self.log.exception(f\"Failed to execute method '{method_name}': {e}\") raise __init__(output_config, state_manager, **kwargs) The Spout class is a base class for all spouts in the given context. It inherits from the Task class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and output configurations for batch or streaming data. The Spout class uses the OutputConfig and StateManager classes, which are abstract base classes for managing output configurations and states, respectively. The OutputConfig class has two subclasses: StreamingOutputConfig and BatchOutputConfig , which manage streaming and batch output configurations, respectively. The StateManager class is used to get and set state, and it has several subclasses for different types of state managers. The Spout class also uses the ECSManager and K8sManager classes in the execute_remote method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage Create an instance of the Spout class by providing an OutputConfig object and a StateManager object. The OutputConfig object specifies the output configuration for the spout. The StateManager object handles the management of the spout's state. Example output_config = OutputConfig(...) state_manager = StateManager(...) spout = Spout(output_config, state_manager) Parameters: Name Type Description Default output_config OutputConfig The output configuration. required state_manager StateManager The state manager. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py def __init__(self, output_config: OutputConfig, state_manager: StateManager, **kwargs) -> None: \"\"\" The `Spout` class is a base class for all spouts in the given context. It inherits from the `Task` class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and output configurations for batch or streaming data. The `Spout` class uses the `OutputConfig` and `StateManager` classes, which are abstract base classes for managing output configurations and states, respectively. The `OutputConfig` class has two subclasses: `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and batch output configurations, respectively. The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers. The `Spout` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage: - Create an instance of the Spout class by providing an OutputConfig object and a StateManager object. - The OutputConfig object specifies the output configuration for the spout. - The StateManager object handles the management of the spout's state. Example: output_config = OutputConfig(...) state_manager = StateManager(...) spout = Spout(output_config, state_manager) Args: output_config (OutputConfig): The output configuration. state_manager (StateManager): The state manager. \"\"\" super().__init__() self.output_config = output_config self.state_manager = state_manager self.log = logging.getLogger(self.__class__.__name__) create(klass, output_type, state_type, **kwargs) staticmethod Create a spout of a specific type. Parameters: Name Type Description Default klass type The Spout class to create. required output_type str The type of output config (\"batch\" or \"streaming\"). required state_type str The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). required **kwargs Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The host address for the Redis server. - redis_port (int): The port number for the Redis server. - redis_db (int): The Redis database to be used. Postgres state manager config: - postgres_host (str): The host address for the PostgreSQL server. - postgres_port (int): The port number for the PostgreSQL server. - postgres_user (str): The username for the PostgreSQL server. - postgres_password (str): The password for the PostgreSQL server. - postgres_database (str): The PostgreSQL database to be used. - postgres_table (str): The PostgreSQL table to be used. DynamoDB state manager config: - dynamodb_table_name (str): The name of the DynamoDB table. - dynamodb_region_name (str): The AWS region for DynamoDB. {} Returns: Name Type Description Spout Spout The created spout. Raises: Type Description ValueError If an invalid output type or state type is provided. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py @staticmethod def create(klass: type, output_type: str, state_type: str, **kwargs) -> \"Spout\": \"\"\" Create a spout of a specific type. Args: klass (type): The Spout class to create. output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The host address for the Redis server. - redis_port (int): The port number for the Redis server. - redis_db (int): The Redis database to be used. Postgres state manager config: - postgres_host (str): The host address for the PostgreSQL server. - postgres_port (int): The port number for the PostgreSQL server. - postgres_user (str): The username for the PostgreSQL server. - postgres_password (str): The password for the PostgreSQL server. - postgres_database (str): The PostgreSQL database to be used. - postgres_table (str): The PostgreSQL table to be used. DynamoDB state manager config: - dynamodb_table_name (str): The name of the DynamoDB table. - dynamodb_region_name (str): The AWS region for DynamoDB. Returns: Spout: The created spout. Raises: ValueError: If an invalid output type or state type is provided. \"\"\" # Create the output config output_config: BatchOutputConfig | StreamingOutputConfig if output_type == \"batch\": output_config = BatchOutputConfig( output_folder=kwargs.get(\"output_folder\", tempfile.mkdtemp()), bucket=kwargs.get(\"output_s3_bucket\", \"geniusrise\"), s3_folder=kwargs.get(\"output_s3_folder\", klass.__class__.__name__), ) elif output_type == \"streaming\": output_config = StreamingOutputConfig( output_topic=kwargs.get(\"output_kafka_topic\", None), kafka_servers=kwargs.get(\"output_kafka_cluster_connection_string\", None), ) else: raise ValueError(f\"Invalid output type: {output_type}\") # Create the state manager state_manager: StateManager if state_type == \"in_memory\": state_manager = InMemoryStateManager() elif state_type == \"redis\": state_manager = RedisStateManager( host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None, port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None, db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None, ) elif state_type == \"postgres\": state_manager = PostgresStateManager( host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None, port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None, user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None, password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None, database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None, table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None, ) elif state_type == \"dynamodb\": state_manager = DynamoDBStateManager( table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None, region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None, ) else: raise ValueError(f\"Invalid state type: {state_type}\") # Create the spout spout = klass(output_config=output_config, state_manager=state_manager, **kwargs) return spout","title":"spout"},{"location":"core/core_spout/#core.spout.Spout","text":"Bases: Task Base class for all spouts. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py class Spout(Task): \"\"\" Base class for all spouts. \"\"\" def __init__(self, output_config: OutputConfig, state_manager: StateManager, **kwargs) -> None: \"\"\" The `Spout` class is a base class for all spouts in the given context. It inherits from the `Task` class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and output configurations for batch or streaming data. The `Spout` class uses the `OutputConfig` and `StateManager` classes, which are abstract base classes for managing output configurations and states, respectively. The `OutputConfig` class has two subclasses: `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and batch output configurations, respectively. The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers. The `Spout` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage: - Create an instance of the Spout class by providing an OutputConfig object and a StateManager object. - The OutputConfig object specifies the output configuration for the spout. - The StateManager object handles the management of the spout's state. Example: output_config = OutputConfig(...) state_manager = StateManager(...) spout = Spout(output_config, state_manager) Args: output_config (OutputConfig): The output configuration. state_manager (StateManager): The state manager. \"\"\" super().__init__() self.output_config = output_config self.state_manager = state_manager self.log = logging.getLogger(self.__class__.__name__) def __call__(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a method locally and manage the state. Args: method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. Returns: Any: The result of the method. \"\"\" try: # Get the type of state manager state_type = self.state_manager.get_state(self.id) # Save the current set of class variables to the state manager self.state_manager.set_state(self.id, {}) # Execute the task's method result = self.execute(method_name, *args, **kwargs) # Flush the output config self.output_config.flush() # Store the state as successful in the state manager state = {} state[\"status\"] = \"success\" self.state_manager.set_state(self.id, state) return result except Exception as e: state = {} state[\"status\"] = \"failed\" self.state_manager.set_state(self.id, state) self.log.exception(f\"Failed to execute method '{method_name}': {e}\") raise @staticmethod def create(klass: type, output_type: str, state_type: str, **kwargs) -> \"Spout\": \"\"\" Create a spout of a specific type. Args: klass (type): The Spout class to create. output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The host address for the Redis server. - redis_port (int): The port number for the Redis server. - redis_db (int): The Redis database to be used. Postgres state manager config: - postgres_host (str): The host address for the PostgreSQL server. - postgres_port (int): The port number for the PostgreSQL server. - postgres_user (str): The username for the PostgreSQL server. - postgres_password (str): The password for the PostgreSQL server. - postgres_database (str): The PostgreSQL database to be used. - postgres_table (str): The PostgreSQL table to be used. DynamoDB state manager config: - dynamodb_table_name (str): The name of the DynamoDB table. - dynamodb_region_name (str): The AWS region for DynamoDB. Returns: Spout: The created spout. Raises: ValueError: If an invalid output type or state type is provided. \"\"\" # Create the output config output_config: BatchOutputConfig | StreamingOutputConfig if output_type == \"batch\": output_config = BatchOutputConfig( output_folder=kwargs.get(\"output_folder\", tempfile.mkdtemp()), bucket=kwargs.get(\"output_s3_bucket\", \"geniusrise\"), s3_folder=kwargs.get(\"output_s3_folder\", klass.__class__.__name__), ) elif output_type == \"streaming\": output_config = StreamingOutputConfig( output_topic=kwargs.get(\"output_kafka_topic\", None), kafka_servers=kwargs.get(\"output_kafka_cluster_connection_string\", None), ) else: raise ValueError(f\"Invalid output type: {output_type}\") # Create the state manager state_manager: StateManager if state_type == \"in_memory\": state_manager = InMemoryStateManager() elif state_type == \"redis\": state_manager = RedisStateManager( host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None, port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None, db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None, ) elif state_type == \"postgres\": state_manager = PostgresStateManager( host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None, port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None, user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None, password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None, database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None, table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None, ) elif state_type == \"dynamodb\": state_manager = DynamoDBStateManager( table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None, region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None, ) else: raise ValueError(f\"Invalid state type: {state_type}\") # Create the spout spout = klass(output_config=output_config, state_manager=state_manager, **kwargs) return spout","title":"Spout"},{"location":"core/core_spout/#core.spout.Spout.__call__","text":"Execute a method locally and manage the state. Parameters: Name Type Description Default method_name str The name of the method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. {} Returns: Name Type Description Any Any The result of the method. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py def __call__(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a method locally and manage the state. Args: method_name (str): The name of the method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Keyword Arguments: - Additional keyword arguments specific to the method. Returns: Any: The result of the method. \"\"\" try: # Get the type of state manager state_type = self.state_manager.get_state(self.id) # Save the current set of class variables to the state manager self.state_manager.set_state(self.id, {}) # Execute the task's method result = self.execute(method_name, *args, **kwargs) # Flush the output config self.output_config.flush() # Store the state as successful in the state manager state = {} state[\"status\"] = \"success\" self.state_manager.set_state(self.id, state) return result except Exception as e: state = {} state[\"status\"] = \"failed\" self.state_manager.set_state(self.id, state) self.log.exception(f\"Failed to execute method '{method_name}': {e}\") raise","title":"__call__()"},{"location":"core/core_spout/#core.spout.Spout.__init__","text":"The Spout class is a base class for all spouts in the given context. It inherits from the Task class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and output configurations for batch or streaming data. The Spout class uses the OutputConfig and StateManager classes, which are abstract base classes for managing output configurations and states, respectively. The OutputConfig class has two subclasses: StreamingOutputConfig and BatchOutputConfig , which manage streaming and batch output configurations, respectively. The StateManager class is used to get and set state, and it has several subclasses for different types of state managers. The Spout class also uses the ECSManager and K8sManager classes in the execute_remote method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage Create an instance of the Spout class by providing an OutputConfig object and a StateManager object. The OutputConfig object specifies the output configuration for the spout. The StateManager object handles the management of the spout's state. Example output_config = OutputConfig(...) state_manager = StateManager(...) spout = Spout(output_config, state_manager) Parameters: Name Type Description Default output_config OutputConfig The output configuration. required state_manager StateManager The state manager. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py def __init__(self, output_config: OutputConfig, state_manager: StateManager, **kwargs) -> None: \"\"\" The `Spout` class is a base class for all spouts in the given context. It inherits from the `Task` class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and output configurations for batch or streaming data. The `Spout` class uses the `OutputConfig` and `StateManager` classes, which are abstract base classes for managing output configurations and states, respectively. The `OutputConfig` class has two subclasses: `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and batch output configurations, respectively. The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers. The `Spout` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively. Usage: - Create an instance of the Spout class by providing an OutputConfig object and a StateManager object. - The OutputConfig object specifies the output configuration for the spout. - The StateManager object handles the management of the spout's state. Example: output_config = OutputConfig(...) state_manager = StateManager(...) spout = Spout(output_config, state_manager) Args: output_config (OutputConfig): The output configuration. state_manager (StateManager): The state manager. \"\"\" super().__init__() self.output_config = output_config self.state_manager = state_manager self.log = logging.getLogger(self.__class__.__name__)","title":"__init__()"},{"location":"core/core_spout/#core.spout.Spout.create","text":"Create a spout of a specific type. Parameters: Name Type Description Default klass type The Spout class to create. required output_type str The type of output config (\"batch\" or \"streaming\"). required state_type str The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). required **kwargs Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The host address for the Redis server. - redis_port (int): The port number for the Redis server. - redis_db (int): The Redis database to be used. Postgres state manager config: - postgres_host (str): The host address for the PostgreSQL server. - postgres_port (int): The port number for the PostgreSQL server. - postgres_user (str): The username for the PostgreSQL server. - postgres_password (str): The password for the PostgreSQL server. - postgres_database (str): The PostgreSQL database to be used. - postgres_table (str): The PostgreSQL table to be used. DynamoDB state manager config: - dynamodb_table_name (str): The name of the DynamoDB table. - dynamodb_region_name (str): The AWS region for DynamoDB. {} Returns: Name Type Description Spout Spout The created spout. Raises: Type Description ValueError If an invalid output type or state type is provided. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py @staticmethod def create(klass: type, output_type: str, state_type: str, **kwargs) -> \"Spout\": \"\"\" Create a spout of a specific type. Args: klass (type): The Spout class to create. output_type (str): The type of output config (\"batch\" or \"streaming\"). state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\"). **kwargs: Additional keyword arguments for initializing the spout. Keyword Arguments: Batch output config: - output_folder (str): The directory where output files should be stored temporarily. - output_s3_bucket (str): The name of the S3 bucket for output storage. - output_s3_folder (str): The S3 folder for output storage. Streaming output config: - output_kafka_topic (str): Kafka output topic for streaming spouts. - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts. Redis state manager config: - redis_host (str): The host address for the Redis server. - redis_port (int): The port number for the Redis server. - redis_db (int): The Redis database to be used. Postgres state manager config: - postgres_host (str): The host address for the PostgreSQL server. - postgres_port (int): The port number for the PostgreSQL server. - postgres_user (str): The username for the PostgreSQL server. - postgres_password (str): The password for the PostgreSQL server. - postgres_database (str): The PostgreSQL database to be used. - postgres_table (str): The PostgreSQL table to be used. DynamoDB state manager config: - dynamodb_table_name (str): The name of the DynamoDB table. - dynamodb_region_name (str): The AWS region for DynamoDB. Returns: Spout: The created spout. Raises: ValueError: If an invalid output type or state type is provided. \"\"\" # Create the output config output_config: BatchOutputConfig | StreamingOutputConfig if output_type == \"batch\": output_config = BatchOutputConfig( output_folder=kwargs.get(\"output_folder\", tempfile.mkdtemp()), bucket=kwargs.get(\"output_s3_bucket\", \"geniusrise\"), s3_folder=kwargs.get(\"output_s3_folder\", klass.__class__.__name__), ) elif output_type == \"streaming\": output_config = StreamingOutputConfig( output_topic=kwargs.get(\"output_kafka_topic\", None), kafka_servers=kwargs.get(\"output_kafka_cluster_connection_string\", None), ) else: raise ValueError(f\"Invalid output type: {output_type}\") # Create the state manager state_manager: StateManager if state_type == \"in_memory\": state_manager = InMemoryStateManager() elif state_type == \"redis\": state_manager = RedisStateManager( host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None, port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None, db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None, ) elif state_type == \"postgres\": state_manager = PostgresStateManager( host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None, port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None, user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None, password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None, database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None, table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None, ) elif state_type == \"dynamodb\": state_manager = DynamoDBStateManager( table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None, region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None, ) else: raise ValueError(f\"Invalid state type: {state_type}\") # Create the spout spout = klass(output_config=output_config, state_manager=state_manager, **kwargs) return spout","title":"create()"},{"location":"core/core_state_base/","text":"StateManager Bases: ABC Abstract base class for a state manager. A state manager is responsible for getting and setting state. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py class StateManager(ABC): \"\"\" Abstract base class for a state manager. A state manager is responsible for getting and setting state. \"\"\" @abstractmethod def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" pass @abstractmethod def set_state(self, key: str, value: Dict): \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" pass get_state(key) abstractmethod Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description Dict Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py @abstractmethod def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" pass set_state(key, value) abstractmethod Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value Dict The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py @abstractmethod def set_state(self, key: str, value: Dict): \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" pass","title":"base"},{"location":"core/core_state_base/#core.state.base.StateManager","text":"Bases: ABC Abstract base class for a state manager. A state manager is responsible for getting and setting state. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py class StateManager(ABC): \"\"\" Abstract base class for a state manager. A state manager is responsible for getting and setting state. \"\"\" @abstractmethod def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" pass @abstractmethod def set_state(self, key: str, value: Dict): \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" pass","title":"StateManager"},{"location":"core/core_state_base/#core.state.base.StateManager.get_state","text":"Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description Dict Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py @abstractmethod def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" pass","title":"get_state()"},{"location":"core/core_state_base/#core.state.base.StateManager.set_state","text":"Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value Dict The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py @abstractmethod def set_state(self, key: str, value: Dict): \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" pass","title":"set_state()"},{"location":"core/core_state_dynamo/","text":"DynamoDBStateManager Bases: StateManager A state manager that stores state in DynamoDB. Attributes: Name Type Description dynamodb boto3 . resources . factory . dynamodb . ServiceResource The DynamoDB service resource. table boto3 . resources . factory . dynamodb . Table The DynamoDB table. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py class DynamoDBStateManager(StateManager): \"\"\" A state manager that stores state in DynamoDB. Attributes: dynamodb (boto3.resources.factory.dynamodb.ServiceResource): The DynamoDB service resource. table (boto3.resources.factory.dynamodb.Table): The DynamoDB table. \"\"\" def __init__(self, table_name: str, region_name: str): \"\"\" Initialize a new DynamoDB state manager. Args: table_name (str): The name of the DynamoDB table. region_name (str): The name of the AWS region. \"\"\" super().__init__() try: self.dynamodb = boto3.resource(\"dynamodb\", region_name=region_name) self.table = self.dynamodb.Table(table_name) except Exception as e: log.exception(f\"Failed to connect to DynamoDB: {e}\") raise self.dynamodb = None self.table = None def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" if self.table: try: response = self.table.get_item(Key={\"id\": key}) return jsonpickle.decode(response[\"Item\"][\"value\"]) if \"Item\" in response else None except Exception as e: log.exception(f\"Failed to get state from DynamoDB: {e}\") raise return None else: log.exception(\"No DynamoDB table.\") raise return None def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" if self.table: try: self.table.put_item(Item={\"id\": key, \"value\": jsonpickle.encode(value)}) except Exception as e: log.exception(f\"Failed to set state in DynamoDB: {e}\") raise else: log.exception(\"No DynamoDB table.\") raise __init__(table_name, region_name) Initialize a new DynamoDB state manager. Parameters: Name Type Description Default table_name str The name of the DynamoDB table. required region_name str The name of the AWS region. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py def __init__(self, table_name: str, region_name: str): \"\"\" Initialize a new DynamoDB state manager. Args: table_name (str): The name of the DynamoDB table. region_name (str): The name of the AWS region. \"\"\" super().__init__() try: self.dynamodb = boto3.resource(\"dynamodb\", region_name=region_name) self.table = self.dynamodb.Table(table_name) except Exception as e: log.exception(f\"Failed to connect to DynamoDB: {e}\") raise self.dynamodb = None self.table = None get_state(key) Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description Dict Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" if self.table: try: response = self.table.get_item(Key={\"id\": key}) return jsonpickle.decode(response[\"Item\"][\"value\"]) if \"Item\" in response else None except Exception as e: log.exception(f\"Failed to get state from DynamoDB: {e}\") raise return None else: log.exception(\"No DynamoDB table.\") raise return None set_state(key, value) Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value Dict The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" if self.table: try: self.table.put_item(Item={\"id\": key, \"value\": jsonpickle.encode(value)}) except Exception as e: log.exception(f\"Failed to set state in DynamoDB: {e}\") raise else: log.exception(\"No DynamoDB table.\") raise","title":"dynamo"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager","text":"Bases: StateManager A state manager that stores state in DynamoDB. Attributes: Name Type Description dynamodb boto3 . resources . factory . dynamodb . ServiceResource The DynamoDB service resource. table boto3 . resources . factory . dynamodb . Table The DynamoDB table. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py class DynamoDBStateManager(StateManager): \"\"\" A state manager that stores state in DynamoDB. Attributes: dynamodb (boto3.resources.factory.dynamodb.ServiceResource): The DynamoDB service resource. table (boto3.resources.factory.dynamodb.Table): The DynamoDB table. \"\"\" def __init__(self, table_name: str, region_name: str): \"\"\" Initialize a new DynamoDB state manager. Args: table_name (str): The name of the DynamoDB table. region_name (str): The name of the AWS region. \"\"\" super().__init__() try: self.dynamodb = boto3.resource(\"dynamodb\", region_name=region_name) self.table = self.dynamodb.Table(table_name) except Exception as e: log.exception(f\"Failed to connect to DynamoDB: {e}\") raise self.dynamodb = None self.table = None def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" if self.table: try: response = self.table.get_item(Key={\"id\": key}) return jsonpickle.decode(response[\"Item\"][\"value\"]) if \"Item\" in response else None except Exception as e: log.exception(f\"Failed to get state from DynamoDB: {e}\") raise return None else: log.exception(\"No DynamoDB table.\") raise return None def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" if self.table: try: self.table.put_item(Item={\"id\": key, \"value\": jsonpickle.encode(value)}) except Exception as e: log.exception(f\"Failed to set state in DynamoDB: {e}\") raise else: log.exception(\"No DynamoDB table.\") raise","title":"DynamoDBStateManager"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager.__init__","text":"Initialize a new DynamoDB state manager. Parameters: Name Type Description Default table_name str The name of the DynamoDB table. required region_name str The name of the AWS region. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py def __init__(self, table_name: str, region_name: str): \"\"\" Initialize a new DynamoDB state manager. Args: table_name (str): The name of the DynamoDB table. region_name (str): The name of the AWS region. \"\"\" super().__init__() try: self.dynamodb = boto3.resource(\"dynamodb\", region_name=region_name) self.table = self.dynamodb.Table(table_name) except Exception as e: log.exception(f\"Failed to connect to DynamoDB: {e}\") raise self.dynamodb = None self.table = None","title":"__init__()"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager.get_state","text":"Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description Dict Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" if self.table: try: response = self.table.get_item(Key={\"id\": key}) return jsonpickle.decode(response[\"Item\"][\"value\"]) if \"Item\" in response else None except Exception as e: log.exception(f\"Failed to get state from DynamoDB: {e}\") raise return None else: log.exception(\"No DynamoDB table.\") raise return None","title":"get_state()"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager.set_state","text":"Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value Dict The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" if self.table: try: self.table.put_item(Item={\"id\": key, \"value\": jsonpickle.encode(value)}) except Exception as e: log.exception(f\"Failed to set state in DynamoDB: {e}\") raise else: log.exception(\"No DynamoDB table.\") raise","title":"set_state()"},{"location":"core/core_state_memory/","text":"InMemoryStateManager Bases: StateManager Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py class InMemoryStateManager(StateManager): store: Dict[str, Dict] \"\"\" A state manager that stores state in memory. \"\"\" def __init__(self): \"\"\" Initialize a new in-memory state manager. \"\"\" self.store = {} def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: str: The state associated with the key. \"\"\" return self.store.get(key) def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (str): The state to set. \"\"\" self.store[key] = value store: Dict[str, Dict] = {} instance-attribute A state manager that stores state in memory. __init__() Initialize a new in-memory state manager. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py def __init__(self): \"\"\" Initialize a new in-memory state manager. \"\"\" self.store = {} get_state(key) Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description str Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: str: The state associated with the key. \"\"\" return self.store.get(key) set_state(key, value) Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value str The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (str): The state to set. \"\"\" self.store[key] = value","title":"memory"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager","text":"Bases: StateManager Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py class InMemoryStateManager(StateManager): store: Dict[str, Dict] \"\"\" A state manager that stores state in memory. \"\"\" def __init__(self): \"\"\" Initialize a new in-memory state manager. \"\"\" self.store = {} def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: str: The state associated with the key. \"\"\" return self.store.get(key) def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (str): The state to set. \"\"\" self.store[key] = value","title":"InMemoryStateManager"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.store","text":"A state manager that stores state in memory.","title":"store"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.__init__","text":"Initialize a new in-memory state manager. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py def __init__(self): \"\"\" Initialize a new in-memory state manager. \"\"\" self.store = {}","title":"__init__()"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.get_state","text":"Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description str Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: str: The state associated with the key. \"\"\" return self.store.get(key)","title":"get_state()"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.set_state","text":"Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value str The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (str): The state to set. \"\"\" self.store[key] = value","title":"set_state()"},{"location":"core/core_state_postgres/","text":"PostgresStateManager Bases: StateManager A state manager that stores state in a PostgreSQL database. Attributes: Name Type Description conn psycopg2 . extensions . connection The PostgreSQL connection. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py class PostgresStateManager(StateManager): \"\"\" A state manager that stores state in a PostgreSQL database. Attributes: conn (psycopg2.extensions.connection): The PostgreSQL connection. \"\"\" def __init__(self, host: str, port: int, user: str, password: str, database: str, table: str = \"geniusrise_state\"): \"\"\" Initialize a new PostgreSQL state manager. Args: host (str): The host of the PostgreSQL server. port (int): The port of the PostgreSQL server. user (str): The user to connect as. password (str): The user's password. database (str): The database to connect to. \"\"\" super().__init__() self.table = table try: self.conn = psycopg2.connect(host=host, port=port, user=user, password=password, database=database) except psycopg2.Error as e: log.exception(f\"Failed to connect to PostgreSQL: {e}\") raise self.conn = None def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" if self.conn: try: with self.conn.cursor() as cur: cur.execute(f\"SELECT value FROM {self.table} WHERE key = '{key}'\") result = cur.fetchone() return jsonpickle.decode(result[0][\"data\"]) if result else None except psycopg2.Error as e: log.exception(f\"Failed to get state from PostgreSQL: {e}\") raise return None else: log.exception(\"No PostgreSQL connection.\") raise return None def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" if self.conn: try: with self.conn.cursor() as cur: data = {\"data\": jsonpickle.encode(value)} cur.execute( f\"\"\" INSERT INTO {self.table} (key, value) VALUES (%s, %s) ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value; \"\"\", (key, json.dumps(data)), ) self.conn.commit() except psycopg2.Error as e: log.exception(f\"Failed to set state in PostgreSQL: {e}\") raise else: log.error(\"No PostgreSQL connection.\") __init__(host, port, user, password, database, table='geniusrise_state') Initialize a new PostgreSQL state manager. Parameters: Name Type Description Default host str The host of the PostgreSQL server. required port int The port of the PostgreSQL server. required user str The user to connect as. required password str The user's password. required database str The database to connect to. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py def __init__(self, host: str, port: int, user: str, password: str, database: str, table: str = \"geniusrise_state\"): \"\"\" Initialize a new PostgreSQL state manager. Args: host (str): The host of the PostgreSQL server. port (int): The port of the PostgreSQL server. user (str): The user to connect as. password (str): The user's password. database (str): The database to connect to. \"\"\" super().__init__() self.table = table try: self.conn = psycopg2.connect(host=host, port=port, user=user, password=password, database=database) except psycopg2.Error as e: log.exception(f\"Failed to connect to PostgreSQL: {e}\") raise self.conn = None get_state(key) Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description Dict Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" if self.conn: try: with self.conn.cursor() as cur: cur.execute(f\"SELECT value FROM {self.table} WHERE key = '{key}'\") result = cur.fetchone() return jsonpickle.decode(result[0][\"data\"]) if result else None except psycopg2.Error as e: log.exception(f\"Failed to get state from PostgreSQL: {e}\") raise return None else: log.exception(\"No PostgreSQL connection.\") raise return None set_state(key, value) Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value Dict The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" if self.conn: try: with self.conn.cursor() as cur: data = {\"data\": jsonpickle.encode(value)} cur.execute( f\"\"\" INSERT INTO {self.table} (key, value) VALUES (%s, %s) ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value; \"\"\", (key, json.dumps(data)), ) self.conn.commit() except psycopg2.Error as e: log.exception(f\"Failed to set state in PostgreSQL: {e}\") raise else: log.error(\"No PostgreSQL connection.\")","title":"postgres"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager","text":"Bases: StateManager A state manager that stores state in a PostgreSQL database. Attributes: Name Type Description conn psycopg2 . extensions . connection The PostgreSQL connection. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py class PostgresStateManager(StateManager): \"\"\" A state manager that stores state in a PostgreSQL database. Attributes: conn (psycopg2.extensions.connection): The PostgreSQL connection. \"\"\" def __init__(self, host: str, port: int, user: str, password: str, database: str, table: str = \"geniusrise_state\"): \"\"\" Initialize a new PostgreSQL state manager. Args: host (str): The host of the PostgreSQL server. port (int): The port of the PostgreSQL server. user (str): The user to connect as. password (str): The user's password. database (str): The database to connect to. \"\"\" super().__init__() self.table = table try: self.conn = psycopg2.connect(host=host, port=port, user=user, password=password, database=database) except psycopg2.Error as e: log.exception(f\"Failed to connect to PostgreSQL: {e}\") raise self.conn = None def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" if self.conn: try: with self.conn.cursor() as cur: cur.execute(f\"SELECT value FROM {self.table} WHERE key = '{key}'\") result = cur.fetchone() return jsonpickle.decode(result[0][\"data\"]) if result else None except psycopg2.Error as e: log.exception(f\"Failed to get state from PostgreSQL: {e}\") raise return None else: log.exception(\"No PostgreSQL connection.\") raise return None def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" if self.conn: try: with self.conn.cursor() as cur: data = {\"data\": jsonpickle.encode(value)} cur.execute( f\"\"\" INSERT INTO {self.table} (key, value) VALUES (%s, %s) ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value; \"\"\", (key, json.dumps(data)), ) self.conn.commit() except psycopg2.Error as e: log.exception(f\"Failed to set state in PostgreSQL: {e}\") raise else: log.error(\"No PostgreSQL connection.\")","title":"PostgresStateManager"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager.__init__","text":"Initialize a new PostgreSQL state manager. Parameters: Name Type Description Default host str The host of the PostgreSQL server. required port int The port of the PostgreSQL server. required user str The user to connect as. required password str The user's password. required database str The database to connect to. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py def __init__(self, host: str, port: int, user: str, password: str, database: str, table: str = \"geniusrise_state\"): \"\"\" Initialize a new PostgreSQL state manager. Args: host (str): The host of the PostgreSQL server. port (int): The port of the PostgreSQL server. user (str): The user to connect as. password (str): The user's password. database (str): The database to connect to. \"\"\" super().__init__() self.table = table try: self.conn = psycopg2.connect(host=host, port=port, user=user, password=password, database=database) except psycopg2.Error as e: log.exception(f\"Failed to connect to PostgreSQL: {e}\") raise self.conn = None","title":"__init__()"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager.get_state","text":"Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description Dict Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" if self.conn: try: with self.conn.cursor() as cur: cur.execute(f\"SELECT value FROM {self.table} WHERE key = '{key}'\") result = cur.fetchone() return jsonpickle.decode(result[0][\"data\"]) if result else None except psycopg2.Error as e: log.exception(f\"Failed to get state from PostgreSQL: {e}\") raise return None else: log.exception(\"No PostgreSQL connection.\") raise return None","title":"get_state()"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager.set_state","text":"Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value Dict The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py def set_state(self, key: str, value: Dict) -> None: \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" if self.conn: try: with self.conn.cursor() as cur: data = {\"data\": jsonpickle.encode(value)} cur.execute( f\"\"\" INSERT INTO {self.table} (key, value) VALUES (%s, %s) ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value; \"\"\", (key, json.dumps(data)), ) self.conn.commit() except psycopg2.Error as e: log.exception(f\"Failed to set state in PostgreSQL: {e}\") raise else: log.error(\"No PostgreSQL connection.\")","title":"set_state()"},{"location":"core/core_state_redis/","text":"RedisStateManager Bases: StateManager A state manager that stores state in Redis. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py class RedisStateManager(StateManager): \"\"\" A state manager that stores state in Redis. \"\"\" def __init__(self, host: str, port: int, db: int): \"\"\" Initialize a new Redis state manager. Args: host (str): The host of the Redis server. port (int): The port of the Redis server. db (int): The database number to connect to. \"\"\" super().__init__() self.redis = redis.Redis(host=host, port=port, db=db) def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" value = self.redis.get(key) if not value: return None else: return jsonpickle.decode(value.decode(\"utf-8\")) def set_state(self, key: str, value: Dict): \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" self.redis.set(key, jsonpickle.encode(value)) __init__(host, port, db) Initialize a new Redis state manager. Parameters: Name Type Description Default host str The host of the Redis server. required port int The port of the Redis server. required db int The database number to connect to. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py def __init__(self, host: str, port: int, db: int): \"\"\" Initialize a new Redis state manager. Args: host (str): The host of the Redis server. port (int): The port of the Redis server. db (int): The database number to connect to. \"\"\" super().__init__() self.redis = redis.Redis(host=host, port=port, db=db) get_state(key) Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description Dict Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" value = self.redis.get(key) if not value: return None else: return jsonpickle.decode(value.decode(\"utf-8\")) set_state(key, value) Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value Dict The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py def set_state(self, key: str, value: Dict): \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" self.redis.set(key, jsonpickle.encode(value))","title":"redis"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager","text":"Bases: StateManager A state manager that stores state in Redis. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py class RedisStateManager(StateManager): \"\"\" A state manager that stores state in Redis. \"\"\" def __init__(self, host: str, port: int, db: int): \"\"\" Initialize a new Redis state manager. Args: host (str): The host of the Redis server. port (int): The port of the Redis server. db (int): The database number to connect to. \"\"\" super().__init__() self.redis = redis.Redis(host=host, port=port, db=db) def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" value = self.redis.get(key) if not value: return None else: return jsonpickle.decode(value.decode(\"utf-8\")) def set_state(self, key: str, value: Dict): \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" self.redis.set(key, jsonpickle.encode(value))","title":"RedisStateManager"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager.__init__","text":"Initialize a new Redis state manager. Parameters: Name Type Description Default host str The host of the Redis server. required port int The port of the Redis server. required db int The database number to connect to. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py def __init__(self, host: str, port: int, db: int): \"\"\" Initialize a new Redis state manager. Args: host (str): The host of the Redis server. port (int): The port of the Redis server. db (int): The database number to connect to. \"\"\" super().__init__() self.redis = redis.Redis(host=host, port=port, db=db)","title":"__init__()"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager.get_state","text":"Get the state associated with a key. Parameters: Name Type Description Default key str The key to get the state for. required Returns: Name Type Description Dict Optional [ Dict ] The state associated with the key. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py def get_state(self, key: str) -> Optional[Dict]: \"\"\" Get the state associated with a key. Args: key (str): The key to get the state for. Returns: Dict: The state associated with the key. \"\"\" value = self.redis.get(key) if not value: return None else: return jsonpickle.decode(value.decode(\"utf-8\"))","title":"get_state()"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager.set_state","text":"Set the state associated with a key. Parameters: Name Type Description Default key str The key to set the state for. required value Dict The state to set. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py def set_state(self, key: str, value: Dict): \"\"\" Set the state associated with a key. Args: key (str): The key to set the state for. value (Dict): The state to set. \"\"\" self.redis.set(key, jsonpickle.encode(value))","title":"set_state()"},{"location":"core/core_task_base/","text":"Task Bases: ABC Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py class Task(ABC): input_config: InputConfig output_config: OutputConfig \"\"\" Class for managing tasks. Attributes: id (uuid.UUID): Unique identifier for the task. input_config (InputConfig): Configuration for input data. output_config (OutputConfig): Configuration for output data. \"\"\" def __init__(self): \"\"\" Initialize a new task. Args: input_config (InputConfig): Configuration for input data. output_config (OutputConfig): Configuration for output data. \"\"\" self.id = str(uuid.uuid4()) def __repr__(self): \"\"\" Return a string representation of the task. Returns: str: A string representation of the task. \"\"\" return f\"Task(id={self.id}, input_config={self.input_config}, output_config={self.output_config})\" def execute(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a given fetch_* method if it exists. Args: method_name (str): The name of the fetch_* method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the fetch_* method, or None if the method does not exist. \"\"\" method = getattr(self, method_name, None) if callable(method): return method(*args, **kwargs) else: raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{method_name}'\") @staticmethod def get_methods(cls) -> List[Tuple[str, List[str], Optional[str]]]: \"\"\" Get all the fetch_* methods and their parameters along with their default values and docstrings. Returns: List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method, a list of its parameters along with their default values, and its docstring. \"\"\" fetch_methods = [] for name, method in inspect.getmembers(cls, predicate=inspect.isfunction): if name.startswith(\"fetch_\"): params = inspect.signature(method).parameters params_str = [ f\"{name}={param.default if param.default is not param.empty else ''}\" for name, param in params.items() ] docstring = inspect.getdoc(method) fetch_methods.append((name, params_str, docstring)) return fetch_methods @staticmethod def print_help(cls): \"\"\" Pretty print the fetch_* methods and their parameters along with their default values and docstrings. Also prints the class's docstring and __init__ parameters. \"\"\" # Print class docstring print(cls.__name__, colored(inspect.getdoc(cls) if inspect.getdoc(cls) else \"\", \"green\")) # Print fetch_* methods fetch_methods = cls.get_methods(cls) if fetch_methods: table = PrettyTable(align=\"l\") table.field_names = [ colored(\"Method\", \"cyan\"), colored(\"Parameters\", \"cyan\"), colored(\"Description\", \"cyan\"), ] for name, params, docstring in fetch_methods: parameters = [_p.replace(\"=\", \"\") for _p in params if \"self\" not in _p] table.add_row([colored(name, \"yellow\"), \"\\n\".join(parameters), docstring], divider=True) print(table) else: print(colored(\"No fetch_* methods found.\", \"red\")) output_config: OutputConfig instance-attribute Class for managing tasks. Attributes: Name Type Description id uuid . UUID Unique identifier for the task. input_config InputConfig Configuration for input data. output_config OutputConfig Configuration for output data. __init__() Initialize a new task. Parameters: Name Type Description Default input_config InputConfig Configuration for input data. required output_config OutputConfig Configuration for output data. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py def __init__(self): \"\"\" Initialize a new task. Args: input_config (InputConfig): Configuration for input data. output_config (OutputConfig): Configuration for output data. \"\"\" self.id = str(uuid.uuid4()) __repr__() Return a string representation of the task. Returns: Name Type Description str A string representation of the task. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py def __repr__(self): \"\"\" Return a string representation of the task. Returns: str: A string representation of the task. \"\"\" return f\"Task(id={self.id}, input_config={self.input_config}, output_config={self.output_config})\" execute(method_name, *args, **kwargs) Execute a given fetch_* method if it exists. Parameters: Name Type Description Default method_name str The name of the fetch_* method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. {} Returns: Name Type Description Any Any The result of the fetch_* method, or None if the method does not exist. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py def execute(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a given fetch_* method if it exists. Args: method_name (str): The name of the fetch_* method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the fetch_* method, or None if the method does not exist. \"\"\" method = getattr(self, method_name, None) if callable(method): return method(*args, **kwargs) else: raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{method_name}'\") get_methods() staticmethod Get all the fetch_* methods and their parameters along with their default values and docstrings. Returns: Type Description List [ Tuple [ str , List [ str ], Optional [ str ]]] List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method, List [ Tuple [ str , List [ str ], Optional [ str ]]] a list of its parameters along with their default values, and its docstring. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py @staticmethod def get_methods(cls) -> List[Tuple[str, List[str], Optional[str]]]: \"\"\" Get all the fetch_* methods and their parameters along with their default values and docstrings. Returns: List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method, a list of its parameters along with their default values, and its docstring. \"\"\" fetch_methods = [] for name, method in inspect.getmembers(cls, predicate=inspect.isfunction): if name.startswith(\"fetch_\"): params = inspect.signature(method).parameters params_str = [ f\"{name}={param.default if param.default is not param.empty else ''}\" for name, param in params.items() ] docstring = inspect.getdoc(method) fetch_methods.append((name, params_str, docstring)) return fetch_methods print_help() staticmethod Pretty print the fetch_* methods and their parameters along with their default values and docstrings. Also prints the class's docstring and init parameters. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py @staticmethod def print_help(cls): \"\"\" Pretty print the fetch_* methods and their parameters along with their default values and docstrings. Also prints the class's docstring and __init__ parameters. \"\"\" # Print class docstring print(cls.__name__, colored(inspect.getdoc(cls) if inspect.getdoc(cls) else \"\", \"green\")) # Print fetch_* methods fetch_methods = cls.get_methods(cls) if fetch_methods: table = PrettyTable(align=\"l\") table.field_names = [ colored(\"Method\", \"cyan\"), colored(\"Parameters\", \"cyan\"), colored(\"Description\", \"cyan\"), ] for name, params, docstring in fetch_methods: parameters = [_p.replace(\"=\", \"\") for _p in params if \"self\" not in _p] table.add_row([colored(name, \"yellow\"), \"\\n\".join(parameters), docstring], divider=True) print(table) else: print(colored(\"No fetch_* methods found.\", \"red\"))","title":"base"},{"location":"core/core_task_base/#core.task.base.Task","text":"Bases: ABC Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py class Task(ABC): input_config: InputConfig output_config: OutputConfig \"\"\" Class for managing tasks. Attributes: id (uuid.UUID): Unique identifier for the task. input_config (InputConfig): Configuration for input data. output_config (OutputConfig): Configuration for output data. \"\"\" def __init__(self): \"\"\" Initialize a new task. Args: input_config (InputConfig): Configuration for input data. output_config (OutputConfig): Configuration for output data. \"\"\" self.id = str(uuid.uuid4()) def __repr__(self): \"\"\" Return a string representation of the task. Returns: str: A string representation of the task. \"\"\" return f\"Task(id={self.id}, input_config={self.input_config}, output_config={self.output_config})\" def execute(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a given fetch_* method if it exists. Args: method_name (str): The name of the fetch_* method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the fetch_* method, or None if the method does not exist. \"\"\" method = getattr(self, method_name, None) if callable(method): return method(*args, **kwargs) else: raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{method_name}'\") @staticmethod def get_methods(cls) -> List[Tuple[str, List[str], Optional[str]]]: \"\"\" Get all the fetch_* methods and their parameters along with their default values and docstrings. Returns: List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method, a list of its parameters along with their default values, and its docstring. \"\"\" fetch_methods = [] for name, method in inspect.getmembers(cls, predicate=inspect.isfunction): if name.startswith(\"fetch_\"): params = inspect.signature(method).parameters params_str = [ f\"{name}={param.default if param.default is not param.empty else ''}\" for name, param in params.items() ] docstring = inspect.getdoc(method) fetch_methods.append((name, params_str, docstring)) return fetch_methods @staticmethod def print_help(cls): \"\"\" Pretty print the fetch_* methods and their parameters along with their default values and docstrings. Also prints the class's docstring and __init__ parameters. \"\"\" # Print class docstring print(cls.__name__, colored(inspect.getdoc(cls) if inspect.getdoc(cls) else \"\", \"green\")) # Print fetch_* methods fetch_methods = cls.get_methods(cls) if fetch_methods: table = PrettyTable(align=\"l\") table.field_names = [ colored(\"Method\", \"cyan\"), colored(\"Parameters\", \"cyan\"), colored(\"Description\", \"cyan\"), ] for name, params, docstring in fetch_methods: parameters = [_p.replace(\"=\", \"\") for _p in params if \"self\" not in _p] table.add_row([colored(name, \"yellow\"), \"\\n\".join(parameters), docstring], divider=True) print(table) else: print(colored(\"No fetch_* methods found.\", \"red\"))","title":"Task"},{"location":"core/core_task_base/#core.task.base.Task.output_config","text":"Class for managing tasks. Attributes: Name Type Description id uuid . UUID Unique identifier for the task. input_config InputConfig Configuration for input data. output_config OutputConfig Configuration for output data.","title":"output_config"},{"location":"core/core_task_base/#core.task.base.Task.__init__","text":"Initialize a new task. Parameters: Name Type Description Default input_config InputConfig Configuration for input data. required output_config OutputConfig Configuration for output data. required Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py def __init__(self): \"\"\" Initialize a new task. Args: input_config (InputConfig): Configuration for input data. output_config (OutputConfig): Configuration for output data. \"\"\" self.id = str(uuid.uuid4())","title":"__init__()"},{"location":"core/core_task_base/#core.task.base.Task.__repr__","text":"Return a string representation of the task. Returns: Name Type Description str A string representation of the task. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py def __repr__(self): \"\"\" Return a string representation of the task. Returns: str: A string representation of the task. \"\"\" return f\"Task(id={self.id}, input_config={self.input_config}, output_config={self.output_config})\"","title":"__repr__()"},{"location":"core/core_task_base/#core.task.base.Task.execute","text":"Execute a given fetch_* method if it exists. Parameters: Name Type Description Default method_name str The name of the fetch_* method to execute. required *args Positional arguments to pass to the method. () **kwargs Keyword arguments to pass to the method. {} Returns: Name Type Description Any Any The result of the fetch_* method, or None if the method does not exist. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py def execute(self, method_name: str, *args, **kwargs) -> Any: \"\"\" Execute a given fetch_* method if it exists. Args: method_name (str): The name of the fetch_* method to execute. *args: Positional arguments to pass to the method. **kwargs: Keyword arguments to pass to the method. Returns: Any: The result of the fetch_* method, or None if the method does not exist. \"\"\" method = getattr(self, method_name, None) if callable(method): return method(*args, **kwargs) else: raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{method_name}'\")","title":"execute()"},{"location":"core/core_task_base/#core.task.base.Task.get_methods","text":"Get all the fetch_* methods and their parameters along with their default values and docstrings. Returns: Type Description List [ Tuple [ str , List [ str ], Optional [ str ]]] List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method, List [ Tuple [ str , List [ str ], Optional [ str ]]] a list of its parameters along with their default values, and its docstring. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py @staticmethod def get_methods(cls) -> List[Tuple[str, List[str], Optional[str]]]: \"\"\" Get all the fetch_* methods and their parameters along with their default values and docstrings. Returns: List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method, a list of its parameters along with their default values, and its docstring. \"\"\" fetch_methods = [] for name, method in inspect.getmembers(cls, predicate=inspect.isfunction): if name.startswith(\"fetch_\"): params = inspect.signature(method).parameters params_str = [ f\"{name}={param.default if param.default is not param.empty else ''}\" for name, param in params.items() ] docstring = inspect.getdoc(method) fetch_methods.append((name, params_str, docstring)) return fetch_methods","title":"get_methods()"},{"location":"core/core_task_base/#core.task.base.Task.print_help","text":"Pretty print the fetch_* methods and their parameters along with their default values and docstrings. Also prints the class's docstring and init parameters. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py @staticmethod def print_help(cls): \"\"\" Pretty print the fetch_* methods and their parameters along with their default values and docstrings. Also prints the class's docstring and __init__ parameters. \"\"\" # Print class docstring print(cls.__name__, colored(inspect.getdoc(cls) if inspect.getdoc(cls) else \"\", \"green\")) # Print fetch_* methods fetch_methods = cls.get_methods(cls) if fetch_methods: table = PrettyTable(align=\"l\") table.field_names = [ colored(\"Method\", \"cyan\"), colored(\"Parameters\", \"cyan\"), colored(\"Description\", \"cyan\"), ] for name, params, docstring in fetch_methods: parameters = [_p.replace(\"=\", \"\") for _p in params if \"self\" not in _p] table.add_row([colored(name, \"yellow\"), \"\\n\".join(parameters), docstring], divider=True) print(table) else: print(colored(\"No fetch_* methods found.\", \"red\"))","title":"print_help()"},{"location":"core/core_task_ecs/","text":"ECSManager A class used to manage the lifecycle of an ECS container. ... Attributes str the name of the ECS task or service List[str] the command that the container runs str the name of the ECS cluster List[str] the subnet IDs for the task or service List[str] the security group IDs for the task or service str the Docker image for the task int the number of task replicas int the port that the container listens on str the CloudWatch log group for the task logs int the CPU value for the task int the memory value for the task Methods create_task_definition() Registers a new task definition from the attributes of this class run_task(task_definition_arn: str) Runs a new task using the specified task definition ARN describe_task(task_definition_arn: str) Describes a task using the specified task definition ARN stop_task(task_definition_arn: str) Stops a running task using the specified task definition ARN update_task(new_image: str, new_command: list) Updates a task with a new Docker image and command create_service(task_definition_arn: str) Creates a new service using the specified task definition ARN update_service(task_definition_arn: str) Updates a service with a new task definition ARN delete_service() Deletes the service Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py class ECSManager: \"\"\" A class used to manage the lifecycle of an ECS container. ... Attributes ---------- name : str the name of the ECS task or service command : List[str] the command that the container runs cluster : str the name of the ECS cluster subnet_ids : List[str] the subnet IDs for the task or service security_group_ids : List[str] the security group IDs for the task or service image : str the Docker image for the task replicas : int the number of task replicas port : int the port that the container listens on log_group : str the CloudWatch log group for the task logs cpu : int the CPU value for the task memory : int the memory value for the task Methods ------- create_task_definition() Registers a new task definition from the attributes of this class run_task(task_definition_arn: str) Runs a new task using the specified task definition ARN describe_task(task_definition_arn: str) Describes a task using the specified task definition ARN stop_task(task_definition_arn: str) Stops a running task using the specified task definition ARN update_task(new_image: str, new_command: list) Updates a task with a new Docker image and command create_service(task_definition_arn: str) Creates a new service using the specified task definition ARN update_service(task_definition_arn: str) Updates a service with a new task definition ARN delete_service() Deletes the service \"\"\" def __init__( self, name: str, account_id: str, cluster: str, command: List[str] = [], subnet_ids: List[str] = [], security_group_ids: List[str] = [], image: str = \"geniusrise/geniusrise\", replicas: int = 1, port: int = 80, log_group: str = \"/ecs/geniusrise\", cpu: int = 256, memory: int = 512, ): \"\"\" Constructs all the necessary attributes for the ECSManager object. Parameters ---------- name : str the name of the ECS task or service account_id : str the id of the AWS account command : List[str] the command that the container runs cluster : str the name of the ECS cluster subnet_ids : List[str] the subnet IDs for the task or service security_group_ids : List[str] the security group IDs for the task or service image : str, optional the Docker image for the task (default is \"geniusrise/geniusrise\") replicas : int, optional the number of task replicas (default is 1) port : int, optional the port that the container listens on (default is 80) log_group : str, optional the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\") cpu : int, optional the CPU value for the task (default is 256) memory : int, optional the memory value for the task (default is 512) \"\"\" self.name = name self.image = image self.cluster = cluster self.command = command self.replicas = replicas self.port = port self.client = boto3.client(\"ecs\") self.log_group = log_group self.logs_client = boto3.client(\"logs\") self.subnet_ids = subnet_ids self.security_group_ids = security_group_ids self.cpu = cpu self.account_id = account_id self.memory = memory def create_task_definition(self) -> Optional[str]: \"\"\" Registers a new task definition from the attributes of this class. Returns ------- str The ARN of the task definition, or None if an error occurred. \"\"\" container_definitions = [ { \"name\": self.name, \"image\": self.image, \"command\": self.command, \"portMappings\": [{\"containerPort\": self.port, \"protocol\": \"tcp\"}], } ] try: response = self.client.register_task_definition( family=self.name, networkMode=\"awsvpc\", containerDefinitions=container_definitions, requiresCompatibilities=[ \"FARGATE\", ], cpu=str(self.cpu), memory=str(self.memory), executionRoleArn=f\"arn:aws:iam::{self.account_id}:role/ecsTaskExecutionRole\", ) log.info(f\"Task definition {self.name} created.\") return response[\"taskDefinition\"][\"taskDefinitionArn\"] except (BotoCoreError, ClientError) as error: log.error(f\"Error creating task definition {self.name}: {error}\") return None def run_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Runs a new task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to run. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.run_task( cluster=self.cluster, taskDefinition=task_definition_arn, count=self.replicas, launchType=\"FARGATE\", networkConfiguration={ \"awsvpcConfiguration\": { \"subnets\": self.subnet_ids, \"assignPublicIp\": \"ENABLED\", \"securityGroups\": self.security_group_ids, } }, platformVersion=\"LATEST\", ) log.info(f\"Task {self.name} started.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error starting task {self.name}: {error}\") return None def describe_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Describes a task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to describe. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.describe_tasks(cluster=self.cluster, tasks=[task_definition_arn]) return response except (BotoCoreError, ClientError) as error: log.error(f\"Error getting status of task {self.name}: {error}\") return None def stop_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Stops a running task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to stop. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.stop_task(cluster=self.cluster, task=task_definition_arn) log.info(f\"Task {self.name} stopped.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error stopping task {self.name}: {error}\") return None def update_task(self, new_image: str, new_command: list) -> None: \"\"\" Updates a task with a new Docker image and command. Parameters ---------- new_image : str The new Docker image for the task. new_command : list The new command for the task. \"\"\" self.image = new_image self.command = new_command task_definition_arn = self.create_task_definition() if task_definition_arn: self.stop_task(task_definition_arn) self.run_task(task_definition_arn) else: log.error(f\"Error updating task {self.name} - could not create ECS task definition.\") def create_service(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Creates a new service using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to use for the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.create_service( cluster=self.cluster, serviceName=self.name, taskDefinition=task_definition_arn, desiredCount=self.replicas, launchType=\"FARGATE\", networkConfiguration={ \"awsvpcConfiguration\": { \"subnets\": self.subnet_ids, \"assignPublicIp\": \"ENABLED\", \"securityGroups\": self.security_group_ids, } }, ) log.info(f\"Service {self.name} created.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error creating service {self.name}: {error}\") return None def update_service(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Updates a service with a new task definition ARN. Parameters ---------- task_definition_arn : str The new ARN of the task definition to use for the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.update_service( cluster=self.cluster, service=self.name, taskDefinition=task_definition_arn, desiredCount=self.replicas, ) log.info(f\"Service {self.name} updated.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error updating service {self.name}: {error}\") return None def delete_service(self) -> Optional[dict]: \"\"\" Deletes the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.delete_service( cluster=self.cluster, service=self.name, ) log.info(f\"Service {self.name} deleted.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error deleting service {self.name}: {error}\") return None __init__(name, account_id, cluster, command=[], subnet_ids=[], security_group_ids=[], image='geniusrise/geniusrise', replicas=1, port=80, log_group='/ecs/geniusrise', cpu=256, memory=512) Constructs all the necessary attributes for the ECSManager object. Parameters name : str the name of the ECS task or service account_id : str the id of the AWS account command : List[str] the command that the container runs cluster : str the name of the ECS cluster subnet_ids : List[str] the subnet IDs for the task or service security_group_ids : List[str] the security group IDs for the task or service image : str, optional the Docker image for the task (default is \"geniusrise/geniusrise\") replicas : int, optional the number of task replicas (default is 1) port : int, optional the port that the container listens on (default is 80) log_group : str, optional the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\") cpu : int, optional the CPU value for the task (default is 256) memory : int, optional the memory value for the task (default is 512) Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def __init__( self, name: str, account_id: str, cluster: str, command: List[str] = [], subnet_ids: List[str] = [], security_group_ids: List[str] = [], image: str = \"geniusrise/geniusrise\", replicas: int = 1, port: int = 80, log_group: str = \"/ecs/geniusrise\", cpu: int = 256, memory: int = 512, ): \"\"\" Constructs all the necessary attributes for the ECSManager object. Parameters ---------- name : str the name of the ECS task or service account_id : str the id of the AWS account command : List[str] the command that the container runs cluster : str the name of the ECS cluster subnet_ids : List[str] the subnet IDs for the task or service security_group_ids : List[str] the security group IDs for the task or service image : str, optional the Docker image for the task (default is \"geniusrise/geniusrise\") replicas : int, optional the number of task replicas (default is 1) port : int, optional the port that the container listens on (default is 80) log_group : str, optional the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\") cpu : int, optional the CPU value for the task (default is 256) memory : int, optional the memory value for the task (default is 512) \"\"\" self.name = name self.image = image self.cluster = cluster self.command = command self.replicas = replicas self.port = port self.client = boto3.client(\"ecs\") self.log_group = log_group self.logs_client = boto3.client(\"logs\") self.subnet_ids = subnet_ids self.security_group_ids = security_group_ids self.cpu = cpu self.account_id = account_id self.memory = memory create_service(task_definition_arn) Creates a new service using the specified task definition ARN. Parameters str The ARN of the task definition to use for the service. Returns dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def create_service(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Creates a new service using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to use for the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.create_service( cluster=self.cluster, serviceName=self.name, taskDefinition=task_definition_arn, desiredCount=self.replicas, launchType=\"FARGATE\", networkConfiguration={ \"awsvpcConfiguration\": { \"subnets\": self.subnet_ids, \"assignPublicIp\": \"ENABLED\", \"securityGroups\": self.security_group_ids, } }, ) log.info(f\"Service {self.name} created.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error creating service {self.name}: {error}\") return None create_task_definition() Registers a new task definition from the attributes of this class. Returns str The ARN of the task definition, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def create_task_definition(self) -> Optional[str]: \"\"\" Registers a new task definition from the attributes of this class. Returns ------- str The ARN of the task definition, or None if an error occurred. \"\"\" container_definitions = [ { \"name\": self.name, \"image\": self.image, \"command\": self.command, \"portMappings\": [{\"containerPort\": self.port, \"protocol\": \"tcp\"}], } ] try: response = self.client.register_task_definition( family=self.name, networkMode=\"awsvpc\", containerDefinitions=container_definitions, requiresCompatibilities=[ \"FARGATE\", ], cpu=str(self.cpu), memory=str(self.memory), executionRoleArn=f\"arn:aws:iam::{self.account_id}:role/ecsTaskExecutionRole\", ) log.info(f\"Task definition {self.name} created.\") return response[\"taskDefinition\"][\"taskDefinitionArn\"] except (BotoCoreError, ClientError) as error: log.error(f\"Error creating task definition {self.name}: {error}\") return None delete_service() Deletes the service. Returns dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def delete_service(self) -> Optional[dict]: \"\"\" Deletes the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.delete_service( cluster=self.cluster, service=self.name, ) log.info(f\"Service {self.name} deleted.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error deleting service {self.name}: {error}\") return None describe_task(task_definition_arn) Describes a task using the specified task definition ARN. Parameters str The ARN of the task definition to describe. Returns dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def describe_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Describes a task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to describe. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.describe_tasks(cluster=self.cluster, tasks=[task_definition_arn]) return response except (BotoCoreError, ClientError) as error: log.error(f\"Error getting status of task {self.name}: {error}\") return None run_task(task_definition_arn) Runs a new task using the specified task definition ARN. Parameters str The ARN of the task definition to run. Returns dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def run_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Runs a new task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to run. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.run_task( cluster=self.cluster, taskDefinition=task_definition_arn, count=self.replicas, launchType=\"FARGATE\", networkConfiguration={ \"awsvpcConfiguration\": { \"subnets\": self.subnet_ids, \"assignPublicIp\": \"ENABLED\", \"securityGroups\": self.security_group_ids, } }, platformVersion=\"LATEST\", ) log.info(f\"Task {self.name} started.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error starting task {self.name}: {error}\") return None stop_task(task_definition_arn) Stops a running task using the specified task definition ARN. Parameters str The ARN of the task definition to stop. Returns dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def stop_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Stops a running task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to stop. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.stop_task(cluster=self.cluster, task=task_definition_arn) log.info(f\"Task {self.name} stopped.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error stopping task {self.name}: {error}\") return None update_service(task_definition_arn) Updates a service with a new task definition ARN. Parameters str The new ARN of the task definition to use for the service. Returns dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def update_service(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Updates a service with a new task definition ARN. Parameters ---------- task_definition_arn : str The new ARN of the task definition to use for the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.update_service( cluster=self.cluster, service=self.name, taskDefinition=task_definition_arn, desiredCount=self.replicas, ) log.info(f\"Service {self.name} updated.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error updating service {self.name}: {error}\") return None update_task(new_image, new_command) Updates a task with a new Docker image and command. Parameters str The new Docker image for the task. list The new command for the task. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def update_task(self, new_image: str, new_command: list) -> None: \"\"\" Updates a task with a new Docker image and command. Parameters ---------- new_image : str The new Docker image for the task. new_command : list The new command for the task. \"\"\" self.image = new_image self.command = new_command task_definition_arn = self.create_task_definition() if task_definition_arn: self.stop_task(task_definition_arn) self.run_task(task_definition_arn) else: log.error(f\"Error updating task {self.name} - could not create ECS task definition.\")","title":"ecs"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager","text":"A class used to manage the lifecycle of an ECS container. ...","title":"ECSManager"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager--attributes","text":"str the name of the ECS task or service List[str] the command that the container runs str the name of the ECS cluster List[str] the subnet IDs for the task or service List[str] the security group IDs for the task or service str the Docker image for the task int the number of task replicas int the port that the container listens on str the CloudWatch log group for the task logs int the CPU value for the task int the memory value for the task","title":"Attributes"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager--methods","text":"create_task_definition() Registers a new task definition from the attributes of this class run_task(task_definition_arn: str) Runs a new task using the specified task definition ARN describe_task(task_definition_arn: str) Describes a task using the specified task definition ARN stop_task(task_definition_arn: str) Stops a running task using the specified task definition ARN update_task(new_image: str, new_command: list) Updates a task with a new Docker image and command create_service(task_definition_arn: str) Creates a new service using the specified task definition ARN update_service(task_definition_arn: str) Updates a service with a new task definition ARN delete_service() Deletes the service Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py class ECSManager: \"\"\" A class used to manage the lifecycle of an ECS container. ... Attributes ---------- name : str the name of the ECS task or service command : List[str] the command that the container runs cluster : str the name of the ECS cluster subnet_ids : List[str] the subnet IDs for the task or service security_group_ids : List[str] the security group IDs for the task or service image : str the Docker image for the task replicas : int the number of task replicas port : int the port that the container listens on log_group : str the CloudWatch log group for the task logs cpu : int the CPU value for the task memory : int the memory value for the task Methods ------- create_task_definition() Registers a new task definition from the attributes of this class run_task(task_definition_arn: str) Runs a new task using the specified task definition ARN describe_task(task_definition_arn: str) Describes a task using the specified task definition ARN stop_task(task_definition_arn: str) Stops a running task using the specified task definition ARN update_task(new_image: str, new_command: list) Updates a task with a new Docker image and command create_service(task_definition_arn: str) Creates a new service using the specified task definition ARN update_service(task_definition_arn: str) Updates a service with a new task definition ARN delete_service() Deletes the service \"\"\" def __init__( self, name: str, account_id: str, cluster: str, command: List[str] = [], subnet_ids: List[str] = [], security_group_ids: List[str] = [], image: str = \"geniusrise/geniusrise\", replicas: int = 1, port: int = 80, log_group: str = \"/ecs/geniusrise\", cpu: int = 256, memory: int = 512, ): \"\"\" Constructs all the necessary attributes for the ECSManager object. Parameters ---------- name : str the name of the ECS task or service account_id : str the id of the AWS account command : List[str] the command that the container runs cluster : str the name of the ECS cluster subnet_ids : List[str] the subnet IDs for the task or service security_group_ids : List[str] the security group IDs for the task or service image : str, optional the Docker image for the task (default is \"geniusrise/geniusrise\") replicas : int, optional the number of task replicas (default is 1) port : int, optional the port that the container listens on (default is 80) log_group : str, optional the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\") cpu : int, optional the CPU value for the task (default is 256) memory : int, optional the memory value for the task (default is 512) \"\"\" self.name = name self.image = image self.cluster = cluster self.command = command self.replicas = replicas self.port = port self.client = boto3.client(\"ecs\") self.log_group = log_group self.logs_client = boto3.client(\"logs\") self.subnet_ids = subnet_ids self.security_group_ids = security_group_ids self.cpu = cpu self.account_id = account_id self.memory = memory def create_task_definition(self) -> Optional[str]: \"\"\" Registers a new task definition from the attributes of this class. Returns ------- str The ARN of the task definition, or None if an error occurred. \"\"\" container_definitions = [ { \"name\": self.name, \"image\": self.image, \"command\": self.command, \"portMappings\": [{\"containerPort\": self.port, \"protocol\": \"tcp\"}], } ] try: response = self.client.register_task_definition( family=self.name, networkMode=\"awsvpc\", containerDefinitions=container_definitions, requiresCompatibilities=[ \"FARGATE\", ], cpu=str(self.cpu), memory=str(self.memory), executionRoleArn=f\"arn:aws:iam::{self.account_id}:role/ecsTaskExecutionRole\", ) log.info(f\"Task definition {self.name} created.\") return response[\"taskDefinition\"][\"taskDefinitionArn\"] except (BotoCoreError, ClientError) as error: log.error(f\"Error creating task definition {self.name}: {error}\") return None def run_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Runs a new task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to run. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.run_task( cluster=self.cluster, taskDefinition=task_definition_arn, count=self.replicas, launchType=\"FARGATE\", networkConfiguration={ \"awsvpcConfiguration\": { \"subnets\": self.subnet_ids, \"assignPublicIp\": \"ENABLED\", \"securityGroups\": self.security_group_ids, } }, platformVersion=\"LATEST\", ) log.info(f\"Task {self.name} started.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error starting task {self.name}: {error}\") return None def describe_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Describes a task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to describe. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.describe_tasks(cluster=self.cluster, tasks=[task_definition_arn]) return response except (BotoCoreError, ClientError) as error: log.error(f\"Error getting status of task {self.name}: {error}\") return None def stop_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Stops a running task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to stop. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.stop_task(cluster=self.cluster, task=task_definition_arn) log.info(f\"Task {self.name} stopped.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error stopping task {self.name}: {error}\") return None def update_task(self, new_image: str, new_command: list) -> None: \"\"\" Updates a task with a new Docker image and command. Parameters ---------- new_image : str The new Docker image for the task. new_command : list The new command for the task. \"\"\" self.image = new_image self.command = new_command task_definition_arn = self.create_task_definition() if task_definition_arn: self.stop_task(task_definition_arn) self.run_task(task_definition_arn) else: log.error(f\"Error updating task {self.name} - could not create ECS task definition.\") def create_service(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Creates a new service using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to use for the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.create_service( cluster=self.cluster, serviceName=self.name, taskDefinition=task_definition_arn, desiredCount=self.replicas, launchType=\"FARGATE\", networkConfiguration={ \"awsvpcConfiguration\": { \"subnets\": self.subnet_ids, \"assignPublicIp\": \"ENABLED\", \"securityGroups\": self.security_group_ids, } }, ) log.info(f\"Service {self.name} created.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error creating service {self.name}: {error}\") return None def update_service(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Updates a service with a new task definition ARN. Parameters ---------- task_definition_arn : str The new ARN of the task definition to use for the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.update_service( cluster=self.cluster, service=self.name, taskDefinition=task_definition_arn, desiredCount=self.replicas, ) log.info(f\"Service {self.name} updated.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error updating service {self.name}: {error}\") return None def delete_service(self) -> Optional[dict]: \"\"\" Deletes the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.delete_service( cluster=self.cluster, service=self.name, ) log.info(f\"Service {self.name} deleted.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error deleting service {self.name}: {error}\") return None","title":"Methods"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.__init__","text":"Constructs all the necessary attributes for the ECSManager object.","title":"__init__()"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.__init__--parameters","text":"name : str the name of the ECS task or service account_id : str the id of the AWS account command : List[str] the command that the container runs cluster : str the name of the ECS cluster subnet_ids : List[str] the subnet IDs for the task or service security_group_ids : List[str] the security group IDs for the task or service image : str, optional the Docker image for the task (default is \"geniusrise/geniusrise\") replicas : int, optional the number of task replicas (default is 1) port : int, optional the port that the container listens on (default is 80) log_group : str, optional the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\") cpu : int, optional the CPU value for the task (default is 256) memory : int, optional the memory value for the task (default is 512) Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def __init__( self, name: str, account_id: str, cluster: str, command: List[str] = [], subnet_ids: List[str] = [], security_group_ids: List[str] = [], image: str = \"geniusrise/geniusrise\", replicas: int = 1, port: int = 80, log_group: str = \"/ecs/geniusrise\", cpu: int = 256, memory: int = 512, ): \"\"\" Constructs all the necessary attributes for the ECSManager object. Parameters ---------- name : str the name of the ECS task or service account_id : str the id of the AWS account command : List[str] the command that the container runs cluster : str the name of the ECS cluster subnet_ids : List[str] the subnet IDs for the task or service security_group_ids : List[str] the security group IDs for the task or service image : str, optional the Docker image for the task (default is \"geniusrise/geniusrise\") replicas : int, optional the number of task replicas (default is 1) port : int, optional the port that the container listens on (default is 80) log_group : str, optional the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\") cpu : int, optional the CPU value for the task (default is 256) memory : int, optional the memory value for the task (default is 512) \"\"\" self.name = name self.image = image self.cluster = cluster self.command = command self.replicas = replicas self.port = port self.client = boto3.client(\"ecs\") self.log_group = log_group self.logs_client = boto3.client(\"logs\") self.subnet_ids = subnet_ids self.security_group_ids = security_group_ids self.cpu = cpu self.account_id = account_id self.memory = memory","title":"Parameters"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_service","text":"Creates a new service using the specified task definition ARN.","title":"create_service()"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_service--parameters","text":"str The ARN of the task definition to use for the service.","title":"Parameters"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_service--returns","text":"dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def create_service(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Creates a new service using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to use for the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.create_service( cluster=self.cluster, serviceName=self.name, taskDefinition=task_definition_arn, desiredCount=self.replicas, launchType=\"FARGATE\", networkConfiguration={ \"awsvpcConfiguration\": { \"subnets\": self.subnet_ids, \"assignPublicIp\": \"ENABLED\", \"securityGroups\": self.security_group_ids, } }, ) log.info(f\"Service {self.name} created.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error creating service {self.name}: {error}\") return None","title":"Returns"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_task_definition","text":"Registers a new task definition from the attributes of this class.","title":"create_task_definition()"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_task_definition--returns","text":"str The ARN of the task definition, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def create_task_definition(self) -> Optional[str]: \"\"\" Registers a new task definition from the attributes of this class. Returns ------- str The ARN of the task definition, or None if an error occurred. \"\"\" container_definitions = [ { \"name\": self.name, \"image\": self.image, \"command\": self.command, \"portMappings\": [{\"containerPort\": self.port, \"protocol\": \"tcp\"}], } ] try: response = self.client.register_task_definition( family=self.name, networkMode=\"awsvpc\", containerDefinitions=container_definitions, requiresCompatibilities=[ \"FARGATE\", ], cpu=str(self.cpu), memory=str(self.memory), executionRoleArn=f\"arn:aws:iam::{self.account_id}:role/ecsTaskExecutionRole\", ) log.info(f\"Task definition {self.name} created.\") return response[\"taskDefinition\"][\"taskDefinitionArn\"] except (BotoCoreError, ClientError) as error: log.error(f\"Error creating task definition {self.name}: {error}\") return None","title":"Returns"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.delete_service","text":"Deletes the service.","title":"delete_service()"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.delete_service--returns","text":"dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def delete_service(self) -> Optional[dict]: \"\"\" Deletes the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.delete_service( cluster=self.cluster, service=self.name, ) log.info(f\"Service {self.name} deleted.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error deleting service {self.name}: {error}\") return None","title":"Returns"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.describe_task","text":"Describes a task using the specified task definition ARN.","title":"describe_task()"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.describe_task--parameters","text":"str The ARN of the task definition to describe.","title":"Parameters"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.describe_task--returns","text":"dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def describe_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Describes a task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to describe. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.describe_tasks(cluster=self.cluster, tasks=[task_definition_arn]) return response except (BotoCoreError, ClientError) as error: log.error(f\"Error getting status of task {self.name}: {error}\") return None","title":"Returns"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.run_task","text":"Runs a new task using the specified task definition ARN.","title":"run_task()"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.run_task--parameters","text":"str The ARN of the task definition to run.","title":"Parameters"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.run_task--returns","text":"dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def run_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Runs a new task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to run. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.run_task( cluster=self.cluster, taskDefinition=task_definition_arn, count=self.replicas, launchType=\"FARGATE\", networkConfiguration={ \"awsvpcConfiguration\": { \"subnets\": self.subnet_ids, \"assignPublicIp\": \"ENABLED\", \"securityGroups\": self.security_group_ids, } }, platformVersion=\"LATEST\", ) log.info(f\"Task {self.name} started.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error starting task {self.name}: {error}\") return None","title":"Returns"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.stop_task","text":"Stops a running task using the specified task definition ARN.","title":"stop_task()"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.stop_task--parameters","text":"str The ARN of the task definition to stop.","title":"Parameters"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.stop_task--returns","text":"dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def stop_task(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Stops a running task using the specified task definition ARN. Parameters ---------- task_definition_arn : str The ARN of the task definition to stop. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.stop_task(cluster=self.cluster, task=task_definition_arn) log.info(f\"Task {self.name} stopped.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error stopping task {self.name}: {error}\") return None","title":"Returns"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_service","text":"Updates a service with a new task definition ARN.","title":"update_service()"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_service--parameters","text":"str The new ARN of the task definition to use for the service.","title":"Parameters"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_service--returns","text":"dict The response from the ECS API, or None if an error occurred. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def update_service(self, task_definition_arn: str) -> Optional[dict]: \"\"\" Updates a service with a new task definition ARN. Parameters ---------- task_definition_arn : str The new ARN of the task definition to use for the service. Returns ------- dict The response from the ECS API, or None if an error occurred. \"\"\" try: response = self.client.update_service( cluster=self.cluster, service=self.name, taskDefinition=task_definition_arn, desiredCount=self.replicas, ) log.info(f\"Service {self.name} updated.\") return response except (BotoCoreError, ClientError) as error: log.error(f\"Error updating service {self.name}: {error}\") return None","title":"Returns"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_task","text":"Updates a task with a new Docker image and command.","title":"update_task()"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_task--parameters","text":"str The new Docker image for the task. list The new command for the task. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py def update_task(self, new_image: str, new_command: list) -> None: \"\"\" Updates a task with a new Docker image and command. Parameters ---------- new_image : str The new Docker image for the task. new_command : list The new command for the task. \"\"\" self.image = new_image self.command = new_command task_definition_arn = self.create_task_definition() if task_definition_arn: self.stop_task(task_definition_arn) self.run_task(task_definition_arn) else: log.error(f\"Error updating task {self.name} - could not create ECS task definition.\")","title":"Parameters"},{"location":"core/core_task_k8s/","text":"K8sManager A class used to manage Kubernetes deployments and services. Attributes str The name of the deployment and service. str The namespace to create the deployment and service in. str The Docker image to use for the deployment. list The command to run in the Docker container. int The number of replicas to create for the deployment. int The port to expose on the service. Methods create_deployment() Creates a new deployment. update_deployment(replicas) Updates the number of replicas in the deployment. scale_deployment(replicas) Scales the deployment to a new number of replicas. delete_deployment() Deletes the deployment. create_service() Creates a new service. delete_service() Deletes the service. run() Creates the deployment and service. destroy() Deletes the deployment and service. get_status() Returns the status of the deployment. get_statistics() Returns the details of the deployment and the pods in the deployment. get_logs() Returns the logs of the pods in the deployment. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py class K8sManager: \"\"\" A class used to manage Kubernetes deployments and services. Attributes ---------- name : str The name of the deployment and service. namespace : str The namespace to create the deployment and service in. image : str The Docker image to use for the deployment. command : list The command to run in the Docker container. replicas : int The number of replicas to create for the deployment. port : int The port to expose on the service. Methods ------- create_deployment() Creates a new deployment. update_deployment(replicas) Updates the number of replicas in the deployment. scale_deployment(replicas) Scales the deployment to a new number of replicas. delete_deployment() Deletes the deployment. create_service() Creates a new service. delete_service() Deletes the service. run() Creates the deployment and service. destroy() Deletes the deployment and service. get_status() Returns the status of the deployment. get_statistics() Returns the details of the deployment and the pods in the deployment. get_logs() Returns the logs of the pods in the deployment. \"\"\" def __init__( self, name: str, command: list = [], namespace: str = \"default\", image: str = \"geniusrise/geniusrise\", replicas: int = 1, port: int = 80, ): \"\"\" Constructs all the necessary attributes for the K8sManager object. Parameters ---------- name : str The name of the deployment and service. command : list The command to run in the Docker container. namespace : str, optional The namespace to create the deployment and service in (default is \"default\"). image : str, optional The Docker image to use for the deployment (default is \"geniusrise/geniusrise\"). replicas : int, optional The number of replicas to create for the deployment (default is 1). port : int, optional The port to expose on the service (default is 80). \"\"\" self.name = name self.namespace = namespace self.image = image self.command = command self.replicas = replicas self.port = port # Load kube config from default location config.load_kube_config() # Create a client instance for Core V1 and Apps V1 of Kubernetes API self.core_api = client.CoreV1Api() self.apps_api = client.AppsV1Api() def create_deployment(self): \"\"\" Creates a new deployment. The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image and command specified in the constructor, and creates the number of replicas specified in the constructor. If an error occurs while creating the deployment, an error message is logged and the method returns None. \"\"\" # Define the container container = client.V1Container(name=self.name, image=self.image, command=self.command) # Define the template template = client.V1PodTemplateSpec( metadata=client.V1ObjectMeta(labels={\"app\": self.name, \"service\": \"geniusrise\"}), spec=client.V1PodSpec(containers=[container]), ) # Define the spec spec = client.V1DeploymentSpec( replicas=self.replicas, selector=client.V1LabelSelector(match_labels={\"app\": self.name, \"service\": \"geniusrise\"}), template=template, ) # Define the deployment deployment = client.V1Deployment(metadata=client.V1ObjectMeta(name=self.name), spec=spec) # Create the deployment try: self.apps_api.create_namespaced_deployment(namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} created.\") except ApiException as e: log.error(f\"Exception when creating deployment {self.name}: {e}\") def update_deployment(self, replicas): \"\"\" Updates the number of replicas in the deployment. Parameters ---------- replicas : int The new number of replicas for the deployment. If an error occurs while updating the deployment, an error message is logged and the method returns None. \"\"\" # Get the existing deployment try: deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) # Update the number of replicas deployment.spec.replicas = replicas # Update the deployment self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} updated.\") except ApiException as e: log.error(f\"Exception when updating deployment {self.name}: {e}\") def scale_deployment(self, replicas): \"\"\" Scales the deployment to a new number of replicas. Parameters ---------- replicas : int The new number of replicas for the deployment. If an error occurs while scaling the deployment, an error message is logged and the method returns None. \"\"\" # Get the existing deployment try: deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) # Update the number of replicas deployment.spec.replicas = replicas # Update the deployment self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} scaled to {replicas} replicas.\") except ApiException as e: log.error(f\"Exception when scaling deployment {self.name}: {e}\") def delete_deployment(self): # Delete the deployment try: self.apps_api.delete_namespaced_deployment(name=self.name, namespace=self.namespace) log.info(f\"Deployment {self.name} deleted.\") except ApiException as e: log.error(f\"Exception when deleting deployment {self.name}: {e}\") def create_service(self): \"\"\" Deletes the deployment. If an error occurs while deleting the deployment, an error message is logged and the method returns None. \"\"\" # Define the service spec spec = client.V1ServiceSpec( selector={\"app\": self.name}, ports=[client.V1ServicePort(port=self.port, target_port=self.port)] ) # Define the service service = client.V1Service(metadata=client.V1ObjectMeta(name=self.name), spec=spec) # Create the service try: self.core_api.create_namespaced_service(namespace=self.namespace, body=service) log.info(f\"Service {self.name} created.\") except ApiException as e: log.error(f\"Exception when creating service {self.name}: {e}\") def delete_service(self): \"\"\" Creates a new service. The service is created in the namespace specified in the constructor. The service exposes the port specified in the constructor. If an error occurs while creating the service, an error message is logged and the method returns None. \"\"\" # Delete the service try: self.core_api.delete_namespaced_service(name=self.name, namespace=self.namespace) log.info(f\"Service {self.name} deleted.\") except ApiException as e: log.error(f\"Exception when deleting service {self.name}: {e}\") def run(self): \"\"\" Creates the deployment and service. If an error occurs while creating the deployment or service, an error message is logged and the method returns None. \"\"\" self.create_deployment() self.create_service() def destroy(self): \"\"\" Deletes the deployment and service. If an error occurs while deleting the deployment or service, an error message is logged and the method returns None. \"\"\" self.delete_deployment() self.delete_service() def get_status(self) -> Dict[str, Any]: \"\"\" Get the status of the deployment Returns: Dict[str, Any]: The status of the deployment \"\"\" try: # Get the status of the deployment deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) return deployment.status.__dict__ except ApiException as e: log.error(f\"Exception when getting status of deployment {self.name}: {e}\") return {} def get_statistics(self) -> Dict[str, Any]: \"\"\" Get the details of the deployment and the pods in the deployment Returns: Dict[str, Any]: The details of the deployment and the pods \"\"\" try: # Get the details of the deployment deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) deployment_stats = deployment.status # Get the details of the pods in the deployment pod_list = self.core_api.list_namespaced_pod(self.namespace, label_selector=f\"app={self.name}\") pod_stats = [pod.status for pod in pod_list.items] return {\"deployment\": deployment_stats, \"pods\": pod_stats} except ApiException as e: log.error(f\"Exception when getting statistics of deployment {self.name}: {e}\") return {} def get_logs(self) -> Dict[str, str]: \"\"\" Get the logs of the pods in the deployment Returns: Dict[str, str]: The logs of the pods \"\"\" try: # Get the logs of the pods in the deployment logs = {} _continue = None while True: pod_list = self.core_api.list_namespaced_pod( self.namespace, label_selector=f\"app={self.name}\", _continue=_continue ) for pod in pod_list.items: logs[pod.metadata.name] = self.core_api.read_namespaced_pod_log(pod.metadata.name, self.namespace) _continue = pod_list.metadata._continue if not _continue: break return logs except ApiException as e: log.error(f\"Exception when getting logs of deployment {self.name}: {e}\") return {} __init__(name, command=[], namespace='default', image='geniusrise/geniusrise', replicas=1, port=80) Constructs all the necessary attributes for the K8sManager object. Parameters str The name of the deployment and service. list The command to run in the Docker container. str, optional The namespace to create the deployment and service in (default is \"default\"). str, optional The Docker image to use for the deployment (default is \"geniusrise/geniusrise\"). int, optional The number of replicas to create for the deployment (default is 1). int, optional The port to expose on the service (default is 80). Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def __init__( self, name: str, command: list = [], namespace: str = \"default\", image: str = \"geniusrise/geniusrise\", replicas: int = 1, port: int = 80, ): \"\"\" Constructs all the necessary attributes for the K8sManager object. Parameters ---------- name : str The name of the deployment and service. command : list The command to run in the Docker container. namespace : str, optional The namespace to create the deployment and service in (default is \"default\"). image : str, optional The Docker image to use for the deployment (default is \"geniusrise/geniusrise\"). replicas : int, optional The number of replicas to create for the deployment (default is 1). port : int, optional The port to expose on the service (default is 80). \"\"\" self.name = name self.namespace = namespace self.image = image self.command = command self.replicas = replicas self.port = port # Load kube config from default location config.load_kube_config() # Create a client instance for Core V1 and Apps V1 of Kubernetes API self.core_api = client.CoreV1Api() self.apps_api = client.AppsV1Api() create_deployment() Creates a new deployment. The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image and command specified in the constructor, and creates the number of replicas specified in the constructor. If an error occurs while creating the deployment, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def create_deployment(self): \"\"\" Creates a new deployment. The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image and command specified in the constructor, and creates the number of replicas specified in the constructor. If an error occurs while creating the deployment, an error message is logged and the method returns None. \"\"\" # Define the container container = client.V1Container(name=self.name, image=self.image, command=self.command) # Define the template template = client.V1PodTemplateSpec( metadata=client.V1ObjectMeta(labels={\"app\": self.name, \"service\": \"geniusrise\"}), spec=client.V1PodSpec(containers=[container]), ) # Define the spec spec = client.V1DeploymentSpec( replicas=self.replicas, selector=client.V1LabelSelector(match_labels={\"app\": self.name, \"service\": \"geniusrise\"}), template=template, ) # Define the deployment deployment = client.V1Deployment(metadata=client.V1ObjectMeta(name=self.name), spec=spec) # Create the deployment try: self.apps_api.create_namespaced_deployment(namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} created.\") except ApiException as e: log.error(f\"Exception when creating deployment {self.name}: {e}\") create_service() Deletes the deployment. If an error occurs while deleting the deployment, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def create_service(self): \"\"\" Deletes the deployment. If an error occurs while deleting the deployment, an error message is logged and the method returns None. \"\"\" # Define the service spec spec = client.V1ServiceSpec( selector={\"app\": self.name}, ports=[client.V1ServicePort(port=self.port, target_port=self.port)] ) # Define the service service = client.V1Service(metadata=client.V1ObjectMeta(name=self.name), spec=spec) # Create the service try: self.core_api.create_namespaced_service(namespace=self.namespace, body=service) log.info(f\"Service {self.name} created.\") except ApiException as e: log.error(f\"Exception when creating service {self.name}: {e}\") delete_service() Creates a new service. The service is created in the namespace specified in the constructor. The service exposes the port specified in the constructor. If an error occurs while creating the service, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def delete_service(self): \"\"\" Creates a new service. The service is created in the namespace specified in the constructor. The service exposes the port specified in the constructor. If an error occurs while creating the service, an error message is logged and the method returns None. \"\"\" # Delete the service try: self.core_api.delete_namespaced_service(name=self.name, namespace=self.namespace) log.info(f\"Service {self.name} deleted.\") except ApiException as e: log.error(f\"Exception when deleting service {self.name}: {e}\") destroy() Deletes the deployment and service. If an error occurs while deleting the deployment or service, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def destroy(self): \"\"\" Deletes the deployment and service. If an error occurs while deleting the deployment or service, an error message is logged and the method returns None. \"\"\" self.delete_deployment() self.delete_service() get_logs() Get the logs of the pods in the deployment Returns: Type Description Dict [ str , str ] Dict[str, str]: The logs of the pods Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def get_logs(self) -> Dict[str, str]: \"\"\" Get the logs of the pods in the deployment Returns: Dict[str, str]: The logs of the pods \"\"\" try: # Get the logs of the pods in the deployment logs = {} _continue = None while True: pod_list = self.core_api.list_namespaced_pod( self.namespace, label_selector=f\"app={self.name}\", _continue=_continue ) for pod in pod_list.items: logs[pod.metadata.name] = self.core_api.read_namespaced_pod_log(pod.metadata.name, self.namespace) _continue = pod_list.metadata._continue if not _continue: break return logs except ApiException as e: log.error(f\"Exception when getting logs of deployment {self.name}: {e}\") return {} get_statistics() Get the details of the deployment and the pods in the deployment Returns: Type Description Dict [ str , Any ] Dict[str, Any]: The details of the deployment and the pods Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def get_statistics(self) -> Dict[str, Any]: \"\"\" Get the details of the deployment and the pods in the deployment Returns: Dict[str, Any]: The details of the deployment and the pods \"\"\" try: # Get the details of the deployment deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) deployment_stats = deployment.status # Get the details of the pods in the deployment pod_list = self.core_api.list_namespaced_pod(self.namespace, label_selector=f\"app={self.name}\") pod_stats = [pod.status for pod in pod_list.items] return {\"deployment\": deployment_stats, \"pods\": pod_stats} except ApiException as e: log.error(f\"Exception when getting statistics of deployment {self.name}: {e}\") return {} get_status() Get the status of the deployment Returns: Type Description Dict [ str , Any ] Dict[str, Any]: The status of the deployment Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def get_status(self) -> Dict[str, Any]: \"\"\" Get the status of the deployment Returns: Dict[str, Any]: The status of the deployment \"\"\" try: # Get the status of the deployment deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) return deployment.status.__dict__ except ApiException as e: log.error(f\"Exception when getting status of deployment {self.name}: {e}\") return {} run() Creates the deployment and service. If an error occurs while creating the deployment or service, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def run(self): \"\"\" Creates the deployment and service. If an error occurs while creating the deployment or service, an error message is logged and the method returns None. \"\"\" self.create_deployment() self.create_service() scale_deployment(replicas) Scales the deployment to a new number of replicas. Parameters int The new number of replicas for the deployment. If an error occurs while scaling the deployment, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def scale_deployment(self, replicas): \"\"\" Scales the deployment to a new number of replicas. Parameters ---------- replicas : int The new number of replicas for the deployment. If an error occurs while scaling the deployment, an error message is logged and the method returns None. \"\"\" # Get the existing deployment try: deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) # Update the number of replicas deployment.spec.replicas = replicas # Update the deployment self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} scaled to {replicas} replicas.\") except ApiException as e: log.error(f\"Exception when scaling deployment {self.name}: {e}\") update_deployment(replicas) Updates the number of replicas in the deployment. Parameters int The new number of replicas for the deployment. If an error occurs while updating the deployment, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def update_deployment(self, replicas): \"\"\" Updates the number of replicas in the deployment. Parameters ---------- replicas : int The new number of replicas for the deployment. If an error occurs while updating the deployment, an error message is logged and the method returns None. \"\"\" # Get the existing deployment try: deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) # Update the number of replicas deployment.spec.replicas = replicas # Update the deployment self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} updated.\") except ApiException as e: log.error(f\"Exception when updating deployment {self.name}: {e}\")","title":"k8s"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager","text":"A class used to manage Kubernetes deployments and services.","title":"K8sManager"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager--attributes","text":"str The name of the deployment and service. str The namespace to create the deployment and service in. str The Docker image to use for the deployment. list The command to run in the Docker container. int The number of replicas to create for the deployment. int The port to expose on the service.","title":"Attributes"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager--methods","text":"create_deployment() Creates a new deployment. update_deployment(replicas) Updates the number of replicas in the deployment. scale_deployment(replicas) Scales the deployment to a new number of replicas. delete_deployment() Deletes the deployment. create_service() Creates a new service. delete_service() Deletes the service. run() Creates the deployment and service. destroy() Deletes the deployment and service. get_status() Returns the status of the deployment. get_statistics() Returns the details of the deployment and the pods in the deployment. get_logs() Returns the logs of the pods in the deployment. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py class K8sManager: \"\"\" A class used to manage Kubernetes deployments and services. Attributes ---------- name : str The name of the deployment and service. namespace : str The namespace to create the deployment and service in. image : str The Docker image to use for the deployment. command : list The command to run in the Docker container. replicas : int The number of replicas to create for the deployment. port : int The port to expose on the service. Methods ------- create_deployment() Creates a new deployment. update_deployment(replicas) Updates the number of replicas in the deployment. scale_deployment(replicas) Scales the deployment to a new number of replicas. delete_deployment() Deletes the deployment. create_service() Creates a new service. delete_service() Deletes the service. run() Creates the deployment and service. destroy() Deletes the deployment and service. get_status() Returns the status of the deployment. get_statistics() Returns the details of the deployment and the pods in the deployment. get_logs() Returns the logs of the pods in the deployment. \"\"\" def __init__( self, name: str, command: list = [], namespace: str = \"default\", image: str = \"geniusrise/geniusrise\", replicas: int = 1, port: int = 80, ): \"\"\" Constructs all the necessary attributes for the K8sManager object. Parameters ---------- name : str The name of the deployment and service. command : list The command to run in the Docker container. namespace : str, optional The namespace to create the deployment and service in (default is \"default\"). image : str, optional The Docker image to use for the deployment (default is \"geniusrise/geniusrise\"). replicas : int, optional The number of replicas to create for the deployment (default is 1). port : int, optional The port to expose on the service (default is 80). \"\"\" self.name = name self.namespace = namespace self.image = image self.command = command self.replicas = replicas self.port = port # Load kube config from default location config.load_kube_config() # Create a client instance for Core V1 and Apps V1 of Kubernetes API self.core_api = client.CoreV1Api() self.apps_api = client.AppsV1Api() def create_deployment(self): \"\"\" Creates a new deployment. The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image and command specified in the constructor, and creates the number of replicas specified in the constructor. If an error occurs while creating the deployment, an error message is logged and the method returns None. \"\"\" # Define the container container = client.V1Container(name=self.name, image=self.image, command=self.command) # Define the template template = client.V1PodTemplateSpec( metadata=client.V1ObjectMeta(labels={\"app\": self.name, \"service\": \"geniusrise\"}), spec=client.V1PodSpec(containers=[container]), ) # Define the spec spec = client.V1DeploymentSpec( replicas=self.replicas, selector=client.V1LabelSelector(match_labels={\"app\": self.name, \"service\": \"geniusrise\"}), template=template, ) # Define the deployment deployment = client.V1Deployment(metadata=client.V1ObjectMeta(name=self.name), spec=spec) # Create the deployment try: self.apps_api.create_namespaced_deployment(namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} created.\") except ApiException as e: log.error(f\"Exception when creating deployment {self.name}: {e}\") def update_deployment(self, replicas): \"\"\" Updates the number of replicas in the deployment. Parameters ---------- replicas : int The new number of replicas for the deployment. If an error occurs while updating the deployment, an error message is logged and the method returns None. \"\"\" # Get the existing deployment try: deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) # Update the number of replicas deployment.spec.replicas = replicas # Update the deployment self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} updated.\") except ApiException as e: log.error(f\"Exception when updating deployment {self.name}: {e}\") def scale_deployment(self, replicas): \"\"\" Scales the deployment to a new number of replicas. Parameters ---------- replicas : int The new number of replicas for the deployment. If an error occurs while scaling the deployment, an error message is logged and the method returns None. \"\"\" # Get the existing deployment try: deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) # Update the number of replicas deployment.spec.replicas = replicas # Update the deployment self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} scaled to {replicas} replicas.\") except ApiException as e: log.error(f\"Exception when scaling deployment {self.name}: {e}\") def delete_deployment(self): # Delete the deployment try: self.apps_api.delete_namespaced_deployment(name=self.name, namespace=self.namespace) log.info(f\"Deployment {self.name} deleted.\") except ApiException as e: log.error(f\"Exception when deleting deployment {self.name}: {e}\") def create_service(self): \"\"\" Deletes the deployment. If an error occurs while deleting the deployment, an error message is logged and the method returns None. \"\"\" # Define the service spec spec = client.V1ServiceSpec( selector={\"app\": self.name}, ports=[client.V1ServicePort(port=self.port, target_port=self.port)] ) # Define the service service = client.V1Service(metadata=client.V1ObjectMeta(name=self.name), spec=spec) # Create the service try: self.core_api.create_namespaced_service(namespace=self.namespace, body=service) log.info(f\"Service {self.name} created.\") except ApiException as e: log.error(f\"Exception when creating service {self.name}: {e}\") def delete_service(self): \"\"\" Creates a new service. The service is created in the namespace specified in the constructor. The service exposes the port specified in the constructor. If an error occurs while creating the service, an error message is logged and the method returns None. \"\"\" # Delete the service try: self.core_api.delete_namespaced_service(name=self.name, namespace=self.namespace) log.info(f\"Service {self.name} deleted.\") except ApiException as e: log.error(f\"Exception when deleting service {self.name}: {e}\") def run(self): \"\"\" Creates the deployment and service. If an error occurs while creating the deployment or service, an error message is logged and the method returns None. \"\"\" self.create_deployment() self.create_service() def destroy(self): \"\"\" Deletes the deployment and service. If an error occurs while deleting the deployment or service, an error message is logged and the method returns None. \"\"\" self.delete_deployment() self.delete_service() def get_status(self) -> Dict[str, Any]: \"\"\" Get the status of the deployment Returns: Dict[str, Any]: The status of the deployment \"\"\" try: # Get the status of the deployment deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) return deployment.status.__dict__ except ApiException as e: log.error(f\"Exception when getting status of deployment {self.name}: {e}\") return {} def get_statistics(self) -> Dict[str, Any]: \"\"\" Get the details of the deployment and the pods in the deployment Returns: Dict[str, Any]: The details of the deployment and the pods \"\"\" try: # Get the details of the deployment deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) deployment_stats = deployment.status # Get the details of the pods in the deployment pod_list = self.core_api.list_namespaced_pod(self.namespace, label_selector=f\"app={self.name}\") pod_stats = [pod.status for pod in pod_list.items] return {\"deployment\": deployment_stats, \"pods\": pod_stats} except ApiException as e: log.error(f\"Exception when getting statistics of deployment {self.name}: {e}\") return {} def get_logs(self) -> Dict[str, str]: \"\"\" Get the logs of the pods in the deployment Returns: Dict[str, str]: The logs of the pods \"\"\" try: # Get the logs of the pods in the deployment logs = {} _continue = None while True: pod_list = self.core_api.list_namespaced_pod( self.namespace, label_selector=f\"app={self.name}\", _continue=_continue ) for pod in pod_list.items: logs[pod.metadata.name] = self.core_api.read_namespaced_pod_log(pod.metadata.name, self.namespace) _continue = pod_list.metadata._continue if not _continue: break return logs except ApiException as e: log.error(f\"Exception when getting logs of deployment {self.name}: {e}\") return {}","title":"Methods"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.__init__","text":"Constructs all the necessary attributes for the K8sManager object.","title":"__init__()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.__init__--parameters","text":"str The name of the deployment and service. list The command to run in the Docker container. str, optional The namespace to create the deployment and service in (default is \"default\"). str, optional The Docker image to use for the deployment (default is \"geniusrise/geniusrise\"). int, optional The number of replicas to create for the deployment (default is 1). int, optional The port to expose on the service (default is 80). Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def __init__( self, name: str, command: list = [], namespace: str = \"default\", image: str = \"geniusrise/geniusrise\", replicas: int = 1, port: int = 80, ): \"\"\" Constructs all the necessary attributes for the K8sManager object. Parameters ---------- name : str The name of the deployment and service. command : list The command to run in the Docker container. namespace : str, optional The namespace to create the deployment and service in (default is \"default\"). image : str, optional The Docker image to use for the deployment (default is \"geniusrise/geniusrise\"). replicas : int, optional The number of replicas to create for the deployment (default is 1). port : int, optional The port to expose on the service (default is 80). \"\"\" self.name = name self.namespace = namespace self.image = image self.command = command self.replicas = replicas self.port = port # Load kube config from default location config.load_kube_config() # Create a client instance for Core V1 and Apps V1 of Kubernetes API self.core_api = client.CoreV1Api() self.apps_api = client.AppsV1Api()","title":"Parameters"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.create_deployment","text":"Creates a new deployment. The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image and command specified in the constructor, and creates the number of replicas specified in the constructor. If an error occurs while creating the deployment, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def create_deployment(self): \"\"\" Creates a new deployment. The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image and command specified in the constructor, and creates the number of replicas specified in the constructor. If an error occurs while creating the deployment, an error message is logged and the method returns None. \"\"\" # Define the container container = client.V1Container(name=self.name, image=self.image, command=self.command) # Define the template template = client.V1PodTemplateSpec( metadata=client.V1ObjectMeta(labels={\"app\": self.name, \"service\": \"geniusrise\"}), spec=client.V1PodSpec(containers=[container]), ) # Define the spec spec = client.V1DeploymentSpec( replicas=self.replicas, selector=client.V1LabelSelector(match_labels={\"app\": self.name, \"service\": \"geniusrise\"}), template=template, ) # Define the deployment deployment = client.V1Deployment(metadata=client.V1ObjectMeta(name=self.name), spec=spec) # Create the deployment try: self.apps_api.create_namespaced_deployment(namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} created.\") except ApiException as e: log.error(f\"Exception when creating deployment {self.name}: {e}\")","title":"create_deployment()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.create_service","text":"Deletes the deployment. If an error occurs while deleting the deployment, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def create_service(self): \"\"\" Deletes the deployment. If an error occurs while deleting the deployment, an error message is logged and the method returns None. \"\"\" # Define the service spec spec = client.V1ServiceSpec( selector={\"app\": self.name}, ports=[client.V1ServicePort(port=self.port, target_port=self.port)] ) # Define the service service = client.V1Service(metadata=client.V1ObjectMeta(name=self.name), spec=spec) # Create the service try: self.core_api.create_namespaced_service(namespace=self.namespace, body=service) log.info(f\"Service {self.name} created.\") except ApiException as e: log.error(f\"Exception when creating service {self.name}: {e}\")","title":"create_service()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.delete_service","text":"Creates a new service. The service is created in the namespace specified in the constructor. The service exposes the port specified in the constructor. If an error occurs while creating the service, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def delete_service(self): \"\"\" Creates a new service. The service is created in the namespace specified in the constructor. The service exposes the port specified in the constructor. If an error occurs while creating the service, an error message is logged and the method returns None. \"\"\" # Delete the service try: self.core_api.delete_namespaced_service(name=self.name, namespace=self.namespace) log.info(f\"Service {self.name} deleted.\") except ApiException as e: log.error(f\"Exception when deleting service {self.name}: {e}\")","title":"delete_service()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.destroy","text":"Deletes the deployment and service. If an error occurs while deleting the deployment or service, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def destroy(self): \"\"\" Deletes the deployment and service. If an error occurs while deleting the deployment or service, an error message is logged and the method returns None. \"\"\" self.delete_deployment() self.delete_service()","title":"destroy()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.get_logs","text":"Get the logs of the pods in the deployment Returns: Type Description Dict [ str , str ] Dict[str, str]: The logs of the pods Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def get_logs(self) -> Dict[str, str]: \"\"\" Get the logs of the pods in the deployment Returns: Dict[str, str]: The logs of the pods \"\"\" try: # Get the logs of the pods in the deployment logs = {} _continue = None while True: pod_list = self.core_api.list_namespaced_pod( self.namespace, label_selector=f\"app={self.name}\", _continue=_continue ) for pod in pod_list.items: logs[pod.metadata.name] = self.core_api.read_namespaced_pod_log(pod.metadata.name, self.namespace) _continue = pod_list.metadata._continue if not _continue: break return logs except ApiException as e: log.error(f\"Exception when getting logs of deployment {self.name}: {e}\") return {}","title":"get_logs()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.get_statistics","text":"Get the details of the deployment and the pods in the deployment Returns: Type Description Dict [ str , Any ] Dict[str, Any]: The details of the deployment and the pods Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def get_statistics(self) -> Dict[str, Any]: \"\"\" Get the details of the deployment and the pods in the deployment Returns: Dict[str, Any]: The details of the deployment and the pods \"\"\" try: # Get the details of the deployment deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) deployment_stats = deployment.status # Get the details of the pods in the deployment pod_list = self.core_api.list_namespaced_pod(self.namespace, label_selector=f\"app={self.name}\") pod_stats = [pod.status for pod in pod_list.items] return {\"deployment\": deployment_stats, \"pods\": pod_stats} except ApiException as e: log.error(f\"Exception when getting statistics of deployment {self.name}: {e}\") return {}","title":"get_statistics()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.get_status","text":"Get the status of the deployment Returns: Type Description Dict [ str , Any ] Dict[str, Any]: The status of the deployment Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def get_status(self) -> Dict[str, Any]: \"\"\" Get the status of the deployment Returns: Dict[str, Any]: The status of the deployment \"\"\" try: # Get the status of the deployment deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) return deployment.status.__dict__ except ApiException as e: log.error(f\"Exception when getting status of deployment {self.name}: {e}\") return {}","title":"get_status()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.run","text":"Creates the deployment and service. If an error occurs while creating the deployment or service, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def run(self): \"\"\" Creates the deployment and service. If an error occurs while creating the deployment or service, an error message is logged and the method returns None. \"\"\" self.create_deployment() self.create_service()","title":"run()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.scale_deployment","text":"Scales the deployment to a new number of replicas.","title":"scale_deployment()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.scale_deployment--parameters","text":"int The new number of replicas for the deployment. If an error occurs while scaling the deployment, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def scale_deployment(self, replicas): \"\"\" Scales the deployment to a new number of replicas. Parameters ---------- replicas : int The new number of replicas for the deployment. If an error occurs while scaling the deployment, an error message is logged and the method returns None. \"\"\" # Get the existing deployment try: deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) # Update the number of replicas deployment.spec.replicas = replicas # Update the deployment self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} scaled to {replicas} replicas.\") except ApiException as e: log.error(f\"Exception when scaling deployment {self.name}: {e}\")","title":"Parameters"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.update_deployment","text":"Updates the number of replicas in the deployment.","title":"update_deployment()"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.update_deployment--parameters","text":"int The new number of replicas for the deployment. If an error occurs while updating the deployment, an error message is logged and the method returns None. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py def update_deployment(self, replicas): \"\"\" Updates the number of replicas in the deployment. Parameters ---------- replicas : int The new number of replicas for the deployment. If an error occurs while updating the deployment, an error message is logged and the method returns None. \"\"\" # Get the existing deployment try: deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace) # Update the number of replicas deployment.spec.replicas = replicas # Update the deployment self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment) log.info(f\"Deployment {self.name} updated.\") except ApiException as e: log.error(f\"Exception when updating deployment {self.name}: {e}\")","title":"Parameters"},{"location":"core/logging/","text":"setup_logger() Return a logger with a default ColoredFormatter. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/logging.py def setup_logger(): \"\"\"Return a logger with a default ColoredFormatter.\"\"\" formatter = colorlog.ColoredFormatter( \"%(log_color)s%(levelname)-8s%(reset)s \" \"%(yellow)s[%(asctime)s] \" \"%(blue)s[%(name)s:%(lineno)d] \" \"%(green)s%(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\", reset=True, log_colors={ \"DEBUG\": \"cyan\", \"INFO\": \"green\", \"WARNING\": \"yellow\", \"ERROR\": \"red\", \"CRITICAL\": \"bold_red\", }, ) logger = logging.getLogger(\"geniusrise-cli\") handler = logging.StreamHandler() handler.setFormatter(formatter) logger.addHandler(handler) logger.setLevel(LOGLEVEL) return logger","title":"Logging"},{"location":"core/logging/#logging.setup_logger","text":"Return a logger with a default ColoredFormatter. Source code in /run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/logging.py def setup_logger(): \"\"\"Return a logger with a default ColoredFormatter.\"\"\" formatter = colorlog.ColoredFormatter( \"%(log_color)s%(levelname)-8s%(reset)s \" \"%(yellow)s[%(asctime)s] \" \"%(blue)s[%(name)s:%(lineno)d] \" \"%(green)s%(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\", reset=True, log_colors={ \"DEBUG\": \"cyan\", \"INFO\": \"green\", \"WARNING\": \"yellow\", \"ERROR\": \"red\", \"CRITICAL\": \"bold_red\", }, ) logger = logging.getLogger(\"geniusrise-cli\") handler = logging.StreamHandler() handler.setFormatter(formatter) logger.addHandler(handler) logger.setLevel(LOGLEVEL) return logger","title":"setup_logger()"},{"location":"core/utils_prompts/","text":"","title":"Utils prompts"}]}