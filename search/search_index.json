{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"YAML structure","text":""},{"location":"#geniusrise-documentation","title":"Geniusrise Documentation","text":""},{"location":"#about","title":"About","text":"<p>Geniusrise is a computation framework is designed to support both batch and streaming data processing asynchronous Directed Acyclic Graphs (DAGs).</p>"},{"location":"#guides","title":"Guides","text":""},{"location":"#getting-started","title":"Getting started","text":"<ol> <li>Home: Front page</li> <li>Concepts: Concepts of the framework</li> <li>Installation: Start here, installation and setup</li> <li>Design and Architecture: Design and architecture of the framework</li> </ol>"},{"location":"#development","title":"Development","text":"<ol> <li>Local experimentation: Local experimentation workflow</li> <li>Packaging: Packaging your application</li> <li>Staged deployment: Deploying parts or whole of your application</li> <li>Workflow ops: Operations and management of workflows</li> <li>Data ops: Operations and management of data</li> <li>Model ops: Operations and management of models</li> </ol>"},{"location":"#deployment","title":"Deployment","text":"<ol> <li>Kubernetes: Running geniusrise on kubernetes</li> <li>Apache Airflow: Orchestrating batch jobs on Apache Airflow</li> <li>Apache Spark: Using geniusrise as a spark library</li> <li>Apache Flink: Using geniusrise as a flink library</li> <li>Apache Beam: Using geniusrise as a beam library</li> <li>Apache Storm: Using geniusrise as a storm library</li> <li>AWS ECS: Running geniusrise on AWS ECS</li> <li>AWS Batch: Running geniusrise batch jobs on AWS Batch</li> </ol>"},{"location":"#reference","title":"Reference","text":"<ol> <li>YAML structure: Geniusfile structure and configuration</li> <li>Community Plugins: Building and shipping community plugins (spouts and bolts)</li> <li>Project templates: Project templates for community plugins</li> </ol>"},{"location":"#examples","title":"Examples","text":"<ol> <li>Write a confluence PRD and have jira and github issues created and linked automatically</li> <li>Monitor, alert and summarize machinery metrics in a process industry</li> <li>Read news and stock market tickers to generate buy and sell alerts</li> <li>Read infosec logs generated by various services and decide whether to generate an alert</li> <li>Batch or streaming fine-tuning and managing a huggingface-hosted model</li> <li>Batch or streaming fine-tuning and managing an openAI model</li> </ol>"},{"location":"#library-reference","title":"Library Reference","text":"<ul> <li>geniusrise.cli:<ul> <li>geniusctl: The main command line application</li> <li>yamlctl: Control spouts and bolts defined in a YAML file</li> <li>boltctl: The main bolt controller</li> <li>spoutctl: The main spout controller</li> <li>schema: YAML schema definition as pydantic</li> <li>discover: Module discovery</li> </ul> </li> <li>geniusrise.core:<ul> <li>bolt: Core Bolt class</li> <li>spout: Core Spout class</li> <li>geniusrise.core.data:<ul> <li>batch_input: Batch input manager</li> <li>batch_output: Batch output manager</li> <li>input: Input manager base class</li> <li>output: Output manager base class</li> <li>streaming_input: Streaming input manager</li> <li>streaming_output: Streaming output manager</li> </ul> </li> <li>geniusrise.core.state:<ul> <li>base: Base class for task state mnager</li> <li>dynamo: State manager using dynamoDB</li> <li>memory: State manager using local memory</li> <li>postgres: State manager using postgres database</li> <li>redis: State manager using redis</li> </ul> </li> <li>geniusrise.core.task:<ul> <li>base: Base class for Task</li> </ul> </li> <li>geniusrise.runners:<ul> <li>ecs: Runner class using AWS ECS</li> <li>k8s: Runner class using kubernetes</li> </ul> </li> </ul> </li> </ul>"},{"location":"core/cli_boltctl/","title":"Boltctl","text":"<p>The main bolt controller</p>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl","title":"<code>BoltCtl</code>","text":"<p>Class for managing bolts end-to-end from the command line.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>class BoltCtl:\n\"\"\"\n    Class for managing bolts end-to-end from the command line.\n    \"\"\"\n\n    def __init__(self, discovered_bolt: DiscoveredBolt):\n\"\"\"\n        Initialize BoltCtl with a DiscoveredBolt object.\n\n        Args:\n            discovered_bolt (DiscoveredBolt): DiscoveredBolt object used to create and manage bolts.\n        \"\"\"\n        self.discovered_bolt = discovered_bolt\n        self.bolt = None\n        self.log = logging.getLogger(self.__class__.__name__)\n\n    def create_parser(self, parser):\n\"\"\"\n        Add arguments to the command-line parser for managing the bolt.\n\n        Args:\n            parser (argparse.ArgumentParser): Command-line parser.\n        \"\"\"\n        subparsers = parser.add_subparsers(dest=\"command\")\n\n        # Create subparser for 'run' command\n        run_parser = subparsers.add_parser(\"run\", help=\"Run a bolt locally.\")\n\n        run_parser.add_argument(\n            \"input_type\",\n            choices=[\"batch\", \"streaming\"],\n            help=\"Choose the type of input configuration: batch or streaming.\",\n            default=\"batch\",\n        )\n        run_parser.add_argument(\n            \"output_type\",\n            choices=[\"batch\", \"streaming\"],\n            help=\"Choose the type of output configuration: batch or streaming.\",\n            default=\"batch\",\n        )\n        run_parser.add_argument(\n            \"state_type\",\n            choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"],\n            help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\",\n            default=\"in_memory\",\n        )\n        run_parser.add_argument(\n            \"--input_folder\",\n            help=\"Specify the directory where output files should be stored temporarily.\",\n            default=\"/tmp\",\n            type=str,\n        )\n        run_parser.add_argument(\n            \"--input_kafka_topic\",\n            help=\"Kafka output topic for streaming spouts.\",\n            default=\"test\",\n            type=str,\n        )\n        run_parser.add_argument(\n            \"--input_kafka_cluster_connection_string\",\n            help=\"Kafka connection string for streaming spouts.\",\n            default=\"localhost:9092\",\n            type=str,\n        )\n        run_parser.add_argument(\n            \"--input_s3_bucket\",\n            help=\"Provide the name of the S3 bucket for output storage.\",\n            default=\"my-bucket\",\n            type=str,\n        )\n        run_parser.add_argument(\n            \"--input_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n        )\n        run_parser.add_argument(\n            \"--output_folder\",\n            help=\"Specify the directory where output files should be stored temporarily.\",\n            default=\"/tmp\",\n            type=str,\n        )\n        run_parser.add_argument(\n            \"--output_kafka_topic\",\n            help=\"Kafka output topic for streaming spouts.\",\n            default=\"test\",\n            type=str,\n        )\n        run_parser.add_argument(\n            \"--output_kafka_cluster_connection_string\",\n            help=\"Kafka connection string for streaming spouts.\",\n            default=\"localhost:9092\",\n            type=str,\n        )\n        run_parser.add_argument(\n            \"--output_s3_bucket\",\n            help=\"Provide the name of the S3 bucket for output storage.\",\n            default=\"my-bucket\",\n            type=str,\n        )\n        run_parser.add_argument(\n            \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n        )\n        run_parser.add_argument(\n            \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str\n        )\n        run_parser.add_argument(\n            \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int\n        )\n        run_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int)\n        run_parser.add_argument(\n            \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str\n        )\n        run_parser.add_argument(\n            \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int\n        )\n        run_parser.add_argument(\n            \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str\n        )\n        run_parser.add_argument(\n            \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str\n        )\n        run_parser.add_argument(\n            \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str\n        )\n        run_parser.add_argument(\n            \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str\n        )\n        run_parser.add_argument(\n            \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str\n        )\n        run_parser.add_argument(\n            \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str\n        )\n        run_parser.add_argument(\n            \"method_name\",\n            help=\"The name of the method to execute on the bolt.\",\n            type=str,\n        )\n        run_parser.add_argument(\n            \"--args\",\n            nargs=argparse.REMAINDER,\n            help=\"Additional keyword arguments to pass to the bolt.\",\n        )\n\n        # Create subparser for 'help' command\n        help_parser = subparsers.add_parser(\"help\", help=\"Print help for the bolt.\")\n        help_parser.add_argument(\"method\", help=\"The method to execute.\")\n\n        return parser\n\n    def run(self, args):\n\"\"\"\n        Run the command-line interface.\n\n        Args:\n            args (argparse.Namespace): Parsed command-line arguments.\n        \"\"\"\n        self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\"))\n        try:\n            if args.command == \"run\":\n                kwargs = {\n                    k: v\n                    for k, v in vars(args).items()\n                    if v is not None and k not in [\"input_type\", \"output_type\", \"state_type\", \"args\", \"method_name\"]\n                }\n                other = args.args or []\n                other_args, other_kwargs = self.parse_args_kwargs(other)\n                self.bolt = self.create_bolt(args.input_type, args.output_type, args.state_type, **kwargs)\n\n                # Pass the method_name from args to execute_bolt\n                result = self.execute_bolt(self.bolt, args.method_name, *other_args, **other_kwargs)\n                self.log.info(emoji.emojize(f\"Successfully executed the bolt method: {args.method_name} :thumbs_up:\"))\n                return result\n\n            elif args.command == \"help\":\n                self.discovered_bolt.klass.print_help(self.discovered_bolt.klass)\n        except ValueError as ve:\n            self.log.exception(f\"Value error: {ve}\")\n            raise\n        except AttributeError as ae:\n            self.log.exception(f\"Attribute error: {ae}\")\n            raise\n        except KeyError as ke:\n            self.log.exception(f\"Missing key: {ke}\")\n            raise\n        except Exception as e:\n            self.log.exception(f\"An unexpected error occurred: {e}\")\n            raise\n\n    @staticmethod\n    def parse_args_kwargs(args_list):\n        args = []\n        kwargs = {}\n\n        def convert(value):\n            try:\n                return int(value)\n            except ValueError:\n                try:\n                    return float(value)\n                except ValueError:\n                    return value\n\n        for item in args_list:\n            if \"=\" in item:\n                key, value = item.split(\"=\", 1)\n                kwargs[key] = convert(value)\n            else:\n                args.append(convert(item))\n        return args, kwargs\n\n    def create_bolt(self, input_type: str, output_type: str, state_type: str, **kwargs) -&gt; Bolt:\n\"\"\"\n        Create a bolt of a specific type.\n\n        Args:\n            input_type (str): The type of input config (\"batch\" or \"streaming\").\n            output_type (str): The type of output config (\"batch\" or \"streaming\").\n            state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n            **kwargs: Additional keyword arguments for initializing the bolt.\n                Keyword Arguments:\n                    Batch input config:\n                    - input_folder (str): The input folder argument.\n                    - input_s3_bucket (str): The input bucket argument.\n                    - input_s3_folder (str): The input S3 folder argument.\n                    Batch outupt config:\n                    - output_folder (str): The output folder argument.\n                    - output_s3_bucket (str): The output bucket argument.\n                    - output_s3_folder (str): The output S3 folder argument.\n                    Streaming input config:\n                    - input_kafka_cluster_connection_string (str): The input Kafka servers argument.\n                    - input_kafka_topic (str): The input kafka topic argument.\n                    - input_kafka_consumer_group_id (str): The Kafka consumer group id.\n                    Streaming output config:\n                    - output_kafka_cluster_connection_string (str): The output Kafka servers argument.\n                    - output_kafka_topic (str): The output kafka topic argument.\n                    Redis state manager config:\n                    - redis_host (str): The Redis host argument.\n                    - redis_port (str): The Redis port argument.\n                    - redis_db (str): The Redis database argument.\n                    Postgres state manager config:\n                    - postgres_host (str): The PostgreSQL host argument.\n                    - postgres_port (str): The PostgreSQL port argument.\n                    - postgres_user (str): The PostgreSQL user argument.\n                    - postgres_password (str): The PostgreSQL password argument.\n                    - postgres_database (str): The PostgreSQL database argument.\n                    - postgres_table (str): The PostgreSQL table argument.\n                    DynamoDB state manager config:\n                    - dynamodb_table_name (str): The DynamoDB table name argument.\n                    - dynamodb_region_name (str): The DynamoDB region name argument.\n\n        Returns:\n            Bolt: The created bolt.\n        \"\"\"\n        return Bolt.create(\n            klass=self.discovered_bolt.klass,\n            input_type=input_type,\n            output_type=output_type,\n            state_type=state_type,\n            **kwargs,\n        )\n\n    def execute_bolt(self, bolt: Bolt, method_name: str, *args, **kwargs):\n\"\"\"\n        Execute a method of a bolt.\n\n        Args:\n            bolt (Bolt): The bolt to execute.\n            method_name (str): The name of the method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n\n        Returns:\n            Any: The result of the method.\n        \"\"\"\n        return bolt.__call__(method_name, *args, **kwargs)\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.__init__","title":"<code>__init__(discovered_bolt)</code>","text":"<p>Initialize BoltCtl with a DiscoveredBolt object.</p> <p>Parameters:</p> Name Type Description Default <code>discovered_bolt</code> <code>DiscoveredBolt</code> <p>DiscoveredBolt object used to create and manage bolts.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def __init__(self, discovered_bolt: DiscoveredBolt):\n\"\"\"\n    Initialize BoltCtl with a DiscoveredBolt object.\n\n    Args:\n        discovered_bolt (DiscoveredBolt): DiscoveredBolt object used to create and manage bolts.\n    \"\"\"\n    self.discovered_bolt = discovered_bolt\n    self.bolt = None\n    self.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.create_bolt","title":"<code>create_bolt(input_type, output_type, state_type, **kwargs)</code>","text":"<p>Create a bolt of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>input_type</code> <code>str</code> <p>The type of input config (\"batch\" or \"streaming\").</p> required <code>output_type</code> <code>str</code> <p>The type of output config (\"batch\" or \"streaming\").</p> required <code>state_type</code> <code>str</code> <p>The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").</p> required <code>**kwargs</code> <p>Additional keyword arguments for initializing the bolt. Keyword Arguments:     Batch input config:     - input_folder (str): The input folder argument.     - input_s3_bucket (str): The input bucket argument.     - input_s3_folder (str): The input S3 folder argument.     Batch outupt config:     - output_folder (str): The output folder argument.     - output_s3_bucket (str): The output bucket argument.     - output_s3_folder (str): The output S3 folder argument.     Streaming input config:     - input_kafka_cluster_connection_string (str): The input Kafka servers argument.     - input_kafka_topic (str): The input kafka topic argument.     - input_kafka_consumer_group_id (str): The Kafka consumer group id.     Streaming output config:     - output_kafka_cluster_connection_string (str): The output Kafka servers argument.     - output_kafka_topic (str): The output kafka topic argument.     Redis state manager config:     - redis_host (str): The Redis host argument.     - redis_port (str): The Redis port argument.     - redis_db (str): The Redis database argument.     Postgres state manager config:     - postgres_host (str): The PostgreSQL host argument.     - postgres_port (str): The PostgreSQL port argument.     - postgres_user (str): The PostgreSQL user argument.     - postgres_password (str): The PostgreSQL password argument.     - postgres_database (str): The PostgreSQL database argument.     - postgres_table (str): The PostgreSQL table argument.     DynamoDB state manager config:     - dynamodb_table_name (str): The DynamoDB table name argument.     - dynamodb_region_name (str): The DynamoDB region name argument.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Bolt</code> <code>Bolt</code> <p>The created bolt.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def create_bolt(self, input_type: str, output_type: str, state_type: str, **kwargs) -&gt; Bolt:\n\"\"\"\n    Create a bolt of a specific type.\n\n    Args:\n        input_type (str): The type of input config (\"batch\" or \"streaming\").\n        output_type (str): The type of output config (\"batch\" or \"streaming\").\n        state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n        **kwargs: Additional keyword arguments for initializing the bolt.\n            Keyword Arguments:\n                Batch input config:\n                - input_folder (str): The input folder argument.\n                - input_s3_bucket (str): The input bucket argument.\n                - input_s3_folder (str): The input S3 folder argument.\n                Batch outupt config:\n                - output_folder (str): The output folder argument.\n                - output_s3_bucket (str): The output bucket argument.\n                - output_s3_folder (str): The output S3 folder argument.\n                Streaming input config:\n                - input_kafka_cluster_connection_string (str): The input Kafka servers argument.\n                - input_kafka_topic (str): The input kafka topic argument.\n                - input_kafka_consumer_group_id (str): The Kafka consumer group id.\n                Streaming output config:\n                - output_kafka_cluster_connection_string (str): The output Kafka servers argument.\n                - output_kafka_topic (str): The output kafka topic argument.\n                Redis state manager config:\n                - redis_host (str): The Redis host argument.\n                - redis_port (str): The Redis port argument.\n                - redis_db (str): The Redis database argument.\n                Postgres state manager config:\n                - postgres_host (str): The PostgreSQL host argument.\n                - postgres_port (str): The PostgreSQL port argument.\n                - postgres_user (str): The PostgreSQL user argument.\n                - postgres_password (str): The PostgreSQL password argument.\n                - postgres_database (str): The PostgreSQL database argument.\n                - postgres_table (str): The PostgreSQL table argument.\n                DynamoDB state manager config:\n                - dynamodb_table_name (str): The DynamoDB table name argument.\n                - dynamodb_region_name (str): The DynamoDB region name argument.\n\n    Returns:\n        Bolt: The created bolt.\n    \"\"\"\n    return Bolt.create(\n        klass=self.discovered_bolt.klass,\n        input_type=input_type,\n        output_type=output_type,\n        state_type=state_type,\n        **kwargs,\n    )\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.create_parser","title":"<code>create_parser(parser)</code>","text":"<p>Add arguments to the command-line parser for managing the bolt.</p> <p>Parameters:</p> Name Type Description Default <code>parser</code> <code>argparse.ArgumentParser</code> <p>Command-line parser.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def create_parser(self, parser):\n\"\"\"\n    Add arguments to the command-line parser for managing the bolt.\n\n    Args:\n        parser (argparse.ArgumentParser): Command-line parser.\n    \"\"\"\n    subparsers = parser.add_subparsers(dest=\"command\")\n\n    # Create subparser for 'run' command\n    run_parser = subparsers.add_parser(\"run\", help=\"Run a bolt locally.\")\n\n    run_parser.add_argument(\n        \"input_type\",\n        choices=[\"batch\", \"streaming\"],\n        help=\"Choose the type of input configuration: batch or streaming.\",\n        default=\"batch\",\n    )\n    run_parser.add_argument(\n        \"output_type\",\n        choices=[\"batch\", \"streaming\"],\n        help=\"Choose the type of output configuration: batch or streaming.\",\n        default=\"batch\",\n    )\n    run_parser.add_argument(\n        \"state_type\",\n        choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"],\n        help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\",\n        default=\"in_memory\",\n    )\n    run_parser.add_argument(\n        \"--input_folder\",\n        help=\"Specify the directory where output files should be stored temporarily.\",\n        default=\"/tmp\",\n        type=str,\n    )\n    run_parser.add_argument(\n        \"--input_kafka_topic\",\n        help=\"Kafka output topic for streaming spouts.\",\n        default=\"test\",\n        type=str,\n    )\n    run_parser.add_argument(\n        \"--input_kafka_cluster_connection_string\",\n        help=\"Kafka connection string for streaming spouts.\",\n        default=\"localhost:9092\",\n        type=str,\n    )\n    run_parser.add_argument(\n        \"--input_s3_bucket\",\n        help=\"Provide the name of the S3 bucket for output storage.\",\n        default=\"my-bucket\",\n        type=str,\n    )\n    run_parser.add_argument(\n        \"--input_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n    )\n    run_parser.add_argument(\n        \"--output_folder\",\n        help=\"Specify the directory where output files should be stored temporarily.\",\n        default=\"/tmp\",\n        type=str,\n    )\n    run_parser.add_argument(\n        \"--output_kafka_topic\",\n        help=\"Kafka output topic for streaming spouts.\",\n        default=\"test\",\n        type=str,\n    )\n    run_parser.add_argument(\n        \"--output_kafka_cluster_connection_string\",\n        help=\"Kafka connection string for streaming spouts.\",\n        default=\"localhost:9092\",\n        type=str,\n    )\n    run_parser.add_argument(\n        \"--output_s3_bucket\",\n        help=\"Provide the name of the S3 bucket for output storage.\",\n        default=\"my-bucket\",\n        type=str,\n    )\n    run_parser.add_argument(\n        \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n    )\n    run_parser.add_argument(\n        \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str\n    )\n    run_parser.add_argument(\n        \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int\n    )\n    run_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int)\n    run_parser.add_argument(\n        \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str\n    )\n    run_parser.add_argument(\n        \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int\n    )\n    run_parser.add_argument(\n        \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str\n    )\n    run_parser.add_argument(\n        \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str\n    )\n    run_parser.add_argument(\n        \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str\n    )\n    run_parser.add_argument(\n        \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str\n    )\n    run_parser.add_argument(\n        \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str\n    )\n    run_parser.add_argument(\n        \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str\n    )\n    run_parser.add_argument(\n        \"method_name\",\n        help=\"The name of the method to execute on the bolt.\",\n        type=str,\n    )\n    run_parser.add_argument(\n        \"--args\",\n        nargs=argparse.REMAINDER,\n        help=\"Additional keyword arguments to pass to the bolt.\",\n    )\n\n    # Create subparser for 'help' command\n    help_parser = subparsers.add_parser(\"help\", help=\"Print help for the bolt.\")\n    help_parser.add_argument(\"method\", help=\"The method to execute.\")\n\n    return parser\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.execute_bolt","title":"<code>execute_bolt(bolt, method_name, *args, **kwargs)</code>","text":"<p>Execute a method of a bolt.</p> <p>Parameters:</p> Name Type Description Default <code>bolt</code> <code>Bolt</code> <p>The bolt to execute.</p> required <code>method_name</code> <code>str</code> <p>The name of the method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>The result of the method.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def execute_bolt(self, bolt: Bolt, method_name: str, *args, **kwargs):\n\"\"\"\n    Execute a method of a bolt.\n\n    Args:\n        bolt (Bolt): The bolt to execute.\n        method_name (str): The name of the method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n\n    Returns:\n        Any: The result of the method.\n    \"\"\"\n    return bolt.__call__(method_name, *args, **kwargs)\n</code></pre>"},{"location":"core/cli_boltctl/#cli.boltctl.BoltCtl.run","title":"<code>run(args)</code>","text":"<p>Run the command-line interface.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>argparse.Namespace</code> <p>Parsed command-line arguments.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/boltctl.py</code> <pre><code>def run(self, args):\n\"\"\"\n    Run the command-line interface.\n\n    Args:\n        args (argparse.Namespace): Parsed command-line arguments.\n    \"\"\"\n    self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\"))\n    try:\n        if args.command == \"run\":\n            kwargs = {\n                k: v\n                for k, v in vars(args).items()\n                if v is not None and k not in [\"input_type\", \"output_type\", \"state_type\", \"args\", \"method_name\"]\n            }\n            other = args.args or []\n            other_args, other_kwargs = self.parse_args_kwargs(other)\n            self.bolt = self.create_bolt(args.input_type, args.output_type, args.state_type, **kwargs)\n\n            # Pass the method_name from args to execute_bolt\n            result = self.execute_bolt(self.bolt, args.method_name, *other_args, **other_kwargs)\n            self.log.info(emoji.emojize(f\"Successfully executed the bolt method: {args.method_name} :thumbs_up:\"))\n            return result\n\n        elif args.command == \"help\":\n            self.discovered_bolt.klass.print_help(self.discovered_bolt.klass)\n    except ValueError as ve:\n        self.log.exception(f\"Value error: {ve}\")\n        raise\n    except AttributeError as ae:\n        self.log.exception(f\"Attribute error: {ae}\")\n        raise\n    except KeyError as ke:\n        self.log.exception(f\"Missing key: {ke}\")\n        raise\n    except Exception as e:\n        self.log.exception(f\"An unexpected error occurred: {e}\")\n        raise\n</code></pre>"},{"location":"core/cli_discover/","title":"Discover","text":"<p>Module discovery</p>"},{"location":"core/cli_discover/#cli.discover.Discover","title":"<code>Discover</code>","text":"Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>class Discover:\n    def __init__(self, directory: Optional[str] = None):\n\"\"\"Initialize the Discover class.\"\"\"\n        self.classes: Dict[str, Any] = {}\n        self.log = logging.getLogger(self.__class__.__name__)\n        self.directory = directory\n\n    def scan_directory(self, directory: Optional[str] = None) -&gt; Dict[str, Any]:\n\"\"\"\n        Scan for spouts/bolts in installed extensions and user's codebase.\n\n        Args:\n            directory (Optional[str]): Directory to scan for user-defined spouts/bolts.\n\n        Returns:\n            Dict[str, Any]: Discovered spouts/bolts.\n        \"\"\"\n        directory = directory if directory else self.directory\n        self.log.info(emoji.emojize(\"\ud83d\udd0d Starting discovery...\"))\n\n        # Discover installed extensions\n        self.discover_installed_extensions()\n\n        # Discover user-defined spouts/bolts\n        if directory:\n            self.directory = directory\n            for root, _, files in os.walk(self.directory):\n                if \"__init__.py\" in files:\n                    module = self.import_module(root)\n                    self.find_classes(module)\n        return self.classes\n\n    def discover_installed_extensions(self):\n\"\"\"Discover installed geniusrise extensions.\"\"\"\n        self.log.info(emoji.emojize(\"\ud83d\udd0e Discovering installed extensions...\"))\n        for entry_point in pkg_resources.iter_entry_points(group=\"geniusrise.extensions\"):\n            try:\n                module = entry_point.load()\n                self.find_classes(module)\n            except Exception as e:\n                self.log.error(emoji.emojize(f\"\u274c Error discovering classes in {entry_point.name}: {e}\"))\n\n    def import_module(self, path: str):\n\"\"\"\n        Import a module given its path.\n\n        Args:\n            path (str): Path to the module.\n\n        Returns:\n            Any: Imported module.\n        \"\"\"\n        project_root = os.path.abspath(os.path.join(self.directory, \"../../../../\"))  # type: ignore\n        relative_path = os.path.relpath(path, project_root)\n        module_path = relative_path.replace(os.sep, \".\")\n        if module_path.endswith(\"__init__\"):\n            module_path = module_path[:-9]  # remove trailing '__init__'\n\n        self.log.info(emoji.emojize(f\"\ud83d\udce6 Importing module {module_path}...\"))\n        module = importlib.import_module(module_path)\n        return module\n\n    def find_classes(self, module: Any):\n\"\"\"\n        Discover spout/bolt classes in a module.\n\n        Args:\n            module (Any): Module to scan for spout/bolt classes.\n        \"\"\"\n        for name, obj in inspect.getmembers(module):\n            discovered: DiscoveredSpout | DiscoveredBolt\n            if inspect.isclass(obj) and issubclass(obj, Spout) and obj != Spout:\n                discovered = DiscoveredSpout(name=name, klass=obj, init_args=self.get_init_args(obj))\n                self.log.info(emoji.emojize(f\"\ud83d\ude80 Discovered Spout {discovered.name}\"))\n                self.classes[name] = discovered\n            elif inspect.isclass(obj) and issubclass(obj, Bolt) and obj != Bolt:\n                discovered = DiscoveredBolt(name=name, klass=obj, init_args=self.get_init_args(obj))\n                self.log.info(emoji.emojize(f\"\u26a1 Discovered Bolt {discovered.name}\"))\n                self.classes[name] = discovered\n\n    def get_init_args(self, cls: type) -&gt; Dict[str, Any]:\n\"\"\"\n        Extract initialization arguments of a class.\n\n        Args:\n            cls (type): Class to extract initialization arguments from.\n\n        Returns:\n            Dict[str, Any]: Initialization arguments.\n        \"\"\"\n        init_signature = inspect.signature(cls.__init__)  # type: ignore\n        init_params = init_signature.parameters\n        init_args = {}\n        for name, kind in init_params.items():\n            if name == \"self\":\n                continue\n            if name == \"kwargs\" or name == \"args\":\n                init_args[\"kwargs\"] = Any\n                continue\n            if isinstance(kind.annotation, ABCMeta):\n                init_args[name] = self.get_init_args(kind.annotation)\n            elif kind.annotation == inspect.Parameter.empty:\n                init_args[name] = \"No type hint provided \ud83d\ude22\"\n            else:\n                init_args[name] = kind.annotation\n        return init_args\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.__init__","title":"<code>__init__(directory=None)</code>","text":"<p>Initialize the Discover class.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def __init__(self, directory: Optional[str] = None):\n\"\"\"Initialize the Discover class.\"\"\"\n    self.classes: Dict[str, Any] = {}\n    self.log = logging.getLogger(self.__class__.__name__)\n    self.directory = directory\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.discover_installed_extensions","title":"<code>discover_installed_extensions()</code>","text":"<p>Discover installed geniusrise extensions.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def discover_installed_extensions(self):\n\"\"\"Discover installed geniusrise extensions.\"\"\"\n    self.log.info(emoji.emojize(\"\ud83d\udd0e Discovering installed extensions...\"))\n    for entry_point in pkg_resources.iter_entry_points(group=\"geniusrise.extensions\"):\n        try:\n            module = entry_point.load()\n            self.find_classes(module)\n        except Exception as e:\n            self.log.error(emoji.emojize(f\"\u274c Error discovering classes in {entry_point.name}: {e}\"))\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.find_classes","title":"<code>find_classes(module)</code>","text":"<p>Discover spout/bolt classes in a module.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>Any</code> <p>Module to scan for spout/bolt classes.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def find_classes(self, module: Any):\n\"\"\"\n    Discover spout/bolt classes in a module.\n\n    Args:\n        module (Any): Module to scan for spout/bolt classes.\n    \"\"\"\n    for name, obj in inspect.getmembers(module):\n        discovered: DiscoveredSpout | DiscoveredBolt\n        if inspect.isclass(obj) and issubclass(obj, Spout) and obj != Spout:\n            discovered = DiscoveredSpout(name=name, klass=obj, init_args=self.get_init_args(obj))\n            self.log.info(emoji.emojize(f\"\ud83d\ude80 Discovered Spout {discovered.name}\"))\n            self.classes[name] = discovered\n        elif inspect.isclass(obj) and issubclass(obj, Bolt) and obj != Bolt:\n            discovered = DiscoveredBolt(name=name, klass=obj, init_args=self.get_init_args(obj))\n            self.log.info(emoji.emojize(f\"\u26a1 Discovered Bolt {discovered.name}\"))\n            self.classes[name] = discovered\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.get_init_args","title":"<code>get_init_args(cls)</code>","text":"<p>Extract initialization arguments of a class.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>type</code> <p>Class to extract initialization arguments from.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Initialization arguments.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def get_init_args(self, cls: type) -&gt; Dict[str, Any]:\n\"\"\"\n    Extract initialization arguments of a class.\n\n    Args:\n        cls (type): Class to extract initialization arguments from.\n\n    Returns:\n        Dict[str, Any]: Initialization arguments.\n    \"\"\"\n    init_signature = inspect.signature(cls.__init__)  # type: ignore\n    init_params = init_signature.parameters\n    init_args = {}\n    for name, kind in init_params.items():\n        if name == \"self\":\n            continue\n        if name == \"kwargs\" or name == \"args\":\n            init_args[\"kwargs\"] = Any\n            continue\n        if isinstance(kind.annotation, ABCMeta):\n            init_args[name] = self.get_init_args(kind.annotation)\n        elif kind.annotation == inspect.Parameter.empty:\n            init_args[name] = \"No type hint provided \ud83d\ude22\"\n        else:\n            init_args[name] = kind.annotation\n    return init_args\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.import_module","title":"<code>import_module(path)</code>","text":"<p>Import a module given its path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the module.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Imported module.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def import_module(self, path: str):\n\"\"\"\n    Import a module given its path.\n\n    Args:\n        path (str): Path to the module.\n\n    Returns:\n        Any: Imported module.\n    \"\"\"\n    project_root = os.path.abspath(os.path.join(self.directory, \"../../../../\"))  # type: ignore\n    relative_path = os.path.relpath(path, project_root)\n    module_path = relative_path.replace(os.sep, \".\")\n    if module_path.endswith(\"__init__\"):\n        module_path = module_path[:-9]  # remove trailing '__init__'\n\n    self.log.info(emoji.emojize(f\"\ud83d\udce6 Importing module {module_path}...\"))\n    module = importlib.import_module(module_path)\n    return module\n</code></pre>"},{"location":"core/cli_discover/#cli.discover.Discover.scan_directory","title":"<code>scan_directory(directory=None)</code>","text":"<p>Scan for spouts/bolts in installed extensions and user's codebase.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Optional[str]</code> <p>Directory to scan for user-defined spouts/bolts.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Discovered spouts/bolts.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/discover.py</code> <pre><code>def scan_directory(self, directory: Optional[str] = None) -&gt; Dict[str, Any]:\n\"\"\"\n    Scan for spouts/bolts in installed extensions and user's codebase.\n\n    Args:\n        directory (Optional[str]): Directory to scan for user-defined spouts/bolts.\n\n    Returns:\n        Dict[str, Any]: Discovered spouts/bolts.\n    \"\"\"\n    directory = directory if directory else self.directory\n    self.log.info(emoji.emojize(\"\ud83d\udd0d Starting discovery...\"))\n\n    # Discover installed extensions\n    self.discover_installed_extensions()\n\n    # Discover user-defined spouts/bolts\n    if directory:\n        self.directory = directory\n        for root, _, files in os.walk(self.directory):\n            if \"__init__.py\" in files:\n                module = self.import_module(root)\n                self.find_classes(module)\n    return self.classes\n</code></pre>"},{"location":"core/cli_geniusctl/","title":"Geniusctl","text":"<p>The main command line application</p>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl","title":"<code>GeniusCtl</code>","text":"<p>Main class for managing the geniusrise CLI application.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>class GeniusCtl:\n\"\"\"\n    Main class for managing the geniusrise CLI application.\n    \"\"\"\n\n    def __init__(self):\n\"\"\"\n        Initialize GeniusCtl.\n\n        Args:\n            directory (str): The directory to scan for spouts and bolts.\n        \"\"\"\n        self.log = logging.getLogger(self.__class__.__name__)\n        self.discover = Discover()\n        discovered_components = self.discover.scan_directory(os.getenv(\"GENIUS_COMPONENTS_DIR\", \".\"))\n\n        # Segregate the discovered components based on their type\n        self.spouts = {\n            name: component\n            for name, component in discovered_components.items()\n            if isinstance(component, DiscoveredSpout)\n        }\n        self.bolts = {\n            name: component\n            for name, component in discovered_components.items()\n            if isinstance(component, DiscoveredBolt)\n        }\n\n        self.spout_ctls: Dict[str, SpoutCtl] = {}\n        self.bolt_ctls: Dict[str, BoltCtl] = {}\n\n    def create_parser(self):\n\"\"\"\n        Create a command-line parser with arguments for managing the application.\n\n        Returns:\n            argparse.ArgumentParser: Command-line parser.\n        \"\"\"\n        parser = argparse.ArgumentParser(description=\"Manage the geniusrise application.\")\n        subparsers = parser.add_subparsers(dest=\"command\")\n\n        # Create subparser for each discovered spout\n        for spout_name, discovered_spout in self.spouts.items():\n            spout_parser = subparsers.add_parser(spout_name, help=f\"Manage {spout_name}.\")\n            spout_ctl = SpoutCtl(discovered_spout)\n            self.spout_ctls[spout_name] = spout_ctl\n            spout_ctl.create_parser(spout_parser)\n\n        # Create subparser for each discovered bolt\n        for bolt_name, discovered_bolt in self.bolts.items():\n            bolt_parser = subparsers.add_parser(bolt_name, help=f\"Manage {bolt_name}.\")\n            bolt_ctl = BoltCtl(discovered_bolt)\n            self.bolt_ctls[bolt_name] = bolt_ctl\n            bolt_ctl.create_parser(bolt_parser)\n\n        # Create subparser for YAML operations\n        yaml_parser = subparsers.add_parser(\"yaml\", help=\"Control spouts and bolts with a YAML file.\")\n        # Initialize YamlCtl with both spout_ctls and bolt_ctls\n        self.yaml_ctl = YamlCtl(self.spout_ctls, self.bolt_ctls)\n        self.yaml_ctl.create_parser(yaml_parser)\n\n        # Add a 'help' command to print help for all spouts and bolts\n        help_parser = subparsers.add_parser(\"help\", help=\"Print help for all spouts and bolts.\")\n        help_parser.add_argument(\"spout_or_bolt\", nargs=\"?\", help=\"The spout or bolt to print help for.\")\n\n        # Add a 'list' command to list all discovered spouts and bolts\n        list_parser = subparsers.add_parser(\"list\", help=\"List all discovered spouts and bolts.\")\n\n        return parser\n\n    def run(self, args):\n\"\"\"\n        Run the command-line interface.\n\n        Args:\n            args (argparse.Namespace): Parsed command-line arguments.\n        \"\"\"\n        self.log.info(f\"Running command: {args.command}\")\n\n        if args.command in self.spouts:\n            self.spout_ctls[args.command].run(args)\n        elif args.command in self.bolts:\n            self.bolt_ctls[args.command].run(args)\n        elif args.command == \"yaml\":\n            self.yaml_ctl.run(args)\n        elif args.command == \"help\":\n            if args.spout_or_bolt in self.spouts:\n                self.spout_ctls[args.spout_or_bolt].run(args)\n            elif args.spout_or_bolt in self.bolts:\n                self.bolt_ctls[args.spout_or_bolt].run(args)\n            else:\n                for spout_ctl in self.spout_ctls.values():\n                    spout_ctl.run(args)\n                for bolt_ctl in self.bolt_ctls.values():\n                    bolt_ctl.run(args)\n        elif args.command == \"list\":\n            if len(self.spout.keys()) == 0:\n                print(\"No spouts or bolts discovered.\")\n            self.list_spouts_and_bolts()\n\n    def list_spouts_and_bolts(self):\n\"\"\"\n        List all discovered spouts and bolts in a table.\n        \"\"\"\n        table = PrettyTable(\n            [colored(\"Name\", \"green\"), colored(\"Type\", \"green\"), colored(\"Methods\", \"green\")], align=\"l\"\n        )\n        for spout_name in self.spouts.keys():\n            s = self.spouts[spout_name].klass\n            table.add_row(\n                [\n                    colored(spout_name, \"yellow\"),\n                    colored(\"Spout\", \"cyan\"),\n                    \"\\n\".join([x for x in dir(s) if \"fetch_\" in x]),\n                ],\n                divider=True,\n            )\n        for bolt_name in self.bolts.keys():\n            b = self.bolts[bolt_name].klass\n            table.add_row(\n                [\n                    colored(bolt_name, \"yellow\"),\n                    colored(\"Bolt\", \"magenta\"),\n                    \"\\n\".join([x for x in dir(b) if not x.startswith(\"_\")]),\n                ],\n                divider=True,\n            )\n        print(table)\n\n    def cli(self):\n\"\"\"\n        Main function to be called when geniusrise is run from the command line.\n        \"\"\"\n        parser = self.create_parser()\n        args = parser.parse_args()\n        return self.run(args)\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.__init__","title":"<code>__init__()</code>","text":"<p>Initialize GeniusCtl.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>The directory to scan for spouts and bolts.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def __init__(self):\n\"\"\"\n    Initialize GeniusCtl.\n\n    Args:\n        directory (str): The directory to scan for spouts and bolts.\n    \"\"\"\n    self.log = logging.getLogger(self.__class__.__name__)\n    self.discover = Discover()\n    discovered_components = self.discover.scan_directory(os.getenv(\"GENIUS_COMPONENTS_DIR\", \".\"))\n\n    # Segregate the discovered components based on their type\n    self.spouts = {\n        name: component\n        for name, component in discovered_components.items()\n        if isinstance(component, DiscoveredSpout)\n    }\n    self.bolts = {\n        name: component\n        for name, component in discovered_components.items()\n        if isinstance(component, DiscoveredBolt)\n    }\n\n    self.spout_ctls: Dict[str, SpoutCtl] = {}\n    self.bolt_ctls: Dict[str, BoltCtl] = {}\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.cli","title":"<code>cli()</code>","text":"<p>Main function to be called when geniusrise is run from the command line.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def cli(self):\n\"\"\"\n    Main function to be called when geniusrise is run from the command line.\n    \"\"\"\n    parser = self.create_parser()\n    args = parser.parse_args()\n    return self.run(args)\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.create_parser","title":"<code>create_parser()</code>","text":"<p>Create a command-line parser with arguments for managing the application.</p> <p>Returns:</p> Type Description <p>argparse.ArgumentParser: Command-line parser.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def create_parser(self):\n\"\"\"\n    Create a command-line parser with arguments for managing the application.\n\n    Returns:\n        argparse.ArgumentParser: Command-line parser.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Manage the geniusrise application.\")\n    subparsers = parser.add_subparsers(dest=\"command\")\n\n    # Create subparser for each discovered spout\n    for spout_name, discovered_spout in self.spouts.items():\n        spout_parser = subparsers.add_parser(spout_name, help=f\"Manage {spout_name}.\")\n        spout_ctl = SpoutCtl(discovered_spout)\n        self.spout_ctls[spout_name] = spout_ctl\n        spout_ctl.create_parser(spout_parser)\n\n    # Create subparser for each discovered bolt\n    for bolt_name, discovered_bolt in self.bolts.items():\n        bolt_parser = subparsers.add_parser(bolt_name, help=f\"Manage {bolt_name}.\")\n        bolt_ctl = BoltCtl(discovered_bolt)\n        self.bolt_ctls[bolt_name] = bolt_ctl\n        bolt_ctl.create_parser(bolt_parser)\n\n    # Create subparser for YAML operations\n    yaml_parser = subparsers.add_parser(\"yaml\", help=\"Control spouts and bolts with a YAML file.\")\n    # Initialize YamlCtl with both spout_ctls and bolt_ctls\n    self.yaml_ctl = YamlCtl(self.spout_ctls, self.bolt_ctls)\n    self.yaml_ctl.create_parser(yaml_parser)\n\n    # Add a 'help' command to print help for all spouts and bolts\n    help_parser = subparsers.add_parser(\"help\", help=\"Print help for all spouts and bolts.\")\n    help_parser.add_argument(\"spout_or_bolt\", nargs=\"?\", help=\"The spout or bolt to print help for.\")\n\n    # Add a 'list' command to list all discovered spouts and bolts\n    list_parser = subparsers.add_parser(\"list\", help=\"List all discovered spouts and bolts.\")\n\n    return parser\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.list_spouts_and_bolts","title":"<code>list_spouts_and_bolts()</code>","text":"<p>List all discovered spouts and bolts in a table.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def list_spouts_and_bolts(self):\n\"\"\"\n    List all discovered spouts and bolts in a table.\n    \"\"\"\n    table = PrettyTable(\n        [colored(\"Name\", \"green\"), colored(\"Type\", \"green\"), colored(\"Methods\", \"green\")], align=\"l\"\n    )\n    for spout_name in self.spouts.keys():\n        s = self.spouts[spout_name].klass\n        table.add_row(\n            [\n                colored(spout_name, \"yellow\"),\n                colored(\"Spout\", \"cyan\"),\n                \"\\n\".join([x for x in dir(s) if \"fetch_\" in x]),\n            ],\n            divider=True,\n        )\n    for bolt_name in self.bolts.keys():\n        b = self.bolts[bolt_name].klass\n        table.add_row(\n            [\n                colored(bolt_name, \"yellow\"),\n                colored(\"Bolt\", \"magenta\"),\n                \"\\n\".join([x for x in dir(b) if not x.startswith(\"_\")]),\n            ],\n            divider=True,\n        )\n    print(table)\n</code></pre>"},{"location":"core/cli_geniusctl/#cli.geniusctl.GeniusCtl.run","title":"<code>run(args)</code>","text":"<p>Run the command-line interface.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>argparse.Namespace</code> <p>Parsed command-line arguments.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/geniusctl.py</code> <pre><code>def run(self, args):\n\"\"\"\n    Run the command-line interface.\n\n    Args:\n        args (argparse.Namespace): Parsed command-line arguments.\n    \"\"\"\n    self.log.info(f\"Running command: {args.command}\")\n\n    if args.command in self.spouts:\n        self.spout_ctls[args.command].run(args)\n    elif args.command in self.bolts:\n        self.bolt_ctls[args.command].run(args)\n    elif args.command == \"yaml\":\n        self.yaml_ctl.run(args)\n    elif args.command == \"help\":\n        if args.spout_or_bolt in self.spouts:\n            self.spout_ctls[args.spout_or_bolt].run(args)\n        elif args.spout_or_bolt in self.bolts:\n            self.bolt_ctls[args.spout_or_bolt].run(args)\n        else:\n            for spout_ctl in self.spout_ctls.values():\n                spout_ctl.run(args)\n            for bolt_ctl in self.bolt_ctls.values():\n                bolt_ctl.run(args)\n    elif args.command == \"list\":\n        if len(self.spout.keys()) == 0:\n            print(\"No spouts or bolts discovered.\")\n        self.list_spouts_and_bolts()\n</code></pre>"},{"location":"core/cli_schema/","title":"YAML schema","text":"<p>YAML schema definition as pydantic</p>"},{"location":"core/cli_schema/#cli.schema.Bolt","title":"<code>Bolt</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines a bolt. A bolt has a name, method, optional arguments, input, output, state, and deployment.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Bolt(BaseModel):\n\"\"\"\n    This class defines a bolt. A bolt has a name, method, optional arguments, input, output, state, and deployment.\n    \"\"\"\n\n    name: str\n    method: str\n    args: Optional[ExtraKwargs]\n    input: Input\n    output: Output\n    state: State\n    deploy: Deploy\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Deploy","title":"<code>Deploy</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the deployment of the spout or bolt. The deployment can be of type k8s or ecs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Deploy(BaseModel):\n\"\"\"\n    This class defines the deployment of the spout or bolt. The deployment can be of type k8s or ecs.\n    \"\"\"\n\n    type: str\n    args: Optional[DeployArgs]\n\n    @validator(\"type\")\n    def validate_type(cls, v, values, **kwargs):\n        if v not in [\"k8s\", \"ecs\"]:\n            raise ValueError(\"Invalid deploy type\")\n        return v\n\n    @validator(\"args\", pre=True, always=True)\n    def validate_args(cls, v, values, **kwargs):\n        if \"type\" in values:\n            if values[\"type\"] == \"ecs\":\n                required_fields = [\n                    \"name\",\n                    \"namespace\",\n                    \"image\",\n                    \"replicas\",\n                    \"account_id\",\n                    \"cluster\",\n                    \"subnet_ids\",\n                    \"security_group_ids\",\n                    \"log_group\",\n                    \"cpu\",\n                    \"memory\",\n                ]\n                for field in required_fields:\n                    if not v or field not in v or not v[field]:\n                        raise ValueError(f\"Missing required field '{field}' for ecs deploy type\")\n            elif values[\"type\"] == \"k8s\":\n                required_fields = [\"name\", \"namespace\", \"image\", \"replicas\"]\n                for field in required_fields:\n                    if not v or field not in v or not v[field]:\n                        raise ValueError(f\"Missing required field '{field}' for k8s deploy type\")\n        return v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.DeployArgs","title":"<code>DeployArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the arguments for the deployment. Depending on the type of deployment (k8s, ecs), different arguments are required.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class DeployArgs(BaseModel):\n\"\"\"\n    This class defines the arguments for the deployment. Depending on the type of deployment (k8s, ecs),\n    different arguments are required.\n    \"\"\"\n\n    name: Optional[str]\n    namespace: Optional[str]\n    image: Optional[str]\n    replicas: Optional[int]\n    account_id: Optional[str]\n    cluster: Optional[str]\n    subnet_ids: Optional[List[str]]\n    security_group_ids: Optional[List[str]]\n    log_group: Optional[str]\n    cpu: Optional[int]\n    memory: Optional[int]\n\n    class Config:\n        extra = Extra.allow\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.ExtraKwargs","title":"<code>ExtraKwargs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class is used to handle any extra arguments that are not explicitly defined in the schema.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class ExtraKwargs(BaseModel):\n\"\"\"\n    This class is used to handle any extra arguments that are not explicitly defined in the schema.\n    \"\"\"\n\n    class Config:\n        extra = Extra.allow\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Geniusfile","title":"<code>Geniusfile</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the overall structure of the YAML file. It includes a version, spouts, and bolts.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Geniusfile(BaseModel):\n\"\"\"\n    This class defines the overall structure of the YAML file. It includes a version, spouts, and bolts.\n    \"\"\"\n\n    version: str\n    spouts: Dict[str, Spout]\n    bolts: Dict[str, Bolt]\n\n    @validator(\"version\")\n    def validate_version(cls, v, values, **kwargs):\n        if v != \"1\":\n            raise ValueError(\"Invalid version\")\n        return v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Input","title":"<code>Input</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the input of the bolt. The input can be of type batch, streaming, spout, or bolt.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Input(BaseModel):\n\"\"\"\n    This class defines the input of the bolt. The input can be of type batch, streaming, spout, or bolt.\n    \"\"\"\n\n    type: str\n    args: Optional[InputArgs]\n\n    @validator(\"type\")\n    def validate_type(cls, v, values, **kwargs):\n        if v not in [\"batch\", \"streaming\", \"spout\", \"bolt\"]:\n            raise ValueError(\"Invalid input type\")\n        return v\n\n    @validator(\"args\", pre=True, always=True)\n    def validate_args(cls, v, values, **kwargs):\n        if \"type\" in values:\n            if values[\"type\"] == \"batch\":\n                if not v or \"bucket\" not in v or \"folder\" not in v:\n                    raise ValueError(\"Missing required fields for batch input type\")\n            elif values[\"type\"] == \"streaming\":\n                if not v or \"input_topic\" not in v or \"kafka_servers\" not in v:\n                    raise ValueError(\"Missing required fields for streaming input type\")\n            elif values[\"type\"] in [\"spout\", \"bolt\"]:\n                if not v or \"name\" not in v:\n                    raise ValueError(f\"Missing required fields for {values['type']} input type\")\n        return v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.InputArgs","title":"<code>InputArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the arguments for the input. Depending on the type of input (batch, streaming, spout, bolt), different arguments are required.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class InputArgs(BaseModel):\n\"\"\"\n    This class defines the arguments for the input. Depending on the type of input (batch, streaming, spout, bolt),\n    different arguments are required.\n    \"\"\"\n\n    input_topic: Optional[str]\n    kafka_servers: Optional[str]\n    output_folder: Optional[str]\n    bucket: Optional[str]\n    folder: Optional[str]\n    name: Optional[str]\n\n    class Config:\n        extra = Extra.allow\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Output","title":"<code>Output</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the output of the spout or bolt. The output can be of type batch or streaming.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Output(BaseModel):\n\"\"\"\n    This class defines the output of the spout or bolt. The output can be of type batch or streaming.\n    \"\"\"\n\n    type: str\n    args: Optional[OutputArgs]\n\n    @validator(\"type\")\n    def validate_type(cls, v, values, **kwargs):\n        if v not in [\"batch\", \"streaming\"]:\n            raise ValueError(\"Invalid output type\")\n        return v\n\n    @validator(\"args\", pre=True, always=True)\n    def validate_args(cls, v, values, **kwargs):\n        if \"type\" in values:\n            if values[\"type\"] == \"batch\":\n                if not v or \"bucket\" not in v or \"folder\" not in v:\n                    raise ValueError(\"Missing required fields for batch output type\")\n            elif values[\"type\"] == \"streaming\":\n                if not v or \"output_topic\" not in v or \"kafka_servers\" not in v:\n                    raise ValueError(\"Missing required fields for streaming output type\")\n        return v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.OutputArgs","title":"<code>OutputArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the arguments for the output. Depending on the type of output (batch, streaming), different arguments are required.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class OutputArgs(BaseModel):\n\"\"\"\n    This class defines the arguments for the output. Depending on the type of output (batch, streaming),\n    different arguments are required.\n    \"\"\"\n\n    bucket: Optional[str]\n    folder: Optional[str]\n    output_topic: Optional[str]\n    kafka_servers: Optional[str]\n\n    class Config:\n        extra = Extra.allow\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.Spout","title":"<code>Spout</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines a spout. A spout has a name, method, optional arguments, output, state, and deployment.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class Spout(BaseModel):\n\"\"\"\n    This class defines a spout. A spout has a name, method, optional arguments, output, state, and deployment.\n    \"\"\"\n\n    name: str\n    method: str\n    args: Optional[ExtraKwargs]\n    output: Output\n    state: State\n    deploy: Deploy\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.State","title":"<code>State</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the state of the spout or bolt. The state can be of type in_memory, redis, postgres, or dynamodb.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class State(BaseModel):\n\"\"\"\n    This class defines the state of the spout or bolt. The state can be of type in_memory, redis, postgres, or dynamodb.\n    \"\"\"\n\n    type: str\n    args: Optional[StateArgs]\n\n    @validator(\"type\")\n    def validate_type(cls, v, values, **kwargs):\n        if v not in [\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"]:\n            raise ValueError(\"Invalid state type\")\n        return v\n\n    @validator(\"args\", pre=True, always=True)\n    def validate_args(cls, v, values, **kwargs):\n        if \"type\" in values:\n            if values[\"type\"] == \"redis\":\n                if not v or \"redis_host\" not in v or \"redis_port\" not in v or \"redis_db\" not in v:\n                    raise ValueError(\"Missing required fields for redis state type\")\n            elif values[\"type\"] == \"postgres\":\n                if (\n                    not v\n                    or \"postgres_host\" not in v\n                    or \"postgres_port\" not in v\n                    or \"postgres_user\" not in v\n                    or \"postgres_password\" not in v\n                    or \"postgres_database\" not in v\n                    or \"postgres_table\" not in v\n                ):\n                    raise ValueError(\"Missing required fields for postgres state type\")\n            elif values[\"type\"] == \"dynamodb\":\n                if not v or \"dynamodb_table_name\" not in v or \"dynamodb_region_name\" not in v:\n                    raise ValueError(\"Missing required fields for dynamodb state type\")\n        return v\n</code></pre>"},{"location":"core/cli_schema/#cli.schema.StateArgs","title":"<code>StateArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>This class defines the arguments for the state. Depending on the type of state (in_memory, redis, postgres, dynamodb), different arguments are required.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/schema.py</code> <pre><code>class StateArgs(BaseModel):\n\"\"\"\n    This class defines the arguments for the state. Depending on the type of state (in_memory, redis, postgres, dynamodb),\n    different arguments are required.\n    \"\"\"\n\n    redis_host: Optional[str]\n    redis_port: Optional[int]\n    redis_db: Optional[int]\n    postgres_host: Optional[str]\n    postgres_port: Optional[int]\n    postgres_user: Optional[str]\n    postgres_password: Optional[str]\n    postgres_database: Optional[str]\n    postgres_table: Optional[str]\n    dynamodb_table_name: Optional[str]\n    dynamodb_region_name: Optional[str]\n\n    class Config:\n        extra = Extra.allow\n</code></pre>"},{"location":"core/cli_spoutctl/","title":"Spoutctl","text":"<p>The main spout controller</p>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl","title":"<code>SpoutCtl</code>","text":"<p>Class for managing spouts end-to-end from the command line.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>class SpoutCtl:\n\"\"\"\n    Class for managing spouts end-to-end from the command line.\n    \"\"\"\n\n    def __init__(self, discovered_spout: DiscoveredSpout):\n\"\"\"\n        Initialize SpoutCtl with a DiscoveredSpout object.\n\n        Args:\n            discovered_spout (DiscoveredSpout): DiscoveredSpout object used to create and manage spouts.\n        \"\"\"\n        self.discovered_spout = discovered_spout\n        self.spout = None\n        self.log = logging.getLogger(self.__class__.__name__)\n\n    def create_parser(self, parser):\n\"\"\"\n        Add arguments to the command-line parser for managing the spout.\n\n        Args:\n            parser (argparse.ArgumentParser): Command-line parser.\n        \"\"\"\n        subparsers = parser.add_subparsers(dest=\"command\")\n\n        # Create subparser for 'create' command\n        create_parser = subparsers.add_parser(\"run\", help=\"Run a spout locally.\")\n        create_parser.add_argument(\n            \"output_type\",\n            choices=[\"batch\", \"streaming\"],\n            help=\"Choose the type of output configuration: batch or streaming.\",\n            default=\"batch\",\n        )\n        create_parser.add_argument(\n            \"state_type\",\n            choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"],\n            help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\",\n            default=\"in_memory\",\n        )\n        create_parser.add_argument(\n            \"--output_folder\",\n            help=\"Specify the directory where output files should be stored temporarily.\",\n            default=\"/tmp\",\n            type=str,\n        )\n        create_parser.add_argument(\n            \"--output_kafka_topic\",\n            help=\"Kafka output topic for streaming spouts.\",\n            default=\"test\",\n            type=str,\n        )\n        create_parser.add_argument(\n            \"--output_kafka_cluster_connection_string\",\n            help=\"Kafka connection string for streaming spouts.\",\n            default=\"localhost:9092\",\n            type=str,\n        )\n        create_parser.add_argument(\n            \"--output_s3_bucket\",\n            help=\"Provide the name of the S3 bucket for output storage.\",\n            default=\"my-bucket\",\n            type=str,\n        )\n        create_parser.add_argument(\n            \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n        )\n        create_parser.add_argument(\n            \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str\n        )\n        create_parser.add_argument(\n            \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int\n        )\n        create_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int)\n        create_parser.add_argument(\n            \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str\n        )\n        create_parser.add_argument(\n            \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int\n        )\n        create_parser.add_argument(\n            \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str\n        )\n        create_parser.add_argument(\n            \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str\n        )\n        create_parser.add_argument(\n            \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str\n        )\n        create_parser.add_argument(\n            \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str\n        )\n        create_parser.add_argument(\n            \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str\n        )\n        create_parser.add_argument(\n            \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str\n        )\n        create_parser.add_argument(\n            \"method_name\",\n            help=\"The name of the method to execute on the spout.\",\n            type=str,\n        )\n        create_parser.add_argument(\n            \"--args\",\n            nargs=argparse.REMAINDER,\n            help=\"Additional keyword arguments to pass to the spout.\",\n        )\n\n        # Create subparser for 'help' command\n        execute_parser = subparsers.add_parser(\"help\", help=\"Print help for the spout.\")\n        execute_parser.add_argument(\"method\", help=\"The method to execute.\")\n\n        return parser\n\n    def run(self, args):\n\"\"\"\n        Run the command-line interface.\n\n        Args:\n            args (argparse.Namespace): Parsed command-line arguments.\n        \"\"\"\n        self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\"))\n        try:\n            if args.command == \"run\":\n                kwargs = {\n                    k: v\n                    for k, v in vars(args).items()\n                    if v is not None and k not in [\"output_type\", \"state_type\", \"args\", \"method_name\"]\n                }\n                other = args.args or []\n                other_args, other_kwargs = self.parse_args_kwargs(other)\n                self.spout = self.create_spout(args.output_type, args.state_type, **kwargs)\n\n                # Pass the method_name from args to execute_spout\n                result = self.execute_spout(self.spout, args.method_name, *other_args, **other_kwargs)\n                return result\n\n            elif args.command == \"help\":\n                self.discovered_spout.klass.print_help(self.discovered_spout.klass)\n        except ValueError as ve:\n            self.log.exception(f\"Value error: {ve}\")\n            raise\n        except AttributeError as ae:\n            self.log.exception(f\"Attribute error: {ae}\")\n            raise\n        except Exception as e:\n            self.log.exception(f\"An unexpected error occurred: {e}\")\n            raise\n\n    @staticmethod\n    def parse_args_kwargs(args_list):\n        args = []\n        kwargs = {}\n\n        def convert(value):\n            try:\n                return int(value)\n            except ValueError:\n                try:\n                    return float(value)\n                except ValueError:\n                    return value\n\n        for item in args_list:\n            if \"=\" in item:\n                key, value = item.split(\"=\", 1)\n                kwargs[key] = convert(value)\n            else:\n                args.append(convert(item))\n        return args, kwargs\n\n    def create_spout(self, output_type: str, state_type: str, **kwargs) -&gt; Spout:\n\"\"\"\n        Create a spout of a specific type.\n\n        Args:\n            output_type (str): The type of output config (\"batch\" or \"streaming\").\n            state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n            **kwargs: Additional keyword arguments for initializing the spout.\n                Keyword Arguments:\n                    Batch output config:\n                    - output_folder (str): The directory where output files should be stored temporarily.\n                    - output_s3_bucket (str): The name of the S3 bucket for output storage.\n                    - output_s3_folder (str): The S3 folder for output storage.\n                    Streaming output config:\n                    - output_kafka_topic (str): Kafka output topic for streaming spouts.\n                    - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.\n                    Redis state manager config:\n                    - redis_host (str): The Redis host argument.\n                    - redis_port (str): The Redis port argument.\n                    - redis_db (str): The Redis database argument.\n                    Postgres state manager config:\n                    - postgres_host (str): The PostgreSQL host argument.\n                    - postgres_port (str): The PostgreSQL port argument.\n                    - postgres_user (str): The PostgreSQL user argument.\n                    - postgres_password (str): The PostgreSQL password argument.\n                    - postgres_database (str): The PostgreSQL database argument.\n                    - postgres_table (str): The PostgreSQL table argument.\n                    DynamoDB state manager config:\n                    - dynamodb_table_name (str): The DynamoDB table name argument.\n                    - dynamodb_region_name (str): The DynamoDB region name argument.\n\n        Returns:\n            Spout: The created spout.\n        \"\"\"\n        return Spout.create(klass=self.discovered_spout.klass, output_type=output_type, state_type=state_type, **kwargs)\n\n    def execute_spout(self, spout: Spout, method_name: str, *args, **kwargs):\n\"\"\"\n        Execute a method of a spout.\n\n        Args:\n            spout (Spout): The spout to execute.\n            method_name (str): The name of the method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n\n        Returns:\n            Any: The result of the method.\n        \"\"\"\n        return spout.__call__(method_name, *args, **kwargs)\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.__init__","title":"<code>__init__(discovered_spout)</code>","text":"<p>Initialize SpoutCtl with a DiscoveredSpout object.</p> <p>Parameters:</p> Name Type Description Default <code>discovered_spout</code> <code>DiscoveredSpout</code> <p>DiscoveredSpout object used to create and manage spouts.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def __init__(self, discovered_spout: DiscoveredSpout):\n\"\"\"\n    Initialize SpoutCtl with a DiscoveredSpout object.\n\n    Args:\n        discovered_spout (DiscoveredSpout): DiscoveredSpout object used to create and manage spouts.\n    \"\"\"\n    self.discovered_spout = discovered_spout\n    self.spout = None\n    self.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.create_parser","title":"<code>create_parser(parser)</code>","text":"<p>Add arguments to the command-line parser for managing the spout.</p> <p>Parameters:</p> Name Type Description Default <code>parser</code> <code>argparse.ArgumentParser</code> <p>Command-line parser.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def create_parser(self, parser):\n\"\"\"\n    Add arguments to the command-line parser for managing the spout.\n\n    Args:\n        parser (argparse.ArgumentParser): Command-line parser.\n    \"\"\"\n    subparsers = parser.add_subparsers(dest=\"command\")\n\n    # Create subparser for 'create' command\n    create_parser = subparsers.add_parser(\"run\", help=\"Run a spout locally.\")\n    create_parser.add_argument(\n        \"output_type\",\n        choices=[\"batch\", \"streaming\"],\n        help=\"Choose the type of output configuration: batch or streaming.\",\n        default=\"batch\",\n    )\n    create_parser.add_argument(\n        \"state_type\",\n        choices=[\"in_memory\", \"redis\", \"postgres\", \"dynamodb\"],\n        help=\"Select the type of state manager: in_memory, redis, postgres, or dynamodb.\",\n        default=\"in_memory\",\n    )\n    create_parser.add_argument(\n        \"--output_folder\",\n        help=\"Specify the directory where output files should be stored temporarily.\",\n        default=\"/tmp\",\n        type=str,\n    )\n    create_parser.add_argument(\n        \"--output_kafka_topic\",\n        help=\"Kafka output topic for streaming spouts.\",\n        default=\"test\",\n        type=str,\n    )\n    create_parser.add_argument(\n        \"--output_kafka_cluster_connection_string\",\n        help=\"Kafka connection string for streaming spouts.\",\n        default=\"localhost:9092\",\n        type=str,\n    )\n    create_parser.add_argument(\n        \"--output_s3_bucket\",\n        help=\"Provide the name of the S3 bucket for output storage.\",\n        default=\"my-bucket\",\n        type=str,\n    )\n    create_parser.add_argument(\n        \"--output_s3_folder\", help=\"Indicate the S3 folder for output storage.\", default=\"my-s3-folder\", type=str\n    )\n    create_parser.add_argument(\n        \"--redis_host\", help=\"Enter the host address for the Redis server.\", default=\"localhost\", type=str\n    )\n    create_parser.add_argument(\n        \"--redis_port\", help=\"Enter the port number for the Redis server.\", default=6379, type=int\n    )\n    create_parser.add_argument(\"--redis_db\", help=\"Specify the Redis database to be used.\", default=0, type=int)\n    create_parser.add_argument(\n        \"--postgres_host\", help=\"Enter the host address for the PostgreSQL server.\", default=\"localhost\", type=str\n    )\n    create_parser.add_argument(\n        \"--postgres_port\", help=\"Enter the port number for the PostgreSQL server.\", default=5432, type=int\n    )\n    create_parser.add_argument(\n        \"--postgres_user\", help=\"Provide the username for the PostgreSQL server.\", default=\"postgres\", type=str\n    )\n    create_parser.add_argument(\n        \"--postgres_password\", help=\"Provide the password for the PostgreSQL server.\", default=\"password\", type=str\n    )\n    create_parser.add_argument(\n        \"--postgres_database\", help=\"Specify the PostgreSQL database to be used.\", default=\"mydatabase\", type=str\n    )\n    create_parser.add_argument(\n        \"--postgres_table\", help=\"Specify the PostgreSQL table to be used.\", default=\"mytable\", type=str\n    )\n    create_parser.add_argument(\n        \"--dynamodb_table_name\", help=\"Provide the name of the DynamoDB table.\", default=\"mytable\", type=str\n    )\n    create_parser.add_argument(\n        \"--dynamodb_region_name\", help=\"Specify the AWS region for DynamoDB.\", default=\"us-west-2\", type=str\n    )\n    create_parser.add_argument(\n        \"method_name\",\n        help=\"The name of the method to execute on the spout.\",\n        type=str,\n    )\n    create_parser.add_argument(\n        \"--args\",\n        nargs=argparse.REMAINDER,\n        help=\"Additional keyword arguments to pass to the spout.\",\n    )\n\n    # Create subparser for 'help' command\n    execute_parser = subparsers.add_parser(\"help\", help=\"Print help for the spout.\")\n    execute_parser.add_argument(\"method\", help=\"The method to execute.\")\n\n    return parser\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.create_spout","title":"<code>create_spout(output_type, state_type, **kwargs)</code>","text":"<p>Create a spout of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>output_type</code> <code>str</code> <p>The type of output config (\"batch\" or \"streaming\").</p> required <code>state_type</code> <code>str</code> <p>The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").</p> required <code>**kwargs</code> <p>Additional keyword arguments for initializing the spout. Keyword Arguments:     Batch output config:     - output_folder (str): The directory where output files should be stored temporarily.     - output_s3_bucket (str): The name of the S3 bucket for output storage.     - output_s3_folder (str): The S3 folder for output storage.     Streaming output config:     - output_kafka_topic (str): Kafka output topic for streaming spouts.     - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.     Redis state manager config:     - redis_host (str): The Redis host argument.     - redis_port (str): The Redis port argument.     - redis_db (str): The Redis database argument.     Postgres state manager config:     - postgres_host (str): The PostgreSQL host argument.     - postgres_port (str): The PostgreSQL port argument.     - postgres_user (str): The PostgreSQL user argument.     - postgres_password (str): The PostgreSQL password argument.     - postgres_database (str): The PostgreSQL database argument.     - postgres_table (str): The PostgreSQL table argument.     DynamoDB state manager config:     - dynamodb_table_name (str): The DynamoDB table name argument.     - dynamodb_region_name (str): The DynamoDB region name argument.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Spout</code> <code>Spout</code> <p>The created spout.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def create_spout(self, output_type: str, state_type: str, **kwargs) -&gt; Spout:\n\"\"\"\n    Create a spout of a specific type.\n\n    Args:\n        output_type (str): The type of output config (\"batch\" or \"streaming\").\n        state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n        **kwargs: Additional keyword arguments for initializing the spout.\n            Keyword Arguments:\n                Batch output config:\n                - output_folder (str): The directory where output files should be stored temporarily.\n                - output_s3_bucket (str): The name of the S3 bucket for output storage.\n                - output_s3_folder (str): The S3 folder for output storage.\n                Streaming output config:\n                - output_kafka_topic (str): Kafka output topic for streaming spouts.\n                - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.\n                Redis state manager config:\n                - redis_host (str): The Redis host argument.\n                - redis_port (str): The Redis port argument.\n                - redis_db (str): The Redis database argument.\n                Postgres state manager config:\n                - postgres_host (str): The PostgreSQL host argument.\n                - postgres_port (str): The PostgreSQL port argument.\n                - postgres_user (str): The PostgreSQL user argument.\n                - postgres_password (str): The PostgreSQL password argument.\n                - postgres_database (str): The PostgreSQL database argument.\n                - postgres_table (str): The PostgreSQL table argument.\n                DynamoDB state manager config:\n                - dynamodb_table_name (str): The DynamoDB table name argument.\n                - dynamodb_region_name (str): The DynamoDB region name argument.\n\n    Returns:\n        Spout: The created spout.\n    \"\"\"\n    return Spout.create(klass=self.discovered_spout.klass, output_type=output_type, state_type=state_type, **kwargs)\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.execute_spout","title":"<code>execute_spout(spout, method_name, *args, **kwargs)</code>","text":"<p>Execute a method of a spout.</p> <p>Parameters:</p> Name Type Description Default <code>spout</code> <code>Spout</code> <p>The spout to execute.</p> required <code>method_name</code> <code>str</code> <p>The name of the method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>The result of the method.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def execute_spout(self, spout: Spout, method_name: str, *args, **kwargs):\n\"\"\"\n    Execute a method of a spout.\n\n    Args:\n        spout (Spout): The spout to execute.\n        method_name (str): The name of the method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n\n    Returns:\n        Any: The result of the method.\n    \"\"\"\n    return spout.__call__(method_name, *args, **kwargs)\n</code></pre>"},{"location":"core/cli_spoutctl/#cli.spoutctl.SpoutCtl.run","title":"<code>run(args)</code>","text":"<p>Run the command-line interface.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>argparse.Namespace</code> <p>Parsed command-line arguments.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/spoutctl.py</code> <pre><code>def run(self, args):\n\"\"\"\n    Run the command-line interface.\n\n    Args:\n        args (argparse.Namespace): Parsed command-line arguments.\n    \"\"\"\n    self.log.info(emoji.emojize(f\"Running command: {args.command} :rocket:\"))\n    try:\n        if args.command == \"run\":\n            kwargs = {\n                k: v\n                for k, v in vars(args).items()\n                if v is not None and k not in [\"output_type\", \"state_type\", \"args\", \"method_name\"]\n            }\n            other = args.args or []\n            other_args, other_kwargs = self.parse_args_kwargs(other)\n            self.spout = self.create_spout(args.output_type, args.state_type, **kwargs)\n\n            # Pass the method_name from args to execute_spout\n            result = self.execute_spout(self.spout, args.method_name, *other_args, **other_kwargs)\n            return result\n\n        elif args.command == \"help\":\n            self.discovered_spout.klass.print_help(self.discovered_spout.klass)\n    except ValueError as ve:\n        self.log.exception(f\"Value error: {ve}\")\n        raise\n    except AttributeError as ae:\n        self.log.exception(f\"Attribute error: {ae}\")\n        raise\n    except Exception as e:\n        self.log.exception(f\"An unexpected error occurred: {e}\")\n        raise\n</code></pre>"},{"location":"core/cli_yamlctl/","title":"YamlCtl","text":"<p>Control spouts and bolts defined in a YAML file</p>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl","title":"<code>YamlCtl</code>","text":"<p>Command-line interface for managing spouts and bolts based on a YAML configuration.</p> <p>The YamlCtl class provides methods to run specific or all spouts and bolts defined in a YAML file. The YAML file's structure is defined by the Geniusfile schema.</p> <p>Example YAML structure:</p> <pre><code>version: \"1\"\nspouts:\n  spout_name1:\n    name: \"spout1\"\n    method: \"method_name\"\n    ...\nbolts:\n  bolt_name1:\n    name: \"bolt1\"\n    method: \"method_name\"\n    ...\n</code></pre> <p>Attributes:</p> Name Type Description <code>geniusfile</code> <code>Geniusfile</code> <p>Parsed YAML configuration.</p> <code>spout_ctls</code> <code>Dict[str, SpoutCtl]</code> <p>Dictionary of SpoutCtl instances.</p> <code>bolt_ctls</code> <code>Dict[str, BoltCtl]</code> <p>Dictionary of BoltCtl instances.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>class YamlCtl:\n\"\"\"\n    Command-line interface for managing spouts and bolts based on a YAML configuration.\n\n    The YamlCtl class provides methods to run specific or all spouts and bolts defined in a YAML file.\n    The YAML file's structure is defined by the Geniusfile schema.\n\n    Example YAML structure:\n    ```\n    version: \"1\"\n    spouts:\n      spout_name1:\n        name: \"spout1\"\n        method: \"method_name\"\n        ...\n    bolts:\n      bolt_name1:\n        name: \"bolt1\"\n        method: \"method_name\"\n        ...\n    ```\n\n    Attributes:\n        geniusfile (Geniusfile): Parsed YAML configuration.\n        spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances.\n        bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances.\n    \"\"\"\n\n    def __init__(self, spout_ctls: Dict[str, SpoutCtl], bolt_ctls: Dict[str, BoltCtl]):\n\"\"\"\n        Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts.\n\n        Args:\n            spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances.\n            bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances.\n        \"\"\"\n        self.spout_ctls = spout_ctls\n        self.bolt_ctls = bolt_ctls\n        self.log = logging.getLogger(self.__class__.__name__)\n\n    def create_parser(self, parser):\n\"\"\"\n        Create and return the command-line parser for managing spouts and bolts.\n        \"\"\"\n        parser.add_argument(\"--spout\", type=str, help=\"Name of the specific spout to run.\")\n        parser.add_argument(\"--bolt\", type=str, help=\"Name of the specific bolt to run.\")\n        parser.add_argument(\"--file\", default=\".\", type=str, help=\"Path of the genius.yml file, default to .\")\n        return parser\n\n    def run(self, args):\n\"\"\"\n        Run the command-line interface for managing spouts and bolts based on provided arguments.\n        Please note that there is no ordering of the spouts and bolts in the YAML configuration.\n        Each spout and bolt is an independent entity even when connected together.\n\n        Args:\n            args (argparse.Namespace): Parsed command-line arguments.\n        \"\"\"\n        with open(args.file, \"r\") as file:\n            self.geniusfile = Geniusfile.parse_obj(yaml.safe_load(file))\n        if args.spout == \"all\":\n            self.run_spouts()\n        elif args.bolt == \"all\":\n            self.run_bolts()\n        elif args.spout:\n            self.run_spout(args.spout)\n        elif args.bolt:\n            self.run_bolt(args.bolt)\n        else:\n            self.run_spouts()\n            self.run_bolts()\n\n    def run_spouts(self):\n\"\"\"Run all spouts defined in the YAML configuration.\"\"\"\n        self.log.info(emoji.emojize(\":rocket: Running all spouts...\"))\n        for spout_name, _ in self.geniusfile.spouts.items():\n            self.run_spout(spout_name)\n\n    def run_bolts(self):\n\"\"\"Run all bolts defined in the YAML configuration.\"\"\"\n        self.log.info(emoji.emojize(\":rocket: Running all bolts...\"))\n        for bolt_name, _ in self.geniusfile.bolts.items():\n            self.run_bolt(bolt_name)\n\n    def run_spout(self, spout_name: str):\n\"\"\"\n        Run a specific spout based on its name.\n\n        Args:\n            spout_name (str): Name of the spout to run.\n        \"\"\"\n        spout = self.geniusfile.spouts.get(spout_name)\n        if not spout:\n            self.log.error(emoji.emojize(f\":x: Spout {spout_name} not found.\"))\n            return\n\n        spout_ctl = self.spout_ctls.get(spout_name)\n        if not spout_ctl:\n            self.log.error(emoji.emojize(f\":x: SpoutCtl for {spout_name} not found.\"))\n            return\n\n        self.log.info(emoji.emojize(f\":rocket: Running spout {spout_name}...\"))\n        flat_args = [\"run\", spout.output.type, spout.state.type, spout.method] + self._convert_spout(spout)\n\n        parser = argparse.ArgumentParser()\n        self.spout_ctls[spout_name].create_parser(parser)\n        namespace_args = parser.parse_args(flat_args)\n        spout_ctl.run(namespace_args)\n\n    def run_bolt(self, bolt_name: str):\n\"\"\"\n        Run a specific bolt based on its name.\n\n        Args:\n            bolt_name (str): Name of the bolt to run.\n        \"\"\"\n        bolt = self.geniusfile.bolts.get(bolt_name)\n        if not bolt:\n            self.log.error(emoji.emojize(f\":x: Bolt {bolt_name} not found.\"))\n            return\n\n        # Resolve reference if input type is \"spout\" or \"bolt\"\n        if bolt.input.type in [\"spout\", \"bolt\"]:\n            if not bolt.input.args or not bolt.input.args.name:\n                raise ValueError(emoji.emojize(f\"Need referenced spouts or bolt to be mentioned here {bolt.input}\"))\n            ref_name = bolt.input.args.name\n            resolved_output = self.resolve_reference(bolt.input.type, ref_name)\n            if not resolved_output:\n                self.log.error(emoji.emojize(f\":x: Failed to resolve reference for bolt {bolt_name}.\"))\n                return\n            bolt.input.type = resolved_output.type  # Set the resolved output type as the bolt's input type\n            bolt.input.args = resolved_output.args  # Set the resolved output args as the bolt's input args\n\n        bolt_ctl = self.bolt_ctls.get(bolt_name)\n        if not bolt_ctl:\n            self.log.error(emoji.emojize(f\":x: BoltCtl for {bolt_name} not found.\"))\n            return\n\n        self.log.info(emoji.emojize(f\":rocket: Running bolt {bolt_name}...\"))\n        flat_args = [\"run\", bolt.input.type, bolt.output.type, bolt.state.type, bolt.method] + self._convert_bolt(bolt)\n\n        parser = argparse.ArgumentParser()\n        self.bolt_ctls[bolt_name].create_parser(parser)\n        namespace_args = parser.parse_args(flat_args)\n        bolt_ctl.run(namespace_args)\n\n    def resolve_reference(self, input_type: str, ref_name: str):\n\"\"\"\n        Resolve the reference of a bolt's input based on the input type (spout or bolt).\n\n        Args:\n            input_type (str): Type of the input (\"spout\" or \"bolt\").\n            ref_name (str): Name of the spout or bolt to refer to.\n\n        Returns:\n            Output: The output configuration of the referred spout or bolt.\n        \"\"\"\n        if input_type == \"spout\":\n            referred_spout = self.geniusfile.spouts.get(ref_name)\n            if not referred_spout:\n                self.log.error(emoji.emojize(f\":x: Referred spout {ref_name} not found.\"))\n                return None\n            return referred_spout.output\n        elif input_type == \"bolt\":\n            referred_bolt = self.geniusfile.bolts.get(ref_name)\n            if not referred_bolt:\n                self.log.error(emoji.emojize(f\":x: Referred bolt {ref_name} not found.\"))\n                return None\n            return referred_bolt.output\n        else:\n            self.log.error(emoji.emojize(f\":x: Invalid reference type {input_type}.\"))\n            return None\n\n    @typing.no_type_check\n    def _convert_spout(self, spout: Spout) -&gt; List[str]:\n        spout_args = []\n\n        # Convert output\n        if spout.output.type == \"batch\":\n            spout_args.append(f\"--output_folder={spout.output.args.folder}\")\n            spout_args.append(f\"--output_s3_bucket={spout.output.args.bucket}\")\n            spout_args.append(f\"--output_s3_folder={spout.output.args.folder}\")\n        elif spout.output.type == \"streaming\":\n            spout_args.append(f\"--output_kafka_topic={spout.output.args.output_topic}\")\n            spout_args.append(f\"--output_kafka_cluster_connection_string={spout.output.args.kafka_servers}\")\n\n        # Convert state\n        if spout.state.type == \"redis\":\n            spout_args.append(f\"--redis_host={spout.state.args.redis_host}\")\n            spout_args.append(f\"--redis_port={spout.state.args.redis_port}\")\n            spout_args.append(f\"--redis_db={spout.state.args.redis_db}\")\n        elif spout.state.type == \"postgres\":\n            spout_args.append(f\"--postgres_host={spout.state.args.postgres_host}\")\n            spout_args.append(f\"--postgres_port={spout.state.args.postgres_port}\")\n            spout_args.append(f\"--postgres_user={spout.state.args.postgres_user}\")\n            spout_args.append(f\"--postgres_password={spout.state.args.postgres_password}\")\n            spout_args.append(f\"--postgres_database={spout.state.args.postgres_database}\")\n            spout_args.append(f\"--postgres_table={spout.state.args.postgres_table}\")\n        elif spout.state.type == \"dynamodb\":\n            spout_args.append(f\"--dynamodb_table_name={spout.state.args.dynamodb_table_name}\")\n            spout_args.append(f\"--dynamodb_region_name={spout.state.args.dynamodb_region_name}\")\n\n        return spout_args\n\n    @typing.no_type_check\n    def _convert_bolt(self, bolt: Bolt) -&gt; List[str]:\n        bolt_args = []\n\n        # Convert input\n        if bolt.input.type == \"batch\":\n            bolt_args.append(f\"--input_folder={bolt.input.args.folder}\")\n            bolt_args.append(f\"--input_s3_bucket={bolt.input.args.bucket}\")\n            bolt_args.append(f\"--input_s3_folder={bolt.input.args.folder}\")\n        elif bolt.input.type == \"streaming\":\n            bolt_args.append(f\"--input_kafka_topic={bolt.input.args.input_topic}\")\n            bolt_args.append(f\"--input_kafka_cluster_connection_string={bolt.input.args.kafka_servers}\")\n\n        # Convert output\n        if bolt.output.type == \"batch\":\n            bolt_args.append(f\"--output_folder={bolt.output.args.folder}\")\n            bolt_args.append(f\"--output_s3_bucket={bolt.output.args.bucket}\")\n            bolt_args.append(f\"--output_s3_folder={bolt.output.args.folder}\")\n        elif bolt.output.type == \"streaming\":\n            bolt_args.append(f\"--output_kafka_topic={bolt.output.args.output_topic}\")\n            bolt_args.append(f\"--output_kafka_cluster_connection_string={bolt.output.args.kafka_servers}\")\n\n        # Convert state\n        if bolt.state.type == \"redis\":\n            bolt_args.append(f\"--redis_host={bolt.state.args.redis_host}\")\n            bolt_args.append(f\"--redis_port={bolt.state.args.redis_port}\")\n            bolt_args.append(f\"--redis_db={bolt.state.args.redis_db}\")\n        elif bolt.state.type == \"postgres\":\n            bolt_args.append(f\"--postgres_host={bolt.state.args.postgres_host}\")\n            bolt_args.append(f\"--postgres_port={bolt.state.args.postgres_port}\")\n            bolt_args.append(f\"--postgres_user={bolt.state.args.postgres_user}\")\n            bolt_args.append(f\"--postgres_password={bolt.state.args.postgres_password}\")\n            bolt_args.append(f\"--postgres_database={bolt.state.args.postgres_database}\")\n            bolt_args.append(f\"--postgres_table={bolt.state.args.postgres_table}\")\n        elif bolt.state.type == \"dynamodb\":\n            bolt_args.append(f\"--dynamodb_table_name={bolt.state.args.dynamodb_table_name}\")\n            bolt_args.append(f\"--dynamodb_region_name={bolt.state.args.dynamodb_region_name}\")\n\n        return bolt_args\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.__init__","title":"<code>__init__(spout_ctls, bolt_ctls)</code>","text":"<p>Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts.</p> <p>Parameters:</p> Name Type Description Default <code>spout_ctls</code> <code>Dict[str, SpoutCtl]</code> <p>Dictionary of SpoutCtl instances.</p> required <code>bolt_ctls</code> <code>Dict[str, BoltCtl]</code> <p>Dictionary of BoltCtl instances.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def __init__(self, spout_ctls: Dict[str, SpoutCtl], bolt_ctls: Dict[str, BoltCtl]):\n\"\"\"\n    Initialize YamlCtl with the path to the YAML file and control instances for spouts and bolts.\n\n    Args:\n        spout_ctls (Dict[str, SpoutCtl]): Dictionary of SpoutCtl instances.\n        bolt_ctls (Dict[str, BoltCtl]): Dictionary of BoltCtl instances.\n    \"\"\"\n    self.spout_ctls = spout_ctls\n    self.bolt_ctls = bolt_ctls\n    self.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.create_parser","title":"<code>create_parser(parser)</code>","text":"<p>Create and return the command-line parser for managing spouts and bolts.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def create_parser(self, parser):\n\"\"\"\n    Create and return the command-line parser for managing spouts and bolts.\n    \"\"\"\n    parser.add_argument(\"--spout\", type=str, help=\"Name of the specific spout to run.\")\n    parser.add_argument(\"--bolt\", type=str, help=\"Name of the specific bolt to run.\")\n    parser.add_argument(\"--file\", default=\".\", type=str, help=\"Path of the genius.yml file, default to .\")\n    return parser\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.resolve_reference","title":"<code>resolve_reference(input_type, ref_name)</code>","text":"<p>Resolve the reference of a bolt's input based on the input type (spout or bolt).</p> <p>Parameters:</p> Name Type Description Default <code>input_type</code> <code>str</code> <p>Type of the input (\"spout\" or \"bolt\").</p> required <code>ref_name</code> <code>str</code> <p>Name of the spout or bolt to refer to.</p> required <p>Returns:</p> Name Type Description <code>Output</code> <p>The output configuration of the referred spout or bolt.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def resolve_reference(self, input_type: str, ref_name: str):\n\"\"\"\n    Resolve the reference of a bolt's input based on the input type (spout or bolt).\n\n    Args:\n        input_type (str): Type of the input (\"spout\" or \"bolt\").\n        ref_name (str): Name of the spout or bolt to refer to.\n\n    Returns:\n        Output: The output configuration of the referred spout or bolt.\n    \"\"\"\n    if input_type == \"spout\":\n        referred_spout = self.geniusfile.spouts.get(ref_name)\n        if not referred_spout:\n            self.log.error(emoji.emojize(f\":x: Referred spout {ref_name} not found.\"))\n            return None\n        return referred_spout.output\n    elif input_type == \"bolt\":\n        referred_bolt = self.geniusfile.bolts.get(ref_name)\n        if not referred_bolt:\n            self.log.error(emoji.emojize(f\":x: Referred bolt {ref_name} not found.\"))\n            return None\n        return referred_bolt.output\n    else:\n        self.log.error(emoji.emojize(f\":x: Invalid reference type {input_type}.\"))\n        return None\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run","title":"<code>run(args)</code>","text":"<p>Run the command-line interface for managing spouts and bolts based on provided arguments. Please note that there is no ordering of the spouts and bolts in the YAML configuration. Each spout and bolt is an independent entity even when connected together.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>argparse.Namespace</code> <p>Parsed command-line arguments.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run(self, args):\n\"\"\"\n    Run the command-line interface for managing spouts and bolts based on provided arguments.\n    Please note that there is no ordering of the spouts and bolts in the YAML configuration.\n    Each spout and bolt is an independent entity even when connected together.\n\n    Args:\n        args (argparse.Namespace): Parsed command-line arguments.\n    \"\"\"\n    with open(args.file, \"r\") as file:\n        self.geniusfile = Geniusfile.parse_obj(yaml.safe_load(file))\n    if args.spout == \"all\":\n        self.run_spouts()\n    elif args.bolt == \"all\":\n        self.run_bolts()\n    elif args.spout:\n        self.run_spout(args.spout)\n    elif args.bolt:\n        self.run_bolt(args.bolt)\n    else:\n        self.run_spouts()\n        self.run_bolts()\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_bolt","title":"<code>run_bolt(bolt_name)</code>","text":"<p>Run a specific bolt based on its name.</p> <p>Parameters:</p> Name Type Description Default <code>bolt_name</code> <code>str</code> <p>Name of the bolt to run.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run_bolt(self, bolt_name: str):\n\"\"\"\n    Run a specific bolt based on its name.\n\n    Args:\n        bolt_name (str): Name of the bolt to run.\n    \"\"\"\n    bolt = self.geniusfile.bolts.get(bolt_name)\n    if not bolt:\n        self.log.error(emoji.emojize(f\":x: Bolt {bolt_name} not found.\"))\n        return\n\n    # Resolve reference if input type is \"spout\" or \"bolt\"\n    if bolt.input.type in [\"spout\", \"bolt\"]:\n        if not bolt.input.args or not bolt.input.args.name:\n            raise ValueError(emoji.emojize(f\"Need referenced spouts or bolt to be mentioned here {bolt.input}\"))\n        ref_name = bolt.input.args.name\n        resolved_output = self.resolve_reference(bolt.input.type, ref_name)\n        if not resolved_output:\n            self.log.error(emoji.emojize(f\":x: Failed to resolve reference for bolt {bolt_name}.\"))\n            return\n        bolt.input.type = resolved_output.type  # Set the resolved output type as the bolt's input type\n        bolt.input.args = resolved_output.args  # Set the resolved output args as the bolt's input args\n\n    bolt_ctl = self.bolt_ctls.get(bolt_name)\n    if not bolt_ctl:\n        self.log.error(emoji.emojize(f\":x: BoltCtl for {bolt_name} not found.\"))\n        return\n\n    self.log.info(emoji.emojize(f\":rocket: Running bolt {bolt_name}...\"))\n    flat_args = [\"run\", bolt.input.type, bolt.output.type, bolt.state.type, bolt.method] + self._convert_bolt(bolt)\n\n    parser = argparse.ArgumentParser()\n    self.bolt_ctls[bolt_name].create_parser(parser)\n    namespace_args = parser.parse_args(flat_args)\n    bolt_ctl.run(namespace_args)\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_bolts","title":"<code>run_bolts()</code>","text":"<p>Run all bolts defined in the YAML configuration.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run_bolts(self):\n\"\"\"Run all bolts defined in the YAML configuration.\"\"\"\n    self.log.info(emoji.emojize(\":rocket: Running all bolts...\"))\n    for bolt_name, _ in self.geniusfile.bolts.items():\n        self.run_bolt(bolt_name)\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_spout","title":"<code>run_spout(spout_name)</code>","text":"<p>Run a specific spout based on its name.</p> <p>Parameters:</p> Name Type Description Default <code>spout_name</code> <code>str</code> <p>Name of the spout to run.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run_spout(self, spout_name: str):\n\"\"\"\n    Run a specific spout based on its name.\n\n    Args:\n        spout_name (str): Name of the spout to run.\n    \"\"\"\n    spout = self.geniusfile.spouts.get(spout_name)\n    if not spout:\n        self.log.error(emoji.emojize(f\":x: Spout {spout_name} not found.\"))\n        return\n\n    spout_ctl = self.spout_ctls.get(spout_name)\n    if not spout_ctl:\n        self.log.error(emoji.emojize(f\":x: SpoutCtl for {spout_name} not found.\"))\n        return\n\n    self.log.info(emoji.emojize(f\":rocket: Running spout {spout_name}...\"))\n    flat_args = [\"run\", spout.output.type, spout.state.type, spout.method] + self._convert_spout(spout)\n\n    parser = argparse.ArgumentParser()\n    self.spout_ctls[spout_name].create_parser(parser)\n    namespace_args = parser.parse_args(flat_args)\n    spout_ctl.run(namespace_args)\n</code></pre>"},{"location":"core/cli_yamlctl/#cli.yamlctl.YamlCtl.run_spouts","title":"<code>run_spouts()</code>","text":"<p>Run all spouts defined in the YAML configuration.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/cli/yamlctl.py</code> <pre><code>def run_spouts(self):\n\"\"\"Run all spouts defined in the YAML configuration.\"\"\"\n    self.log.info(emoji.emojize(\":rocket: Running all spouts...\"))\n    for spout_name, _ in self.geniusfile.spouts.items():\n        self.run_spout(spout_name)\n</code></pre>"},{"location":"core/config/","title":"Encironment Configuration","text":""},{"location":"core/core_bolt/","title":"Bolt","text":"<p>Core Bolt class</p>"},{"location":"core/core_bolt/#core.bolt.Bolt","title":"<code>Bolt</code>","text":"<p>             Bases: <code>Task</code></p> <p>Base class for all bolts.</p> <p>A bolt is a component that consumes streams of data, processes them, and possibly emits new data streams.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py</code> <pre><code>class Bolt(Task):\n\"\"\"\n    Base class for all bolts.\n\n    A bolt is a component that consumes streams of data, processes them, and possibly emits new data streams.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_config: InputConfig,\n        output_config: OutputConfig,\n        state_manager: StateManager,\n        **kwargs,\n    ) -&gt; None:\n\"\"\"\n        The `Bolt` class is a base class for all bolts in the given context.\n        It inherits from the `Task` class and provides methods for executing tasks\n        both locally and remotely, as well as managing their state, with state management\n        options including in-memory, Redis, PostgreSQL, and DynamoDB,\n        and input and output configurations for batch or streaming data.\n\n        The `Bolt` class uses the `InputConfig`, `OutputConfig` and `StateManager` classes, which are abstract base\n        classes for managing input configurations, output configurations and states, respectively. The `InputConfig` and\n        `OutputConfig` classes each have two subclasses: `StreamingInputConfig`, `BatchInputConfig`, `StreamingOutputConfig`\n        and `BatchOutputConfig`, which manage streaming and batch input and output configurations, respectively.\n        The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers.\n\n        The `Bolt` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method,\n        which are used to manage tasks on Amazon ECS and Kubernetes, respectively.\n\n        Usage:\n            - Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object.\n            - The InputConfig object specifies the input configuration for the bolt.\n            - The OutputConfig object specifies the output configuration for the bolt.\n            - The StateManager object handles the management of the bolt's state.\n\n        Example:\n            input_config = InputConfig(...)\n            output_config = OutputConfig(...)\n            state_manager = StateManager(...)\n            bolt = Bolt(input_config, output_config, state_manager)\n\n        Args:\n            input_config (InputConfig): The input configuration.\n            output_config (OutputConfig): The output configuration.\n            state_manager (StateManager): The state manager.\n        \"\"\"\n        super().__init__()\n        self.input_config = input_config\n        self.output_config = output_config\n        self.state_manager = state_manager\n\n        self.log = logging.getLogger(self.__class__.__name__)\n\n    def __call__(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n        Execute a method locally and manage the state.\n\n        Args:\n            method_name (str): The name of the method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n                Keyword Arguments:\n                    - Additional keyword arguments specific to the method.\n\n        Returns:\n            Any: The result of the method.\n        \"\"\"\n        try:\n            # Get the type of state manager\n            state_type = self.state_manager.get_state(self.id)\n\n            # Save the current set of class variables to the state manager\n            self.state_manager.set_state(self.id, {})\n\n            # Copy input data to local or connect to kafka and pass on the details\n            if type(self.input_config) is BatchInputConfig:\n                self.input_config.copy_from_remote()\n                input_folder = self.input_config.get()\n                kwargs[\"input_folder\"] = input_folder\n            elif type(self.input_config) is StreamingInputConfig:\n                kafka_consumer = self.input_config.get()\n                kwargs[\"kafka_consumer\"] = kafka_consumer\n\n            # Execute the task's method\n            result = self.execute(method_name, *args, **kwargs)\n\n            # Flush the output config\n            self.output_config.flush()\n\n            # Store the state as successful in the state manager\n            state = {}\n            state[\"status\"] = \"success\"\n            self.state_manager.set_state(self.id, state)\n\n            return result\n        except Exception as e:\n            state = {}\n            state[\"status\"] = \"failed\"\n            self.state_manager.set_state(self.id, state)\n            self.log.exception(f\"Failed to execute method '{method_name}': {e}\")\n            raise\n\n    @staticmethod\n    def create(klass: type, input_type: str, output_type: str, state_type: str, **kwargs) -&gt; \"Bolt\":\n\"\"\"\n        Create a bolt of a specific type.\n\n        This static method is used to create a bolt of a specific type. It takes in an input type,\n        an output type, a state type, and additional keyword arguments for initializing the bolt.\n\n        The method creates the input config, output config, and state manager based on the provided types,\n        and then creates and returns a bolt using these configurations.\n\n        Args:\n            klass (type): The Bolt class to create.\n            input_type (str): The type of input config (\"batch\" or \"streaming\").\n            output_type (str): The type of output config (\"batch\" or \"streaming\").\n            state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n            **kwargs: Additional keyword arguments for initializing the bolt.\n                Keyword Arguments:\n                    Batch input config:\n                    - input_folder (str): The input folder argument.\n                    - input_s3_bucket (str): The input bucket argument.\n                    - input_s3_folder (str): The input S3 folder argument.\n                    Batch outupt config:\n                    - output_folder (str): The output folder argument.\n                    - output_s3_bucket (str): The output bucket argument.\n                    - output_s3_folder (str): The output S3 folder argument.\n                    Streaming input config:\n                    - input_kafka_cluster_connection_string (str): The input Kafka servers argument.\n                    - input_kafka_topic (str): The input kafka topic argument.\n                    - input_kafka_consumer_group_id (str): The Kafka consumer group id.\n                    Streaming output config:\n                    - output_kafka_cluster_connection_string (str): The output Kafka servers argument.\n                    - output_kafka_topic (str): The output kafka topic argument.\n                    Redis state manager config:\n                    - redis_host (str): The Redis host argument.\n                    - redis_port (str): The Redis port argument.\n                    - redis_db (str): The Redis database argument.\n                    Postgres state manager config:\n                    - postgres_host (str): The PostgreSQL host argument.\n                    - postgres_port (str): The PostgreSQL port argument.\n                    - postgres_user (str): The PostgreSQL user argument.\n                    - postgres_password (str): The PostgreSQL password argument.\n                    - postgres_database (str): The PostgreSQL database argument.\n                    - postgres_table (str): The PostgreSQL table argument.\n                    DynamoDB state manager config:\n                    - dynamodb_table_name (str): The DynamoDB table name argument.\n                    - dynamodb_region_name (str): The DynamoDB region name argument.\n\n        Returns:\n            Bolt: The created bolt.\n\n        Raises:\n            ValueError: If an invalid input type, output type, or state type is provided.\n        \"\"\"\n        # Create the input config\n        input_config: BatchInputConfig | StreamingInputConfig\n        if input_type == \"batch\":\n            input_config = BatchInputConfig(\n                input_folder=kwargs[\"input_folder\"] if \"input_folder\" in kwargs else tempfile.mkdtemp(),\n                bucket=kwargs[\"input_s3_bucket\"] if \"input_s3_bucket\" in kwargs else None,\n                s3_folder=kwargs[\"input_s3_folder\"] if \"input_s3_folder\" in kwargs else None,\n            )\n        elif input_type == \"streaming\":\n            input_config = StreamingInputConfig(\n                input_topic=kwargs[\"input_kafka_topic\"] if \"input_kafka_topic\" in kwargs else None,\n                kafka_cluster_connection_string=kwargs[\"input_kafka_cluster_connection_string\"]\n                if \"input_kafka_cluster_connection_string\" in kwargs\n                else None,\n                group_id=kwargs[\"input_kafka_consumer_group_id\"] if \"input_kafka_consumer_group_id\" in kwargs else None,\n            )\n        else:\n            raise ValueError(f\"Invalid input type: {input_type}\")\n\n        # Create the output config\n        output_config: BatchOutputConfig | StreamingOutputConfig\n        if output_type == \"batch\":\n            output_config = BatchOutputConfig(\n                output_folder=kwargs[\"output_folder\"] if \"output_folder\" in kwargs else tempfile.mkdtemp(),\n                bucket=kwargs[\"output_s3_bucket\"] if \"output_s3_bucket\" in kwargs else tempfile.mkdtemp(),\n                s3_folder=kwargs[\"output_s3_folder\"] if \"output_s3_folder\" in kwargs else tempfile.mkdtemp(),\n            )\n        elif output_type == \"streaming\":\n            output_config = StreamingOutputConfig(\n                kwargs[\"output_kafka_topic\"] if \"output_kafka_topic\" in kwargs else None,\n                kwargs[\"output_kafka_cluster_connection_string\"]\n                if \"output_kafka_cluster_connection_string\" in kwargs\n                else None,\n            )\n        else:\n            raise ValueError(f\"Invalid output type: {output_type}\")\n\n        # Create the state manager\n        state_manager: StateManager\n        if state_type == \"in_memory\":\n            state_manager = InMemoryStateManager()\n        elif state_type == \"redis\":\n            state_manager = RedisStateManager(\n                host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None,\n                port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None,\n                db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None,\n            )\n        elif state_type == \"postgres\":\n            state_manager = PostgresStateManager(\n                host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None,\n                port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None,\n                user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None,\n                password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None,\n                database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None,\n                table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None,\n            )\n        elif state_type == \"dynamodb\":\n            state_manager = DynamoDBStateManager(\n                table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None,\n                region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None,\n            )\n        else:\n            raise ValueError(f\"Invalid state type: {state_type}\")\n\n        # Create the bolt\n        bolt = klass(\n            input_config=input_config,\n            output_config=output_config,\n            state_manager=state_manager,\n            **kwargs,\n        )\n        return bolt\n</code></pre>"},{"location":"core/core_bolt/#core.bolt.Bolt.__call__","title":"<code>__call__(method_name, *args, **kwargs)</code>","text":"<p>Execute a method locally and manage the state.</p> <p>Parameters:</p> Name Type Description Default <code>method_name</code> <code>str</code> <p>The name of the method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method. Keyword Arguments:     - Additional keyword arguments specific to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the method.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py</code> <pre><code>def __call__(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n    Execute a method locally and manage the state.\n\n    Args:\n        method_name (str): The name of the method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n            Keyword Arguments:\n                - Additional keyword arguments specific to the method.\n\n    Returns:\n        Any: The result of the method.\n    \"\"\"\n    try:\n        # Get the type of state manager\n        state_type = self.state_manager.get_state(self.id)\n\n        # Save the current set of class variables to the state manager\n        self.state_manager.set_state(self.id, {})\n\n        # Copy input data to local or connect to kafka and pass on the details\n        if type(self.input_config) is BatchInputConfig:\n            self.input_config.copy_from_remote()\n            input_folder = self.input_config.get()\n            kwargs[\"input_folder\"] = input_folder\n        elif type(self.input_config) is StreamingInputConfig:\n            kafka_consumer = self.input_config.get()\n            kwargs[\"kafka_consumer\"] = kafka_consumer\n\n        # Execute the task's method\n        result = self.execute(method_name, *args, **kwargs)\n\n        # Flush the output config\n        self.output_config.flush()\n\n        # Store the state as successful in the state manager\n        state = {}\n        state[\"status\"] = \"success\"\n        self.state_manager.set_state(self.id, state)\n\n        return result\n    except Exception as e:\n        state = {}\n        state[\"status\"] = \"failed\"\n        self.state_manager.set_state(self.id, state)\n        self.log.exception(f\"Failed to execute method '{method_name}': {e}\")\n        raise\n</code></pre>"},{"location":"core/core_bolt/#core.bolt.Bolt.__init__","title":"<code>__init__(input_config, output_config, state_manager, **kwargs)</code>","text":"<p>The <code>Bolt</code> class is a base class for all bolts in the given context. It inherits from the <code>Task</code> class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and input and output configurations for batch or streaming data.</p> <p>The <code>Bolt</code> class uses the <code>InputConfig</code>, <code>OutputConfig</code> and <code>StateManager</code> classes, which are abstract base classes for managing input configurations, output configurations and states, respectively. The <code>InputConfig</code> and <code>OutputConfig</code> classes each have two subclasses: <code>StreamingInputConfig</code>, <code>BatchInputConfig</code>, <code>StreamingOutputConfig</code> and <code>BatchOutputConfig</code>, which manage streaming and batch input and output configurations, respectively. The <code>StateManager</code> class is used to get and set state, and it has several subclasses for different types of state managers.</p> <p>The <code>Bolt</code> class also uses the <code>ECSManager</code> and <code>K8sManager</code> classes in the <code>execute_remote</code> method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively.</p> Usage <ul> <li>Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object.</li> <li>The InputConfig object specifies the input configuration for the bolt.</li> <li>The OutputConfig object specifies the output configuration for the bolt.</li> <li>The StateManager object handles the management of the bolt's state.</li> </ul> Example <p>input_config = InputConfig(...) output_config = OutputConfig(...) state_manager = StateManager(...) bolt = Bolt(input_config, output_config, state_manager)</p> <p>Parameters:</p> Name Type Description Default <code>input_config</code> <code>InputConfig</code> <p>The input configuration.</p> required <code>output_config</code> <code>OutputConfig</code> <p>The output configuration.</p> required <code>state_manager</code> <code>StateManager</code> <p>The state manager.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py</code> <pre><code>def __init__(\n    self,\n    input_config: InputConfig,\n    output_config: OutputConfig,\n    state_manager: StateManager,\n    **kwargs,\n) -&gt; None:\n\"\"\"\n    The `Bolt` class is a base class for all bolts in the given context.\n    It inherits from the `Task` class and provides methods for executing tasks\n    both locally and remotely, as well as managing their state, with state management\n    options including in-memory, Redis, PostgreSQL, and DynamoDB,\n    and input and output configurations for batch or streaming data.\n\n    The `Bolt` class uses the `InputConfig`, `OutputConfig` and `StateManager` classes, which are abstract base\n    classes for managing input configurations, output configurations and states, respectively. The `InputConfig` and\n    `OutputConfig` classes each have two subclasses: `StreamingInputConfig`, `BatchInputConfig`, `StreamingOutputConfig`\n    and `BatchOutputConfig`, which manage streaming and batch input and output configurations, respectively.\n    The `StateManager` class is used to get and set state, and it has several subclasses for different types of state managers.\n\n    The `Bolt` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method,\n    which are used to manage tasks on Amazon ECS and Kubernetes, respectively.\n\n    Usage:\n        - Create an instance of the Bolt class by providing an InputConfig object, an OutputConfig object and a StateManager object.\n        - The InputConfig object specifies the input configuration for the bolt.\n        - The OutputConfig object specifies the output configuration for the bolt.\n        - The StateManager object handles the management of the bolt's state.\n\n    Example:\n        input_config = InputConfig(...)\n        output_config = OutputConfig(...)\n        state_manager = StateManager(...)\n        bolt = Bolt(input_config, output_config, state_manager)\n\n    Args:\n        input_config (InputConfig): The input configuration.\n        output_config (OutputConfig): The output configuration.\n        state_manager (StateManager): The state manager.\n    \"\"\"\n    super().__init__()\n    self.input_config = input_config\n    self.output_config = output_config\n    self.state_manager = state_manager\n\n    self.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/core_bolt/#core.bolt.Bolt.create","title":"<code>create(klass, input_type, output_type, state_type, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a bolt of a specific type.</p> <p>This static method is used to create a bolt of a specific type. It takes in an input type, an output type, a state type, and additional keyword arguments for initializing the bolt.</p> <p>The method creates the input config, output config, and state manager based on the provided types, and then creates and returns a bolt using these configurations.</p> <p>Parameters:</p> Name Type Description Default <code>klass</code> <code>type</code> <p>The Bolt class to create.</p> required <code>input_type</code> <code>str</code> <p>The type of input config (\"batch\" or \"streaming\").</p> required <code>output_type</code> <code>str</code> <p>The type of output config (\"batch\" or \"streaming\").</p> required <code>state_type</code> <code>str</code> <p>The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").</p> required <code>**kwargs</code> <p>Additional keyword arguments for initializing the bolt. Keyword Arguments:     Batch input config:     - input_folder (str): The input folder argument.     - input_s3_bucket (str): The input bucket argument.     - input_s3_folder (str): The input S3 folder argument.     Batch outupt config:     - output_folder (str): The output folder argument.     - output_s3_bucket (str): The output bucket argument.     - output_s3_folder (str): The output S3 folder argument.     Streaming input config:     - input_kafka_cluster_connection_string (str): The input Kafka servers argument.     - input_kafka_topic (str): The input kafka topic argument.     - input_kafka_consumer_group_id (str): The Kafka consumer group id.     Streaming output config:     - output_kafka_cluster_connection_string (str): The output Kafka servers argument.     - output_kafka_topic (str): The output kafka topic argument.     Redis state manager config:     - redis_host (str): The Redis host argument.     - redis_port (str): The Redis port argument.     - redis_db (str): The Redis database argument.     Postgres state manager config:     - postgres_host (str): The PostgreSQL host argument.     - postgres_port (str): The PostgreSQL port argument.     - postgres_user (str): The PostgreSQL user argument.     - postgres_password (str): The PostgreSQL password argument.     - postgres_database (str): The PostgreSQL database argument.     - postgres_table (str): The PostgreSQL table argument.     DynamoDB state manager config:     - dynamodb_table_name (str): The DynamoDB table name argument.     - dynamodb_region_name (str): The DynamoDB region name argument.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Bolt</code> <code>Bolt</code> <p>The created bolt.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid input type, output type, or state type is provided.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/bolt.py</code> <pre><code>@staticmethod\ndef create(klass: type, input_type: str, output_type: str, state_type: str, **kwargs) -&gt; \"Bolt\":\n\"\"\"\n    Create a bolt of a specific type.\n\n    This static method is used to create a bolt of a specific type. It takes in an input type,\n    an output type, a state type, and additional keyword arguments for initializing the bolt.\n\n    The method creates the input config, output config, and state manager based on the provided types,\n    and then creates and returns a bolt using these configurations.\n\n    Args:\n        klass (type): The Bolt class to create.\n        input_type (str): The type of input config (\"batch\" or \"streaming\").\n        output_type (str): The type of output config (\"batch\" or \"streaming\").\n        state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n        **kwargs: Additional keyword arguments for initializing the bolt.\n            Keyword Arguments:\n                Batch input config:\n                - input_folder (str): The input folder argument.\n                - input_s3_bucket (str): The input bucket argument.\n                - input_s3_folder (str): The input S3 folder argument.\n                Batch outupt config:\n                - output_folder (str): The output folder argument.\n                - output_s3_bucket (str): The output bucket argument.\n                - output_s3_folder (str): The output S3 folder argument.\n                Streaming input config:\n                - input_kafka_cluster_connection_string (str): The input Kafka servers argument.\n                - input_kafka_topic (str): The input kafka topic argument.\n                - input_kafka_consumer_group_id (str): The Kafka consumer group id.\n                Streaming output config:\n                - output_kafka_cluster_connection_string (str): The output Kafka servers argument.\n                - output_kafka_topic (str): The output kafka topic argument.\n                Redis state manager config:\n                - redis_host (str): The Redis host argument.\n                - redis_port (str): The Redis port argument.\n                - redis_db (str): The Redis database argument.\n                Postgres state manager config:\n                - postgres_host (str): The PostgreSQL host argument.\n                - postgres_port (str): The PostgreSQL port argument.\n                - postgres_user (str): The PostgreSQL user argument.\n                - postgres_password (str): The PostgreSQL password argument.\n                - postgres_database (str): The PostgreSQL database argument.\n                - postgres_table (str): The PostgreSQL table argument.\n                DynamoDB state manager config:\n                - dynamodb_table_name (str): The DynamoDB table name argument.\n                - dynamodb_region_name (str): The DynamoDB region name argument.\n\n    Returns:\n        Bolt: The created bolt.\n\n    Raises:\n        ValueError: If an invalid input type, output type, or state type is provided.\n    \"\"\"\n    # Create the input config\n    input_config: BatchInputConfig | StreamingInputConfig\n    if input_type == \"batch\":\n        input_config = BatchInputConfig(\n            input_folder=kwargs[\"input_folder\"] if \"input_folder\" in kwargs else tempfile.mkdtemp(),\n            bucket=kwargs[\"input_s3_bucket\"] if \"input_s3_bucket\" in kwargs else None,\n            s3_folder=kwargs[\"input_s3_folder\"] if \"input_s3_folder\" in kwargs else None,\n        )\n    elif input_type == \"streaming\":\n        input_config = StreamingInputConfig(\n            input_topic=kwargs[\"input_kafka_topic\"] if \"input_kafka_topic\" in kwargs else None,\n            kafka_cluster_connection_string=kwargs[\"input_kafka_cluster_connection_string\"]\n            if \"input_kafka_cluster_connection_string\" in kwargs\n            else None,\n            group_id=kwargs[\"input_kafka_consumer_group_id\"] if \"input_kafka_consumer_group_id\" in kwargs else None,\n        )\n    else:\n        raise ValueError(f\"Invalid input type: {input_type}\")\n\n    # Create the output config\n    output_config: BatchOutputConfig | StreamingOutputConfig\n    if output_type == \"batch\":\n        output_config = BatchOutputConfig(\n            output_folder=kwargs[\"output_folder\"] if \"output_folder\" in kwargs else tempfile.mkdtemp(),\n            bucket=kwargs[\"output_s3_bucket\"] if \"output_s3_bucket\" in kwargs else tempfile.mkdtemp(),\n            s3_folder=kwargs[\"output_s3_folder\"] if \"output_s3_folder\" in kwargs else tempfile.mkdtemp(),\n        )\n    elif output_type == \"streaming\":\n        output_config = StreamingOutputConfig(\n            kwargs[\"output_kafka_topic\"] if \"output_kafka_topic\" in kwargs else None,\n            kwargs[\"output_kafka_cluster_connection_string\"]\n            if \"output_kafka_cluster_connection_string\" in kwargs\n            else None,\n        )\n    else:\n        raise ValueError(f\"Invalid output type: {output_type}\")\n\n    # Create the state manager\n    state_manager: StateManager\n    if state_type == \"in_memory\":\n        state_manager = InMemoryStateManager()\n    elif state_type == \"redis\":\n        state_manager = RedisStateManager(\n            host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None,\n            port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None,\n            db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None,\n        )\n    elif state_type == \"postgres\":\n        state_manager = PostgresStateManager(\n            host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None,\n            port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None,\n            user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None,\n            password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None,\n            database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None,\n            table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None,\n        )\n    elif state_type == \"dynamodb\":\n        state_manager = DynamoDBStateManager(\n            table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None,\n            region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None,\n        )\n    else:\n        raise ValueError(f\"Invalid state type: {state_type}\")\n\n    # Create the bolt\n    bolt = klass(\n        input_config=input_config,\n        output_config=output_config,\n        state_manager=state_manager,\n        **kwargs,\n    )\n    return bolt\n</code></pre>"},{"location":"core/core_data_batch_input/","title":"Batch data input","text":"<p>Batch input manager</p>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig","title":"<code>BatchInputConfig</code>","text":"<p>             Bases: <code>InputConfig</code></p> <p>\ud83d\udcc1 BatchInputConfig: Manages batch input configurations.</p> <p>Attributes:</p> Name Type Description <code>input_folder</code> <code>str</code> <p>Folder to read input files.</p> <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> <code>s3_folder</code> <code>str</code> <p>Folder within the S3 bucket.</p> <p>Usage:</p> <pre><code>config = BatchInputConfig(\"/path/to/input\", \"my_bucket\", \"s3/folder\")\nfiles = config.list_files()\ncontent = config.read_file(\"example.txt\")\n</code></pre> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>class BatchInputConfig(InputConfig):\n\"\"\"\n    \ud83d\udcc1 BatchInputConfig: Manages batch input configurations.\n\n    Attributes:\n        input_folder (str): Folder to read input files.\n        bucket (str): S3 bucket name.\n        s3_folder (str): Folder within the S3 bucket.\n\n    Usage:\n    ```python\n    config = BatchInputConfig(\"/path/to/input\", \"my_bucket\", \"s3/folder\")\n    files = config.list_files()\n    content = config.read_file(\"example.txt\")\n    ```\n    \"\"\"\n\n    def __init__(self, input_folder: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n        Initialize a new batch input configuration.\n\n        Args:\n            input_folder (str): Folder to read input files.\n            bucket (str): S3 bucket name.\n            s3_folder (str): Folder within the S3 bucket.\n        \"\"\"\n        self.input_folder = input_folder\n        self.bucket = bucket\n        self.s3_folder = s3_folder\n        self.log = logging.getLogger(__name__)\n\n    def get(self) -&gt; str:\n\"\"\"\n        \ud83d\udccd Get the input folder location.\n\n        Returns:\n            str: The input folder location.\n\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\n        if self.input_folder:\n            return self.input_folder\n        else:\n            self.log.exception(\"\ud83d\udeab No input folder specified.\")\n            raise Exception(\"Input folder not specified.\")\n\n    def copy_from_remote(self) -&gt; None:\n\"\"\"\n        \ud83d\udd04 Copy contents from a given S3 bucket and location to the input folder.\n\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\n        if self.input_folder:\n            s3 = boto3.resource(\"s3\")\n            _bucket = s3.Bucket(self.bucket)\n            prefix = self.s3_folder if self.s3_folder.endswith(\"/\") else self.s3_folder + \"/\"\n            for obj in _bucket.objects.filter(Prefix=prefix):\n                if not os.path.exists(os.path.dirname(f\"{self.input_folder}/{obj.key}\")):\n                    os.makedirs(os.path.dirname(f\"{self.input_folder}/{obj.key}\"))\n                _bucket.download_file(obj.key, f\"{self.input_folder}/{obj.key}\")\n        else:\n            self.log.exception(\"\ud83d\udeab No input folder specified.\")\n            raise Exception(\"Input folder not specified.\")\n\n    def list_files(self) -&gt; list:\n\"\"\"\n        \ud83d\udcdc List all files in the input folder.\n\n        Returns:\n            list: A list of file paths.\n\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\n        if self.input_folder:\n            return [\n                os.path.join(self.input_folder, f)\n                for f in os.listdir(self.input_folder)\n                if os.path.isfile(os.path.join(self.input_folder, f))\n            ]\n        else:\n            self.log.exception(\"\ud83d\udeab No input folder specified.\")\n            raise Exception(\"Input folder not specified.\")\n\n    def read_file(self, filename: str) -&gt; str:\n\"\"\"\n        \ud83d\udcd6 Read a file from the input folder.\n\n        Args:\n            filename (str): The name of the file.\n\n        Returns:\n            str: The contents of the file.\n\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\n        if self.input_folder:\n            with open(os.path.join(self.input_folder, filename), \"r\") as file:\n                return file.read()\n        else:\n            self.log.exception(\"\ud83d\udeab No input folder specified.\")\n            raise Exception(\"Input folder not specified.\")\n\n    def delete_file(self, filename: str) -&gt; None:\n\"\"\"\n        \ud83d\uddd1\ufe0f Delete a file from the input folder.\n\n        Args:\n            filename (str): The name of the file.\n\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\n        if self.input_folder:\n            os.remove(os.path.join(self.input_folder, filename))\n        else:\n            self.log.exception(\"\ud83d\udeab No input folder specified.\")\n            raise Exception(\"Input folder not specified.\")\n\n    def copy_to_remote(self, filename: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n        \u2601\ufe0f Copy a file from the input folder to an S3 bucket.\n\n        Args:\n            filename (str): The name of the file.\n            bucket (str): The name of the S3 bucket.\n            s3_folder (str): The folder in the S3 bucket.\n\n        Raises:\n            Exception: If no input folder is specified.\n        \"\"\"\n        if self.input_folder:\n            s3 = boto3.resource(\"s3\")\n            s3.meta.client.upload_file(\n                os.path.join(self.input_folder, filename),\n                bucket,\n                os.path.join(s3_folder, filename),\n            )\n        else:\n            self.log.exception(\"\ud83d\udeab No input folder specified.\")\n            raise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.__init__","title":"<code>__init__(input_folder, bucket, s3_folder)</code>","text":"<p>Initialize a new batch input configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_folder</code> <code>str</code> <p>Folder to read input files.</p> required <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>s3_folder</code> <code>str</code> <p>Folder within the S3 bucket.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def __init__(self, input_folder: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n    Initialize a new batch input configuration.\n\n    Args:\n        input_folder (str): Folder to read input files.\n        bucket (str): S3 bucket name.\n        s3_folder (str): Folder within the S3 bucket.\n    \"\"\"\n    self.input_folder = input_folder\n    self.bucket = bucket\n    self.s3_folder = s3_folder\n    self.log = logging.getLogger(__name__)\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.copy_from_remote","title":"<code>copy_from_remote()</code>","text":"<p>\ud83d\udd04 Copy contents from a given S3 bucket and location to the input folder.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def copy_from_remote(self) -&gt; None:\n\"\"\"\n    \ud83d\udd04 Copy contents from a given S3 bucket and location to the input folder.\n\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\n    if self.input_folder:\n        s3 = boto3.resource(\"s3\")\n        _bucket = s3.Bucket(self.bucket)\n        prefix = self.s3_folder if self.s3_folder.endswith(\"/\") else self.s3_folder + \"/\"\n        for obj in _bucket.objects.filter(Prefix=prefix):\n            if not os.path.exists(os.path.dirname(f\"{self.input_folder}/{obj.key}\")):\n                os.makedirs(os.path.dirname(f\"{self.input_folder}/{obj.key}\"))\n            _bucket.download_file(obj.key, f\"{self.input_folder}/{obj.key}\")\n    else:\n        self.log.exception(\"\ud83d\udeab No input folder specified.\")\n        raise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.copy_to_remote","title":"<code>copy_to_remote(filename, bucket, s3_folder)</code>","text":"<p>\u2601\ufe0f Copy a file from the input folder to an S3 bucket.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file.</p> required <code>bucket</code> <code>str</code> <p>The name of the S3 bucket.</p> required <code>s3_folder</code> <code>str</code> <p>The folder in the S3 bucket.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def copy_to_remote(self, filename: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n    \u2601\ufe0f Copy a file from the input folder to an S3 bucket.\n\n    Args:\n        filename (str): The name of the file.\n        bucket (str): The name of the S3 bucket.\n        s3_folder (str): The folder in the S3 bucket.\n\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\n    if self.input_folder:\n        s3 = boto3.resource(\"s3\")\n        s3.meta.client.upload_file(\n            os.path.join(self.input_folder, filename),\n            bucket,\n            os.path.join(s3_folder, filename),\n        )\n    else:\n        self.log.exception(\"\ud83d\udeab No input folder specified.\")\n        raise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.delete_file","title":"<code>delete_file(filename)</code>","text":"<p>\ud83d\uddd1\ufe0f Delete a file from the input folder.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def delete_file(self, filename: str) -&gt; None:\n\"\"\"\n    \ud83d\uddd1\ufe0f Delete a file from the input folder.\n\n    Args:\n        filename (str): The name of the file.\n\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\n    if self.input_folder:\n        os.remove(os.path.join(self.input_folder, filename))\n    else:\n        self.log.exception(\"\ud83d\udeab No input folder specified.\")\n        raise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.get","title":"<code>get()</code>","text":"<p>\ud83d\udccd Get the input folder location.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The input folder location.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def get(self) -&gt; str:\n\"\"\"\n    \ud83d\udccd Get the input folder location.\n\n    Returns:\n        str: The input folder location.\n\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\n    if self.input_folder:\n        return self.input_folder\n    else:\n        self.log.exception(\"\ud83d\udeab No input folder specified.\")\n        raise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.list_files","title":"<code>list_files()</code>","text":"<p>\ud83d\udcdc List all files in the input folder.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of file paths.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def list_files(self) -&gt; list:\n\"\"\"\n    \ud83d\udcdc List all files in the input folder.\n\n    Returns:\n        list: A list of file paths.\n\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\n    if self.input_folder:\n        return [\n            os.path.join(self.input_folder, f)\n            for f in os.listdir(self.input_folder)\n            if os.path.isfile(os.path.join(self.input_folder, f))\n        ]\n    else:\n        self.log.exception(\"\ud83d\udeab No input folder specified.\")\n        raise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_input/#core.data.batch_input.BatchInputConfig.read_file","title":"<code>read_file(filename)</code>","text":"<p>\ud83d\udcd6 Read a file from the input folder.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The contents of the file.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input folder is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_input.py</code> <pre><code>def read_file(self, filename: str) -&gt; str:\n\"\"\"\n    \ud83d\udcd6 Read a file from the input folder.\n\n    Args:\n        filename (str): The name of the file.\n\n    Returns:\n        str: The contents of the file.\n\n    Raises:\n        Exception: If no input folder is specified.\n    \"\"\"\n    if self.input_folder:\n        with open(os.path.join(self.input_folder, filename), \"r\") as file:\n            return file.read()\n    else:\n        self.log.exception(\"\ud83d\udeab No input folder specified.\")\n        raise Exception(\"Input folder not specified.\")\n</code></pre>"},{"location":"core/core_data_batch_output/","title":"Batch data output","text":"<p>Batch output manager</p>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig","title":"<code>BatchOutputConfig</code>","text":"<p>             Bases: <code>OutputConfig</code></p> <p>\ud83d\udcc1 BatchOutputConfig: Manages batch output configurations.</p> <p>Attributes:</p> Name Type Description <code>output_folder</code> <code>str</code> <p>Folder to save output files.</p> <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> <code>s3_folder</code> <code>str</code> <p>Folder within the S3 bucket.</p> <p>Usage:</p> <pre><code>config = BatchOutputConfig(\"/path/to/output\", \"my_bucket\", \"s3/folder\")\nconfig.save({\"key\": \"value\"}, \"example.json\")\nfiles = config.list_files()\ncontent = config.read_file(\"example.json\")\n</code></pre> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>class BatchOutputConfig(OutputConfig):\n\"\"\"\n    \ud83d\udcc1 BatchOutputConfig: Manages batch output configurations.\n\n    Attributes:\n        output_folder (str): Folder to save output files.\n        bucket (str): S3 bucket name.\n        s3_folder (str): Folder within the S3 bucket.\n\n    Usage:\n    ```python\n    config = BatchOutputConfig(\"/path/to/output\", \"my_bucket\", \"s3/folder\")\n    config.save({\"key\": \"value\"}, \"example.json\")\n    files = config.list_files()\n    content = config.read_file(\"example.json\")\n    ```\n    \"\"\"\n\n    def __init__(self, output_folder: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n        Initialize a new batch output configuration.\n\n        Args:\n            output_folder (str): Folder to save output files.\n            bucket (str): S3 bucket name.\n            s3_folder (str): Folder within the S3 bucket.\n        \"\"\"\n        self.output_folder = output_folder\n        self.bucket = bucket\n        self.s3_folder = s3_folder\n        self.log = logging.getLogger(self.__class__.__name__)\n\n    def save(self, data: Any, filename: str) -&gt; None:\n\"\"\"\n        \ud83d\udcbe Save data to a file in the output folder.\n\n        Args:\n            data (Any): The data to save.\n            filename (str): The filename to use when saving the data to a file.\n        \"\"\"\n        try:\n            with open(os.path.join(self.output_folder, filename), \"w\") as f:\n                f.write(json.dumps(data))\n            self.log.debug(f\"\u2705 Wrote the data into {self.output_folder}/{filename}.\")\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to write data to file: {e}\")\n            raise\n\n    def copy_to_remote(self) -&gt; None:\n\"\"\"\n        \u2601\ufe0f Recursively copy all files and directories from the output folder to a given S3 bucket and folder.\n        \"\"\"\n        s3 = boto3.client(\"s3\")\n        try:\n            for root, _, files in os.walk(self.output_folder):\n                for filename in files:\n                    local_path = os.path.join(root, filename)\n                    relative_path = os.path.relpath(local_path, self.output_folder)\n                    s3_key = os.path.join(self.s3_folder, relative_path)\n                    s3.upload_file(local_path, self.bucket, s3_key)\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to copy files to S3: {e}\")\n            raise\n\n    def flush(self) -&gt; None:\n\"\"\"\n        \ud83d\udd04 Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder.\n        \"\"\"\n        self.copy_to_remote()\n\n    def list_files(self) -&gt; List[str]:\n\"\"\"\n        \ud83d\udcdc List all files in the output folder.\n\n        Returns:\n            list: The list of files in the output folder.\n        \"\"\"\n        return [\n            os.path.join(self.output_folder, f)\n            for f in os.listdir(self.output_folder)\n            if os.path.isfile(os.path.join(self.output_folder, f))\n        ]\n\n    def read_file(self, filename: str) -&gt; str:\n\"\"\"\n        \ud83d\udcd6 Read a file from the output folder.\n\n        Args:\n            filename (str): The name of the file to read.\n\n        Returns:\n            str: The contents of the file.\n        \"\"\"\n        with open(os.path.join(self.output_folder, filename), \"r\") as f:\n            return f.read()\n\n    def delete_file(self, filename: str) -&gt; None:\n\"\"\"\n        \ud83d\uddd1\ufe0f Delete a file from the output folder.\n\n        Args:\n            filename (str): The name of the file to delete.\n        \"\"\"\n        os.remove(os.path.join(self.output_folder, filename))\n\n    def copy_file_to_remote(self, filename: str) -&gt; None:\n\"\"\"\n        \u2601\ufe0f Copy a specific file from the output folder to the S3 bucket.\n\n        Args:\n            filename (str): The name of the file to copy.\n        \"\"\"\n        s3 = boto3.client(\"s3\")\n        try:\n            s3.upload_file(\n                os.path.join(self.output_folder, filename),\n                self.bucket,\n                os.path.join(self.s3_folder, filename),\n            )\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to copy file to S3: {e}\")\n            raise\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.__init__","title":"<code>__init__(output_folder, bucket, s3_folder)</code>","text":"<p>Initialize a new batch output configuration.</p> <p>Parameters:</p> Name Type Description Default <code>output_folder</code> <code>str</code> <p>Folder to save output files.</p> required <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>s3_folder</code> <code>str</code> <p>Folder within the S3 bucket.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def __init__(self, output_folder: str, bucket: str, s3_folder: str) -&gt; None:\n\"\"\"\n    Initialize a new batch output configuration.\n\n    Args:\n        output_folder (str): Folder to save output files.\n        bucket (str): S3 bucket name.\n        s3_folder (str): Folder within the S3 bucket.\n    \"\"\"\n    self.output_folder = output_folder\n    self.bucket = bucket\n    self.s3_folder = s3_folder\n    self.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.copy_file_to_remote","title":"<code>copy_file_to_remote(filename)</code>","text":"<p>\u2601\ufe0f Copy a specific file from the output folder to the S3 bucket.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to copy.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def copy_file_to_remote(self, filename: str) -&gt; None:\n\"\"\"\n    \u2601\ufe0f Copy a specific file from the output folder to the S3 bucket.\n\n    Args:\n        filename (str): The name of the file to copy.\n    \"\"\"\n    s3 = boto3.client(\"s3\")\n    try:\n        s3.upload_file(\n            os.path.join(self.output_folder, filename),\n            self.bucket,\n            os.path.join(self.s3_folder, filename),\n        )\n    except Exception as e:\n        self.log.exception(f\"\ud83d\udeab Failed to copy file to S3: {e}\")\n        raise\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.copy_to_remote","title":"<code>copy_to_remote()</code>","text":"<p>\u2601\ufe0f Recursively copy all files and directories from the output folder to a given S3 bucket and folder.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def copy_to_remote(self) -&gt; None:\n\"\"\"\n    \u2601\ufe0f Recursively copy all files and directories from the output folder to a given S3 bucket and folder.\n    \"\"\"\n    s3 = boto3.client(\"s3\")\n    try:\n        for root, _, files in os.walk(self.output_folder):\n            for filename in files:\n                local_path = os.path.join(root, filename)\n                relative_path = os.path.relpath(local_path, self.output_folder)\n                s3_key = os.path.join(self.s3_folder, relative_path)\n                s3.upload_file(local_path, self.bucket, s3_key)\n    except Exception as e:\n        self.log.exception(f\"\ud83d\udeab Failed to copy files to S3: {e}\")\n        raise\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.delete_file","title":"<code>delete_file(filename)</code>","text":"<p>\ud83d\uddd1\ufe0f Delete a file from the output folder.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to delete.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def delete_file(self, filename: str) -&gt; None:\n\"\"\"\n    \ud83d\uddd1\ufe0f Delete a file from the output folder.\n\n    Args:\n        filename (str): The name of the file to delete.\n    \"\"\"\n    os.remove(os.path.join(self.output_folder, filename))\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.flush","title":"<code>flush()</code>","text":"<p>\ud83d\udd04 Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def flush(self) -&gt; None:\n\"\"\"\n    \ud83d\udd04 Flush the output by copying all files and directories from the output folder to a given S3 bucket and folder.\n    \"\"\"\n    self.copy_to_remote()\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.list_files","title":"<code>list_files()</code>","text":"<p>\ud83d\udcdc List all files in the output folder.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>List[str]</code> <p>The list of files in the output folder.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def list_files(self) -&gt; List[str]:\n\"\"\"\n    \ud83d\udcdc List all files in the output folder.\n\n    Returns:\n        list: The list of files in the output folder.\n    \"\"\"\n    return [\n        os.path.join(self.output_folder, f)\n        for f in os.listdir(self.output_folder)\n        if os.path.isfile(os.path.join(self.output_folder, f))\n    ]\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.read_file","title":"<code>read_file(filename)</code>","text":"<p>\ud83d\udcd6 Read a file from the output folder.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file to read.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The contents of the file.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def read_file(self, filename: str) -&gt; str:\n\"\"\"\n    \ud83d\udcd6 Read a file from the output folder.\n\n    Args:\n        filename (str): The name of the file to read.\n\n    Returns:\n        str: The contents of the file.\n    \"\"\"\n    with open(os.path.join(self.output_folder, filename), \"r\") as f:\n        return f.read()\n</code></pre>"},{"location":"core/core_data_batch_output/#core.data.batch_output.BatchOutputConfig.save","title":"<code>save(data, filename)</code>","text":"<p>\ud83d\udcbe Save data to a file in the output folder.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to save.</p> required <code>filename</code> <code>str</code> <p>The filename to use when saving the data to a file.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/batch_output.py</code> <pre><code>def save(self, data: Any, filename: str) -&gt; None:\n\"\"\"\n    \ud83d\udcbe Save data to a file in the output folder.\n\n    Args:\n        data (Any): The data to save.\n        filename (str): The filename to use when saving the data to a file.\n    \"\"\"\n    try:\n        with open(os.path.join(self.output_folder, filename), \"w\") as f:\n            f.write(json.dumps(data))\n        self.log.debug(f\"\u2705 Wrote the data into {self.output_folder}/{filename}.\")\n    except Exception as e:\n        self.log.exception(f\"\ud83d\udeab Failed to write data to file: {e}\")\n        raise\n</code></pre>"},{"location":"core/core_data_input/","title":"Data input","text":"<p>Input manager base class</p>"},{"location":"core/core_data_input/#core.data.input.InputConfig","title":"<code>InputConfig</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class for managing input configurations.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/input.py</code> <pre><code>class InputConfig(ABC):\n\"\"\"\n    Abstract class for managing input configurations.\n    \"\"\"\n\n    @abstractmethod\n    def get(self):\n\"\"\"\n        Abstract method to get data from the input source.\n\n        Returns:\n            The data from the input source.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"core/core_data_input/#core.data.input.InputConfig.get","title":"<code>get()</code>  <code>abstractmethod</code>","text":"<p>Abstract method to get data from the input source.</p> <p>Returns:</p> Type Description <p>The data from the input source.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/input.py</code> <pre><code>@abstractmethod\ndef get(self):\n\"\"\"\n    Abstract method to get data from the input source.\n\n    Returns:\n        The data from the input source.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/core_data_output/","title":"Data output","text":"<p>Output manager base class</p>"},{"location":"core/core_data_output/#core.data.output.OutputConfig","title":"<code>OutputConfig</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract base class for managing output configurations.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py</code> <pre><code>class OutputConfig(ABC):\n\"\"\"\n    Abstract base class for managing output configurations.\n    \"\"\"\n\n    @abstractmethod\n    def save(self, data: Any, filename: str):\n\"\"\"\n        Save data to a file or ingest it into a Kafka topic.\n\n        Args:\n            data (Any): The data to save or ingest.\n            filename (str): The filename to use when saving the data to a file.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def flush(self):\n\"\"\"\n        Flush the output. This method should be implemented by subclasses.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"core/core_data_output/#core.data.output.OutputConfig.flush","title":"<code>flush()</code>  <code>abstractmethod</code>","text":"<p>Flush the output. This method should be implemented by subclasses.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py</code> <pre><code>@abstractmethod\ndef flush(self):\n\"\"\"\n    Flush the output. This method should be implemented by subclasses.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/core_data_output/#core.data.output.OutputConfig.save","title":"<code>save(data, filename)</code>  <code>abstractmethod</code>","text":"<p>Save data to a file or ingest it into a Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to save or ingest.</p> required <code>filename</code> <code>str</code> <p>The filename to use when saving the data to a file.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/output.py</code> <pre><code>@abstractmethod\ndef save(self, data: Any, filename: str):\n\"\"\"\n    Save data to a file or ingest it into a Kafka topic.\n\n    Args:\n        data (Any): The data to save or ingest.\n        filename (str): The filename to use when saving the data to a file.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/core_data_streaming_input/","title":"Streaming data input","text":"<p>Streaming input manager</p>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig","title":"<code>StreamingInputConfig</code>","text":"<p>             Bases: <code>InputConfig</code></p> <p>\ud83d\udce1 StreamingInputConfig: Manages streaming input configurations.</p> <p>Attributes:</p> Name Type Description <code>input_topic</code> <code>str</code> <p>Kafka topic to consume data.</p> <code>consumer</code> <code>KafkaConsumer</code> <p>Kafka consumer for consuming data.</p> <p>Usage:</p> <pre><code>config = StreamingInputConfig(\"my_topic\", \"localhost:9092\")\nfor message in config.iterator():\n    print(message.value)\n</code></pre> <p>Note: - Ensure the Kafka cluster is running and accessible. - Adjust the <code>group_id</code> if needed.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>class StreamingInputConfig(InputConfig):\n\"\"\"\n    \ud83d\udce1 **StreamingInputConfig**: Manages streaming input configurations.\n\n    Attributes:\n        input_topic (str): Kafka topic to consume data.\n        consumer (KafkaConsumer): Kafka consumer for consuming data.\n\n    Usage:\n    ```python\n    config = StreamingInputConfig(\"my_topic\", \"localhost:9092\")\n    for message in config.iterator():\n        print(message.value)\n    ```\n\n    Note:\n    - Ensure the Kafka cluster is running and accessible.\n    - Adjust the `group_id` if needed.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_topic: str,\n        kafka_cluster_connection_string: str,\n        group_id: str = \"geniusrise\",\n    ) -&gt; None:\n\"\"\"\n        Initialize a new streaming input configuration.\n\n        Args:\n            input_topic (str): Kafka topic to consume data.\n            kafka_cluster_connection_string (str): Kafka cluster connection string.\n            group_id (str, optional): Kafka consumer group id. Defaults to \"geniusrise\".\n        \"\"\"\n        self.input_topic = input_topic\n        self.log = logging.getLogger(self.__class__.__name__)\n        try:\n            self.consumer = KafkaConsumer(\n                self.input_topic,\n                bootstrap_servers=kafka_cluster_connection_string,\n                group_id=group_id,\n            )\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to create Kafka consumer: {e}\")\n            raise\n            self.consumer = None\n\n    def get(self) -&gt; KafkaConsumer:\n\"\"\"\n        \ud83d\udce5 Get data from the input topic.\n\n        Returns:\n            KafkaConsumer: The Kafka consumer.\n\n        Raises:\n            Exception: If no input source or consumer is specified.\n        \"\"\"\n        if self.input_topic and self.consumer:\n            try:\n                return self.consumer\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to consume from Kafka topic {self.input_topic}: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No input source specified.\")\n            raise\n\n    def iterator(self) -&gt; Iterator:\n\"\"\"\n        \ud83d\udd04 Iterator method for yielding data from the Kafka consumer.\n\n        Yields:\n            Kafka message: The next message from the Kafka consumer.\n\n        Raises:\n            Exception: If no Kafka consumer is available.\n        \"\"\"\n        if self.consumer:\n            try:\n                for message in self.consumer:\n                    yield message\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to iterate over Kafka consumer: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\n            raise\n\n    def __iter__(self) -&gt; Iterator:\n\"\"\"\n        Make the class iterable.\n        \"\"\"\n        return self\n\n    def __next__(self) -&gt; Any:\n\"\"\"\n        Get the next message from the Kafka consumer.\n\n        Raises:\n            Exception: If no Kafka consumer is available or an error occurs.\n        \"\"\"\n        if self.consumer:\n            try:\n                return next(self.consumer)\n            except StopIteration:\n                raise\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to get next message from Kafka consumer: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\n            raise\n\n    def close(self) -&gt; None:\n\"\"\"\n        \ud83d\udeaa Close the Kafka consumer.\n\n        Raises:\n            Exception: If an error occurs while closing the consumer.\n        \"\"\"\n        if self.consumer:\n            try:\n                self.consumer.close()\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to close Kafka consumer: {e}\")\n                raise\n\n    def seek(self, partition: int, offset: int) -&gt; None:\n\"\"\"\n        \ud83d\udd0d Change the position from which the Kafka consumer reads.\n\n        Args:\n            partition (int): The partition to seek.\n            offset (int): The offset to seek to.\n\n        Raises:\n            Exception: If an error occurs while seeking.\n        \"\"\"\n        if self.consumer:\n            try:\n                self.consumer.seek(partition, offset)\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to seek Kafka consumer: {e}\")\n                raise\n\n    def commit(self) -&gt; None:\n\"\"\"\n        \u2705 Manually commit offsets.\n\n        Raises:\n            Exception: If an error occurs while committing offsets.\n        \"\"\"\n        if self.consumer:\n            try:\n                self.consumer.commit()\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to commit offsets: {e}\")\n                raise\n\n    def filter_messages(self, filter_func: Callable) -&gt; Iterator:\n\"\"\"\n        \ud83d\udd0d Filter messages from the Kafka consumer based on a filter function.\n\n        Args:\n            filter_func (callable): A function that takes a Kafka message and returns a boolean.\n\n        Yields:\n            Kafka message: The next message from the Kafka consumer that passes the filter.\n\n        Raises:\n            Exception: If no Kafka consumer is available or an error occurs.\n        \"\"\"\n        if self.consumer:\n            try:\n                for message in self.consumer:\n                    if filter_func(message):\n                        yield message\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to filter messages from Kafka consumer: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\n            raise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.__init__","title":"<code>__init__(input_topic, kafka_cluster_connection_string, group_id='geniusrise')</code>","text":"<p>Initialize a new streaming input configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_topic</code> <code>str</code> <p>Kafka topic to consume data.</p> required <code>kafka_cluster_connection_string</code> <code>str</code> <p>Kafka cluster connection string.</p> required <code>group_id</code> <code>str</code> <p>Kafka consumer group id. Defaults to \"geniusrise\".</p> <code>'geniusrise'</code> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def __init__(\n    self,\n    input_topic: str,\n    kafka_cluster_connection_string: str,\n    group_id: str = \"geniusrise\",\n) -&gt; None:\n\"\"\"\n    Initialize a new streaming input configuration.\n\n    Args:\n        input_topic (str): Kafka topic to consume data.\n        kafka_cluster_connection_string (str): Kafka cluster connection string.\n        group_id (str, optional): Kafka consumer group id. Defaults to \"geniusrise\".\n    \"\"\"\n    self.input_topic = input_topic\n    self.log = logging.getLogger(self.__class__.__name__)\n    try:\n        self.consumer = KafkaConsumer(\n            self.input_topic,\n            bootstrap_servers=kafka_cluster_connection_string,\n            group_id=group_id,\n        )\n    except Exception as e:\n        self.log.exception(f\"\ud83d\udeab Failed to create Kafka consumer: {e}\")\n        raise\n        self.consumer = None\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.__iter__","title":"<code>__iter__()</code>","text":"<p>Make the class iterable.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def __iter__(self) -&gt; Iterator:\n\"\"\"\n    Make the class iterable.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.__next__","title":"<code>__next__()</code>","text":"<p>Get the next message from the Kafka consumer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka consumer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def __next__(self) -&gt; Any:\n\"\"\"\n    Get the next message from the Kafka consumer.\n\n    Raises:\n        Exception: If no Kafka consumer is available or an error occurs.\n    \"\"\"\n    if self.consumer:\n        try:\n            return next(self.consumer)\n        except StopIteration:\n            raise\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to get next message from Kafka consumer: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\n        raise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.close","title":"<code>close()</code>","text":"<p>\ud83d\udeaa Close the Kafka consumer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs while closing the consumer.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def close(self) -&gt; None:\n\"\"\"\n    \ud83d\udeaa Close the Kafka consumer.\n\n    Raises:\n        Exception: If an error occurs while closing the consumer.\n    \"\"\"\n    if self.consumer:\n        try:\n            self.consumer.close()\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to close Kafka consumer: {e}\")\n            raise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.commit","title":"<code>commit()</code>","text":"<p>\u2705 Manually commit offsets.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs while committing offsets.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def commit(self) -&gt; None:\n\"\"\"\n    \u2705 Manually commit offsets.\n\n    Raises:\n        Exception: If an error occurs while committing offsets.\n    \"\"\"\n    if self.consumer:\n        try:\n            self.consumer.commit()\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to commit offsets: {e}\")\n            raise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.filter_messages","title":"<code>filter_messages(filter_func)</code>","text":"<p>\ud83d\udd0d Filter messages from the Kafka consumer based on a filter function.</p> <p>Parameters:</p> Name Type Description Default <code>filter_func</code> <code>callable</code> <p>A function that takes a Kafka message and returns a boolean.</p> required <p>Yields:</p> Type Description <code>Iterator</code> <p>Kafka message: The next message from the Kafka consumer that passes the filter.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka consumer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def filter_messages(self, filter_func: Callable) -&gt; Iterator:\n\"\"\"\n    \ud83d\udd0d Filter messages from the Kafka consumer based on a filter function.\n\n    Args:\n        filter_func (callable): A function that takes a Kafka message and returns a boolean.\n\n    Yields:\n        Kafka message: The next message from the Kafka consumer that passes the filter.\n\n    Raises:\n        Exception: If no Kafka consumer is available or an error occurs.\n    \"\"\"\n    if self.consumer:\n        try:\n            for message in self.consumer:\n                if filter_func(message):\n                    yield message\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to filter messages from Kafka consumer: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\n        raise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.get","title":"<code>get()</code>","text":"<p>\ud83d\udce5 Get data from the input topic.</p> <p>Returns:</p> Name Type Description <code>KafkaConsumer</code> <code>KafkaConsumer</code> <p>The Kafka consumer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no input source or consumer is specified.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def get(self) -&gt; KafkaConsumer:\n\"\"\"\n    \ud83d\udce5 Get data from the input topic.\n\n    Returns:\n        KafkaConsumer: The Kafka consumer.\n\n    Raises:\n        Exception: If no input source or consumer is specified.\n    \"\"\"\n    if self.input_topic and self.consumer:\n        try:\n            return self.consumer\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to consume from Kafka topic {self.input_topic}: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No input source specified.\")\n        raise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.iterator","title":"<code>iterator()</code>","text":"<p>\ud83d\udd04 Iterator method for yielding data from the Kafka consumer.</p> <p>Yields:</p> Type Description <code>Iterator</code> <p>Kafka message: The next message from the Kafka consumer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka consumer is available.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def iterator(self) -&gt; Iterator:\n\"\"\"\n    \ud83d\udd04 Iterator method for yielding data from the Kafka consumer.\n\n    Yields:\n        Kafka message: The next message from the Kafka consumer.\n\n    Raises:\n        Exception: If no Kafka consumer is available.\n    \"\"\"\n    if self.consumer:\n        try:\n            for message in self.consumer:\n                yield message\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to iterate over Kafka consumer: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka consumer available.\")\n        raise\n</code></pre>"},{"location":"core/core_data_streaming_input/#core.data.streaming_input.StreamingInputConfig.seek","title":"<code>seek(partition, offset)</code>","text":"<p>\ud83d\udd0d Change the position from which the Kafka consumer reads.</p> <p>Parameters:</p> Name Type Description Default <code>partition</code> <code>int</code> <p>The partition to seek.</p> required <code>offset</code> <code>int</code> <p>The offset to seek to.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs while seeking.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_input.py</code> <pre><code>def seek(self, partition: int, offset: int) -&gt; None:\n\"\"\"\n    \ud83d\udd0d Change the position from which the Kafka consumer reads.\n\n    Args:\n        partition (int): The partition to seek.\n        offset (int): The offset to seek to.\n\n    Raises:\n        Exception: If an error occurs while seeking.\n    \"\"\"\n    if self.consumer:\n        try:\n            self.consumer.seek(partition, offset)\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to seek Kafka consumer: {e}\")\n            raise\n</code></pre>"},{"location":"core/core_data_streaming_output/","title":"Streaming data output","text":"<p>Streaming output manager</p>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig","title":"<code>StreamingOutputConfig</code>","text":"<p>             Bases: <code>OutputConfig</code></p> <p>\ud83d\udce1 StreamingOutputConfig: Manages streaming output configurations.</p> <p>Attributes:</p> Name Type Description <code>output_topic</code> <code>str</code> <p>Kafka topic to ingest data.</p> <code>producer</code> <code>KafkaProducer</code> <p>Kafka producer for ingesting data.</p> <p>Usage:</p> <pre><code>config = StreamingOutputConfig(\"my_topic\", \"localhost:9092\")\nconfig.save({\"key\": \"value\"}, \"ignored_filename\")\nconfig.flush()\n</code></pre> <p>Note: - Ensure the Kafka cluster is running and accessible.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>class StreamingOutputConfig(OutputConfig):\n\"\"\"\n    \ud83d\udce1 **StreamingOutputConfig**: Manages streaming output configurations.\n\n    Attributes:\n        output_topic (str): Kafka topic to ingest data.\n        producer (KafkaProducer): Kafka producer for ingesting data.\n\n    Usage:\n    ```python\n    config = StreamingOutputConfig(\"my_topic\", \"localhost:9092\")\n    config.save({\"key\": \"value\"}, \"ignored_filename\")\n    config.flush()\n    ```\n\n    Note:\n    - Ensure the Kafka cluster is running and accessible.\n    \"\"\"\n\n    def __init__(self, output_topic: str, kafka_servers: str) -&gt; None:\n\"\"\"\n        Initialize a new streaming output configuration.\n\n        Args:\n            output_topic (str): Kafka topic to ingest data.\n            kafka_servers (str): Kafka bootstrap servers.\n        \"\"\"\n        self.output_topic = output_topic\n        self.log = logging.getLogger(self.__class__.__name__)\n        try:\n            self.producer = KafkaProducer(bootstrap_servers=kafka_servers)\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to create Kafka producer: {e}\")\n            raise\n            self.producer = None\n\n    def save(self, data: Any, filename: str) -&gt; None:\n\"\"\"\n        \ud83d\udce4 Ingest data into the Kafka topic.\n\n        Args:\n            data (Any): The data to ingest.\n            filename (str): This argument is ignored for streaming outputs.\n\n        Raises:\n            Exception: If no Kafka producer is available or an error occurs.\n        \"\"\"\n        if self.producer:\n            try:\n                self.producer.send(self.output_topic, bytes(json.dumps(data).encode(\"utf-8\")))\n                self.log.debug(f\"\u2705 Inserted the data into {self.output_topic} topic.\")\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to send data to Kafka topic: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n            raise\n\n    def flush(self) -&gt; None:\n\"\"\"\n        \ud83d\udd04 Flush the output by flushing the Kafka producer.\n\n        Raises:\n            Exception: If no Kafka producer is available.\n        \"\"\"\n        if self.producer:\n            self.producer.flush()\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n            raise\n\n    def send_key_value(self, key: Any, value: Any) -&gt; None:\n\"\"\"\n        \ud83d\udd11 Send a message with a key to the Kafka topic.\n\n        Args:\n            key (Any): The key of the message.\n            value (Any): The value of the message.\n\n        Raises:\n            Exception: If no Kafka producer is available or an error occurs.\n        \"\"\"\n        if self.producer:\n            try:\n                self.producer.send(\n                    self.output_topic,\n                    key=bytes(json.dumps(key).encode(\"utf-8\")),\n                    value=bytes(json.dumps(value).encode(\"utf-8\")),\n                )\n                self.log.debug(f\"\u2705 Inserted the key-value pair into {self.output_topic} topic.\")\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to send key-value pair to Kafka topic: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n            raise\n\n    def close(self) -&gt; None:\n\"\"\"\n        \ud83d\udeaa Close the Kafka producer.\n\n        Raises:\n            Exception: If no Kafka producer is available.\n        \"\"\"\n        if self.producer:\n            self.producer.close()\n            self.producer = None\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n            raise\n\n    def partition_available(self, partition: int) -&gt; bool:\n\"\"\"\n        \ud83e\uddd0 Check if a partition is available in the Kafka topic.\n\n        Args:\n            partition (int): The partition to check.\n\n        Returns:\n            bool: True if the partition is available, False otherwise.\n\n        Raises:\n            Exception: If no Kafka producer is available.\n        \"\"\"\n        if self.producer:\n            return partition in self.producer.partitions_for(self.output_topic)\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n            raise\n            return False\n\n    def save_to_partition(self, value: Any, partition: int) -&gt; None:\n\"\"\"\n        \ud83c\udfaf Send a message to a specific partition in the Kafka topic.\n\n        Args:\n            value (Any): The value of the message.\n            partition (int): The partition to send the message to.\n\n        Raises:\n            Exception: If no Kafka producer is available or an error occurs.\n        \"\"\"\n        if self.producer:\n            try:\n                self.producer.send(\n                    self.output_topic,\n                    value=bytes(json.dumps(value).encode(\"utf-8\")),\n                    partition=partition,\n                )\n                self.log.debug(f\"\u2705 Inserted the message into partition {partition} of {self.output_topic} topic.\")\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to send message to Kafka topic: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n            raise\n\n    def save_bulk(self, messages: List[Any]) -&gt; None:\n\"\"\"\n        \ud83d\udce6 Send multiple messages at once to the Kafka topic.\n\n        Args:\n            messages (list): The messages to send.\n\n        Raises:\n            Exception: If no Kafka producer is available or an error occurs.\n        \"\"\"\n        if self.producer:\n            try:\n                for message in messages:\n                    self.producer.send(self.output_topic, bytes(json.dumps(message).encode(\"utf-8\")))\n                self.log.debug(f\"\u2705 Inserted {len(messages)} messages into {self.output_topic} topic.\")\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to send messages to Kafka topic: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n            raise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.__init__","title":"<code>__init__(output_topic, kafka_servers)</code>","text":"<p>Initialize a new streaming output configuration.</p> <p>Parameters:</p> Name Type Description Default <code>output_topic</code> <code>str</code> <p>Kafka topic to ingest data.</p> required <code>kafka_servers</code> <code>str</code> <p>Kafka bootstrap servers.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def __init__(self, output_topic: str, kafka_servers: str) -&gt; None:\n\"\"\"\n    Initialize a new streaming output configuration.\n\n    Args:\n        output_topic (str): Kafka topic to ingest data.\n        kafka_servers (str): Kafka bootstrap servers.\n    \"\"\"\n    self.output_topic = output_topic\n    self.log = logging.getLogger(self.__class__.__name__)\n    try:\n        self.producer = KafkaProducer(bootstrap_servers=kafka_servers)\n    except Exception as e:\n        self.log.exception(f\"\ud83d\udeab Failed to create Kafka producer: {e}\")\n        raise\n        self.producer = None\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.close","title":"<code>close()</code>","text":"<p>\ud83d\udeaa Close the Kafka producer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def close(self) -&gt; None:\n\"\"\"\n    \ud83d\udeaa Close the Kafka producer.\n\n    Raises:\n        Exception: If no Kafka producer is available.\n    \"\"\"\n    if self.producer:\n        self.producer.close()\n        self.producer = None\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n        raise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.flush","title":"<code>flush()</code>","text":"<p>\ud83d\udd04 Flush the output by flushing the Kafka producer.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def flush(self) -&gt; None:\n\"\"\"\n    \ud83d\udd04 Flush the output by flushing the Kafka producer.\n\n    Raises:\n        Exception: If no Kafka producer is available.\n    \"\"\"\n    if self.producer:\n        self.producer.flush()\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n        raise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.partition_available","title":"<code>partition_available(partition)</code>","text":"<p>\ud83e\uddd0 Check if a partition is available in the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>partition</code> <code>int</code> <p>The partition to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the partition is available, False otherwise.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def partition_available(self, partition: int) -&gt; bool:\n\"\"\"\n    \ud83e\uddd0 Check if a partition is available in the Kafka topic.\n\n    Args:\n        partition (int): The partition to check.\n\n    Returns:\n        bool: True if the partition is available, False otherwise.\n\n    Raises:\n        Exception: If no Kafka producer is available.\n    \"\"\"\n    if self.producer:\n        return partition in self.producer.partitions_for(self.output_topic)\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n        raise\n        return False\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.save","title":"<code>save(data, filename)</code>","text":"<p>\ud83d\udce4 Ingest data into the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to ingest.</p> required <code>filename</code> <code>str</code> <p>This argument is ignored for streaming outputs.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def save(self, data: Any, filename: str) -&gt; None:\n\"\"\"\n    \ud83d\udce4 Ingest data into the Kafka topic.\n\n    Args:\n        data (Any): The data to ingest.\n        filename (str): This argument is ignored for streaming outputs.\n\n    Raises:\n        Exception: If no Kafka producer is available or an error occurs.\n    \"\"\"\n    if self.producer:\n        try:\n            self.producer.send(self.output_topic, bytes(json.dumps(data).encode(\"utf-8\")))\n            self.log.debug(f\"\u2705 Inserted the data into {self.output_topic} topic.\")\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to send data to Kafka topic: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n        raise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.save_bulk","title":"<code>save_bulk(messages)</code>","text":"<p>\ud83d\udce6 Send multiple messages at once to the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>list</code> <p>The messages to send.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def save_bulk(self, messages: List[Any]) -&gt; None:\n\"\"\"\n    \ud83d\udce6 Send multiple messages at once to the Kafka topic.\n\n    Args:\n        messages (list): The messages to send.\n\n    Raises:\n        Exception: If no Kafka producer is available or an error occurs.\n    \"\"\"\n    if self.producer:\n        try:\n            for message in messages:\n                self.producer.send(self.output_topic, bytes(json.dumps(message).encode(\"utf-8\")))\n            self.log.debug(f\"\u2705 Inserted {len(messages)} messages into {self.output_topic} topic.\")\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to send messages to Kafka topic: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n        raise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.save_to_partition","title":"<code>save_to_partition(value, partition)</code>","text":"<p>\ud83c\udfaf Send a message to a specific partition in the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value of the message.</p> required <code>partition</code> <code>int</code> <p>The partition to send the message to.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def save_to_partition(self, value: Any, partition: int) -&gt; None:\n\"\"\"\n    \ud83c\udfaf Send a message to a specific partition in the Kafka topic.\n\n    Args:\n        value (Any): The value of the message.\n        partition (int): The partition to send the message to.\n\n    Raises:\n        Exception: If no Kafka producer is available or an error occurs.\n    \"\"\"\n    if self.producer:\n        try:\n            self.producer.send(\n                self.output_topic,\n                value=bytes(json.dumps(value).encode(\"utf-8\")),\n                partition=partition,\n            )\n            self.log.debug(f\"\u2705 Inserted the message into partition {partition} of {self.output_topic} topic.\")\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to send message to Kafka topic: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n        raise\n</code></pre>"},{"location":"core/core_data_streaming_output/#core.data.streaming_output.StreamingOutputConfig.send_key_value","title":"<code>send_key_value(key, value)</code>","text":"<p>\ud83d\udd11 Send a message with a key to the Kafka topic.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Any</code> <p>The key of the message.</p> required <code>value</code> <code>Any</code> <p>The value of the message.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If no Kafka producer is available or an error occurs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/data/streaming_output.py</code> <pre><code>def send_key_value(self, key: Any, value: Any) -&gt; None:\n\"\"\"\n    \ud83d\udd11 Send a message with a key to the Kafka topic.\n\n    Args:\n        key (Any): The key of the message.\n        value (Any): The value of the message.\n\n    Raises:\n        Exception: If no Kafka producer is available or an error occurs.\n    \"\"\"\n    if self.producer:\n        try:\n            self.producer.send(\n                self.output_topic,\n                key=bytes(json.dumps(key).encode(\"utf-8\")),\n                value=bytes(json.dumps(value).encode(\"utf-8\")),\n            )\n            self.log.debug(f\"\u2705 Inserted the key-value pair into {self.output_topic} topic.\")\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to send key-value pair to Kafka topic: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No Kafka producer available.\")\n        raise\n</code></pre>"},{"location":"core/core_spout/","title":"Spout","text":"<p>Core Spout class</p>"},{"location":"core/core_spout/#core.spout.Spout","title":"<code>Spout</code>","text":"<p>             Bases: <code>Task</code></p> <p>Base class for all spouts.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py</code> <pre><code>class Spout(Task):\n\"\"\"\n    Base class for all spouts.\n    \"\"\"\n\n    def __init__(self, output_config: OutputConfig, state_manager: StateManager, **kwargs) -&gt; None:\n\"\"\"\n        The `Spout` class is a base class for all spouts in the given context.\n        It inherits from the `Task` class and provides methods for executing tasks\n        both locally and remotely, as well as managing their state, with state management\n        options including in-memory, Redis, PostgreSQL, and DynamoDB,\n        and output configurations for batch or streaming data.\n\n        The `Spout` class uses the `OutputConfig` and `StateManager` classes, which are abstract base\n         classes for managing output configurations and states, respectively. The `OutputConfig` class\n         has two subclasses: `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and\n         batch output configurations, respectively. The `StateManager` class is used to get and set state,\n         and it has several subclasses for different types of state managers.\n\n        The `Spout` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method,\n        which are used to manage tasks on Amazon ECS and Kubernetes, respectively.\n\n        Usage:\n            - Create an instance of the Spout class by providing an OutputConfig object and a StateManager object.\n            - The OutputConfig object specifies the output configuration for the spout.\n            - The StateManager object handles the management of the spout's state.\n\n        Example:\n            output_config = OutputConfig(...)\n            state_manager = StateManager(...)\n            spout = Spout(output_config, state_manager)\n\n        Args:\n            output_config (OutputConfig): The output configuration.\n            state_manager (StateManager): The state manager.\n        \"\"\"\n        super().__init__()\n        self.output_config = output_config\n        self.state_manager = state_manager\n\n        self.log = logging.getLogger(self.__class__.__name__)\n\n    def __call__(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n        Execute a method locally and manage the state.\n\n        Args:\n            method_name (str): The name of the method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n                Keyword Arguments:\n                    - Additional keyword arguments specific to the method.\n\n        Returns:\n            Any: The result of the method.\n        \"\"\"\n        try:\n            # Get the type of state manager\n            state_type = self.state_manager.get_state(self.id)\n\n            # Save the current set of class variables to the state manager\n            self.state_manager.set_state(self.id, {})\n\n            # Execute the task's method\n            result = self.execute(method_name, *args, **kwargs)\n\n            # Flush the output config\n            self.output_config.flush()\n\n            # Store the state as successful in the state manager\n            state = {}\n            state[\"status\"] = \"success\"\n            self.state_manager.set_state(self.id, state)\n\n            return result\n        except Exception as e:\n            state = {}\n            state[\"status\"] = \"failed\"\n            self.state_manager.set_state(self.id, state)\n            self.log.exception(f\"Failed to execute method '{method_name}': {e}\")\n            raise\n\n    @staticmethod\n    def create(klass: type, output_type: str, state_type: str, **kwargs) -&gt; \"Spout\":\n\"\"\"\n        Create a spout of a specific type.\n\n        Args:\n            klass (type): The Spout class to create.\n            output_type (str): The type of output config (\"batch\" or \"streaming\").\n            state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n            **kwargs: Additional keyword arguments for initializing the spout.\n                Keyword Arguments:\n                    Batch output config:\n                    - output_folder (str): The directory where output files should be stored temporarily.\n                    - output_s3_bucket (str): The name of the S3 bucket for output storage.\n                    - output_s3_folder (str): The S3 folder for output storage.\n                    Streaming output config:\n                    - output_kafka_topic (str): Kafka output topic for streaming spouts.\n                    - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.\n                    Redis state manager config:\n                    - redis_host (str): The host address for the Redis server.\n                    - redis_port (int): The port number for the Redis server.\n                    - redis_db (int): The Redis database to be used.\n                    Postgres state manager config:\n                    - postgres_host (str): The host address for the PostgreSQL server.\n                    - postgres_port (int): The port number for the PostgreSQL server.\n                    - postgres_user (str): The username for the PostgreSQL server.\n                    - postgres_password (str): The password for the PostgreSQL server.\n                    - postgres_database (str): The PostgreSQL database to be used.\n                    - postgres_table (str): The PostgreSQL table to be used.\n                    DynamoDB state manager config:\n                    - dynamodb_table_name (str): The name of the DynamoDB table.\n                    - dynamodb_region_name (str): The AWS region for DynamoDB.\n\n        Returns:\n            Spout: The created spout.\n\n        Raises:\n            ValueError: If an invalid output type or state type is provided.\n        \"\"\"\n        # Create the output config\n        output_config: BatchOutputConfig | StreamingOutputConfig\n        if output_type == \"batch\":\n            output_config = BatchOutputConfig(\n                output_folder=kwargs.get(\"output_folder\", tempfile.mkdtemp()),\n                bucket=kwargs.get(\"output_s3_bucket\", \"geniusrise\"),\n                s3_folder=kwargs.get(\"output_s3_folder\", klass.__class__.__name__),\n            )\n        elif output_type == \"streaming\":\n            output_config = StreamingOutputConfig(\n                output_topic=kwargs.get(\"output_kafka_topic\", None),\n                kafka_servers=kwargs.get(\"output_kafka_cluster_connection_string\", None),\n            )\n        else:\n            raise ValueError(f\"Invalid output type: {output_type}\")\n\n        # Create the state manager\n        state_manager: StateManager\n        if state_type == \"in_memory\":\n            state_manager = InMemoryStateManager()\n        elif state_type == \"redis\":\n            state_manager = RedisStateManager(\n                host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None,\n                port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None,\n                db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None,\n            )\n        elif state_type == \"postgres\":\n            state_manager = PostgresStateManager(\n                host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None,\n                port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None,\n                user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None,\n                password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None,\n                database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None,\n                table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None,\n            )\n        elif state_type == \"dynamodb\":\n            state_manager = DynamoDBStateManager(\n                table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None,\n                region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None,\n            )\n        else:\n            raise ValueError(f\"Invalid state type: {state_type}\")\n\n        # Create the spout\n        spout = klass(output_config=output_config, state_manager=state_manager, **kwargs)\n        return spout\n</code></pre>"},{"location":"core/core_spout/#core.spout.Spout.__call__","title":"<code>__call__(method_name, *args, **kwargs)</code>","text":"<p>Execute a method locally and manage the state.</p> <p>Parameters:</p> Name Type Description Default <code>method_name</code> <code>str</code> <p>The name of the method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method. Keyword Arguments:     - Additional keyword arguments specific to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the method.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py</code> <pre><code>def __call__(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n    Execute a method locally and manage the state.\n\n    Args:\n        method_name (str): The name of the method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n            Keyword Arguments:\n                - Additional keyword arguments specific to the method.\n\n    Returns:\n        Any: The result of the method.\n    \"\"\"\n    try:\n        # Get the type of state manager\n        state_type = self.state_manager.get_state(self.id)\n\n        # Save the current set of class variables to the state manager\n        self.state_manager.set_state(self.id, {})\n\n        # Execute the task's method\n        result = self.execute(method_name, *args, **kwargs)\n\n        # Flush the output config\n        self.output_config.flush()\n\n        # Store the state as successful in the state manager\n        state = {}\n        state[\"status\"] = \"success\"\n        self.state_manager.set_state(self.id, state)\n\n        return result\n    except Exception as e:\n        state = {}\n        state[\"status\"] = \"failed\"\n        self.state_manager.set_state(self.id, state)\n        self.log.exception(f\"Failed to execute method '{method_name}': {e}\")\n        raise\n</code></pre>"},{"location":"core/core_spout/#core.spout.Spout.__init__","title":"<code>__init__(output_config, state_manager, **kwargs)</code>","text":"<p>The <code>Spout</code> class is a base class for all spouts in the given context. It inherits from the <code>Task</code> class and provides methods for executing tasks both locally and remotely, as well as managing their state, with state management options including in-memory, Redis, PostgreSQL, and DynamoDB, and output configurations for batch or streaming data.</p> <p>The <code>Spout</code> class uses the <code>OutputConfig</code> and <code>StateManager</code> classes, which are abstract base  classes for managing output configurations and states, respectively. The <code>OutputConfig</code> class  has two subclasses: <code>StreamingOutputConfig</code> and <code>BatchOutputConfig</code>, which manage streaming and  batch output configurations, respectively. The <code>StateManager</code> class is used to get and set state,  and it has several subclasses for different types of state managers.</p> <p>The <code>Spout</code> class also uses the <code>ECSManager</code> and <code>K8sManager</code> classes in the <code>execute_remote</code> method, which are used to manage tasks on Amazon ECS and Kubernetes, respectively.</p> Usage <ul> <li>Create an instance of the Spout class by providing an OutputConfig object and a StateManager object.</li> <li>The OutputConfig object specifies the output configuration for the spout.</li> <li>The StateManager object handles the management of the spout's state.</li> </ul> Example <p>output_config = OutputConfig(...) state_manager = StateManager(...) spout = Spout(output_config, state_manager)</p> <p>Parameters:</p> Name Type Description Default <code>output_config</code> <code>OutputConfig</code> <p>The output configuration.</p> required <code>state_manager</code> <code>StateManager</code> <p>The state manager.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py</code> <pre><code>def __init__(self, output_config: OutputConfig, state_manager: StateManager, **kwargs) -&gt; None:\n\"\"\"\n    The `Spout` class is a base class for all spouts in the given context.\n    It inherits from the `Task` class and provides methods for executing tasks\n    both locally and remotely, as well as managing their state, with state management\n    options including in-memory, Redis, PostgreSQL, and DynamoDB,\n    and output configurations for batch or streaming data.\n\n    The `Spout` class uses the `OutputConfig` and `StateManager` classes, which are abstract base\n     classes for managing output configurations and states, respectively. The `OutputConfig` class\n     has two subclasses: `StreamingOutputConfig` and `BatchOutputConfig`, which manage streaming and\n     batch output configurations, respectively. The `StateManager` class is used to get and set state,\n     and it has several subclasses for different types of state managers.\n\n    The `Spout` class also uses the `ECSManager` and `K8sManager` classes in the `execute_remote` method,\n    which are used to manage tasks on Amazon ECS and Kubernetes, respectively.\n\n    Usage:\n        - Create an instance of the Spout class by providing an OutputConfig object and a StateManager object.\n        - The OutputConfig object specifies the output configuration for the spout.\n        - The StateManager object handles the management of the spout's state.\n\n    Example:\n        output_config = OutputConfig(...)\n        state_manager = StateManager(...)\n        spout = Spout(output_config, state_manager)\n\n    Args:\n        output_config (OutputConfig): The output configuration.\n        state_manager (StateManager): The state manager.\n    \"\"\"\n    super().__init__()\n    self.output_config = output_config\n    self.state_manager = state_manager\n\n    self.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/core_spout/#core.spout.Spout.create","title":"<code>create(klass, output_type, state_type, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a spout of a specific type.</p> <p>Parameters:</p> Name Type Description Default <code>klass</code> <code>type</code> <p>The Spout class to create.</p> required <code>output_type</code> <code>str</code> <p>The type of output config (\"batch\" or \"streaming\").</p> required <code>state_type</code> <code>str</code> <p>The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").</p> required <code>**kwargs</code> <p>Additional keyword arguments for initializing the spout. Keyword Arguments:     Batch output config:     - output_folder (str): The directory where output files should be stored temporarily.     - output_s3_bucket (str): The name of the S3 bucket for output storage.     - output_s3_folder (str): The S3 folder for output storage.     Streaming output config:     - output_kafka_topic (str): Kafka output topic for streaming spouts.     - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.     Redis state manager config:     - redis_host (str): The host address for the Redis server.     - redis_port (int): The port number for the Redis server.     - redis_db (int): The Redis database to be used.     Postgres state manager config:     - postgres_host (str): The host address for the PostgreSQL server.     - postgres_port (int): The port number for the PostgreSQL server.     - postgres_user (str): The username for the PostgreSQL server.     - postgres_password (str): The password for the PostgreSQL server.     - postgres_database (str): The PostgreSQL database to be used.     - postgres_table (str): The PostgreSQL table to be used.     DynamoDB state manager config:     - dynamodb_table_name (str): The name of the DynamoDB table.     - dynamodb_region_name (str): The AWS region for DynamoDB.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Spout</code> <code>Spout</code> <p>The created spout.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid output type or state type is provided.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/spout.py</code> <pre><code>@staticmethod\ndef create(klass: type, output_type: str, state_type: str, **kwargs) -&gt; \"Spout\":\n\"\"\"\n    Create a spout of a specific type.\n\n    Args:\n        klass (type): The Spout class to create.\n        output_type (str): The type of output config (\"batch\" or \"streaming\").\n        state_type (str): The type of state manager (\"in_memory\", \"redis\", \"postgres\", or \"dynamodb\").\n        **kwargs: Additional keyword arguments for initializing the spout.\n            Keyword Arguments:\n                Batch output config:\n                - output_folder (str): The directory where output files should be stored temporarily.\n                - output_s3_bucket (str): The name of the S3 bucket for output storage.\n                - output_s3_folder (str): The S3 folder for output storage.\n                Streaming output config:\n                - output_kafka_topic (str): Kafka output topic for streaming spouts.\n                - output_kafka_cluster_connection_string (str): Kafka connection string for streaming spouts.\n                Redis state manager config:\n                - redis_host (str): The host address for the Redis server.\n                - redis_port (int): The port number for the Redis server.\n                - redis_db (int): The Redis database to be used.\n                Postgres state manager config:\n                - postgres_host (str): The host address for the PostgreSQL server.\n                - postgres_port (int): The port number for the PostgreSQL server.\n                - postgres_user (str): The username for the PostgreSQL server.\n                - postgres_password (str): The password for the PostgreSQL server.\n                - postgres_database (str): The PostgreSQL database to be used.\n                - postgres_table (str): The PostgreSQL table to be used.\n                DynamoDB state manager config:\n                - dynamodb_table_name (str): The name of the DynamoDB table.\n                - dynamodb_region_name (str): The AWS region for DynamoDB.\n\n    Returns:\n        Spout: The created spout.\n\n    Raises:\n        ValueError: If an invalid output type or state type is provided.\n    \"\"\"\n    # Create the output config\n    output_config: BatchOutputConfig | StreamingOutputConfig\n    if output_type == \"batch\":\n        output_config = BatchOutputConfig(\n            output_folder=kwargs.get(\"output_folder\", tempfile.mkdtemp()),\n            bucket=kwargs.get(\"output_s3_bucket\", \"geniusrise\"),\n            s3_folder=kwargs.get(\"output_s3_folder\", klass.__class__.__name__),\n        )\n    elif output_type == \"streaming\":\n        output_config = StreamingOutputConfig(\n            output_topic=kwargs.get(\"output_kafka_topic\", None),\n            kafka_servers=kwargs.get(\"output_kafka_cluster_connection_string\", None),\n        )\n    else:\n        raise ValueError(f\"Invalid output type: {output_type}\")\n\n    # Create the state manager\n    state_manager: StateManager\n    if state_type == \"in_memory\":\n        state_manager = InMemoryStateManager()\n    elif state_type == \"redis\":\n        state_manager = RedisStateManager(\n            host=kwargs[\"redis_host\"] if \"redis_host\" in kwargs else None,\n            port=kwargs[\"redis_port\"] if \"redis_port\" in kwargs else None,\n            db=kwargs[\"redis_db\"] if \"redis_db\" in kwargs else None,\n        )\n    elif state_type == \"postgres\":\n        state_manager = PostgresStateManager(\n            host=kwargs[\"postgres_host\"] if \"postgres_host\" in kwargs else None,\n            port=kwargs[\"postgres_port\"] if \"postgres_port\" in kwargs else None,\n            user=kwargs[\"postgres_user\"] if \"postgres_user\" in kwargs else None,\n            password=kwargs[\"postgres_password\"] if \"postgres_password\" in kwargs else None,\n            database=kwargs[\"postgres_database\"] if \"postgres_database\" in kwargs else None,\n            table=kwargs[\"postgres_table\"] if \"postgres_table\" in kwargs else None,\n        )\n    elif state_type == \"dynamodb\":\n        state_manager = DynamoDBStateManager(\n            table_name=kwargs[\"dynamodb_table_name\"] if \"dynamodb_table_name\" in kwargs else None,\n            region_name=kwargs[\"dynamodb_region_name\"] if \"dynamodb_region_name\" in kwargs else None,\n        )\n    else:\n        raise ValueError(f\"Invalid state type: {state_type}\")\n\n    # Create the spout\n    spout = klass(output_config=output_config, state_manager=state_manager, **kwargs)\n    return spout\n</code></pre>"},{"location":"core/core_state_base/","title":"State","text":"<p>Base class for task state mnager</p>"},{"location":"core/core_state_base/#core.state.base.StateManager","title":"<code>StateManager</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract base class for a state manager.</p> <p>A state manager is responsible for getting and setting state.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py</code> <pre><code>class StateManager(ABC):\n\"\"\"\n    Abstract base class for a state manager.\n\n    A state manager is responsible for getting and setting state.\n    \"\"\"\n\n    @abstractmethod\n    def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        Get the state associated with a key.\n\n        Args:\n            key (str): The key to get the state for.\n\n        Returns:\n            Dict: The state associated with the key.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_state(self, key: str, value: Dict):\n\"\"\"\n        Set the state associated with a key.\n\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"core/core_state_base/#core.state.base.StateManager.get_state","title":"<code>get_state(key)</code>  <code>abstractmethod</code>","text":"<p>Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py</code> <pre><code>@abstractmethod\ndef get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    Get the state associated with a key.\n\n    Args:\n        key (str): The key to get the state for.\n\n    Returns:\n        Dict: The state associated with the key.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/core_state_base/#core.state.base.StateManager.set_state","title":"<code>set_state(key, value)</code>  <code>abstractmethod</code>","text":"<p>Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/base.py</code> <pre><code>@abstractmethod\ndef set_state(self, key: str, value: Dict):\n\"\"\"\n    Set the state associated with a key.\n\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"core/core_state_dynamo/","title":"DynamoDB State","text":"<p>State manager using dynamoDB</p>"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager","title":"<code>DynamoDBStateManager</code>","text":"<p>             Bases: <code>StateManager</code></p> <p>\ud83d\uddc4\ufe0f DynamoDBStateManager: A state manager that stores state in DynamoDB.</p> <p>Attributes:</p> Name Type Description <code>dynamodb</code> <code>boto3.resources.factory.dynamodb.ServiceResource</code> <p>The DynamoDB service resource.</p> <code>table</code> <code>boto3.resources.factory.dynamodb.Table</code> <p>The DynamoDB table.</p> <p>Usage:</p> <pre><code>manager = DynamoDBStateManager(\"my_table\", \"us-west-1\")\nmanager.set_state(\"key123\", {\"status\": \"active\"})\nstate = manager.get_state(\"key123\")\nprint(state)  # Outputs: {\"status\": \"active\"}\n</code></pre> <p>Note: - Ensure DynamoDB is accessible and the table exists.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py</code> <pre><code>class DynamoDBStateManager(StateManager):\n\"\"\"\n    \ud83d\uddc4\ufe0f **DynamoDBStateManager**: A state manager that stores state in DynamoDB.\n\n    Attributes:\n        dynamodb (boto3.resources.factory.dynamodb.ServiceResource): The DynamoDB service resource.\n        table (boto3.resources.factory.dynamodb.Table): The DynamoDB table.\n\n    Usage:\n    ```python\n    manager = DynamoDBStateManager(\"my_table\", \"us-west-1\")\n    manager.set_state(\"key123\", {\"status\": \"active\"})\n    state = manager.get_state(\"key123\")\n    print(state)  # Outputs: {\"status\": \"active\"}\n    ```\n\n    Note:\n    - Ensure DynamoDB is accessible and the table exists.\n    \"\"\"\n\n    def __init__(self, table_name: str, region_name: str) -&gt; None:\n\"\"\"\n        Initialize a new DynamoDB state manager.\n\n        Args:\n            table_name (str): The name of the DynamoDB table.\n            region_name (str): The name of the AWS region.\n        \"\"\"\n        super().__init__()\n        self.log = logging.getLogger(self.__class__.__name__)\n        try:\n            self.dynamodb = boto3.resource(\"dynamodb\", region_name=region_name)\n            self.table = self.dynamodb.Table(table_name)\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to connect to DynamoDB: {e}\")\n            raise\n            self.dynamodb = None\n            self.table = None\n\n    def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        \ud83d\udcd6 Get the state associated with a key.\n\n        Args:\n            key (str): The key to get the state for.\n\n        Returns:\n            Dict: The state associated with the key, or None if not found.\n\n        Raises:\n            Exception: If there's an error accessing DynamoDB.\n        \"\"\"\n        if self.table:\n            try:\n                response = self.table.get_item(Key={\"id\": key})\n                return jsonpickle.decode(response[\"Item\"][\"value\"]) if \"Item\" in response else None\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to get state from DynamoDB: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No DynamoDB table.\")\n            raise\n\n    def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n        \ud83d\udcdd Set the state associated with a key.\n\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n\n        Raises:\n            Exception: If there's an error accessing DynamoDB.\n        \"\"\"\n        if self.table:\n            try:\n                self.table.put_item(Item={\"id\": key, \"value\": jsonpickle.encode(value)})\n            except Exception as e:\n                self.log.exception(f\"\ud83d\udeab Failed to set state in DynamoDB: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No DynamoDB table.\")\n            raise\n</code></pre>"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager.__init__","title":"<code>__init__(table_name, region_name)</code>","text":"<p>Initialize a new DynamoDB state manager.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the DynamoDB table.</p> required <code>region_name</code> <code>str</code> <p>The name of the AWS region.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py</code> <pre><code>def __init__(self, table_name: str, region_name: str) -&gt; None:\n\"\"\"\n    Initialize a new DynamoDB state manager.\n\n    Args:\n        table_name (str): The name of the DynamoDB table.\n        region_name (str): The name of the AWS region.\n    \"\"\"\n    super().__init__()\n    self.log = logging.getLogger(self.__class__.__name__)\n    try:\n        self.dynamodb = boto3.resource(\"dynamodb\", region_name=region_name)\n        self.table = self.dynamodb.Table(table_name)\n    except Exception as e:\n        self.log.exception(f\"\ud83d\udeab Failed to connect to DynamoDB: {e}\")\n        raise\n        self.dynamodb = None\n        self.table = None\n</code></pre>"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager.get_state","title":"<code>get_state(key)</code>","text":"<p>\ud83d\udcd6 Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key, or None if not found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing DynamoDB.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py</code> <pre><code>def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    \ud83d\udcd6 Get the state associated with a key.\n\n    Args:\n        key (str): The key to get the state for.\n\n    Returns:\n        Dict: The state associated with the key, or None if not found.\n\n    Raises:\n        Exception: If there's an error accessing DynamoDB.\n    \"\"\"\n    if self.table:\n        try:\n            response = self.table.get_item(Key={\"id\": key})\n            return jsonpickle.decode(response[\"Item\"][\"value\"]) if \"Item\" in response else None\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to get state from DynamoDB: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No DynamoDB table.\")\n        raise\n</code></pre>"},{"location":"core/core_state_dynamo/#core.state.dynamo.DynamoDBStateManager.set_state","title":"<code>set_state(key, value)</code>","text":"<p>\ud83d\udcdd Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing DynamoDB.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/dynamo.py</code> <pre><code>def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n    \ud83d\udcdd Set the state associated with a key.\n\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n\n    Raises:\n        Exception: If there's an error accessing DynamoDB.\n    \"\"\"\n    if self.table:\n        try:\n            self.table.put_item(Item={\"id\": key, \"value\": jsonpickle.encode(value)})\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to set state in DynamoDB: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No DynamoDB table.\")\n        raise\n</code></pre>"},{"location":"core/core_state_memory/","title":"In-memory State","text":"<p>State manager using local memory</p>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager","title":"<code>InMemoryStateManager</code>","text":"<p>             Bases: <code>StateManager</code></p> <p>\ud83e\udde0 InMemoryStateManager: A state manager that stores state in memory.</p> <p>This manager is useful for temporary storage or testing purposes. Since it's in-memory, the data will be lost once the application stops.</p>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager--attributes","title":"Attributes:","text":"<ul> <li><code>store</code> (Dict[str, Dict]): The in-memory store for states.</li> </ul>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager--usage","title":"Usage:","text":"<pre><code>manager = InMemoryStateManager()\nmanager.set_state(\"user123\", {\"status\": \"active\"})\nstate = manager.get_state(\"user123\")\nprint(state)  # Outputs: {\"status\": \"active\"}\n</code></pre> <p>!!! warning     Remember, this is an in-memory store. Do not use it for persistent storage!</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py</code> <pre><code>class InMemoryStateManager(StateManager):\n\"\"\"\n    \ud83e\udde0 **InMemoryStateManager**: A state manager that stores state in memory.\n\n    This manager is useful for temporary storage or testing purposes. Since it's in-memory, the data will be lost once the application stops.\n\n    ## Attributes:\n    - `store` (Dict[str, Dict]): The in-memory store for states.\n\n    ## Usage:\n    ```python\n    manager = InMemoryStateManager()\n    manager.set_state(\"user123\", {\"status\": \"active\"})\n    state = manager.get_state(\"user123\")\n    print(state)  # Outputs: {\"status\": \"active\"}\n    ```\n\n    !!! warning\n        Remember, this is an in-memory store. Do not use it for persistent storage!\n    \"\"\"\n\n    store: Dict[str, Dict]\n\n    def __init__(self) -&gt; None:\n\"\"\"\n        Initialize a new in-memory state manager.\n        \"\"\"\n        self.store = {}\n        self.log = logging.getLogger(self.__class__.__name__)\n\n    def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        \ud83d\udcd6 Get the state associated with a key.\n\n        Args:\n            key (str): The key to get the state for.\n\n        Returns:\n            Dict: The state associated with the key, or None if not found.\n        \"\"\"\n        state = self.store.get(key)\n        if state:\n            self.log.debug(f\"\u2705 Retrieved state for key: {key}\")\n        else:\n            self.log.warning(f\"\ud83d\udeab No state found for key: {key}\")\n        return state\n\n    def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n        \ud83d\udcdd Set the state associated with a key.\n\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n\n        Example:\n        ```python\n        manager.set_state(\"user123\", {\"status\": \"active\"})\n        ```\n        \"\"\"\n        self.store[key] = value\n        self.log.debug(f\"\u2705 Set state for key: {key}\")\n</code></pre>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.__init__","title":"<code>__init__()</code>","text":"<p>Initialize a new in-memory state manager.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py</code> <pre><code>def __init__(self) -&gt; None:\n\"\"\"\n    Initialize a new in-memory state manager.\n    \"\"\"\n    self.store = {}\n    self.log = logging.getLogger(self.__class__.__name__)\n</code></pre>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.get_state","title":"<code>get_state(key)</code>","text":"<p>\ud83d\udcd6 Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key, or None if not found.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py</code> <pre><code>def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    \ud83d\udcd6 Get the state associated with a key.\n\n    Args:\n        key (str): The key to get the state for.\n\n    Returns:\n        Dict: The state associated with the key, or None if not found.\n    \"\"\"\n    state = self.store.get(key)\n    if state:\n        self.log.debug(f\"\u2705 Retrieved state for key: {key}\")\n    else:\n        self.log.warning(f\"\ud83d\udeab No state found for key: {key}\")\n    return state\n</code></pre>"},{"location":"core/core_state_memory/#core.state.memory.InMemoryStateManager.set_state","title":"<code>set_state(key, value)</code>","text":"<p>\ud83d\udcdd Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required <p>Example:</p> <pre><code>manager.set_state(\"user123\", {\"status\": \"active\"})\n</code></pre> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/memory.py</code> <pre><code>def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n    \ud83d\udcdd Set the state associated with a key.\n\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n\n    Example:\n    ```python\n    manager.set_state(\"user123\", {\"status\": \"active\"})\n    ```\n    \"\"\"\n    self.store[key] = value\n    self.log.debug(f\"\u2705 Set state for key: {key}\")\n</code></pre>"},{"location":"core/core_state_postgres/","title":"Postgres State","text":"<p>State manager using postgres database</p>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager","title":"<code>PostgresStateManager</code>","text":"<p>             Bases: <code>StateManager</code></p> <p>\ud83d\uddc4\ufe0f PostgresStateManager: A state manager that stores state in a PostgreSQL database.</p> <p>This manager provides a persistent storage solution using a PostgreSQL database.</p>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager--attributes","title":"Attributes:","text":"<ul> <li><code>conn</code> (psycopg2.extensions.connection): The PostgreSQL connection.</li> </ul>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager--usage","title":"Usage:","text":"<pre><code>manager = PostgresStateManager(host=\"localhost\", port=5432, user=\"admin\", password=\"password\", database=\"mydb\")\nmanager.set_state(\"user123\", {\"status\": \"active\"})\nstate = manager.get_state(\"user123\")\nprint(state)  # Outputs: {\"status\": \"active\"}\n</code></pre> <p>!!! warning     Ensure PostgreSQL is accessible and the table exists.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py</code> <pre><code>class PostgresStateManager(StateManager):\n\"\"\"\n    \ud83d\uddc4\ufe0f **PostgresStateManager**: A state manager that stores state in a PostgreSQL database.\n\n    This manager provides a persistent storage solution using a PostgreSQL database.\n\n    ## Attributes:\n    - `conn` (psycopg2.extensions.connection): The PostgreSQL connection.\n\n    ## Usage:\n    ```python\n    manager = PostgresStateManager(host=\"localhost\", port=5432, user=\"admin\", password=\"password\", database=\"mydb\")\n    manager.set_state(\"user123\", {\"status\": \"active\"})\n    state = manager.get_state(\"user123\")\n    print(state)  # Outputs: {\"status\": \"active\"}\n    ```\n\n    !!! warning\n        Ensure PostgreSQL is accessible and the table exists.\n    \"\"\"\n\n    def __init__(\n        self,\n        host: str,\n        port: int,\n        user: str,\n        password: str,\n        database: str,\n        table: str = \"geniusrise_state\",\n    ) -&gt; None:\n\"\"\"\n        Initialize a new PostgreSQL state manager.\n\n        Args:\n            host (str): The host of the PostgreSQL server.\n            port (int): The port of the PostgreSQL server.\n            user (str): The user to connect as.\n            password (str): The user's password.\n            database (str): The database to connect to.\n            table (str, optional): The table to use. Defaults to \"geniusrise_state\".\n        \"\"\"\n        super().__init__()\n        self.table = table\n        self.log = logging.getLogger(self.__class__.__name__)\n        try:\n            self.conn = psycopg2.connect(host=host, port=port, user=user, password=password, database=database)\n        except psycopg2.Error as e:\n            self.log.exception(f\"\ud83d\udeab Failed to connect to PostgreSQL: {e}\")\n            raise\n            self.conn = None\n\n    def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        \ud83d\udcd6 Get the state associated with a key.\n\n        Args:\n            key (str): The key to get the state for.\n\n        Returns:\n            Dict: The state associated with the key, or None if not found.\n\n        Raises:\n            Exception: If there's an error accessing PostgreSQL.\n        \"\"\"\n        if self.conn:\n            try:\n                with self.conn.cursor() as cur:\n                    cur.execute(f\"SELECT value FROM {self.table} WHERE key = %s\", (key,))\n                    result = cur.fetchone()\n                    return jsonpickle.decode(result[0][\"data\"]) if result else None\n            except psycopg2.Error as e:\n                self.log.exception(f\"\ud83d\udeab Failed to get state from PostgreSQL: {e}\")\n                raise\n        else:\n            self.log.exception(\"\ud83d\udeab No PostgreSQL connection.\")\n            raise\n\n    def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n        \ud83d\udcdd Set the state associated with a key.\n\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n\n        Raises:\n            Exception: If there's an error accessing PostgreSQL.\n        \"\"\"\n        if self.conn:\n            try:\n                with self.conn.cursor() as cur:\n                    data = {\"data\": jsonpickle.encode(value)}\n                    cur.execute(\n                        f\"\"\"\n                        INSERT INTO {self.table} (key, value)\n                        VALUES (%s, %s)\n                        ON CONFLICT (key)\n                        DO UPDATE SET value = EXCLUDED.value;\n                        \"\"\",\n                        (key, json.dumps(data)),\n                    )\n                self.conn.commit()\n            except psycopg2.Error as e:\n                self.log.exception(f\"\ud83d\udeab Failed to set state in PostgreSQL: {e}\")\n                raise\n        else:\n            self.log.error(\"\ud83d\udeab No PostgreSQL connection.\")\n</code></pre>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager.__init__","title":"<code>__init__(host, port, user, password, database, table='geniusrise_state')</code>","text":"<p>Initialize a new PostgreSQL state manager.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>The host of the PostgreSQL server.</p> required <code>port</code> <code>int</code> <p>The port of the PostgreSQL server.</p> required <code>user</code> <code>str</code> <p>The user to connect as.</p> required <code>password</code> <code>str</code> <p>The user's password.</p> required <code>database</code> <code>str</code> <p>The database to connect to.</p> required <code>table</code> <code>str</code> <p>The table to use. Defaults to \"geniusrise_state\".</p> <code>'geniusrise_state'</code> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py</code> <pre><code>def __init__(\n    self,\n    host: str,\n    port: int,\n    user: str,\n    password: str,\n    database: str,\n    table: str = \"geniusrise_state\",\n) -&gt; None:\n\"\"\"\n    Initialize a new PostgreSQL state manager.\n\n    Args:\n        host (str): The host of the PostgreSQL server.\n        port (int): The port of the PostgreSQL server.\n        user (str): The user to connect as.\n        password (str): The user's password.\n        database (str): The database to connect to.\n        table (str, optional): The table to use. Defaults to \"geniusrise_state\".\n    \"\"\"\n    super().__init__()\n    self.table = table\n    self.log = logging.getLogger(self.__class__.__name__)\n    try:\n        self.conn = psycopg2.connect(host=host, port=port, user=user, password=password, database=database)\n    except psycopg2.Error as e:\n        self.log.exception(f\"\ud83d\udeab Failed to connect to PostgreSQL: {e}\")\n        raise\n        self.conn = None\n</code></pre>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager.get_state","title":"<code>get_state(key)</code>","text":"<p>\ud83d\udcd6 Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key, or None if not found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing PostgreSQL.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py</code> <pre><code>def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    \ud83d\udcd6 Get the state associated with a key.\n\n    Args:\n        key (str): The key to get the state for.\n\n    Returns:\n        Dict: The state associated with the key, or None if not found.\n\n    Raises:\n        Exception: If there's an error accessing PostgreSQL.\n    \"\"\"\n    if self.conn:\n        try:\n            with self.conn.cursor() as cur:\n                cur.execute(f\"SELECT value FROM {self.table} WHERE key = %s\", (key,))\n                result = cur.fetchone()\n                return jsonpickle.decode(result[0][\"data\"]) if result else None\n        except psycopg2.Error as e:\n            self.log.exception(f\"\ud83d\udeab Failed to get state from PostgreSQL: {e}\")\n            raise\n    else:\n        self.log.exception(\"\ud83d\udeab No PostgreSQL connection.\")\n        raise\n</code></pre>"},{"location":"core/core_state_postgres/#core.state.postgres.PostgresStateManager.set_state","title":"<code>set_state(key, value)</code>","text":"<p>\ud83d\udcdd Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing PostgreSQL.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/postgres.py</code> <pre><code>def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n    \ud83d\udcdd Set the state associated with a key.\n\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n\n    Raises:\n        Exception: If there's an error accessing PostgreSQL.\n    \"\"\"\n    if self.conn:\n        try:\n            with self.conn.cursor() as cur:\n                data = {\"data\": jsonpickle.encode(value)}\n                cur.execute(\n                    f\"\"\"\n                    INSERT INTO {self.table} (key, value)\n                    VALUES (%s, %s)\n                    ON CONFLICT (key)\n                    DO UPDATE SET value = EXCLUDED.value;\n                    \"\"\",\n                    (key, json.dumps(data)),\n                )\n            self.conn.commit()\n        except psycopg2.Error as e:\n            self.log.exception(f\"\ud83d\udeab Failed to set state in PostgreSQL: {e}\")\n            raise\n    else:\n        self.log.error(\"\ud83d\udeab No PostgreSQL connection.\")\n</code></pre>"},{"location":"core/core_state_redis/","title":"Redis State","text":"<p>State manager using redis</p>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager","title":"<code>RedisStateManager</code>","text":"<p>             Bases: <code>StateManager</code></p> <p>\ud83d\uddc4\ufe0f RedisStateManager: A state manager that stores state in Redis.</p> <p>This manager provides a fast, in-memory storage solution using Redis.</p>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager--attributes","title":"Attributes:","text":"<ul> <li><code>redis</code> (redis.Redis): The Redis connection.</li> </ul>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager--usage","title":"Usage:","text":"<pre><code>manager = RedisStateManager(host=\"localhost\", port=6379, db=0)\nmanager.set_state(\"user123\", {\"status\": \"active\"})\nstate = manager.get_state(\"user123\")\nprint(state)  # Outputs: {\"status\": \"active\"}\n</code></pre> <p>!!! warning     Ensure Redis is accessible and running.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py</code> <pre><code>class RedisStateManager(StateManager):\n\"\"\"\n    \ud83d\uddc4\ufe0f **RedisStateManager**: A state manager that stores state in Redis.\n\n    This manager provides a fast, in-memory storage solution using Redis.\n\n    ## Attributes:\n    - `redis` (redis.Redis): The Redis connection.\n\n    ## Usage:\n    ```python\n    manager = RedisStateManager(host=\"localhost\", port=6379, db=0)\n    manager.set_state(\"user123\", {\"status\": \"active\"})\n    state = manager.get_state(\"user123\")\n    print(state)  # Outputs: {\"status\": \"active\"}\n    ```\n\n    !!! warning\n        Ensure Redis is accessible and running.\n    \"\"\"\n\n    def __init__(self, host: str, port: int, db: int) -&gt; None:\n\"\"\"\n        Initialize a new Redis state manager.\n\n        Args:\n            host (str): The host of the Redis server.\n            port (int): The port of the Redis server.\n            db (int): The database number to connect to.\n        \"\"\"\n        super().__init__()\n        self.redis = redis.Redis(host=host, port=port, db=db)\n        self.log = logging.getLogger(self.__class__.__name__)\n        self.log.info(f\"\ud83d\udd0c Connected to Redis at {host}:{port}, DB: {db}\")\n\n    def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n        \ud83d\udcd6 Get the state associated with a key.\n\n        Args:\n            key (str): The key to get the state for.\n\n        Returns:\n            Dict: The state associated with the key, or None if not found.\n\n        Raises:\n            Exception: If there's an error accessing Redis.\n        \"\"\"\n        value = self.redis.get(key)\n        if not value:\n            self.log.warning(f\"\ud83d\udd0d Key '{key}' not found in Redis.\")\n            return None\n        else:\n            return jsonpickle.decode(value.decode(\"utf-8\"))\n\n    def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n        \ud83d\udcdd Set the state associated with a key.\n\n        Args:\n            key (str): The key to set the state for.\n            value (Dict): The state to set.\n\n        Raises:\n            Exception: If there's an error accessing Redis.\n        \"\"\"\n        try:\n            self.redis.set(key, jsonpickle.encode(value))\n            self.log.info(f\"\u2705 State for key '{key}' set in Redis.\")\n        except Exception as e:\n            self.log.exception(f\"\ud83d\udeab Failed to set state in Redis: {e}\")\n            raise\n</code></pre>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager.__init__","title":"<code>__init__(host, port, db)</code>","text":"<p>Initialize a new Redis state manager.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>The host of the Redis server.</p> required <code>port</code> <code>int</code> <p>The port of the Redis server.</p> required <code>db</code> <code>int</code> <p>The database number to connect to.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py</code> <pre><code>def __init__(self, host: str, port: int, db: int) -&gt; None:\n\"\"\"\n    Initialize a new Redis state manager.\n\n    Args:\n        host (str): The host of the Redis server.\n        port (int): The port of the Redis server.\n        db (int): The database number to connect to.\n    \"\"\"\n    super().__init__()\n    self.redis = redis.Redis(host=host, port=port, db=db)\n    self.log = logging.getLogger(self.__class__.__name__)\n    self.log.info(f\"\ud83d\udd0c Connected to Redis at {host}:{port}, DB: {db}\")\n</code></pre>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager.get_state","title":"<code>get_state(key)</code>","text":"<p>\ud83d\udcd6 Get the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to get the state for.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Optional[Dict]</code> <p>The state associated with the key, or None if not found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing Redis.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py</code> <pre><code>def get_state(self, key: str) -&gt; Optional[Dict]:\n\"\"\"\n    \ud83d\udcd6 Get the state associated with a key.\n\n    Args:\n        key (str): The key to get the state for.\n\n    Returns:\n        Dict: The state associated with the key, or None if not found.\n\n    Raises:\n        Exception: If there's an error accessing Redis.\n    \"\"\"\n    value = self.redis.get(key)\n    if not value:\n        self.log.warning(f\"\ud83d\udd0d Key '{key}' not found in Redis.\")\n        return None\n    else:\n        return jsonpickle.decode(value.decode(\"utf-8\"))\n</code></pre>"},{"location":"core/core_state_redis/#core.state.redis.RedisStateManager.set_state","title":"<code>set_state(key, value)</code>","text":"<p>\ud83d\udcdd Set the state associated with a key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to set the state for.</p> required <code>value</code> <code>Dict</code> <p>The state to set.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error accessing Redis.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/state/redis.py</code> <pre><code>def set_state(self, key: str, value: Dict) -&gt; None:\n\"\"\"\n    \ud83d\udcdd Set the state associated with a key.\n\n    Args:\n        key (str): The key to set the state for.\n        value (Dict): The state to set.\n\n    Raises:\n        Exception: If there's an error accessing Redis.\n    \"\"\"\n    try:\n        self.redis.set(key, jsonpickle.encode(value))\n        self.log.info(f\"\u2705 State for key '{key}' set in Redis.\")\n    except Exception as e:\n        self.log.exception(f\"\ud83d\udeab Failed to set state in Redis: {e}\")\n        raise\n</code></pre>"},{"location":"core/core_task_base/","title":"Task","text":"<p>Base class for Task</p>"},{"location":"core/core_task_base/#core.task.base.Task","title":"<code>Task</code>","text":"<p>             Bases: <code>ABC</code></p> <p>\ud83d\udee0\ufe0f Task: Class for managing tasks.</p> <p>This class provides a foundation for creating and managing tasks. Each task has a unique identifier and can be associated with specific input and output configurations.</p>"},{"location":"core/core_task_base/#core.task.base.Task--attributes","title":"Attributes:","text":"<ul> <li><code>id</code> (uuid.UUID): Unique identifier for the task.</li> <li><code>input_config</code> (InputConfig): Configuration for input data.</li> <li><code>output_config</code> (OutputConfig): Configuration for output data.</li> </ul>"},{"location":"core/core_task_base/#core.task.base.Task--usage","title":"Usage:","text":"<pre><code>task = Task()\ntask.execute(\"fetch_data\")\n</code></pre> <p>!!! note     Extend this class to implement specific task functionalities.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>class Task(ABC):\n\"\"\"\n    \ud83d\udee0\ufe0f **Task**: Class for managing tasks.\n\n    This class provides a foundation for creating and managing tasks. Each task has a unique identifier and can be associated with specific input and output configurations.\n\n    ## Attributes:\n    - `id` (uuid.UUID): Unique identifier for the task.\n    - `input_config` (InputConfig): Configuration for input data.\n    - `output_config` (OutputConfig): Configuration for output data.\n\n    ## Usage:\n    ```python\n    task = Task()\n    task.execute(\"fetch_data\")\n    ```\n\n    !!! note\n        Extend this class to implement specific task functionalities.\n    \"\"\"\n\n    input_config: InputConfig\n    output_config: OutputConfig\n\n    def __init__(self) -&gt; None:\n\"\"\"\n        Initialize a new task.\n\n        Args:\n            input_config (InputConfig): Configuration for input data.\n            output_config (OutputConfig): Configuration for output data.\n        \"\"\"\n        self.id = str(uuid.uuid4())\n        self.log = logging.getLogger(self.__class__.__name__)\n        self.log.info(f\"\ud83d\ude80 Initialized Task with ID: {self.id}\")\n\n    def __repr__(self) -&gt; str:\n\"\"\"\n        Return a string representation of the task.\n\n        Returns:\n            str: A string representation of the task.\n        \"\"\"\n        return f\"Task(id={self.id}, input_config={self.input_config}, output_config={self.output_config})\"\n\n    def execute(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n        \ud83d\ude80 Execute a given fetch_* method if it exists.\n\n        Args:\n            method_name (str): The name of the fetch_* method to execute.\n            *args: Positional arguments to pass to the method.\n            **kwargs: Keyword arguments to pass to the method.\n\n        Returns:\n            Any: The result of the fetch_* method, or None if the method does not exist.\n\n        Raises:\n            AttributeError: If the specified method doesn't exist.\n        \"\"\"\n        method = getattr(self, method_name, None)\n        if callable(method):\n            return method(*args, **kwargs)\n        else:\n            self.log.error(f\"\ud83d\udeab Method '{method_name}' not found!\")\n            raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{method_name}'\")\n\n    @staticmethod\n    def get_methods(cls) -&gt; List[Tuple[str, List[str], Optional[str]]]:\n\"\"\"\n        \ud83d\udcdc Get all the fetch_* methods and their parameters along with their default values and docstrings.\n\n        Returns:\n            List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method,\n            a list of its parameters along with their default values, and its docstring.\n        \"\"\"\n        fetch_methods = []\n        for name, method in inspect.getmembers(cls, predicate=inspect.isfunction):\n            if name.startswith(\"fetch_\"):\n                params = inspect.signature(method).parameters\n                params_str = [\n                    f\"{name}={param.default if param.default is not param.empty else ''}\"\n                    for name, param in params.items()\n                ]\n                docstring = inspect.getdoc(method)\n                fetch_methods.append((name, params_str, docstring))\n        return fetch_methods\n\n    @staticmethod\n    def print_help(cls) -&gt; None:\n\"\"\"\n        \ud83d\udda8\ufe0f Pretty print the fetch_* methods and their parameters along with their default values and docstrings.\n        Also prints the class's docstring and __init__ parameters.\n        \"\"\"\n        # Print class docstring\n        print(cls.__name__, colored(inspect.getdoc(cls) if inspect.getdoc(cls) else \"\", \"green\"))  # type: ignore\n\n        # Print fetch_* methods\n        fetch_methods = cls.get_methods(cls)\n        if fetch_methods:\n            table = PrettyTable(align=\"l\")\n            table.field_names = [\n                colored(\"Method\", \"cyan\"),\n                colored(\"Parameters\", \"cyan\"),\n                colored(\"Description\", \"cyan\"),\n            ]\n            for name, params, docstring in fetch_methods:\n                parameters = [_p.replace(\"=\", \"\") for _p in params if \"self\" not in _p]\n                table.add_row(\n                    [colored(name, \"yellow\"), \"\\n\".join(parameters), docstring],\n                    divider=True,\n                )\n            print(table)\n        else:\n            print(colored(\"No fetch_* methods found.\", \"red\"))\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.__init__","title":"<code>__init__()</code>","text":"<p>Initialize a new task.</p> <p>Parameters:</p> Name Type Description Default <code>input_config</code> <code>InputConfig</code> <p>Configuration for input data.</p> required <code>output_config</code> <code>OutputConfig</code> <p>Configuration for output data.</p> required Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>def __init__(self) -&gt; None:\n\"\"\"\n    Initialize a new task.\n\n    Args:\n        input_config (InputConfig): Configuration for input data.\n        output_config (OutputConfig): Configuration for output data.\n    \"\"\"\n    self.id = str(uuid.uuid4())\n    self.log = logging.getLogger(self.__class__.__name__)\n    self.log.info(f\"\ud83d\ude80 Initialized Task with ID: {self.id}\")\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the task.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string representation of the task.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>def __repr__(self) -&gt; str:\n\"\"\"\n    Return a string representation of the task.\n\n    Returns:\n        str: A string representation of the task.\n    \"\"\"\n    return f\"Task(id={self.id}, input_config={self.input_config}, output_config={self.output_config})\"\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.execute","title":"<code>execute(method_name, *args, **kwargs)</code>","text":"<p>\ud83d\ude80 Execute a given fetch_* method if it exists.</p> <p>Parameters:</p> Name Type Description Default <code>method_name</code> <code>str</code> <p>The name of the fetch_* method to execute.</p> required <code>*args</code> <p>Positional arguments to pass to the method.</p> <code>()</code> <code>**kwargs</code> <p>Keyword arguments to pass to the method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the fetch_* method, or None if the method does not exist.</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the specified method doesn't exist.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>def execute(self, method_name: str, *args, **kwargs) -&gt; Any:\n\"\"\"\n    \ud83d\ude80 Execute a given fetch_* method if it exists.\n\n    Args:\n        method_name (str): The name of the fetch_* method to execute.\n        *args: Positional arguments to pass to the method.\n        **kwargs: Keyword arguments to pass to the method.\n\n    Returns:\n        Any: The result of the fetch_* method, or None if the method does not exist.\n\n    Raises:\n        AttributeError: If the specified method doesn't exist.\n    \"\"\"\n    method = getattr(self, method_name, None)\n    if callable(method):\n        return method(*args, **kwargs)\n    else:\n        self.log.error(f\"\ud83d\udeab Method '{method_name}' not found!\")\n        raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{method_name}'\")\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.get_methods","title":"<code>get_methods()</code>  <code>staticmethod</code>","text":"<p>\ud83d\udcdc Get all the fetch_* methods and their parameters along with their default values and docstrings.</p> <p>Returns:</p> Type Description <code>List[Tuple[str, List[str], Optional[str]]]</code> <p>List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method,</p> <code>List[Tuple[str, List[str], Optional[str]]]</code> <p>a list of its parameters along with their default values, and its docstring.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>@staticmethod\ndef get_methods(cls) -&gt; List[Tuple[str, List[str], Optional[str]]]:\n\"\"\"\n    \ud83d\udcdc Get all the fetch_* methods and their parameters along with their default values and docstrings.\n\n    Returns:\n        List[Tuple[str, List[str], str]]: A list of tuples, where each tuple contains the name of a fetch_* method,\n        a list of its parameters along with their default values, and its docstring.\n    \"\"\"\n    fetch_methods = []\n    for name, method in inspect.getmembers(cls, predicate=inspect.isfunction):\n        if name.startswith(\"fetch_\"):\n            params = inspect.signature(method).parameters\n            params_str = [\n                f\"{name}={param.default if param.default is not param.empty else ''}\"\n                for name, param in params.items()\n            ]\n            docstring = inspect.getdoc(method)\n            fetch_methods.append((name, params_str, docstring))\n    return fetch_methods\n</code></pre>"},{"location":"core/core_task_base/#core.task.base.Task.print_help","title":"<code>print_help()</code>  <code>staticmethod</code>","text":"<p>\ud83d\udda8\ufe0f Pretty print the fetch_* methods and their parameters along with their default values and docstrings. Also prints the class's docstring and init parameters.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/base.py</code> <pre><code>@staticmethod\ndef print_help(cls) -&gt; None:\n\"\"\"\n    \ud83d\udda8\ufe0f Pretty print the fetch_* methods and their parameters along with their default values and docstrings.\n    Also prints the class's docstring and __init__ parameters.\n    \"\"\"\n    # Print class docstring\n    print(cls.__name__, colored(inspect.getdoc(cls) if inspect.getdoc(cls) else \"\", \"green\"))  # type: ignore\n\n    # Print fetch_* methods\n    fetch_methods = cls.get_methods(cls)\n    if fetch_methods:\n        table = PrettyTable(align=\"l\")\n        table.field_names = [\n            colored(\"Method\", \"cyan\"),\n            colored(\"Parameters\", \"cyan\"),\n            colored(\"Description\", \"cyan\"),\n        ]\n        for name, params, docstring in fetch_methods:\n            parameters = [_p.replace(\"=\", \"\") for _p in params if \"self\" not in _p]\n            table.add_row(\n                [colored(name, \"yellow\"), \"\\n\".join(parameters), docstring],\n                divider=True,\n            )\n        print(table)\n    else:\n        print(colored(\"No fetch_* methods found.\", \"red\"))\n</code></pre>"},{"location":"core/core_task_ecs/","title":"ECS Runner","text":""},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager","title":"<code>ECSManager</code>","text":"<p>A class used to manage the lifecycle of an ECS container.</p> <p>...</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager--attributes","title":"Attributes","text":"str <p>the name of the ECS task or service</p> List[str] <p>the command that the container runs</p> str <p>the name of the ECS cluster</p> List[str] <p>the subnet IDs for the task or service</p> List[str] <p>the security group IDs for the task or service</p> str <p>the Docker image for the task</p> int <p>the number of task replicas</p> int <p>the port that the container listens on</p> str <p>the CloudWatch log group for the task logs</p> int <p>the CPU value for the task</p> int <p>the memory value for the task</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager--methods","title":"Methods","text":"<p>create_task_definition()     Registers a new task definition from the attributes of this class run_task(task_definition_arn: str)     Runs a new task using the specified task definition ARN describe_task(task_definition_arn: str)     Describes a task using the specified task definition ARN stop_task(task_definition_arn: str)     Stops a running task using the specified task definition ARN update_task(new_image: str, new_command: list)     Updates a task with a new Docker image and command create_service(task_definition_arn: str)     Creates a new service using the specified task definition ARN update_service(task_definition_arn: str)     Updates a service with a new task definition ARN delete_service()     Deletes the service</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>class ECSManager:\n\"\"\"\n    A class used to manage the lifecycle of an ECS container.\n\n    ...\n\n    Attributes\n    ----------\n    name : str\n        the name of the ECS task or service\n    command : List[str]\n        the command that the container runs\n    cluster : str\n        the name of the ECS cluster\n    subnet_ids : List[str]\n        the subnet IDs for the task or service\n    security_group_ids : List[str]\n        the security group IDs for the task or service\n    image : str\n        the Docker image for the task\n    replicas : int\n        the number of task replicas\n    port : int\n        the port that the container listens on\n    log_group : str\n        the CloudWatch log group for the task logs\n    cpu : int\n        the CPU value for the task\n    memory : int\n        the memory value for the task\n\n    Methods\n    -------\n    create_task_definition()\n        Registers a new task definition from the attributes of this class\n    run_task(task_definition_arn: str)\n        Runs a new task using the specified task definition ARN\n    describe_task(task_definition_arn: str)\n        Describes a task using the specified task definition ARN\n    stop_task(task_definition_arn: str)\n        Stops a running task using the specified task definition ARN\n    update_task(new_image: str, new_command: list)\n        Updates a task with a new Docker image and command\n    create_service(task_definition_arn: str)\n        Creates a new service using the specified task definition ARN\n    update_service(task_definition_arn: str)\n        Updates a service with a new task definition ARN\n    delete_service()\n        Deletes the service\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        account_id: str,\n        cluster: str,\n        command: List[str] = [],\n        subnet_ids: List[str] = [],\n        security_group_ids: List[str] = [],\n        image: str = \"geniusrise/geniusrise\",\n        replicas: int = 1,\n        port: int = 80,\n        log_group: str = \"/ecs/geniusrise\",\n        cpu: int = 256,\n        memory: int = 512,\n    ):\n\"\"\"\n        Constructs all the necessary attributes for the ECSManager object.\n\n        Parameters\n        ----------\n            name : str\n                the name of the ECS task or service\n            account_id : str\n                the id of the AWS account\n            command : List[str]\n                the command that the container runs\n            cluster : str\n                the name of the ECS cluster\n            subnet_ids : List[str]\n                the subnet IDs for the task or service\n            security_group_ids : List[str]\n                the security group IDs for the task or service\n            image : str, optional\n                the Docker image for the task (default is \"geniusrise/geniusrise\")\n            replicas : int, optional\n                the number of task replicas (default is 1)\n            port : int, optional\n                the port that the container listens on (default is 80)\n            log_group : str, optional\n                the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\")\n            cpu : int, optional\n                the CPU value for the task (default is 256)\n            memory : int, optional\n                the memory value for the task (default is 512)\n        \"\"\"\n        self.name = name\n        self.image = image\n        self.cluster = cluster\n        self.command = command\n        self.replicas = replicas\n        self.port = port\n        self.client = boto3.client(\"ecs\")\n        self.log_group = log_group\n        self.logs_client = boto3.client(\"logs\")\n        self.subnet_ids = subnet_ids\n        self.security_group_ids = security_group_ids\n        self.cpu = cpu\n        self.account_id = account_id\n        self.memory = memory\n\n    def create_task_definition(self) -&gt; Optional[str]:\n\"\"\"\n        Registers a new task definition from the attributes of this class.\n\n        Returns\n        -------\n        str\n            The ARN of the task definition, or None if an error occurred.\n        \"\"\"\n        container_definitions = [\n            {\n                \"name\": self.name,\n                \"image\": self.image,\n                \"command\": self.command,\n                \"portMappings\": [{\"containerPort\": self.port, \"protocol\": \"tcp\"}],\n            }\n        ]\n\n        try:\n            response = self.client.register_task_definition(\n                family=self.name,\n                networkMode=\"awsvpc\",\n                containerDefinitions=container_definitions,\n                requiresCompatibilities=[\n                    \"FARGATE\",\n                ],\n                cpu=str(self.cpu),\n                memory=str(self.memory),\n                executionRoleArn=f\"arn:aws:iam::{self.account_id}:role/ecsTaskExecutionRole\",\n            )\n            log.info(f\"Task definition {self.name} created.\")\n            return response[\"taskDefinition\"][\"taskDefinitionArn\"]\n        except (BotoCoreError, ClientError) as error:\n            log.error(f\"Error creating task definition {self.name}: {error}\")\n            return None\n\n    def run_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Runs a new task using the specified task definition ARN.\n\n        Parameters\n        ----------\n        task_definition_arn : str\n            The ARN of the task definition to run.\n\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\n        try:\n            response = self.client.run_task(\n                cluster=self.cluster,\n                taskDefinition=task_definition_arn,\n                count=self.replicas,\n                launchType=\"FARGATE\",\n                networkConfiguration={\n                    \"awsvpcConfiguration\": {\n                        \"subnets\": self.subnet_ids,\n                        \"assignPublicIp\": \"ENABLED\",\n                        \"securityGroups\": self.security_group_ids,\n                    }\n                },\n                platformVersion=\"LATEST\",\n            )\n            log.info(f\"Task {self.name} started.\")\n            return response\n        except (BotoCoreError, ClientError) as error:\n            log.error(f\"Error starting task {self.name}: {error}\")\n            return None\n\n    def describe_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Describes a task using the specified task definition ARN.\n\n        Parameters\n        ----------\n        task_definition_arn : str\n            The ARN of the task definition to describe.\n\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\n        try:\n            response = self.client.describe_tasks(cluster=self.cluster, tasks=[task_definition_arn])\n            return response\n        except (BotoCoreError, ClientError) as error:\n            log.error(f\"Error getting status of task {self.name}: {error}\")\n            return None\n\n    def stop_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Stops a running task using the specified task definition ARN.\n\n        Parameters\n        ----------\n        task_definition_arn : str\n            The ARN of the task definition to stop.\n\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\n        try:\n            response = self.client.stop_task(cluster=self.cluster, task=task_definition_arn)\n            log.info(f\"Task {self.name} stopped.\")\n            return response\n        except (BotoCoreError, ClientError) as error:\n            log.error(f\"Error stopping task {self.name}: {error}\")\n            return None\n\n    def update_task(self, new_image: str, new_command: list) -&gt; None:\n\"\"\"\n        Updates a task with a new Docker image and command.\n\n        Parameters\n        ----------\n        new_image : str\n            The new Docker image for the task.\n        new_command : list\n            The new command for the task.\n        \"\"\"\n        self.image = new_image\n        self.command = new_command\n        task_definition_arn = self.create_task_definition()\n        if task_definition_arn:\n            self.stop_task(task_definition_arn)\n            self.run_task(task_definition_arn)\n        else:\n            log.error(f\"Error updating task {self.name} - could not create ECS task definition.\")\n\n    def create_service(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Creates a new service using the specified task definition ARN.\n\n        Parameters\n        ----------\n        task_definition_arn : str\n            The ARN of the task definition to use for the service.\n\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\n        try:\n            response = self.client.create_service(\n                cluster=self.cluster,\n                serviceName=self.name,\n                taskDefinition=task_definition_arn,\n                desiredCount=self.replicas,\n                launchType=\"FARGATE\",\n                networkConfiguration={\n                    \"awsvpcConfiguration\": {\n                        \"subnets\": self.subnet_ids,\n                        \"assignPublicIp\": \"ENABLED\",\n                        \"securityGroups\": self.security_group_ids,\n                    }\n                },\n            )\n            log.info(f\"Service {self.name} created.\")\n            return response\n        except (BotoCoreError, ClientError) as error:\n            log.error(f\"Error creating service {self.name}: {error}\")\n            return None\n\n    def update_service(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n        Updates a service with a new task definition ARN.\n\n        Parameters\n        ----------\n        task_definition_arn : str\n            The new ARN of the task definition to use for the service.\n\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\n        try:\n            response = self.client.update_service(\n                cluster=self.cluster,\n                service=self.name,\n                taskDefinition=task_definition_arn,\n                desiredCount=self.replicas,\n            )\n            log.info(f\"Service {self.name} updated.\")\n            return response\n        except (BotoCoreError, ClientError) as error:\n            log.error(f\"Error updating service {self.name}: {error}\")\n            return None\n\n    def delete_service(self) -&gt; Optional[dict]:\n\"\"\"\n        Deletes the service.\n\n        Returns\n        -------\n        dict\n            The response from the ECS API, or None if an error occurred.\n        \"\"\"\n        try:\n            response = self.client.delete_service(\n                cluster=self.cluster,\n                service=self.name,\n            )\n            log.info(f\"Service {self.name} deleted.\")\n            return response\n        except (BotoCoreError, ClientError) as error:\n            log.error(f\"Error deleting service {self.name}: {error}\")\n            return None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.__init__","title":"<code>__init__(name, account_id, cluster, command=[], subnet_ids=[], security_group_ids=[], image='geniusrise/geniusrise', replicas=1, port=80, log_group='/ecs/geniusrise', cpu=256, memory=512)</code>","text":"<p>Constructs all the necessary attributes for the ECSManager object.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.__init__--parameters","title":"Parameters","text":"<pre><code>name : str\n    the name of the ECS task or service\naccount_id : str\n    the id of the AWS account\ncommand : List[str]\n    the command that the container runs\ncluster : str\n    the name of the ECS cluster\nsubnet_ids : List[str]\n    the subnet IDs for the task or service\nsecurity_group_ids : List[str]\n    the security group IDs for the task or service\nimage : str, optional\n    the Docker image for the task (default is \"geniusrise/geniusrise\")\nreplicas : int, optional\n    the number of task replicas (default is 1)\nport : int, optional\n    the port that the container listens on (default is 80)\nlog_group : str, optional\n    the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\")\ncpu : int, optional\n    the CPU value for the task (default is 256)\nmemory : int, optional\n    the memory value for the task (default is 512)\n</code></pre> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    account_id: str,\n    cluster: str,\n    command: List[str] = [],\n    subnet_ids: List[str] = [],\n    security_group_ids: List[str] = [],\n    image: str = \"geniusrise/geniusrise\",\n    replicas: int = 1,\n    port: int = 80,\n    log_group: str = \"/ecs/geniusrise\",\n    cpu: int = 256,\n    memory: int = 512,\n):\n\"\"\"\n    Constructs all the necessary attributes for the ECSManager object.\n\n    Parameters\n    ----------\n        name : str\n            the name of the ECS task or service\n        account_id : str\n            the id of the AWS account\n        command : List[str]\n            the command that the container runs\n        cluster : str\n            the name of the ECS cluster\n        subnet_ids : List[str]\n            the subnet IDs for the task or service\n        security_group_ids : List[str]\n            the security group IDs for the task or service\n        image : str, optional\n            the Docker image for the task (default is \"geniusrise/geniusrise\")\n        replicas : int, optional\n            the number of task replicas (default is 1)\n        port : int, optional\n            the port that the container listens on (default is 80)\n        log_group : str, optional\n            the CloudWatch log group for the task logs (default is \"/ecs/geniusrise\")\n        cpu : int, optional\n            the CPU value for the task (default is 256)\n        memory : int, optional\n            the memory value for the task (default is 512)\n    \"\"\"\n    self.name = name\n    self.image = image\n    self.cluster = cluster\n    self.command = command\n    self.replicas = replicas\n    self.port = port\n    self.client = boto3.client(\"ecs\")\n    self.log_group = log_group\n    self.logs_client = boto3.client(\"logs\")\n    self.subnet_ids = subnet_ids\n    self.security_group_ids = security_group_ids\n    self.cpu = cpu\n    self.account_id = account_id\n    self.memory = memory\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_service","title":"<code>create_service(task_definition_arn)</code>","text":"<p>Creates a new service using the specified task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_service--parameters","title":"Parameters","text":"str <p>The ARN of the task definition to use for the service.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_service--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def create_service(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Creates a new service using the specified task definition ARN.\n\n    Parameters\n    ----------\n    task_definition_arn : str\n        The ARN of the task definition to use for the service.\n\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\n    try:\n        response = self.client.create_service(\n            cluster=self.cluster,\n            serviceName=self.name,\n            taskDefinition=task_definition_arn,\n            desiredCount=self.replicas,\n            launchType=\"FARGATE\",\n            networkConfiguration={\n                \"awsvpcConfiguration\": {\n                    \"subnets\": self.subnet_ids,\n                    \"assignPublicIp\": \"ENABLED\",\n                    \"securityGroups\": self.security_group_ids,\n                }\n            },\n        )\n        log.info(f\"Service {self.name} created.\")\n        return response\n    except (BotoCoreError, ClientError) as error:\n        log.error(f\"Error creating service {self.name}: {error}\")\n        return None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_task_definition","title":"<code>create_task_definition()</code>","text":"<p>Registers a new task definition from the attributes of this class.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.create_task_definition--returns","title":"Returns","text":"<p>str     The ARN of the task definition, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def create_task_definition(self) -&gt; Optional[str]:\n\"\"\"\n    Registers a new task definition from the attributes of this class.\n\n    Returns\n    -------\n    str\n        The ARN of the task definition, or None if an error occurred.\n    \"\"\"\n    container_definitions = [\n        {\n            \"name\": self.name,\n            \"image\": self.image,\n            \"command\": self.command,\n            \"portMappings\": [{\"containerPort\": self.port, \"protocol\": \"tcp\"}],\n        }\n    ]\n\n    try:\n        response = self.client.register_task_definition(\n            family=self.name,\n            networkMode=\"awsvpc\",\n            containerDefinitions=container_definitions,\n            requiresCompatibilities=[\n                \"FARGATE\",\n            ],\n            cpu=str(self.cpu),\n            memory=str(self.memory),\n            executionRoleArn=f\"arn:aws:iam::{self.account_id}:role/ecsTaskExecutionRole\",\n        )\n        log.info(f\"Task definition {self.name} created.\")\n        return response[\"taskDefinition\"][\"taskDefinitionArn\"]\n    except (BotoCoreError, ClientError) as error:\n        log.error(f\"Error creating task definition {self.name}: {error}\")\n        return None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.delete_service","title":"<code>delete_service()</code>","text":"<p>Deletes the service.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.delete_service--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def delete_service(self) -&gt; Optional[dict]:\n\"\"\"\n    Deletes the service.\n\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\n    try:\n        response = self.client.delete_service(\n            cluster=self.cluster,\n            service=self.name,\n        )\n        log.info(f\"Service {self.name} deleted.\")\n        return response\n    except (BotoCoreError, ClientError) as error:\n        log.error(f\"Error deleting service {self.name}: {error}\")\n        return None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.describe_task","title":"<code>describe_task(task_definition_arn)</code>","text":"<p>Describes a task using the specified task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.describe_task--parameters","title":"Parameters","text":"str <p>The ARN of the task definition to describe.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.describe_task--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def describe_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Describes a task using the specified task definition ARN.\n\n    Parameters\n    ----------\n    task_definition_arn : str\n        The ARN of the task definition to describe.\n\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\n    try:\n        response = self.client.describe_tasks(cluster=self.cluster, tasks=[task_definition_arn])\n        return response\n    except (BotoCoreError, ClientError) as error:\n        log.error(f\"Error getting status of task {self.name}: {error}\")\n        return None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.run_task","title":"<code>run_task(task_definition_arn)</code>","text":"<p>Runs a new task using the specified task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.run_task--parameters","title":"Parameters","text":"str <p>The ARN of the task definition to run.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.run_task--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def run_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Runs a new task using the specified task definition ARN.\n\n    Parameters\n    ----------\n    task_definition_arn : str\n        The ARN of the task definition to run.\n\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\n    try:\n        response = self.client.run_task(\n            cluster=self.cluster,\n            taskDefinition=task_definition_arn,\n            count=self.replicas,\n            launchType=\"FARGATE\",\n            networkConfiguration={\n                \"awsvpcConfiguration\": {\n                    \"subnets\": self.subnet_ids,\n                    \"assignPublicIp\": \"ENABLED\",\n                    \"securityGroups\": self.security_group_ids,\n                }\n            },\n            platformVersion=\"LATEST\",\n        )\n        log.info(f\"Task {self.name} started.\")\n        return response\n    except (BotoCoreError, ClientError) as error:\n        log.error(f\"Error starting task {self.name}: {error}\")\n        return None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.stop_task","title":"<code>stop_task(task_definition_arn)</code>","text":"<p>Stops a running task using the specified task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.stop_task--parameters","title":"Parameters","text":"str <p>The ARN of the task definition to stop.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.stop_task--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def stop_task(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Stops a running task using the specified task definition ARN.\n\n    Parameters\n    ----------\n    task_definition_arn : str\n        The ARN of the task definition to stop.\n\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\n    try:\n        response = self.client.stop_task(cluster=self.cluster, task=task_definition_arn)\n        log.info(f\"Task {self.name} stopped.\")\n        return response\n    except (BotoCoreError, ClientError) as error:\n        log.error(f\"Error stopping task {self.name}: {error}\")\n        return None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_service","title":"<code>update_service(task_definition_arn)</code>","text":"<p>Updates a service with a new task definition ARN.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_service--parameters","title":"Parameters","text":"str <p>The new ARN of the task definition to use for the service.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_service--returns","title":"Returns","text":"<p>dict     The response from the ECS API, or None if an error occurred.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def update_service(self, task_definition_arn: str) -&gt; Optional[dict]:\n\"\"\"\n    Updates a service with a new task definition ARN.\n\n    Parameters\n    ----------\n    task_definition_arn : str\n        The new ARN of the task definition to use for the service.\n\n    Returns\n    -------\n    dict\n        The response from the ECS API, or None if an error occurred.\n    \"\"\"\n    try:\n        response = self.client.update_service(\n            cluster=self.cluster,\n            service=self.name,\n            taskDefinition=task_definition_arn,\n            desiredCount=self.replicas,\n        )\n        log.info(f\"Service {self.name} updated.\")\n        return response\n    except (BotoCoreError, ClientError) as error:\n        log.error(f\"Error updating service {self.name}: {error}\")\n        return None\n</code></pre>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_task","title":"<code>update_task(new_image, new_command)</code>","text":"<p>Updates a task with a new Docker image and command.</p>"},{"location":"core/core_task_ecs/#core.task.ecs.ECSManager.update_task--parameters","title":"Parameters","text":"str <p>The new Docker image for the task.</p> list <p>The new command for the task.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/ecs.py</code> <pre><code>def update_task(self, new_image: str, new_command: list) -&gt; None:\n\"\"\"\n    Updates a task with a new Docker image and command.\n\n    Parameters\n    ----------\n    new_image : str\n        The new Docker image for the task.\n    new_command : list\n        The new command for the task.\n    \"\"\"\n    self.image = new_image\n    self.command = new_command\n    task_definition_arn = self.create_task_definition()\n    if task_definition_arn:\n        self.stop_task(task_definition_arn)\n        self.run_task(task_definition_arn)\n    else:\n        log.error(f\"Error updating task {self.name} - could not create ECS task definition.\")\n</code></pre>"},{"location":"core/core_task_k8s/","title":"Kubernetes Runner","text":""},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager","title":"<code>K8sManager</code>","text":"<p>A class used to manage Kubernetes deployments and services.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager--attributes","title":"Attributes","text":"str <p>The name of the deployment and service.</p> str <p>The namespace to create the deployment and service in.</p> str <p>The Docker image to use for the deployment.</p> list <p>The command to run in the Docker container.</p> int <p>The number of replicas to create for the deployment.</p> int <p>The port to expose on the service.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager--methods","title":"Methods","text":"<p>create_deployment()     Creates a new deployment. update_deployment(replicas)     Updates the number of replicas in the deployment. scale_deployment(replicas)     Scales the deployment to a new number of replicas. delete_deployment()     Deletes the deployment. create_service()     Creates a new service. delete_service()     Deletes the service. run()     Creates the deployment and service. destroy()     Deletes the deployment and service. get_status()     Returns the status of the deployment. get_statistics()     Returns the details of the deployment and the pods in the deployment. get_logs()     Returns the logs of the pods in the deployment.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>class K8sManager:\n\"\"\"\n    A class used to manage Kubernetes deployments and services.\n\n    Attributes\n    ----------\n    name : str\n        The name of the deployment and service.\n    namespace : str\n        The namespace to create the deployment and service in.\n    image : str\n        The Docker image to use for the deployment.\n    command : list\n        The command to run in the Docker container.\n    replicas : int\n        The number of replicas to create for the deployment.\n    port : int\n        The port to expose on the service.\n\n    Methods\n    -------\n    create_deployment()\n        Creates a new deployment.\n    update_deployment(replicas)\n        Updates the number of replicas in the deployment.\n    scale_deployment(replicas)\n        Scales the deployment to a new number of replicas.\n    delete_deployment()\n        Deletes the deployment.\n    create_service()\n        Creates a new service.\n    delete_service()\n        Deletes the service.\n    run()\n        Creates the deployment and service.\n    destroy()\n        Deletes the deployment and service.\n    get_status()\n        Returns the status of the deployment.\n    get_statistics()\n        Returns the details of the deployment and the pods in the deployment.\n    get_logs()\n        Returns the logs of the pods in the deployment.\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        command: list = [],\n        namespace: str = \"default\",\n        image: str = \"geniusrise/geniusrise\",\n        replicas: int = 1,\n        port: int = 80,\n    ):\n\"\"\"\n        Constructs all the necessary attributes for the K8sManager object.\n\n        Parameters\n        ----------\n        name : str\n            The name of the deployment and service.\n        command : list\n            The command to run in the Docker container.\n        namespace : str, optional\n            The namespace to create the deployment and service in (default is \"default\").\n        image : str, optional\n            The Docker image to use for the deployment (default is \"geniusrise/geniusrise\").\n        replicas : int, optional\n            The number of replicas to create for the deployment (default is 1).\n        port : int, optional\n            The port to expose on the service (default is 80).\n        \"\"\"\n        self.name = name\n        self.namespace = namespace\n        self.image = image\n        self.command = command\n        self.replicas = replicas\n        self.port = port\n\n        # Load kube config from default location\n        config.load_kube_config()\n\n        # Create a client instance for Core V1 and Apps V1 of Kubernetes API\n        self.core_api = client.CoreV1Api()\n        self.apps_api = client.AppsV1Api()\n\n    def create_deployment(self):\n\"\"\"\n        Creates a new deployment.\n\n        The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image\n        and command specified in the constructor, and creates the number of replicas specified in the constructor.\n\n        If an error occurs while creating the deployment, an error message is logged and the method returns None.\n        \"\"\"\n        # Define the container\n        container = client.V1Container(name=self.name, image=self.image, command=self.command)\n\n        # Define the template\n        template = client.V1PodTemplateSpec(\n            metadata=client.V1ObjectMeta(labels={\"app\": self.name, \"service\": \"geniusrise\"}),\n            spec=client.V1PodSpec(containers=[container]),\n        )\n\n        # Define the spec\n        spec = client.V1DeploymentSpec(\n            replicas=self.replicas,\n            selector=client.V1LabelSelector(match_labels={\"app\": self.name, \"service\": \"geniusrise\"}),\n            template=template,\n        )\n\n        # Define the deployment\n        deployment = client.V1Deployment(metadata=client.V1ObjectMeta(name=self.name), spec=spec)\n\n        # Create the deployment\n        try:\n            self.apps_api.create_namespaced_deployment(namespace=self.namespace, body=deployment)\n            log.info(f\"Deployment {self.name} created.\")\n        except ApiException as e:\n            log.error(f\"Exception when creating deployment {self.name}: {e}\")\n\n    def update_deployment(self, replicas):\n\"\"\"\n        Updates the number of replicas in the deployment.\n\n        Parameters\n        ----------\n        replicas : int\n            The new number of replicas for the deployment.\n\n        If an error occurs while updating the deployment, an error message is logged and the method returns None.\n        \"\"\"\n        # Get the existing deployment\n        try:\n            deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n\n            # Update the number of replicas\n            deployment.spec.replicas = replicas\n\n            # Update the deployment\n            self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment)\n            log.info(f\"Deployment {self.name} updated.\")\n        except ApiException as e:\n            log.error(f\"Exception when updating deployment {self.name}: {e}\")\n\n    def scale_deployment(self, replicas):\n\"\"\"\n        Scales the deployment to a new number of replicas.\n\n        Parameters\n        ----------\n        replicas : int\n            The new number of replicas for the deployment.\n\n        If an error occurs while scaling the deployment, an error message is logged and the method returns None.\n        \"\"\"\n        # Get the existing deployment\n        try:\n            deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n\n            # Update the number of replicas\n            deployment.spec.replicas = replicas\n\n            # Update the deployment\n            self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment)\n            log.info(f\"Deployment {self.name} scaled to {replicas} replicas.\")\n        except ApiException as e:\n            log.error(f\"Exception when scaling deployment {self.name}: {e}\")\n\n    def delete_deployment(self):\n        # Delete the deployment\n        try:\n            self.apps_api.delete_namespaced_deployment(name=self.name, namespace=self.namespace)\n            log.info(f\"Deployment {self.name} deleted.\")\n        except ApiException as e:\n            log.error(f\"Exception when deleting deployment {self.name}: {e}\")\n\n    def create_service(self):\n\"\"\"\n        Deletes the deployment.\n\n        If an error occurs while deleting the deployment, an error message is logged and the method returns None.\n        \"\"\"\n        # Define the service spec\n        spec = client.V1ServiceSpec(\n            selector={\"app\": self.name},\n            ports=[client.V1ServicePort(port=self.port, target_port=self.port)],\n        )\n\n        # Define the service\n        service = client.V1Service(metadata=client.V1ObjectMeta(name=self.name), spec=spec)\n\n        # Create the service\n        try:\n            self.core_api.create_namespaced_service(namespace=self.namespace, body=service)\n            log.info(f\"Service {self.name} created.\")\n        except ApiException as e:\n            log.error(f\"Exception when creating service {self.name}: {e}\")\n\n    def delete_service(self):\n\"\"\"\n        Creates a new service.\n\n        The service is created in the namespace specified in the constructor. The service exposes the port specified\n        in the constructor.\n\n        If an error occurs while creating the service, an error message is logged and the method returns None.\n        \"\"\"\n        # Delete the service\n        try:\n            self.core_api.delete_namespaced_service(name=self.name, namespace=self.namespace)\n            log.info(f\"Service {self.name} deleted.\")\n        except ApiException as e:\n            log.error(f\"Exception when deleting service {self.name}: {e}\")\n\n    def run(self):\n\"\"\"\n        Creates the deployment and service.\n\n        If an error occurs while creating the deployment or service,\n        an error message is logged and the method returns None.\n        \"\"\"\n        self.create_deployment()\n        self.create_service()\n\n    def destroy(self):\n\"\"\"\n        Deletes the deployment and service.\n\n        If an error occurs while deleting the deployment or service,\n        an error message is logged and the method returns None.\n        \"\"\"\n        self.delete_deployment()\n        self.delete_service()\n\n    def get_status(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Get the status of the deployment\n\n        Returns:\n            Dict[str, Any]: The status of the deployment\n        \"\"\"\n        try:\n            # Get the status of the deployment\n            deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n            return deployment.status.__dict__\n        except ApiException as e:\n            log.error(f\"Exception when getting status of deployment {self.name}: {e}\")\n            return {}\n\n    def get_statistics(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Get the details of the deployment and the pods in the deployment\n\n        Returns:\n            Dict[str, Any]: The details of the deployment and the pods\n        \"\"\"\n        try:\n            # Get the details of the deployment\n            deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n            deployment_stats = deployment.status\n\n            # Get the details of the pods in the deployment\n            pod_list = self.core_api.list_namespaced_pod(self.namespace, label_selector=f\"app={self.name}\")\n            pod_stats = [pod.status for pod in pod_list.items]\n\n            return {\"deployment\": deployment_stats, \"pods\": pod_stats}\n        except ApiException as e:\n            log.error(f\"Exception when getting statistics of deployment {self.name}: {e}\")\n            return {}\n\n    def get_logs(self) -&gt; Dict[str, str]:\n\"\"\"\n        Get the logs of the pods in the deployment\n\n        Returns:\n            Dict[str, str]: The logs of the pods\n        \"\"\"\n        try:\n            # Get the logs of the pods in the deployment\n            logs = {}\n            _continue = None\n            while True:\n                pod_list = self.core_api.list_namespaced_pod(\n                    self.namespace,\n                    label_selector=f\"app={self.name}\",\n                    _continue=_continue,\n                )\n                for pod in pod_list.items:\n                    logs[pod.metadata.name] = self.core_api.read_namespaced_pod_log(pod.metadata.name, self.namespace)\n                _continue = pod_list.metadata._continue\n                if not _continue:\n                    break\n            return logs\n        except ApiException as e:\n            log.error(f\"Exception when getting logs of deployment {self.name}: {e}\")\n            return {}\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.__init__","title":"<code>__init__(name, command=[], namespace='default', image='geniusrise/geniusrise', replicas=1, port=80)</code>","text":"<p>Constructs all the necessary attributes for the K8sManager object.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.__init__--parameters","title":"Parameters","text":"str <p>The name of the deployment and service.</p> list <p>The command to run in the Docker container.</p> str, optional <p>The namespace to create the deployment and service in (default is \"default\").</p> str, optional <p>The Docker image to use for the deployment (default is \"geniusrise/geniusrise\").</p> int, optional <p>The number of replicas to create for the deployment (default is 1).</p> int, optional <p>The port to expose on the service (default is 80).</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    command: list = [],\n    namespace: str = \"default\",\n    image: str = \"geniusrise/geniusrise\",\n    replicas: int = 1,\n    port: int = 80,\n):\n\"\"\"\n    Constructs all the necessary attributes for the K8sManager object.\n\n    Parameters\n    ----------\n    name : str\n        The name of the deployment and service.\n    command : list\n        The command to run in the Docker container.\n    namespace : str, optional\n        The namespace to create the deployment and service in (default is \"default\").\n    image : str, optional\n        The Docker image to use for the deployment (default is \"geniusrise/geniusrise\").\n    replicas : int, optional\n        The number of replicas to create for the deployment (default is 1).\n    port : int, optional\n        The port to expose on the service (default is 80).\n    \"\"\"\n    self.name = name\n    self.namespace = namespace\n    self.image = image\n    self.command = command\n    self.replicas = replicas\n    self.port = port\n\n    # Load kube config from default location\n    config.load_kube_config()\n\n    # Create a client instance for Core V1 and Apps V1 of Kubernetes API\n    self.core_api = client.CoreV1Api()\n    self.apps_api = client.AppsV1Api()\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.create_deployment","title":"<code>create_deployment()</code>","text":"<p>Creates a new deployment.</p> <p>The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image and command specified in the constructor, and creates the number of replicas specified in the constructor.</p> <p>If an error occurs while creating the deployment, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def create_deployment(self):\n\"\"\"\n    Creates a new deployment.\n\n    The deployment is created in the namespace specified in the constructor. The deployment uses the Docker image\n    and command specified in the constructor, and creates the number of replicas specified in the constructor.\n\n    If an error occurs while creating the deployment, an error message is logged and the method returns None.\n    \"\"\"\n    # Define the container\n    container = client.V1Container(name=self.name, image=self.image, command=self.command)\n\n    # Define the template\n    template = client.V1PodTemplateSpec(\n        metadata=client.V1ObjectMeta(labels={\"app\": self.name, \"service\": \"geniusrise\"}),\n        spec=client.V1PodSpec(containers=[container]),\n    )\n\n    # Define the spec\n    spec = client.V1DeploymentSpec(\n        replicas=self.replicas,\n        selector=client.V1LabelSelector(match_labels={\"app\": self.name, \"service\": \"geniusrise\"}),\n        template=template,\n    )\n\n    # Define the deployment\n    deployment = client.V1Deployment(metadata=client.V1ObjectMeta(name=self.name), spec=spec)\n\n    # Create the deployment\n    try:\n        self.apps_api.create_namespaced_deployment(namespace=self.namespace, body=deployment)\n        log.info(f\"Deployment {self.name} created.\")\n    except ApiException as e:\n        log.error(f\"Exception when creating deployment {self.name}: {e}\")\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.create_service","title":"<code>create_service()</code>","text":"<p>Deletes the deployment.</p> <p>If an error occurs while deleting the deployment, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def create_service(self):\n\"\"\"\n    Deletes the deployment.\n\n    If an error occurs while deleting the deployment, an error message is logged and the method returns None.\n    \"\"\"\n    # Define the service spec\n    spec = client.V1ServiceSpec(\n        selector={\"app\": self.name},\n        ports=[client.V1ServicePort(port=self.port, target_port=self.port)],\n    )\n\n    # Define the service\n    service = client.V1Service(metadata=client.V1ObjectMeta(name=self.name), spec=spec)\n\n    # Create the service\n    try:\n        self.core_api.create_namespaced_service(namespace=self.namespace, body=service)\n        log.info(f\"Service {self.name} created.\")\n    except ApiException as e:\n        log.error(f\"Exception when creating service {self.name}: {e}\")\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.delete_service","title":"<code>delete_service()</code>","text":"<p>Creates a new service.</p> <p>The service is created in the namespace specified in the constructor. The service exposes the port specified in the constructor.</p> <p>If an error occurs while creating the service, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def delete_service(self):\n\"\"\"\n    Creates a new service.\n\n    The service is created in the namespace specified in the constructor. The service exposes the port specified\n    in the constructor.\n\n    If an error occurs while creating the service, an error message is logged and the method returns None.\n    \"\"\"\n    # Delete the service\n    try:\n        self.core_api.delete_namespaced_service(name=self.name, namespace=self.namespace)\n        log.info(f\"Service {self.name} deleted.\")\n    except ApiException as e:\n        log.error(f\"Exception when deleting service {self.name}: {e}\")\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.destroy","title":"<code>destroy()</code>","text":"<p>Deletes the deployment and service.</p> <p>If an error occurs while deleting the deployment or service, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def destroy(self):\n\"\"\"\n    Deletes the deployment and service.\n\n    If an error occurs while deleting the deployment or service,\n    an error message is logged and the method returns None.\n    \"\"\"\n    self.delete_deployment()\n    self.delete_service()\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.get_logs","title":"<code>get_logs()</code>","text":"<p>Get the logs of the pods in the deployment</p> <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dict[str, str]: The logs of the pods</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def get_logs(self) -&gt; Dict[str, str]:\n\"\"\"\n    Get the logs of the pods in the deployment\n\n    Returns:\n        Dict[str, str]: The logs of the pods\n    \"\"\"\n    try:\n        # Get the logs of the pods in the deployment\n        logs = {}\n        _continue = None\n        while True:\n            pod_list = self.core_api.list_namespaced_pod(\n                self.namespace,\n                label_selector=f\"app={self.name}\",\n                _continue=_continue,\n            )\n            for pod in pod_list.items:\n                logs[pod.metadata.name] = self.core_api.read_namespaced_pod_log(pod.metadata.name, self.namespace)\n            _continue = pod_list.metadata._continue\n            if not _continue:\n                break\n        return logs\n    except ApiException as e:\n        log.error(f\"Exception when getting logs of deployment {self.name}: {e}\")\n        return {}\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.get_statistics","title":"<code>get_statistics()</code>","text":"<p>Get the details of the deployment and the pods in the deployment</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: The details of the deployment and the pods</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def get_statistics(self) -&gt; Dict[str, Any]:\n\"\"\"\n    Get the details of the deployment and the pods in the deployment\n\n    Returns:\n        Dict[str, Any]: The details of the deployment and the pods\n    \"\"\"\n    try:\n        # Get the details of the deployment\n        deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n        deployment_stats = deployment.status\n\n        # Get the details of the pods in the deployment\n        pod_list = self.core_api.list_namespaced_pod(self.namespace, label_selector=f\"app={self.name}\")\n        pod_stats = [pod.status for pod in pod_list.items]\n\n        return {\"deployment\": deployment_stats, \"pods\": pod_stats}\n    except ApiException as e:\n        log.error(f\"Exception when getting statistics of deployment {self.name}: {e}\")\n        return {}\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.get_status","title":"<code>get_status()</code>","text":"<p>Get the status of the deployment</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: The status of the deployment</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def get_status(self) -&gt; Dict[str, Any]:\n\"\"\"\n    Get the status of the deployment\n\n    Returns:\n        Dict[str, Any]: The status of the deployment\n    \"\"\"\n    try:\n        # Get the status of the deployment\n        deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n        return deployment.status.__dict__\n    except ApiException as e:\n        log.error(f\"Exception when getting status of deployment {self.name}: {e}\")\n        return {}\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.run","title":"<code>run()</code>","text":"<p>Creates the deployment and service.</p> <p>If an error occurs while creating the deployment or service, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def run(self):\n\"\"\"\n    Creates the deployment and service.\n\n    If an error occurs while creating the deployment or service,\n    an error message is logged and the method returns None.\n    \"\"\"\n    self.create_deployment()\n    self.create_service()\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.scale_deployment","title":"<code>scale_deployment(replicas)</code>","text":"<p>Scales the deployment to a new number of replicas.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.scale_deployment--parameters","title":"Parameters","text":"int <p>The new number of replicas for the deployment.</p> <p>If an error occurs while scaling the deployment, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def scale_deployment(self, replicas):\n\"\"\"\n    Scales the deployment to a new number of replicas.\n\n    Parameters\n    ----------\n    replicas : int\n        The new number of replicas for the deployment.\n\n    If an error occurs while scaling the deployment, an error message is logged and the method returns None.\n    \"\"\"\n    # Get the existing deployment\n    try:\n        deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n\n        # Update the number of replicas\n        deployment.spec.replicas = replicas\n\n        # Update the deployment\n        self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment)\n        log.info(f\"Deployment {self.name} scaled to {replicas} replicas.\")\n    except ApiException as e:\n        log.error(f\"Exception when scaling deployment {self.name}: {e}\")\n</code></pre>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.update_deployment","title":"<code>update_deployment(replicas)</code>","text":"<p>Updates the number of replicas in the deployment.</p>"},{"location":"core/core_task_k8s/#core.task.k8s.K8sManager.update_deployment--parameters","title":"Parameters","text":"int <p>The new number of replicas for the deployment.</p> <p>If an error occurs while updating the deployment, an error message is logged and the method returns None.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/core/task/k8s.py</code> <pre><code>def update_deployment(self, replicas):\n\"\"\"\n    Updates the number of replicas in the deployment.\n\n    Parameters\n    ----------\n    replicas : int\n        The new number of replicas for the deployment.\n\n    If an error occurs while updating the deployment, an error message is logged and the method returns None.\n    \"\"\"\n    # Get the existing deployment\n    try:\n        deployment = self.apps_api.read_namespaced_deployment(name=self.name, namespace=self.namespace)\n\n        # Update the number of replicas\n        deployment.spec.replicas = replicas\n\n        # Update the deployment\n        self.apps_api.replace_namespaced_deployment(name=self.name, namespace=self.namespace, body=deployment)\n        log.info(f\"Deployment {self.name} updated.\")\n    except ApiException as e:\n        log.error(f\"Exception when updating deployment {self.name}: {e}\")\n</code></pre>"},{"location":"core/logging/","title":"Logging Configuration","text":""},{"location":"core/logging/#logging.setup_logger","title":"<code>setup_logger()</code>","text":"<p>\ud83d\udee0\ufe0f Setup Logger: Configure and return a logger with a default ColoredFormatter.</p> <p>This function sets up a logger for the <code>geniusrise-cli</code> with colorful logging outputs. The log level is determined by the <code>LOGLEVEL</code> from the configuration.</p>"},{"location":"core/logging/#logging.setup_logger--usage","title":"Usage:","text":"<pre><code>logger = setup_logger()\nlogger.info(\"This is a fancy info log!\")\n</code></pre> <p>Returns:</p> Type Description <code>logging.Logger</code> <p>logging.Logger: Configured logger with colorful outputs.</p> Source code in <code>/run/media/ixaxaar/src/code/src/geniusrise/geniusrise/geniusrise/logging.py</code> <pre><code>def setup_logger() -&gt; logging.Logger:\n\"\"\"\n    \ud83d\udee0\ufe0f **Setup Logger**: Configure and return a logger with a default ColoredFormatter.\n\n    This function sets up a logger for the `geniusrise-cli` with colorful logging outputs. The log level is determined by the `LOGLEVEL` from the configuration.\n\n    ## Usage:\n    ```python\n    logger = setup_logger()\n    logger.info(\"This is a fancy info log!\")\n    ```\n\n    Returns:\n        logging.Logger: Configured logger with colorful outputs.\n    \"\"\"\n    # Define the custom formatter\n    formatter = colorlog.ColoredFormatter(\n        \"%(log_color)s%(levelname)-8s%(reset)s \"\n        \"%(yellow)s[%(asctime)s] \"\n        \"%(blue)s[%(name)s:%(lineno)d] \"\n        \"%(green)s%(message)s\",\n        datefmt=\"%Y-%m-%d %H:%M:%S\",\n        reset=True,\n        log_colors={\n            \"DEBUG\": \"cyan\",\n            \"INFO\": \"green\",\n            \"WARNING\": \"yellow\",\n            \"ERROR\": \"red\",\n            \"CRITICAL\": \"bold_red\",\n        },\n    )\n\n    # Setup logger for geniusrise\n    logger = logging.getLogger(\"geniusrise\")\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    logger.setLevel(LOGLEVEL)\n\n    # \ud83c\udf89 Logger is ready to use!\n    logger.info(\"\ud83d\ude80 Logger is set up and ready to use!\")\n\n    return logger\n</code></pre>"},{"location":"guides/concepts/","title":"Concepts","text":""},{"location":"guides/concepts/#need","title":"Need","text":"<p>The landscape of machine learning and data processing has been rapidly evolving. While there are numerous solutions available for MLOps and DAG orchestration, most of them cater primarily to data engineering and data science teams. However, the rise of Large Language Models (LLMs) is reshaping this landscape, necessitating a more inclusive approach to MLOps.</p> <p>LLMs have democratized the use of machine learning models, enabling a broader spectrum of users within an organization to engage with them. This means that even organizations without a traditional data science data management or model management functions are now venturing into this domain.</p> <p>This shift brings forth several challenges:</p> <ol> <li> <p>Infrastructure Complexity: The world of MLOps is vast, with a plethora of options available for different use cases. Organizations often grapple with questions like:</p> <ul> <li>Which infrastructure is best suited for their needs?</li> <li>How can they efficiently reuse their existing infrastructure?</li> <li>How can they ensure scalability and performance while managing costs?</li> </ul> </li> <li> <p>Diverse Competence Levels: As LLM workflows become more prevalent, their volume is set to surpass that of traditional ML workflows in many organizations. This surge means that individuals without a formal engineering background or core ML expertise will be involved in the MLOps process. Ensuring that these individuals can contribute effectively without compromising the quality or integrity of the workflows is crucial.</p> </li> <li> <p>Standardization and Productionization: While many aspects of building LLM workflows can be managed without deep engineering expertise, there's a critical need for standardization. Engineers play a pivotal role in defining the processes for productionizing these workflows. Without standardized practices:</p> <ul> <li>How can organizations ensure consistency across workflows?</li> <li>How can they maintain the reliability and robustness of deployed models?</li> <li>How can they ensure that best practices are adhered to, regardless of who is building or deploying the workflow?</li> </ul> </li> </ol> <p>The advent of LLMs underscores the need for a comprehensive MLOps framework that caters to a diverse audience. Such a framework should be flexible enough to accommodate the varied infrastructure needs of organizations, inclusive enough to empower contributors regardless of their technical expertise, and robust enough to ensure standardized, reliable workflows.</p>"},{"location":"guides/concepts/#introduction","title":"Introduction","text":"<p>In the ever-evolving landscape of software development, the need for modular, scalable, and interoperable systems has never been greater. The Geniusrise framework is a testament to this philosophy, designed to act as a cohesive adhesive between distinct, modular components, much like how one would piece together Lego blocks. This design approach not only promotes flexibility but also ensures that each module or \"Lego block\" remains sufficiently independent. Such independence is crucial for diverse teams, each with its own unique infrastructure and requirements, to seamlessly build and manage their respective components.</p> <p>In brief these are the concepts:</p> <ol> <li> <p>Task: At its core, a task represents a discrete unit of work within the Geniusrise framework. Think of it as a singular action or operation that the system needs to execute. A task further manifests itself into a Bolt or a Spout as stated below.</p> </li> <li> <p>Components of a Task: Each task is equipped with four components:</p> <ol> <li>State Manager: This component is responsible for continuously monitoring and managing the task's state, ensuring that it progresses smoothly from initiation to completion and to report errors and ship logs into a central location.</li> <li>Data Manager: As the name suggests, the Data Manager oversees the input and output data associated with a task, ensuring data integrity and efficient data flow. It also ensures data sanity follows partition semantics and isolation.</li> <li>Model Manager: In the realm of machine learning, model versioning and management are paramount. The Model Manager serves as a GitOps tool for ML models, ensuring that they are versioned, tracked, and managed effectively.</li> <li>Runner: These are wrappers for executing a task on various platforms. Depending on the platform, the runner ensures that the task is executed seamlessly.</li> </ol> </li> <li> <p>Task Classification: Tasks within the Geniusrise framework can be broadly classified into two categories:</p> <ul> <li>Spout: If a task's primary function is to ingest or bring in data, it's termed as a 'spout'.</li> <li>Bolt: For tasks that don't primarily ingest data but perform other operations, they are termed 'bolts'.</li> </ul> </li> </ol> <p>The beauty of the Geniusrise framework lies in its adaptability. Developers can script their workflow components once and have the freedom to deploy them across various platforms. To facilitate this, Geniusrise offers:</p> <ol> <li> <p>Runners for Task Execution: Geniusrise is equipped with a diverse set of runners, each tailored for different platforms, ensuring that tasks can be executed almost anywhere:</p> <ol> <li>On your local machine for quick testing and development.</li> <li>Within Docker containers for isolated, reproducible environments.</li> <li>On Kubernetes clusters for scalable, cloud-native deployments.</li> <li>Using Apache Airflow for complex workflow orchestration.</li> <li>On AWS ECS for containerized application management.</li> <li>With AWS Batch for efficient batch computing workloads.</li> </ol> </li> <li> <p>Library Wrappers: To ensure that tasks can interface with a variety of frameworks, Geniusrise provides integrations with:</p> <ol> <li>Jupyter/ipython for interactive computing.</li> <li>Apache PySpark for large-scale data processing.</li> <li>Apache PyFlink for stream and batch processing.</li> <li>Apache Beam for unified stream and batch data processing.</li> <li>Apache Storm for real-time computation.</li> </ol> </li> </ol> <p>The framework aims to support multiple languages:</p> <ol> <li>Python</li> <li>Scala / JVM (WIP)</li> <li>Golang (WIP)</li> </ol> <p>This document delves into the core components and concepts that make up the Geniusrise framework.</p>"},{"location":"guides/concepts/#tasks","title":"Tasks","text":"<p>A task is the fundamental unit of work in the Geniusrise framework. It represents a specific operation or computation and can run for an arbitrary amount of time, performing any amount of work.</p> <pre>fc5858eb-d4fb-4f93-a626-ae6e67819436</pre>"},{"location":"guides/concepts/#state-managers","title":"State Managers","text":"<p>State Managers play a pivotal role in maintaining the state of tasks. They ensure that the progress and status of tasks are tracked, especially in distributed environments. Geniusrise offers various types of State Managers:</p> <ol> <li>DynamoDBStateManager: Interfaces with Amazon DynamoDB.</li> <li>InMemoryStateManager: Maintains state within the application's memory.</li> <li>PostgresStateManager: Interfaces with PostgreSQL databases.</li> <li>RedisStateManager: Interfaces with Redis in-memory data structure store.</li> </ol> <p>State Managers store data in various locations, allowing organizations to connect dashboards to these storage systems for real-time monitoring and analytics. This centralized storage and reporting mechanism ensures that stakeholders have a unified view of task states.</p> <pre>66358bc9-7746-4309-9968-c1a47cf18321</pre>"},{"location":"guides/concepts/#data-managers","title":"Data Managers","text":"<p>Data Managers are responsible for handling the input and output data for tasks. They implement various data operations methods that tasks can leverage to ingest or save data during their runs. Data Managers can be categorized based on their function and data processing type:</p> <ul> <li>BatchInputConfig: Manages batch input data.</li> <li>BatchOutputConfig: Manages batch output data.</li> <li>StreamingInputConfig: Manages streaming input data.</li> <li>StreamingOutputConfig: Manages streaming output data.</li> </ul> <p>Data Managers play a crucial role in managing data partitioning for both batch and streaming data. By adhering to common data patterns, they enable the system's components to operate independently, fostering the creation of intricate networks of tasks. This independence, while allowing for flexibility and scalability, ensures that cascading failures in one component don't necessarily compromise the entire system.</p> <pre>ba577ab0-0b66-4788-b909-9a936b762ab2</pre>"},{"location":"guides/concepts/#model-managers","title":"Model Managers","text":"<p>Model Managers oversee model operations, ensuring that models are saved, loaded, and managed efficiently. They can be of two primary types:</p> <ol> <li>S3ModelManager: Interfaces with Amazon S3 for model storage.</li> <li>WANDBModelManager: Interfaces with Weights &amp; Biases for model versioning.</li> <li>GitModelManager: Interfaces with Git repositories for versioning of models.</li> </ol> <pre>fe093a90-a090-456f-8902-f835c101942e</pre>"},{"location":"guides/concepts/#spouts-and-bolts","title":"Spouts and Bolts","text":"<p>At the heart of the Geniusrise framework are two primary component types: spouts and bolts.</p> <ul> <li> <p>Spouts: These are tasks responsible for ingesting data from various sources. Depending on the output type, spouts can either produce streaming output or batch output.</p> </li> <li> <p>Bolts: Bolts are tasks that take in data, process it, and produce output. They can be categorized based on their input and output types:</p> </li> <li>Stream-Stream: Reads streaming data and produces streaming output.</li> <li>Stream-Batch: Reads streaming data and produces batch output.</li> <li>Batch-Stream: Reads batch data and produces streaming output.</li> <li>Batch-Batch: Reads batch data and produces batch output.</li> </ul> <pre>1755c1ca-8b85-4196-98db-05a77925c3df</pre>"},{"location":"guides/concepts/#runners","title":"Runners","text":"<p>Runners are the backbone of the Geniusrise framework, ensuring that tasks are executed seamlessly across various platforms. They encapsulate the environment and resources required for task execution, abstracting away the underlying complexities. Geniusrise offers a diverse set of runners:</p> <ol> <li>Local Runner: Executes tasks directly on a local machine, ideal for development and testing.</li> <li>Docker Runner: Runs tasks within Docker containers, ensuring a consistent and isolated environment.</li> <li>Kubernetes Runner: Deploys tasks on Kubernetes clusters, leveraging its scalability and orchestration capabilities.</li> <li>Airflow Runner: Integrates with Apache Airflow, allowing for complex workflow orchestration and scheduling.</li> <li>ECS Runner: Executes tasks on AWS ECS, providing a managed container service.</li> <li>Batch Runner: Optimized for batch computing workloads on platforms like AWS Batch.</li> </ol>"},{"location":"guides/concepts/#tradeoffs","title":"Tradeoffs","text":"<p>Because of the very loose coupling of the components, though the framework can be used to build very complex networks with independently running nodes, it provides limited orchestration capability, like synchronous pipelines. An external orchestrator like airflow can be used in such cases to orchestrate geniusrise components.</p>"},{"location":"guides/installation/","title":"Installation","text":"<p>Geniusrise is composed of the core framework and various plugins that implement specific tasks. The core has to be installed first, and after that selected plugins can be installed as and when required.</p>"},{"location":"guides/installation/#installing-geniusrise-core-framework","title":"Installing Geniusrise Core Framework","text":""},{"location":"guides/installation/#using-pip","title":"Using pip","text":"<p>To install the core framework using pip in local env, simply run:</p> <pre><code>pip install geniusrise\n</code></pre> <p>Or if you wish to install at user level:</p> <pre><code>pip install generiusrise --user\n</code></pre> <p>Or on a global level (might conflict with your OS package manager):</p> <pre><code>sudo pip install geniusrise\n</code></pre> <p>To verify the installation, you can check whether the geniusrise binary exists in PATH:</p> <pre><code>which geniusrise\n\ngeniusrise --help\n</code></pre>"},{"location":"guides/installation/#installing-geniusrise-plugins","title":"Installing Geniusrise Plugins","text":"<p>Geniusrise offers a variety of plugins that act as composable lego blocks. To install a specific plugin, use the following format:</p> <pre><code>pip install geniusrise[plugin-name]\n</code></pre> <p>Replace <code>plugin-name</code> with the name of the desired plugin.</p>"},{"location":"guides/installation/#alternative-installation-methods","title":"Alternative Installation Methods","text":""},{"location":"guides/installation/#using-conda","title":"Using Conda","text":"<ol> <li>Activate the environment:</li> </ol> <pre><code>conda activate your-env\n</code></pre> <ol> <li>Install Geniusrise:</li> </ol> <pre><code>pip install geniusrise\n</code></pre> <p>For plugins:</p> <pre><code>pip install geniusrise[plugin-name]\n</code></pre>"},{"location":"guides/installation/#using-poetry","title":"Using Poetry","text":"<ol> <li>Add Geniusrise as a dependency:</li> </ol> <pre><code>poetry add geniusrise\n</code></pre> <p>For plugins:</p> <pre><code>poetry add geniusrise[plugin-name]\n</code></pre>"},{"location":"guides/installation/#development","title":"Development","text":"<p>For development, you may want to install from the repo:</p> <pre><code>git clone git@github.com:geniusrise/geniusrise.git\ncd geniusrise\nvirtualenv venv -p `which python3.10`\nsource venv/bin/activate\npip install -r ./requirements.txt\n\nmake install # installs in your local venv directory\n</code></pre> <p>That's it! You've successfully installed Geniusrise and its plugins. \ud83c\udf89</p>"}]}